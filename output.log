nohup: ignoring input
/home/ntu/dql/project/classification/models/csms6s.py:13: UserWarning: Can not import selective_scan_cuda_oflex. This affects speed.
  warnings.warn("Can not import selective_scan_cuda_oflex. This affects speed.")
Can not import selective_scan_cuda_oflex. This affects speed.
/home/ntu/dql/project/classification/models/csms6s.py:73: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd
/home/ntu/dql/project/classification/models/csms6s.py:90: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_bwd
/home/ntu/dql/project/classification/models/mamba2/ssd_combined.py:763: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @custom_fwd
/home/ntu/dql/project/classification/models/mamba2/ssd_combined.py:841: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  @custom_bwd
=> merge config from /home/ntu/dql/project/classification/cfg.yaml
/home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419
[2024-11-09 10:34:19 vssm1_tiny_0230s](training.py 327): INFO Full config saved to /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/config.json
[2024-11-09 10:34:19 vssm1_tiny_0230s](training.py 330): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 128
  CACHE_MODE: part
  DATASET: project
  DATA_PATH: /home/ntu/dql/datasets
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 8
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  MMCKPT: false
  NAME: vssm1_tiny_0230s
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  TYPE: vssm
  VSSM:
    DEPTHS:
    - 2
    - 8
    DOWNSAMPLE: v3
    EMBED_DIM: 96
    GMLP: false
    IN_CHANS: 3
    MLP_ACT_LAYER: gelu
    MLP_DROP_RATE: 0.0
    MLP_RATIO: 4.0
    NORM_LAYER: ln2d
    PATCHEMBED: v2
    PATCH_NORM: true
    PATCH_SIZE: 4
    POSEMBED: false
    SSM_ACT_LAYER: silu
    SSM_CONV: 3
    SSM_CONV_BIAS: false
    SSM_DROP_RATE: 0.0
    SSM_DT_RANK: auto
    SSM_D_STATE: 1
    SSM_FORWARDTYPE: v05_noz
    SSM_INIT: v0
    SSM_RANK_RATIO: 2.0
    SSM_RATIO: 1.0
OUTPUT: /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: '20241109103419'
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 0.000125
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.25e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.25e-07
  WEIGHT_DECAY: 0.05
TRAINCOST_MODE: false

[2024-11-09 10:34:19 vssm1_tiny_0230s](training.py 331): INFO {"cfg": "/home/ntu/dql/project/classification/cfg.yaml", "batch-size": 128, "data_path": "/home/ntu/dql/datasets", "opts": null, "cache-model": "part", "output": "/home/ntu/dql/project/output/training", "tag": "20241109103419", "model_ema": true, "model_ema_decay": 0.9999, "model_ema_force_cpu": false, "memory_limit_rate": -1}
rank 0 successfully build train dataset
rank 0 successfully build val dataset
[2024-11-09 10:34:20 vssm1_tiny_0230s](training.py 43): INFO Creating model:vssm/vssm1_tiny_0230s
[2024-11-09 10:34:33 vssm1_tiny_0230s](training.py 46): INFO VSSM(
  (patch_embed): Sequential(
    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): Identity()
    (2): LayerNorm2d((48,), eps=1e-05, elementwise_affine=True)
    (3): Identity()
    (4): GELU(approximate='none')
    (5): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (6): Identity()
    (7): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
  )
  (layers): ModuleList(
    (0): Sequential(
      (blocks): Sequential(
        (0): VSSBlock(
          (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=96, out_features=96, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=96, out_features=96, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.0)
          (norm2): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VSSBlock(
          (norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=96, out_features=96, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=96, out_features=96, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.02222222276031971)
          (norm2): LayerNorm2d((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): Sequential(
        (0): Identity()
        (1): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (2): Identity()
        (3): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): Sequential(
      (blocks): Sequential(
        (0): VSSBlock(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.04444444552063942)
          (norm2): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): VSSBlock(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.06666667014360428)
          (norm2): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): VSSBlock(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.08888889104127884)
          (norm2): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): VSSBlock(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.1111111119389534)
          (norm2): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): VSSBlock(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.13333334028720856)
          (norm2): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): VSSBlock(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.15555556118488312)
          (norm2): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): VSSBlock(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.17777778208255768)
          (norm2): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): VSSBlock(
          (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (out_norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
            (in_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (out_act): Identity()
            (out_proj): Linear2d(in_features=192, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.20000000298023224)
          (norm2): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear2d(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear2d(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): Identity()
    )
  )
  (classifier): Sequential(
    (norm): LayerNorm2d((192,), eps=1e-05, elementwise_affine=True)
    (permute): Identity()
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (head): Linear(in_features=192, out_features=2, bias=True)
  )
)
[2024-11-09 10:34:33 vssm1_tiny_0230s](training.py 48): INFO number of params: 3569666
input params:  u.1 delta.1 A.1 B.1 C.1 D.1 delta_bias.1 
input params:  u.3 delta.3 A.3 B.3 C.3 D.3 delta_bias.3 
input params:  u.5 delta.5 A.5 B.5 C.5 D.5 delta_bias.5 
input params:  u.7 delta.7 A.7 B.7 C.7 D.7 delta_bias.7 
input params:  u.9 delta.9 A.9 B.9 C.9 D.9 delta_bias.9 
input params:  u.11 delta.11 A.11 B.11 C.11 D.11 delta_bias.11 
input params:  u.13 delta.13 A.13 B.13 C.13 D.13 delta_bias.13 
input params:  u.15 delta.15 A.15 B.15 C.15 D.15 delta_bias.15 
input params:  u.17 delta.17 A.17 B.17 C.17 D.17 delta_bias.17 
input params:  u delta A B C D delta_bias 
Unsupported operator aten::gelu encountered 11 time(s)
Unsupported operator aten::mul encountered 10 time(s)
Unsupported operator prim::PythonOp.CrossScanTritonF encountered 10 time(s)
Unsupported operator prim::PythonOp.CrossMergeTritonF encountered 10 time(s)
Unsupported operator aten::add encountered 20 time(s)
The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
layers.0.blocks.0.drop_path, layers.0.blocks.1.drop_path, layers.1.blocks.0.drop_path, layers.1.blocks.1.drop_path, layers.1.blocks.2.drop_path, layers.1.blocks.3.drop_path, layers.1.blocks.4.drop_path, layers.1.blocks.5.drop_path, layers.1.blocks.6.drop_path, layers.1.blocks.7.drop_path
[2024-11-09 10:34:40 vssm1_tiny_0230s](training.py 50): INFO number of GFLOPs: 3.447242112
Using EMA with decay = 0.99990000
[2024-11-09 10:34:40 vssm1_tiny_0230s](optimizer.py 18): INFO ==============> building optimizer adamw....................
[2024-11-09 10:34:40 vssm1_tiny_0230s](optimizer.py 36): INFO No weight decay list: ['patch_embed.0.bias', 'patch_embed.2.weight', 'patch_embed.2.bias', 'patch_embed.5.bias', 'patch_embed.7.weight', 'patch_embed.7.bias', 'layers.0.blocks.0.norm.weight', 'layers.0.blocks.0.norm.bias', 'layers.0.blocks.0.op.Ds', 'layers.0.blocks.0.op.out_norm.weight', 'layers.0.blocks.0.op.out_norm.bias', 'layers.0.blocks.0.norm2.weight', 'layers.0.blocks.0.norm2.bias', 'layers.0.blocks.0.mlp.fc1.bias', 'layers.0.blocks.0.mlp.fc2.bias', 'layers.0.blocks.1.norm.weight', 'layers.0.blocks.1.norm.bias', 'layers.0.blocks.1.op.Ds', 'layers.0.blocks.1.op.out_norm.weight', 'layers.0.blocks.1.op.out_norm.bias', 'layers.0.blocks.1.norm2.weight', 'layers.0.blocks.1.norm2.bias', 'layers.0.blocks.1.mlp.fc1.bias', 'layers.0.blocks.1.mlp.fc2.bias', 'layers.0.downsample.1.bias', 'layers.0.downsample.3.weight', 'layers.0.downsample.3.bias', 'layers.1.blocks.0.norm.weight', 'layers.1.blocks.0.norm.bias', 'layers.1.blocks.0.op.Ds', 'layers.1.blocks.0.op.out_norm.weight', 'layers.1.blocks.0.op.out_norm.bias', 'layers.1.blocks.0.norm2.weight', 'layers.1.blocks.0.norm2.bias', 'layers.1.blocks.0.mlp.fc1.bias', 'layers.1.blocks.0.mlp.fc2.bias', 'layers.1.blocks.1.norm.weight', 'layers.1.blocks.1.norm.bias', 'layers.1.blocks.1.op.Ds', 'layers.1.blocks.1.op.out_norm.weight', 'layers.1.blocks.1.op.out_norm.bias', 'layers.1.blocks.1.norm2.weight', 'layers.1.blocks.1.norm2.bias', 'layers.1.blocks.1.mlp.fc1.bias', 'layers.1.blocks.1.mlp.fc2.bias', 'layers.1.blocks.2.norm.weight', 'layers.1.blocks.2.norm.bias', 'layers.1.blocks.2.op.Ds', 'layers.1.blocks.2.op.out_norm.weight', 'layers.1.blocks.2.op.out_norm.bias', 'layers.1.blocks.2.norm2.weight', 'layers.1.blocks.2.norm2.bias', 'layers.1.blocks.2.mlp.fc1.bias', 'layers.1.blocks.2.mlp.fc2.bias', 'layers.1.blocks.3.norm.weight', 'layers.1.blocks.3.norm.bias', 'layers.1.blocks.3.op.Ds', 'layers.1.blocks.3.op.out_norm.weight', 'layers.1.blocks.3.op.out_norm.bias', 'layers.1.blocks.3.norm2.weight', 'layers.1.blocks.3.norm2.bias', 'layers.1.blocks.3.mlp.fc1.bias', 'layers.1.blocks.3.mlp.fc2.bias', 'layers.1.blocks.4.norm.weight', 'layers.1.blocks.4.norm.bias', 'layers.1.blocks.4.op.Ds', 'layers.1.blocks.4.op.out_norm.weight', 'layers.1.blocks.4.op.out_norm.bias', 'layers.1.blocks.4.norm2.weight', 'layers.1.blocks.4.norm2.bias', 'layers.1.blocks.4.mlp.fc1.bias', 'layers.1.blocks.4.mlp.fc2.bias', 'layers.1.blocks.5.norm.weight', 'layers.1.blocks.5.norm.bias', 'layers.1.blocks.5.op.Ds', 'layers.1.blocks.5.op.out_norm.weight', 'layers.1.blocks.5.op.out_norm.bias', 'layers.1.blocks.5.norm2.weight', 'layers.1.blocks.5.norm2.bias', 'layers.1.blocks.5.mlp.fc1.bias', 'layers.1.blocks.5.mlp.fc2.bias', 'layers.1.blocks.6.norm.weight', 'layers.1.blocks.6.norm.bias', 'layers.1.blocks.6.op.Ds', 'layers.1.blocks.6.op.out_norm.weight', 'layers.1.blocks.6.op.out_norm.bias', 'layers.1.blocks.6.norm2.weight', 'layers.1.blocks.6.norm2.bias', 'layers.1.blocks.6.mlp.fc1.bias', 'layers.1.blocks.6.mlp.fc2.bias', 'layers.1.blocks.7.norm.weight', 'layers.1.blocks.7.norm.bias', 'layers.1.blocks.7.op.Ds', 'layers.1.blocks.7.op.out_norm.weight', 'layers.1.blocks.7.op.out_norm.bias', 'layers.1.blocks.7.norm2.weight', 'layers.1.blocks.7.norm2.bias', 'layers.1.blocks.7.mlp.fc1.bias', 'layers.1.blocks.7.mlp.fc2.bias', 'classifier.norm.weight', 'classifier.norm.bias', 'classifier.head.bias']
/home/ntu/dql/project/classification/utils/utils.py:157: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()
All checkpoints founded in /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419: []
[2024-11-09 10:34:40 vssm1_tiny_0230s](training.py 94): INFO no checkpoint found in /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419, ignoring auto resume
[2024-11-09 10:34:40 vssm1_tiny_0230s](training.py 117): INFO Start training
/home/ntu/dql/project/classification/training.py:167: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=config.AMP_ENABLE):
[2024-11-09 10:34:55 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][0/156]	eta 0:39:43 lr 0.000000	 wd 0.0500	time 15.2811 (15.2811)	data time 5.5982 (5.5982)	model time 0.0000 (0.0000)	loss 0.6977 (0.6977)	grad_norm 0.9055 (0.9055)	loss_scale 65536.0000 (65536.0000)	mem 14263MB
[2024-11-09 10:35:00 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][10/156]	eta 0:04:28 lr 0.000001	 wd 0.0500	time 0.5476 (1.8380)	data time 0.0081 (0.5241)	model time 0.0000 (0.0000)	loss 0.6950 (0.7050)	grad_norm 0.7796 (1.8297)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:05 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][20/156]	eta 0:02:41 lr 0.000001	 wd 0.0500	time 0.4804 (1.1885)	data time 0.0105 (0.2820)	model time 0.0000 (0.0000)	loss 0.6982 (0.7028)	grad_norm 1.2606 (1.5426)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:10 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][30/156]	eta 0:02:01 lr 0.000001	 wd 0.0500	time 0.5160 (0.9615)	data time 0.0006 (0.1962)	model time 0.0000 (0.0000)	loss 0.6938 (0.7006)	grad_norm 1.0392 (1.3171)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:15 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][40/156]	eta 0:01:39 lr 0.000002	 wd 0.0500	time 0.4742 (0.8563)	data time 0.0094 (0.1506)	model time 0.0000 (0.0000)	loss 0.6936 (0.6991)	grad_norm 0.9128 (1.1784)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:20 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][50/156]	eta 0:01:22 lr 0.000002	 wd 0.0500	time 0.4162 (0.7781)	data time 0.0043 (0.1237)	model time 0.0000 (0.0000)	loss 0.6923 (0.6980)	grad_norm 0.5649 (1.0778)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:25 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][60/156]	eta 0:01:10 lr 0.000003	 wd 0.0500	time 0.5637 (0.7337)	data time 0.0228 (0.1064)	model time 0.5409 (0.4893)	loss 0.6905 (0.6972)	grad_norm 0.8098 (1.0248)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:30 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][70/156]	eta 0:01:00 lr 0.000003	 wd 0.0500	time 0.4717 (0.7011)	data time 0.0085 (0.0931)	model time 0.4631 (0.4896)	loss 0.6863 (0.6968)	grad_norm 0.4881 (0.9765)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:34 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][80/156]	eta 0:00:51 lr 0.000003	 wd 0.0500	time 0.6546 (0.6720)	data time 0.1122 (0.0840)	model time 0.5424 (0.4751)	loss 0.6958 (0.6964)	grad_norm 0.9880 (1.0115)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:39 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][90/156]	eta 0:00:42 lr 0.000004	 wd 0.0500	time 0.6349 (0.6515)	data time 0.0115 (0.0766)	model time 0.6234 (0.4735)	loss 0.6941 (0.6959)	grad_norm 0.3370 (1.0002)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:44 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][100/156]	eta 0:00:35 lr 0.000004	 wd 0.0500	time 0.5115 (0.6324)	data time 0.0308 (0.0700)	model time 0.4806 (0.4687)	loss 0.6903 (0.6956)	grad_norm 0.4269 (0.9604)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:49 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][110/156]	eta 0:00:28 lr 0.000005	 wd 0.0500	time 0.5026 (0.6210)	data time 0.0075 (0.0658)	model time 0.4952 (0.4709)	loss 0.6935 (0.6953)	grad_norm 0.9187 (0.9622)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:54 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][120/156]	eta 0:00:22 lr 0.000005	 wd 0.0500	time 0.4243 (0.6121)	data time 0.0077 (0.0618)	model time 0.4166 (0.4744)	loss 0.6949 (0.6952)	grad_norm 0.8138 (0.9548)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:35:59 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][130/156]	eta 0:00:15 lr 0.000005	 wd 0.0500	time 0.5607 (0.6044)	data time 0.0363 (0.0585)	model time 0.5244 (0.4767)	loss 0.6954 (0.6950)	grad_norm 0.6079 (0.9490)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:36:04 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][140/156]	eta 0:00:09 lr 0.000006	 wd 0.0500	time 0.4922 (0.5965)	data time 0.0007 (0.0549)	model time 0.4916 (0.4777)	loss 0.6919 (0.6949)	grad_norm 0.7540 (0.9470)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:36:09 vssm1_tiny_0230s](training.py 201): INFO Train: [0/300][150/156]	eta 0:00:03 lr 0.000006	 wd 0.0500	time 0.4710 (0.5900)	data time 0.0006 (0.0513)	model time 0.4704 (0.4796)	loss 0.6937 (0.6948)	grad_norm 1.6677 (0.9505)	loss_scale 65536.0000 (65536.0000)	mem 13676MB
[2024-11-09 10:36:12 vssm1_tiny_0230s](training.py 212): INFO EPOCH 0 training takes 0:01:32
[2024-11-09 10:36:12 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_0.pth saving......
[2024-11-09 10:36:13 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_0.pth saved !!!
/home/ntu/dql/project/classification/training.py:236: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=config.AMP_ENABLE):
[2024-11-09 10:36:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.411 (4.411)	Loss 0.7158 (0.7158)	Acc@1 25.781 (25.781)	Acc@5 100.000 (100.000)	Mem 13676MB
[2024-11-09 10:36:19 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.162 (0.563)	Loss 0.7188 (0.7158)	Acc@1 17.969 (24.645)	Acc@5 100.000 (100.000)	Mem 13676MB
[2024-11-09 10:36:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.227 (0.381)	Loss 0.6577 (0.7131)	Acc@1 84.375 (28.088)	Acc@5 100.000 (100.000)	Mem 13676MB
[2024-11-09 10:36:24 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.348)	Loss 0.6597 (0.6962)	Acc@1 83.594 (46.220)	Acc@5 100.000 (100.000)	Mem 13676MB
[2024-11-09 10:36:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 54.120 Acc@5 100.000
[2024-11-09 10:36:27 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 54.1%
[2024-11-09 10:36:27 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 54.12%
[2024-11-09 10:36:30 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.809 (2.809)	Loss 0.7744 (0.7744)	Acc@1 2.344 (2.344)	Acc@5 100.000 (100.000)	Mem 13676MB
[2024-11-09 10:36:32 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.142 (0.462)	Loss 0.7822 (0.7753)	Acc@1 1.562 (1.491)	Acc@5 100.000 (100.000)	Mem 13676MB
[2024-11-09 10:36:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.202 (0.356)	Loss 0.6265 (0.7649)	Acc@1 97.656 (8.371)	Acc@5 100.000 (100.000)	Mem 13676MB
[2024-11-09 10:36:37 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.261 (0.336)	Loss 0.6240 (0.7188)	Acc@1 96.875 (37.349)	Acc@5 100.000 (100.000)	Mem 13676MB
[2024-11-09 10:36:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 49.880 Acc@5 100.000
[2024-11-09 10:36:40 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 49.9%
[2024-11-09 10:36:40 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 49.88%
[2024-11-09 10:36:44 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][0/156]	eta 0:12:24 lr 0.000006	 wd 0.0500	time 4.7712 (4.7712)	data time 4.2300 (4.2300)	model time 0.0000 (0.0000)	loss 0.6912 (0.6912)	grad_norm 0.4048 (0.4048)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:36:50 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][10/156]	eta 0:02:13 lr 0.000007	 wd 0.0500	time 0.5874 (0.9152)	data time 0.0008 (0.4127)	model time 0.0000 (0.0000)	loss 0.6912 (0.6912)	grad_norm 0.3810 (0.7307)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:36:55 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][20/156]	eta 0:01:39 lr 0.000007	 wd 0.0500	time 0.4961 (0.7330)	data time 0.0025 (0.2259)	model time 0.0000 (0.0000)	loss 0.6892 (0.6915)	grad_norm 0.9612 (0.6979)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:00 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][30/156]	eta 0:01:23 lr 0.000008	 wd 0.0500	time 0.5164 (0.6614)	data time 0.0006 (0.1558)	model time 0.0000 (0.0000)	loss 0.6969 (0.6916)	grad_norm 1.4150 (0.7697)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:05 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][40/156]	eta 0:01:12 lr 0.000008	 wd 0.0500	time 0.6184 (0.6278)	data time 0.0653 (0.1233)	model time 0.0000 (0.0000)	loss 0.6957 (0.6914)	grad_norm 0.9787 (0.8131)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:11 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][50/156]	eta 0:01:04 lr 0.000008	 wd 0.0500	time 0.4154 (0.6048)	data time 0.0005 (0.1027)	model time 0.0000 (0.0000)	loss 0.6890 (0.6915)	grad_norm 1.1178 (0.8224)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:16 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][60/156]	eta 0:00:56 lr 0.000009	 wd 0.0500	time 0.4947 (0.5873)	data time 0.0075 (0.0875)	model time 0.4872 (0.4882)	loss 0.6940 (0.6916)	grad_norm 1.0318 (0.8378)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:21 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][70/156]	eta 0:00:49 lr 0.000009	 wd 0.0500	time 0.4920 (0.5795)	data time 0.0131 (0.0772)	model time 0.4789 (0.5026)	loss 0.6936 (0.6916)	grad_norm 1.2357 (0.8589)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:26 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][80/156]	eta 0:00:43 lr 0.000010	 wd 0.0500	time 0.5091 (0.5693)	data time 0.0033 (0.0694)	model time 0.5057 (0.4960)	loss 0.6933 (0.6916)	grad_norm 0.6653 (0.8751)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:31 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][90/156]	eta 0:00:37 lr 0.000010	 wd 0.0500	time 0.4557 (0.5629)	data time 0.0008 (0.0641)	model time 0.4549 (0.4947)	loss 0.6910 (0.6914)	grad_norm 0.4958 (0.8764)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:36 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][100/156]	eta 0:00:31 lr 0.000010	 wd 0.0500	time 0.6216 (0.5601)	data time 0.0062 (0.0600)	model time 0.6154 (0.4982)	loss 0.7022 (0.6913)	grad_norm 0.8739 (0.8865)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:41 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][110/156]	eta 0:00:25 lr 0.000011	 wd 0.0500	time 0.5545 (0.5560)	data time 0.0355 (0.0561)	model time 0.5190 (0.4981)	loss 0.6926 (0.6915)	grad_norm 0.6535 (0.8788)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:46 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][120/156]	eta 0:00:19 lr 0.000011	 wd 0.0500	time 0.4495 (0.5519)	data time 0.0008 (0.0522)	model time 0.4486 (0.4978)	loss 0.6947 (0.6914)	grad_norm 0.5859 (0.8664)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:52 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][130/156]	eta 0:00:14 lr 0.000012	 wd 0.0500	time 0.4893 (0.5492)	data time 0.0480 (0.0507)	model time 0.4413 (0.4963)	loss 0.6842 (0.6914)	grad_norm 0.8004 (0.8731)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:37:57 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][140/156]	eta 0:00:08 lr 0.000012	 wd 0.0500	time 0.4463 (0.5451)	data time 0.0009 (0.0480)	model time 0.4455 (0.4943)	loss 0.6789 (0.6913)	grad_norm 0.4638 (0.8783)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:38:01 vssm1_tiny_0230s](training.py 201): INFO Train: [1/300][150/156]	eta 0:00:03 lr 0.000012	 wd 0.0500	time 0.4438 (0.5390)	data time 0.0004 (0.0449)	model time 0.4433 (0.4900)	loss 0.6965 (0.6912)	grad_norm 0.8856 (0.8765)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:38:04 vssm1_tiny_0230s](training.py 212): INFO EPOCH 1 training takes 0:01:24
[2024-11-09 10:38:04 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_1.pth saving......
[2024-11-09 10:38:05 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_1.pth saved !!!
[2024-11-09 10:38:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.306 (3.306)	Loss 0.6055 (0.6055)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:38:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.466)	Loss 0.5986 (0.5979)	Acc@1 91.406 (89.773)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:38:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.335)	Loss 0.7524 (0.6116)	Acc@1 26.562 (84.449)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:38:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.301)	Loss 0.7622 (0.6619)	Acc@1 19.531 (63.810)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:38:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 54.460 Acc@5 100.000
[2024-11-09 10:38:16 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 54.5%
[2024-11-09 10:38:16 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 54.46%
[2024-11-09 10:38:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.823 (1.823)	Loss 0.7725 (0.7725)	Acc@1 2.344 (2.344)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:38:21 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.267 (0.397)	Loss 0.7803 (0.7736)	Acc@1 1.562 (1.207)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:38:22 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.181 (0.284)	Loss 0.6274 (0.7634)	Acc@1 99.219 (8.296)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:38:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.263)	Loss 0.6250 (0.7181)	Acc@1 96.875 (37.298)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:38:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 49.920 Acc@5 100.000
[2024-11-09 10:38:27 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 49.9%
[2024-11-09 10:38:27 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 49.92%
[2024-11-09 10:38:30 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][0/156]	eta 0:08:21 lr 0.000013	 wd 0.0500	time 3.2154 (3.2154)	data time 2.7930 (2.7930)	model time 0.0000 (0.0000)	loss 0.6958 (0.6958)	grad_norm 1.5543 (1.5543)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:38:36 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][10/156]	eta 0:02:05 lr 0.000013	 wd 0.0500	time 0.4496 (0.8576)	data time 0.0054 (0.3827)	model time 0.0000 (0.0000)	loss 0.6852 (0.6931)	grad_norm 0.4274 (1.0971)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:38:42 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][20/156]	eta 0:01:35 lr 0.000013	 wd 0.0500	time 0.4752 (0.7004)	data time 0.0033 (0.2156)	model time 0.0000 (0.0000)	loss 0.6998 (0.6924)	grad_norm 0.7841 (0.8926)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:38:47 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][30/156]	eta 0:01:20 lr 0.000014	 wd 0.0500	time 0.5123 (0.6405)	data time 0.0259 (0.1518)	model time 0.0000 (0.0000)	loss 0.6896 (0.6924)	grad_norm 0.5957 (0.8588)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:38:52 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][40/156]	eta 0:01:11 lr 0.000014	 wd 0.0500	time 0.4927 (0.6129)	data time 0.0108 (0.1195)	model time 0.0000 (0.0000)	loss 0.6909 (0.6920)	grad_norm 0.7439 (0.8876)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:38:57 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][50/156]	eta 0:01:02 lr 0.000015	 wd 0.0500	time 0.5360 (0.5918)	data time 0.0071 (0.0993)	model time 0.0000 (0.0000)	loss 0.6795 (0.6912)	grad_norm 0.7385 (0.9381)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:02 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][60/156]	eta 0:00:55 lr 0.000015	 wd 0.0500	time 0.6496 (0.5826)	data time 0.0119 (0.0876)	model time 0.6376 (0.5078)	loss 0.6910 (0.6912)	grad_norm 1.2116 (0.9926)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:07 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][70/156]	eta 0:00:49 lr 0.000015	 wd 0.0500	time 0.4211 (0.5702)	data time 0.0007 (0.0773)	model time 0.4205 (0.4938)	loss 0.6896 (0.6910)	grad_norm 0.5489 (0.9473)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:13 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][80/156]	eta 0:00:42 lr 0.000016	 wd 0.0500	time 0.4146 (0.5636)	data time 0.0008 (0.0708)	model time 0.4138 (0.4934)	loss 0.6941 (0.6909)	grad_norm 0.9612 (0.9597)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:17 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][90/156]	eta 0:00:36 lr 0.000016	 wd 0.0500	time 0.4091 (0.5544)	data time 0.0007 (0.0648)	model time 0.4084 (0.4857)	loss 0.6710 (0.6908)	grad_norm 1.5099 (0.9769)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:22 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][100/156]	eta 0:00:30 lr 0.000017	 wd 0.0500	time 0.6570 (0.5496)	data time 0.0010 (0.0598)	model time 0.6560 (0.4870)	loss 0.6886 (0.6909)	grad_norm 1.2840 (0.9772)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:27 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][110/156]	eta 0:00:25 lr 0.000017	 wd 0.0500	time 0.5197 (0.5446)	data time 0.0050 (0.0550)	model time 0.5147 (0.4871)	loss 0.6957 (0.6907)	grad_norm 0.7100 (0.9596)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:32 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][120/156]	eta 0:00:19 lr 0.000017	 wd 0.0500	time 0.4519 (0.5403)	data time 0.0124 (0.0520)	model time 0.4394 (0.4853)	loss 0.6861 (0.6909)	grad_norm 0.9354 (0.9694)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:38 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][130/156]	eta 0:00:14 lr 0.000018	 wd 0.0500	time 0.4765 (0.5388)	data time 0.0078 (0.0499)	model time 0.4688 (0.4866)	loss 0.6890 (0.6910)	grad_norm 1.1220 (0.9726)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:43 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][140/156]	eta 0:00:08 lr 0.000018	 wd 0.0500	time 0.4353 (0.5374)	data time 0.0006 (0.0469)	model time 0.4347 (0.4892)	loss 0.6820 (0.6908)	grad_norm 0.9645 (0.9649)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:48 vssm1_tiny_0230s](training.py 201): INFO Train: [2/300][150/156]	eta 0:00:03 lr 0.000019	 wd 0.0500	time 0.5615 (0.5337)	data time 0.0347 (0.0442)	model time 0.5268 (0.4880)	loss 0.7033 (0.6905)	grad_norm 0.8026 (0.9605)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:39:50 vssm1_tiny_0230s](training.py 212): INFO EPOCH 2 training takes 0:01:23
[2024-11-09 10:39:50 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_2.pth saving......
[2024-11-09 10:39:51 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_2.pth saved !!!
[2024-11-09 10:39:55 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.729 (4.729)	Loss 0.7046 (0.7046)	Acc@1 57.812 (57.812)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:39:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.182 (0.611)	Loss 0.6978 (0.6937)	Acc@1 55.469 (56.605)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:40:00 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.235 (0.449)	Loss 0.6431 (0.6937)	Acc@1 68.750 (55.841)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:40:02 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.144 (0.356)	Loss 0.6553 (0.6825)	Acc@1 64.062 (57.787)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:40:05 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 58.440 Acc@5 100.000
[2024-11-09 10:40:05 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 58.4%
[2024-11-09 10:40:05 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 58.44%
[2024-11-09 10:40:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.315 (3.315)	Loss 0.7705 (0.7705)	Acc@1 2.344 (2.344)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:40:11 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.177 (0.615)	Loss 0.7778 (0.7715)	Acc@1 1.562 (0.994)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:40:14 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.176 (0.434)	Loss 0.6284 (0.7616)	Acc@1 99.219 (8.073)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:40:16 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.158 (0.361)	Loss 0.6260 (0.7172)	Acc@1 97.656 (37.223)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:40:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 49.920 Acc@5 100.000
[2024-11-09 10:40:18 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 49.9%
[2024-11-09 10:40:18 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 49.92%
[2024-11-09 10:40:23 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][0/156]	eta 0:12:19 lr 0.000019	 wd 0.0500	time 4.7384 (4.7384)	data time 4.2926 (4.2926)	model time 0.0000 (0.0000)	loss 0.6980 (0.6980)	grad_norm 1.7578 (1.7578)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:40:28 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][10/156]	eta 0:02:06 lr 0.000019	 wd 0.0500	time 0.5521 (0.8673)	data time 0.0060 (0.3987)	model time 0.0000 (0.0000)	loss 0.6990 (0.6965)	grad_norm 1.3710 (1.1757)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:40:33 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][20/156]	eta 0:01:31 lr 0.000020	 wd 0.0500	time 0.4913 (0.6759)	data time 0.0017 (0.2121)	model time 0.0000 (0.0000)	loss 0.6973 (0.6946)	grad_norm 1.4465 (1.1987)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:40:38 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][30/156]	eta 0:01:18 lr 0.000020	 wd 0.0500	time 0.4353 (0.6259)	data time 0.0013 (0.1468)	model time 0.0000 (0.0000)	loss 0.6945 (0.6954)	grad_norm 1.3276 (1.1835)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:40:43 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][40/156]	eta 0:01:09 lr 0.000020	 wd 0.0500	time 0.4667 (0.5973)	data time 0.0536 (0.1147)	model time 0.0000 (0.0000)	loss 0.7034 (0.6950)	grad_norm 0.5590 (1.1235)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:40:48 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][50/156]	eta 0:01:01 lr 0.000021	 wd 0.0500	time 0.5270 (0.5807)	data time 0.0462 (0.0960)	model time 0.0000 (0.0000)	loss 0.6877 (0.6941)	grad_norm 0.7061 (1.0473)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:40:54 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][60/156]	eta 0:00:55 lr 0.000021	 wd 0.0500	time 0.4699 (0.5781)	data time 0.0057 (0.0821)	model time 0.4642 (0.5534)	loss 0.6847 (0.6940)	grad_norm 0.6891 (0.9937)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:40:59 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][70/156]	eta 0:00:49 lr 0.000022	 wd 0.0500	time 0.5133 (0.5703)	data time 0.0182 (0.0726)	model time 0.4952 (0.5307)	loss 0.6870 (0.6934)	grad_norm 1.6720 (1.0061)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:41:04 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][80/156]	eta 0:00:42 lr 0.000022	 wd 0.0500	time 0.4429 (0.5643)	data time 0.0121 (0.0658)	model time 0.4308 (0.5219)	loss 0.7057 (0.6934)	grad_norm 1.9972 (1.0092)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:41:09 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][90/156]	eta 0:00:36 lr 0.000022	 wd 0.0500	time 0.5712 (0.5596)	data time 0.0369 (0.0608)	model time 0.5342 (0.5166)	loss 0.6884 (0.6928)	grad_norm 0.5969 (0.9945)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:41:14 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][100/156]	eta 0:00:31 lr 0.000023	 wd 0.0500	time 0.5962 (0.5555)	data time 0.0179 (0.0568)	model time 0.5783 (0.5131)	loss 0.6802 (0.6926)	grad_norm 0.3935 (0.9497)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:41:20 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][110/156]	eta 0:00:25 lr 0.000023	 wd 0.0500	time 0.5273 (0.5537)	data time 0.0078 (0.0537)	model time 0.5195 (0.5131)	loss 0.6895 (0.6925)	grad_norm 1.2920 (0.9487)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:41:25 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][120/156]	eta 0:00:19 lr 0.000024	 wd 0.0500	time 0.4636 (0.5493)	data time 0.0031 (0.0511)	model time 0.4605 (0.5081)	loss 0.6859 (0.6924)	grad_norm 0.7738 (0.9385)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:41:30 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][130/156]	eta 0:00:14 lr 0.000024	 wd 0.0500	time 0.6257 (0.5449)	data time 0.0081 (0.0480)	model time 0.6176 (0.5047)	loss 0.6965 (0.6925)	grad_norm 0.9948 (0.9312)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:41:35 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][140/156]	eta 0:00:08 lr 0.000024	 wd 0.0500	time 0.5641 (0.5411)	data time 0.0008 (0.0448)	model time 0.5634 (0.5028)	loss 0.6866 (0.6922)	grad_norm 0.6356 (0.9236)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:41:40 vssm1_tiny_0230s](training.py 201): INFO Train: [3/300][150/156]	eta 0:00:03 lr 0.000025	 wd 0.0500	time 0.4726 (0.5397)	data time 0.0005 (0.0419)	model time 0.4722 (0.5045)	loss 0.6932 (0.6919)	grad_norm 1.0206 (0.9059)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:41:43 vssm1_tiny_0230s](training.py 212): INFO EPOCH 3 training takes 0:01:24
[2024-11-09 10:41:43 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_3.pth saving......
[2024-11-09 10:41:43 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_3.pth saved !!!
[2024-11-09 10:41:46 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.845 (2.845)	Loss 0.6318 (0.6318)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:41:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.591)	Loss 0.6226 (0.6227)	Acc@1 86.719 (84.020)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:41:52 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.178 (0.411)	Loss 0.7090 (0.6315)	Acc@1 37.500 (79.836)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:41:54 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.361)	Loss 0.7266 (0.6621)	Acc@1 33.594 (64.163)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:41:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.180 Acc@5 100.000
[2024-11-09 10:41:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 57.2%
[2024-11-09 10:41:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 58.44%
[2024-11-09 10:42:01 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.700 (3.700)	Loss 0.7686 (0.7686)	Acc@1 1.562 (1.562)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:42:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.545)	Loss 0.7759 (0.7693)	Acc@1 0.781 (0.852)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:42:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.225 (0.365)	Loss 0.6294 (0.7596)	Acc@1 99.219 (7.850)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:42:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.142 (0.336)	Loss 0.6270 (0.7163)	Acc@1 98.438 (37.147)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:42:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 49.920 Acc@5 100.000
[2024-11-09 10:42:10 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 49.9%
[2024-11-09 10:42:10 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 49.92%
[2024-11-09 10:42:14 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][0/156]	eta 0:12:12 lr 0.000025	 wd 0.0500	time 4.6946 (4.6946)	data time 4.2285 (4.2285)	model time 0.0000 (0.0000)	loss 0.6931 (0.6931)	grad_norm 0.4605 (0.4605)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:42:19 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][10/156]	eta 0:02:08 lr 0.000026	 wd 0.0500	time 0.6210 (0.8792)	data time 0.0053 (0.3910)	model time 0.0000 (0.0000)	loss 0.6830 (0.6906)	grad_norm 0.5131 (0.7831)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:42:24 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][20/156]	eta 0:01:34 lr 0.000026	 wd 0.0500	time 0.5055 (0.6955)	data time 0.0064 (0.2126)	model time 0.0000 (0.0000)	loss 0.6761 (0.6893)	grad_norm 0.7944 (0.8173)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:42:29 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][30/156]	eta 0:01:18 lr 0.000026	 wd 0.0500	time 0.4875 (0.6259)	data time 0.0005 (0.1490)	model time 0.0000 (0.0000)	loss 0.6805 (0.6896)	grad_norm 0.6779 (0.8164)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:42:35 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][40/156]	eta 0:01:10 lr 0.000027	 wd 0.0500	time 0.5068 (0.6099)	data time 0.0285 (0.1159)	model time 0.0000 (0.0000)	loss 0.7010 (0.6890)	grad_norm 0.6903 (0.7641)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:42:40 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][50/156]	eta 0:01:02 lr 0.000027	 wd 0.0500	time 0.4830 (0.5904)	data time 0.0084 (0.0970)	model time 0.0000 (0.0000)	loss 0.6840 (0.6890)	grad_norm 0.8744 (0.7446)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:42:45 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][60/156]	eta 0:00:55 lr 0.000028	 wd 0.0500	time 0.6329 (0.5810)	data time 0.0058 (0.0861)	model time 0.6271 (0.5020)	loss 0.6850 (0.6885)	grad_norm 0.3164 (0.7238)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:42:50 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][70/156]	eta 0:00:49 lr 0.000028	 wd 0.0500	time 0.5631 (0.5725)	data time 0.0891 (0.0781)	model time 0.4740 (0.4971)	loss 0.6878 (0.6887)	grad_norm 0.6335 (0.7265)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:42:55 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][80/156]	eta 0:00:42 lr 0.000028	 wd 0.0500	time 0.4717 (0.5602)	data time 0.0192 (0.0703)	model time 0.4524 (0.4840)	loss 0.6870 (0.6890)	grad_norm 0.6631 (0.7100)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:43:00 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][90/156]	eta 0:00:36 lr 0.000029	 wd 0.0500	time 0.5275 (0.5547)	data time 0.0220 (0.0649)	model time 0.5056 (0.4852)	loss 0.6870 (0.6892)	grad_norm 0.8479 (0.7346)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:43:05 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][100/156]	eta 0:00:30 lr 0.000029	 wd 0.0500	time 0.4678 (0.5510)	data time 0.0008 (0.0596)	model time 0.4670 (0.4893)	loss 0.6880 (0.6891)	grad_norm 0.9353 (0.7321)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:43:10 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][110/156]	eta 0:00:25 lr 0.000030	 wd 0.0500	time 0.4931 (0.5443)	data time 0.0005 (0.0555)	model time 0.4926 (0.4848)	loss 0.6842 (0.6892)	grad_norm 0.5799 (0.7231)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:43:15 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][120/156]	eta 0:00:19 lr 0.000030	 wd 0.0500	time 0.5884 (0.5415)	data time 0.0060 (0.0516)	model time 0.5824 (0.4874)	loss 0.6793 (0.6894)	grad_norm 0.4008 (0.7327)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:43:20 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][130/156]	eta 0:00:13 lr 0.000030	 wd 0.0500	time 0.5242 (0.5385)	data time 0.0163 (0.0490)	model time 0.5079 (0.4870)	loss 0.6929 (0.6894)	grad_norm 0.6018 (0.7314)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:43:25 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][140/156]	eta 0:00:08 lr 0.000031	 wd 0.0500	time 0.4847 (0.5342)	data time 0.0007 (0.0463)	model time 0.4840 (0.4848)	loss 0.6871 (0.6894)	grad_norm 0.9381 (0.7284)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:43:29 vssm1_tiny_0230s](training.py 201): INFO Train: [4/300][150/156]	eta 0:00:03 lr 0.000031	 wd 0.0500	time 0.4158 (0.5278)	data time 0.0007 (0.0433)	model time 0.4152 (0.4800)	loss 0.6861 (0.6896)	grad_norm 0.6488 (0.7443)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:43:32 vssm1_tiny_0230s](training.py 212): INFO EPOCH 4 training takes 0:01:22
[2024-11-09 10:43:32 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_4.pth saving......
[2024-11-09 10:43:33 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_4.pth saved !!!
[2024-11-09 10:43:37 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.604 (4.604)	Loss 0.5752 (0.5752)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:43:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.253 (0.595)	Loss 0.5684 (0.5695)	Acc@1 96.875 (95.597)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:43:42 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.446)	Loss 0.7720 (0.5858)	Acc@1 17.188 (90.216)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:43:44 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.356)	Loss 0.7915 (0.6503)	Acc@1 15.625 (66.205)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:43:46 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.620 Acc@5 100.000
[2024-11-09 10:43:46 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 55.6%
[2024-11-09 10:43:46 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 58.44%
[2024-11-09 10:43:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.304 (3.304)	Loss 0.7666 (0.7666)	Acc@1 1.562 (1.562)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:43:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.162 (0.596)	Loss 0.7729 (0.7668)	Acc@1 0.781 (0.852)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:43:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.220 (0.423)	Loss 0.6304 (0.7575)	Acc@1 99.219 (7.775)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:43:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.142 (0.365)	Loss 0.6279 (0.7152)	Acc@1 99.219 (37.248)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:43:59 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 50.060 Acc@5 100.000
[2024-11-09 10:43:59 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 50.1%
[2024-11-09 10:43:59 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 50.06%
[2024-11-09 10:44:03 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][0/156]	eta 0:10:26 lr 0.000031	 wd 0.0500	time 4.0139 (4.0139)	data time 3.5481 (3.5481)	model time 0.0000 (0.0000)	loss 0.6909 (0.6909)	grad_norm 0.9838 (0.9838)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:08 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][10/156]	eta 0:02:02 lr 0.000032	 wd 0.0500	time 0.4208 (0.8399)	data time 0.0058 (0.3534)	model time 0.0000 (0.0000)	loss 0.6931 (0.6919)	grad_norm 0.5277 (0.8109)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:13 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][20/156]	eta 0:01:30 lr 0.000032	 wd 0.0500	time 0.4482 (0.6662)	data time 0.0211 (0.1914)	model time 0.0000 (0.0000)	loss 0.6944 (0.6914)	grad_norm 0.3234 (0.7448)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:18 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][30/156]	eta 0:01:16 lr 0.000033	 wd 0.0500	time 0.4363 (0.6038)	data time 0.0190 (0.1357)	model time 0.0000 (0.0000)	loss 0.6952 (0.6914)	grad_norm 0.7370 (0.7424)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:23 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][40/156]	eta 0:01:06 lr 0.000033	 wd 0.0500	time 0.5270 (0.5773)	data time 0.0006 (0.1055)	model time 0.0000 (0.0000)	loss 0.6889 (0.6903)	grad_norm 0.6698 (0.6918)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:28 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][50/156]	eta 0:01:00 lr 0.000033	 wd 0.0500	time 0.5150 (0.5677)	data time 0.0630 (0.0892)	model time 0.0000 (0.0000)	loss 0.6800 (0.6897)	grad_norm 1.0544 (0.7037)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:33 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][60/156]	eta 0:00:53 lr 0.000034	 wd 0.0500	time 0.5442 (0.5575)	data time 0.0119 (0.0768)	model time 0.5324 (0.4917)	loss 0.6984 (0.6897)	grad_norm 1.6430 (0.7152)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:38 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][70/156]	eta 0:00:47 lr 0.000034	 wd 0.0500	time 0.5357 (0.5468)	data time 0.0320 (0.0691)	model time 0.5037 (0.4758)	loss 0.6938 (0.6895)	grad_norm 0.9966 (0.7351)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:43 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][80/156]	eta 0:00:41 lr 0.000035	 wd 0.0500	time 0.4617 (0.5458)	data time 0.0112 (0.0635)	model time 0.4505 (0.4887)	loss 0.6835 (0.6897)	grad_norm 0.5988 (0.7202)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:48 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][90/156]	eta 0:00:35 lr 0.000035	 wd 0.0500	time 0.4525 (0.5354)	data time 0.0362 (0.0587)	model time 0.4163 (0.4745)	loss 0.6858 (0.6896)	grad_norm 0.7154 (0.7204)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:53 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][100/156]	eta 0:00:29 lr 0.000035	 wd 0.0500	time 0.5635 (0.5336)	data time 0.0618 (0.0554)	model time 0.5018 (0.4779)	loss 0.6855 (0.6896)	grad_norm 0.4737 (0.7237)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:44:58 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][110/156]	eta 0:00:24 lr 0.000036	 wd 0.0500	time 0.4511 (0.5288)	data time 0.0007 (0.0514)	model time 0.4504 (0.4765)	loss 0.6811 (0.6892)	grad_norm 0.4418 (0.7200)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:45:03 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][120/156]	eta 0:00:19 lr 0.000036	 wd 0.0500	time 0.4873 (0.5303)	data time 0.0089 (0.0495)	model time 0.4784 (0.4825)	loss 0.6825 (0.6893)	grad_norm 0.8821 (0.7260)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:45:09 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][130/156]	eta 0:00:13 lr 0.000037	 wd 0.0500	time 0.5481 (0.5297)	data time 0.0253 (0.0471)	model time 0.5228 (0.4852)	loss 0.6818 (0.6894)	grad_norm 0.4185 (0.7147)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:45:13 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][140/156]	eta 0:00:08 lr 0.000037	 wd 0.0500	time 0.4505 (0.5255)	data time 0.0008 (0.0442)	model time 0.4497 (0.4828)	loss 0.6887 (0.6896)	grad_norm 0.6278 (0.7280)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:45:18 vssm1_tiny_0230s](training.py 201): INFO Train: [5/300][150/156]	eta 0:00:03 lr 0.000037	 wd 0.0500	time 0.4095 (0.5199)	data time 0.0006 (0.0414)	model time 0.4089 (0.4786)	loss 0.6956 (0.6897)	grad_norm 0.5033 (0.7151)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:45:20 vssm1_tiny_0230s](training.py 212): INFO EPOCH 5 training takes 0:01:21
[2024-11-09 10:45:20 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_5.pth saving......
[2024-11-09 10:45:21 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_5.pth saved !!!
[2024-11-09 10:45:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.702 (2.702)	Loss 0.6934 (0.6934)	Acc@1 59.375 (59.375)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:45:27 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.532 (0.524)	Loss 0.6855 (0.6894)	Acc@1 59.375 (60.938)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:45:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.387)	Loss 0.6362 (0.6881)	Acc@1 65.625 (59.747)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:45:32 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.219 (0.352)	Loss 0.6533 (0.6767)	Acc@1 58.594 (59.929)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:45:34 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 60.000 Acc@5 100.000
[2024-11-09 10:45:34 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 60.0%
[2024-11-09 10:45:34 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 60.00%
[2024-11-09 10:45:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.047 (4.047)	Loss 0.7642 (0.7642)	Acc@1 0.781 (0.781)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:45:40 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.528)	Loss 0.7705 (0.7645)	Acc@1 0.000 (0.710)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:45:42 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.144 (0.374)	Loss 0.6309 (0.7554)	Acc@1 99.219 (7.515)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:45:44 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.224 (0.308)	Loss 0.6294 (0.7142)	Acc@1 100.000 (37.122)	Acc@5 100.000 (100.000)	Mem 13678MB
[2024-11-09 10:45:45 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 49.980 Acc@5 100.000
[2024-11-09 10:45:45 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 50.0%
[2024-11-09 10:45:45 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 50.06%
[2024-11-09 10:45:49 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][0/156]	eta 0:10:17 lr 0.000038	 wd 0.0500	time 3.9564 (3.9564)	data time 3.4430 (3.4430)	model time 0.0000 (0.0000)	loss 0.6908 (0.6908)	grad_norm 0.6083 (0.6083)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:45:55 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][10/156]	eta 0:02:02 lr 0.000038	 wd 0.0500	time 0.4839 (0.8423)	data time 0.0368 (0.3198)	model time 0.0000 (0.0000)	loss 0.6873 (0.6924)	grad_norm 0.4151 (0.7262)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:00 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][20/156]	eta 0:01:32 lr 0.000038	 wd 0.0500	time 0.4609 (0.6796)	data time 0.0244 (0.1771)	model time 0.0000 (0.0000)	loss 0.6845 (0.6899)	grad_norm 0.2049 (0.7093)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:05 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][30/156]	eta 0:01:18 lr 0.000039	 wd 0.0500	time 0.4536 (0.6212)	data time 0.0039 (0.1233)	model time 0.0000 (0.0000)	loss 0.6888 (0.6889)	grad_norm 0.8956 (0.6796)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:10 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][40/156]	eta 0:01:09 lr 0.000039	 wd 0.0500	time 0.5721 (0.5957)	data time 0.0007 (0.0999)	model time 0.0000 (0.0000)	loss 0.6913 (0.6894)	grad_norm 0.8636 (0.6712)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:15 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][50/156]	eta 0:01:01 lr 0.000040	 wd 0.0500	time 0.4973 (0.5768)	data time 0.0008 (0.0829)	model time 0.0000 (0.0000)	loss 0.6888 (0.6886)	grad_norm 1.3186 (0.6908)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:20 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][60/156]	eta 0:00:53 lr 0.000040	 wd 0.0500	time 0.5269 (0.5619)	data time 0.0202 (0.0721)	model time 0.5067 (0.4688)	loss 0.7034 (0.6894)	grad_norm 1.6475 (0.7237)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:24 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][70/156]	eta 0:00:47 lr 0.000040	 wd 0.0500	time 0.4229 (0.5500)	data time 0.0045 (0.0626)	model time 0.4184 (0.4709)	loss 0.6981 (0.6895)	grad_norm 0.9229 (0.7171)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:29 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][80/156]	eta 0:00:41 lr 0.000041	 wd 0.0500	time 0.4608 (0.5439)	data time 0.0244 (0.0573)	model time 0.4364 (0.4743)	loss 0.6833 (0.6891)	grad_norm 0.8160 (0.7084)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:35 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][90/156]	eta 0:00:35 lr 0.000041	 wd 0.0500	time 0.7121 (0.5412)	data time 0.0059 (0.0540)	model time 0.7062 (0.4787)	loss 0.7042 (0.6895)	grad_norm 0.9355 (0.7098)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:40 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][100/156]	eta 0:00:30 lr 0.000042	 wd 0.0500	time 0.5991 (0.5394)	data time 0.1003 (0.0515)	model time 0.4987 (0.4818)	loss 0.6811 (0.6893)	grad_norm 0.4058 (0.7168)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:45 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][110/156]	eta 0:00:24 lr 0.000042	 wd 0.0500	time 0.5534 (0.5405)	data time 0.0014 (0.0487)	model time 0.5519 (0.4899)	loss 0.6985 (0.6893)	grad_norm 0.8657 (0.7099)	loss_scale 65536.0000 (65536.0000)	mem 13678MB
[2024-11-09 10:46:50 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][120/156]	eta 0:00:19 lr 0.000042	 wd 0.0500	time 0.4220 (0.5377)	data time 0.0007 (0.0457)	model time 0.4212 (0.4907)	loss 0.6802 (0.6891)	grad_norm 0.5576 (0.6882)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:46:56 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][130/156]	eta 0:00:14 lr 0.000043	 wd 0.0500	time 0.6503 (0.5396)	data time 0.0058 (0.0446)	model time 0.6445 (0.4957)	loss 0.6872 (0.6887)	grad_norm 0.8769 (0.6836)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:47:01 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][140/156]	eta 0:00:08 lr 0.000043	 wd 0.0500	time 0.4561 (0.5392)	data time 0.0010 (0.0430)	model time 0.4551 (0.4976)	loss 0.6800 (0.6887)	grad_norm 0.6119 (0.6815)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:47:07 vssm1_tiny_0230s](training.py 201): INFO Train: [6/300][150/156]	eta 0:00:03 lr 0.000044	 wd 0.0500	time 0.4305 (0.5391)	data time 0.0005 (0.0411)	model time 0.4300 (0.5001)	loss 0.6714 (0.6886)	grad_norm 0.7466 (0.6833)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:47:09 vssm1_tiny_0230s](training.py 212): INFO EPOCH 6 training takes 0:01:24
[2024-11-09 10:47:09 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_6.pth saving......
[2024-11-09 10:47:10 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_6.pth saved !!!
[2024-11-09 10:47:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.565 (3.565)	Loss 0.6597 (0.6597)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:47:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.131 (0.634)	Loss 0.6553 (0.6570)	Acc@1 77.344 (73.082)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:47:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.412)	Loss 0.6592 (0.6598)	Acc@1 57.031 (70.275)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:47:21 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.177 (0.350)	Loss 0.6812 (0.6654)	Acc@1 47.656 (63.861)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:47:23 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 61.400 Acc@5 100.000
[2024-11-09 10:47:23 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 61.4%
[2024-11-09 10:47:23 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 61.40%
[2024-11-09 10:47:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.797 (2.797)	Loss 0.7622 (0.7622)	Acc@1 0.781 (0.781)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:47:29 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.559 (0.480)	Loss 0.7681 (0.7620)	Acc@1 0.000 (0.781)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:47:31 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.367)	Loss 0.6318 (0.7532)	Acc@1 99.219 (7.478)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:47:34 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.240 (0.330)	Loss 0.6304 (0.7131)	Acc@1 100.000 (37.147)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:47:35 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 50.000 Acc@5 100.000
[2024-11-09 10:47:35 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 50.0%
[2024-11-09 10:47:35 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 50.06%
[2024-11-09 10:47:40 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][0/156]	eta 0:11:36 lr 0.000044	 wd 0.0500	time 4.4671 (4.4671)	data time 4.0274 (4.0274)	model time 0.0000 (0.0000)	loss 0.6871 (0.6871)	grad_norm 0.5190 (0.5190)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:47:45 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][10/156]	eta 0:02:06 lr 0.000044	 wd 0.0500	time 0.4575 (0.8633)	data time 0.0025 (0.3719)	model time 0.0000 (0.0000)	loss 0.6870 (0.6847)	grad_norm 0.4001 (0.5500)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:47:50 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][20/156]	eta 0:01:32 lr 0.000045	 wd 0.0500	time 0.4755 (0.6798)	data time 0.0040 (0.2012)	model time 0.0000 (0.0000)	loss 0.7027 (0.6861)	grad_norm 0.3874 (0.5795)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:47:55 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][30/156]	eta 0:01:19 lr 0.000045	 wd 0.0500	time 0.6244 (0.6323)	data time 0.0509 (0.1452)	model time 0.0000 (0.0000)	loss 0.6757 (0.6863)	grad_norm 0.4538 (0.6425)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:00 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][40/156]	eta 0:01:10 lr 0.000045	 wd 0.0500	time 0.5853 (0.6059)	data time 0.1671 (0.1220)	model time 0.0000 (0.0000)	loss 0.6890 (0.6873)	grad_norm 0.9674 (0.6355)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:05 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][50/156]	eta 0:01:01 lr 0.000046	 wd 0.0500	time 0.4681 (0.5836)	data time 0.0218 (0.1040)	model time 0.0000 (0.0000)	loss 0.6939 (0.6871)	grad_norm 0.6498 (0.6311)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:10 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][60/156]	eta 0:00:54 lr 0.000046	 wd 0.0500	time 0.4409 (0.5676)	data time 0.0247 (0.0896)	model time 0.4163 (0.4700)	loss 0.6824 (0.6870)	grad_norm 0.6245 (0.6486)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:15 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][70/156]	eta 0:00:48 lr 0.000047	 wd 0.0500	time 0.4080 (0.5582)	data time 0.0009 (0.0799)	model time 0.4071 (0.4749)	loss 0.6856 (0.6866)	grad_norm 0.6175 (0.6406)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:20 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][80/156]	eta 0:00:42 lr 0.000047	 wd 0.0500	time 0.5155 (0.5570)	data time 0.0462 (0.0725)	model time 0.4693 (0.4928)	loss 0.6963 (0.6863)	grad_norm 0.9546 (0.6699)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:26 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][90/156]	eta 0:00:36 lr 0.000047	 wd 0.0500	time 0.5410 (0.5579)	data time 0.0213 (0.0683)	model time 0.5198 (0.5025)	loss 0.7002 (0.6868)	grad_norm 0.8929 (0.6727)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:31 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][100/156]	eta 0:00:30 lr 0.000048	 wd 0.0500	time 0.4545 (0.5490)	data time 0.0314 (0.0625)	model time 0.4231 (0.4937)	loss 0.6861 (0.6869)	grad_norm 0.4326 (0.6754)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:36 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][110/156]	eta 0:00:25 lr 0.000048	 wd 0.0500	time 0.4371 (0.5451)	data time 0.0099 (0.0578)	model time 0.4272 (0.4938)	loss 0.6799 (0.6867)	grad_norm 0.6287 (0.6745)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:41 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][120/156]	eta 0:00:19 lr 0.000049	 wd 0.0500	time 0.5141 (0.5452)	data time 0.0209 (0.0549)	model time 0.4931 (0.4981)	loss 0.6887 (0.6867)	grad_norm 0.7808 (0.6672)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:46 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][130/156]	eta 0:00:14 lr 0.000049	 wd 0.0500	time 0.4338 (0.5430)	data time 0.0080 (0.0522)	model time 0.4258 (0.4979)	loss 0.6862 (0.6865)	grad_norm 0.6389 (0.6660)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:51 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][140/156]	eta 0:00:08 lr 0.000049	 wd 0.0500	time 0.5319 (0.5382)	data time 0.0009 (0.0494)	model time 0.5310 (0.4939)	loss 0.6956 (0.6865)	grad_norm 0.6405 (0.6707)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:56 vssm1_tiny_0230s](training.py 201): INFO Train: [7/300][150/156]	eta 0:00:03 lr 0.000050	 wd 0.0500	time 0.4716 (0.5347)	data time 0.0006 (0.0462)	model time 0.4710 (0.4930)	loss 0.6853 (0.6866)	grad_norm 0.3256 (0.6632)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:48:59 vssm1_tiny_0230s](training.py 212): INFO EPOCH 7 training takes 0:01:23
[2024-11-09 10:48:59 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_7.pth saving......
[2024-11-09 10:49:00 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_7.pth saved !!!
[2024-11-09 10:49:04 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.141 (4.141)	Loss 0.6665 (0.6665)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:49:06 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.569)	Loss 0.6592 (0.6594)	Acc@1 69.531 (69.247)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:49:08 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.395)	Loss 0.6411 (0.6606)	Acc@1 58.594 (67.411)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:49:11 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.157 (0.353)	Loss 0.6675 (0.6606)	Acc@1 51.562 (63.432)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:49:13 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 61.520 Acc@5 100.000
[2024-11-09 10:49:13 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 61.5%
[2024-11-09 10:49:13 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 61.52%
[2024-11-09 10:49:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.140 (3.140)	Loss 0.7593 (0.7593)	Acc@1 0.000 (0.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:49:18 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.217 (0.468)	Loss 0.7646 (0.7588)	Acc@1 0.000 (0.426)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:49:20 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.344)	Loss 0.6328 (0.7504)	Acc@1 100.000 (7.440)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:49:22 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.289)	Loss 0.6318 (0.7117)	Acc@1 100.000 (37.223)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:49:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 50.040 Acc@5 100.000
[2024-11-09 10:49:24 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 50.0%
[2024-11-09 10:49:24 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 50.06%
[2024-11-09 10:49:28 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][0/156]	eta 0:09:28 lr 0.000050	 wd 0.0500	time 3.6422 (3.6422)	data time 3.2363 (3.2363)	model time 0.0000 (0.0000)	loss 0.6792 (0.6792)	grad_norm 0.5725 (0.5725)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:49:33 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][10/156]	eta 0:01:49 lr 0.000050	 wd 0.0500	time 0.4400 (0.7508)	data time 0.0009 (0.3023)	model time 0.0000 (0.0000)	loss 0.6860 (0.6834)	grad_norm 0.6532 (0.6862)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:49:38 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][20/156]	eta 0:01:26 lr 0.000051	 wd 0.0500	time 0.5896 (0.6329)	data time 0.1158 (0.1727)	model time 0.0000 (0.0000)	loss 0.6953 (0.6850)	grad_norm 0.9574 (0.6700)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:49:42 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][30/156]	eta 0:01:14 lr 0.000051	 wd 0.0500	time 0.4871 (0.5882)	data time 0.0646 (0.1243)	model time 0.0000 (0.0000)	loss 0.7000 (0.6867)	grad_norm 0.6373 (0.6968)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:49:47 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][40/156]	eta 0:01:05 lr 0.000052	 wd 0.0500	time 0.4835 (0.5606)	data time 0.0195 (0.0985)	model time 0.0000 (0.0000)	loss 0.6713 (0.6860)	grad_norm 0.5618 (0.6696)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:49:52 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][50/156]	eta 0:00:58 lr 0.000052	 wd 0.0500	time 0.5981 (0.5519)	data time 0.0272 (0.0816)	model time 0.0000 (0.0000)	loss 0.6971 (0.6857)	grad_norm 0.2752 (0.6560)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:49:58 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][60/156]	eta 0:00:52 lr 0.000052	 wd 0.0500	time 0.4987 (0.5467)	data time 0.0006 (0.0697)	model time 0.4981 (0.5111)	loss 0.6931 (0.6854)	grad_norm 0.9797 (0.6702)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:50:03 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][70/156]	eta 0:00:46 lr 0.000053	 wd 0.0500	time 0.4774 (0.5394)	data time 0.0008 (0.0612)	model time 0.4766 (0.4982)	loss 0.6886 (0.6858)	grad_norm 0.9222 (0.6760)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:50:07 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][80/156]	eta 0:00:40 lr 0.000053	 wd 0.0500	time 0.4630 (0.5308)	data time 0.0262 (0.0551)	model time 0.4368 (0.4850)	loss 0.6847 (0.6861)	grad_norm 1.2423 (0.6751)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:50:12 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][90/156]	eta 0:00:34 lr 0.000054	 wd 0.0500	time 0.5800 (0.5300)	data time 0.0296 (0.0513)	model time 0.5504 (0.4896)	loss 0.6995 (0.6862)	grad_norm 0.9717 (0.6683)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:50:17 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][100/156]	eta 0:00:29 lr 0.000054	 wd 0.0500	time 0.4552 (0.5252)	data time 0.0005 (0.0476)	model time 0.4547 (0.4850)	loss 0.6816 (0.6857)	grad_norm 1.1439 (0.6664)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:50:22 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][110/156]	eta 0:00:23 lr 0.000054	 wd 0.0500	time 0.5218 (0.5216)	data time 0.0324 (0.0447)	model time 0.4894 (0.4824)	loss 0.6617 (0.6855)	grad_norm 0.3472 (0.6667)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:50:27 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][120/156]	eta 0:00:18 lr 0.000055	 wd 0.0500	time 0.4184 (0.5209)	data time 0.0101 (0.0432)	model time 0.4084 (0.4831)	loss 0.6913 (0.6854)	grad_norm 0.3565 (0.6457)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:50:32 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][130/156]	eta 0:00:13 lr 0.000055	 wd 0.0500	time 0.4146 (0.5178)	data time 0.0043 (0.0407)	model time 0.4104 (0.4815)	loss 0.6930 (0.6857)	grad_norm 0.2232 (0.6430)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:50:37 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][140/156]	eta 0:00:08 lr 0.000056	 wd 0.0500	time 0.5322 (0.5184)	data time 0.0150 (0.0391)	model time 0.5173 (0.4844)	loss 0.6916 (0.6856)	grad_norm 0.4919 (0.6379)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:50:42 vssm1_tiny_0230s](training.py 201): INFO Train: [8/300][150/156]	eta 0:00:03 lr 0.000056	 wd 0.0500	time 0.4858 (0.5158)	data time 0.0005 (0.0366)	model time 0.4853 (0.4837)	loss 0.6814 (0.6856)	grad_norm 0.4684 (0.6414)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:50:45 vssm1_tiny_0230s](training.py 212): INFO EPOCH 8 training takes 0:01:20
[2024-11-09 10:50:45 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_8.pth saving......
[2024-11-09 10:50:45 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_8.pth saved !!!
[2024-11-09 10:50:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.657 (3.657)	Loss 0.6978 (0.6978)	Acc@1 60.938 (60.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:50:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.212 (0.491)	Loss 0.6807 (0.6897)	Acc@1 64.844 (60.440)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:50:52 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.293 (0.360)	Loss 0.6074 (0.6856)	Acc@1 71.875 (60.045)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:50:54 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.304)	Loss 0.6304 (0.6672)	Acc@1 63.281 (61.164)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:50:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 61.120 Acc@5 100.000
[2024-11-09 10:50:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 61.1%
[2024-11-09 10:50:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 61.52%
[2024-11-09 10:51:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.208 (3.208)	Loss 0.7554 (0.7554)	Acc@1 0.000 (0.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:51:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.178 (0.439)	Loss 0.7607 (0.7548)	Acc@1 0.000 (0.923)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:51:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.266 (0.390)	Loss 0.6348 (0.7470)	Acc@1 100.000 (7.775)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:51:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.356)	Loss 0.6343 (0.7101)	Acc@1 99.219 (37.424)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:51:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 50.180 Acc@5 100.000
[2024-11-09 10:51:10 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 50.2%
[2024-11-09 10:51:10 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 50.18%
[2024-11-09 10:51:16 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][0/156]	eta 0:14:28 lr 0.000056	 wd 0.0500	time 5.5664 (5.5664)	data time 4.9101 (4.9101)	model time 0.0000 (0.0000)	loss 0.6673 (0.6673)	grad_norm 0.8402 (0.8402)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:51:21 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][10/156]	eta 0:02:20 lr 0.000057	 wd 0.0500	time 0.5619 (0.9608)	data time 0.0029 (0.4589)	model time 0.0000 (0.0000)	loss 0.6840 (0.6855)	grad_norm 0.5589 (0.5425)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:51:26 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][20/156]	eta 0:01:40 lr 0.000057	 wd 0.0500	time 0.4363 (0.7365)	data time 0.0023 (0.2448)	model time 0.0000 (0.0000)	loss 0.6823 (0.6834)	grad_norm 0.4393 (0.5556)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:51:31 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][30/156]	eta 0:01:24 lr 0.000058	 wd 0.0500	time 0.4269 (0.6667)	data time 0.0039 (0.1692)	model time 0.0000 (0.0000)	loss 0.6854 (0.6823)	grad_norm 1.4789 (0.6063)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:51:36 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][40/156]	eta 0:01:12 lr 0.000058	 wd 0.0500	time 0.5548 (0.6227)	data time 0.0340 (0.1323)	model time 0.0000 (0.0000)	loss 0.6852 (0.6815)	grad_norm 0.7251 (0.6044)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:51:41 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][50/156]	eta 0:01:04 lr 0.000058	 wd 0.0500	time 0.5197 (0.6067)	data time 0.0006 (0.1115)	model time 0.0000 (0.0000)	loss 0.6867 (0.6830)	grad_norm 0.5846 (0.6150)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:51:47 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][60/156]	eta 0:00:56 lr 0.000059	 wd 0.0500	time 0.4657 (0.5906)	data time 0.0212 (0.0989)	model time 0.4445 (0.4738)	loss 0.6762 (0.6830)	grad_norm 0.4834 (0.6402)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:51:51 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][70/156]	eta 0:00:49 lr 0.000059	 wd 0.0500	time 0.4282 (0.5747)	data time 0.0183 (0.0867)	model time 0.4100 (0.4695)	loss 0.6630 (0.6828)	grad_norm 0.9227 (0.6463)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:51:56 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][80/156]	eta 0:00:42 lr 0.000060	 wd 0.0500	time 0.4264 (0.5648)	data time 0.0018 (0.0769)	model time 0.4246 (0.4755)	loss 0.6922 (0.6833)	grad_norm 1.8150 (0.7074)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:52:01 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][90/156]	eta 0:00:36 lr 0.000060	 wd 0.0500	time 0.4751 (0.5568)	data time 0.0005 (0.0695)	model time 0.4746 (0.4771)	loss 0.6817 (0.6833)	grad_norm 0.6841 (0.6977)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:52:06 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][100/156]	eta 0:00:30 lr 0.000060	 wd 0.0500	time 0.4600 (0.5502)	data time 0.0021 (0.0644)	model time 0.4579 (0.4762)	loss 0.6817 (0.6839)	grad_norm 0.2380 (0.6807)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:52:11 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][110/156]	eta 0:00:25 lr 0.000061	 wd 0.0500	time 0.5124 (0.5447)	data time 0.0105 (0.0595)	model time 0.5020 (0.4765)	loss 0.6995 (0.6841)	grad_norm 0.4859 (0.6690)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:52:16 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][120/156]	eta 0:00:19 lr 0.000061	 wd 0.0500	time 0.4560 (0.5403)	data time 0.0051 (0.0560)	model time 0.4509 (0.4762)	loss 0.6857 (0.6843)	grad_norm 0.7763 (0.6673)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:52:21 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][130/156]	eta 0:00:13 lr 0.000062	 wd 0.0500	time 0.5279 (0.5359)	data time 0.0297 (0.0528)	model time 0.4982 (0.4753)	loss 0.6851 (0.6844)	grad_norm 0.7460 (0.6661)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:52:26 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][140/156]	eta 0:00:08 lr 0.000062	 wd 0.0500	time 0.4834 (0.5343)	data time 0.0270 (0.0506)	model time 0.4564 (0.4772)	loss 0.6768 (0.6844)	grad_norm 0.6143 (0.6550)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:52:31 vssm1_tiny_0230s](training.py 201): INFO Train: [9/300][150/156]	eta 0:00:03 lr 0.000062	 wd 0.0500	time 0.4521 (0.5305)	data time 0.0005 (0.0474)	model time 0.4516 (0.4769)	loss 0.6984 (0.6845)	grad_norm 0.4484 (0.6468)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:52:33 vssm1_tiny_0230s](training.py 212): INFO EPOCH 9 training takes 0:01:22
[2024-11-09 10:52:33 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_9.pth saving......
[2024-11-09 10:52:33 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_9.pth saved !!!
[2024-11-09 10:52:36 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.448 (2.448)	Loss 0.6855 (0.6855)	Acc@1 55.469 (55.469)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:52:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.372 (0.516)	Loss 0.6909 (0.6887)	Acc@1 55.469 (56.960)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:52:42 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.394)	Loss 0.5991 (0.6868)	Acc@1 78.906 (56.176)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:52:45 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.224 (0.363)	Loss 0.6265 (0.6643)	Acc@1 63.281 (60.988)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:52:47 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 62.800 Acc@5 100.000
[2024-11-09 10:52:47 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 62.8%
[2024-11-09 10:52:47 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 62.80%
[2024-11-09 10:52:51 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.904 (3.904)	Loss 0.7505 (0.7505)	Acc@1 0.000 (0.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:52:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.255 (0.720)	Loss 0.7559 (0.7498)	Acc@1 0.781 (1.847)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:52:57 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.155 (0.464)	Loss 0.6377 (0.7425)	Acc@1 100.000 (8.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:53:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.424)	Loss 0.6377 (0.7082)	Acc@1 98.438 (37.878)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:53:04 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 50.580 Acc@5 100.000
[2024-11-09 10:53:04 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 50.6%
[2024-11-09 10:53:04 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 50.58%
[2024-11-09 10:53:07 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][0/156]	eta 0:09:05 lr 0.000063	 wd 0.0500	time 3.4941 (3.4941)	data time 3.0566 (3.0566)	model time 0.0000 (0.0000)	loss 0.6895 (0.6895)	grad_norm 0.5457 (0.5457)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:53:13 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][10/156]	eta 0:01:58 lr 0.000063	 wd 0.0500	time 0.5298 (0.8106)	data time 0.0265 (0.2880)	model time 0.0000 (0.0000)	loss 0.6849 (0.6846)	grad_norm 0.3659 (0.5936)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:53:18 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][20/156]	eta 0:01:31 lr 0.000063	 wd 0.0500	time 0.5009 (0.6711)	data time 0.0017 (0.1554)	model time 0.0000 (0.0000)	loss 0.6965 (0.6854)	grad_norm 0.9492 (0.6283)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:53:22 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][30/156]	eta 0:01:16 lr 0.000064	 wd 0.0500	time 0.4817 (0.6078)	data time 0.0028 (0.1102)	model time 0.0000 (0.0000)	loss 0.6850 (0.6838)	grad_norm 0.4229 (0.6029)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:53:27 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][40/156]	eta 0:01:06 lr 0.000064	 wd 0.0500	time 0.5319 (0.5773)	data time 0.0191 (0.0857)	model time 0.0000 (0.0000)	loss 0.6884 (0.6841)	grad_norm 0.3689 (0.6135)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:53:32 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][50/156]	eta 0:00:59 lr 0.000065	 wd 0.0500	time 0.4840 (0.5637)	data time 0.0184 (0.0747)	model time 0.0000 (0.0000)	loss 0.6898 (0.6848)	grad_norm 1.1312 (0.6246)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:53:37 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][60/156]	eta 0:00:53 lr 0.000065	 wd 0.0500	time 0.4617 (0.5526)	data time 0.0046 (0.0634)	model time 0.4571 (0.4906)	loss 0.6952 (0.6845)	grad_norm 0.8770 (0.6257)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:53:42 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][70/156]	eta 0:00:46 lr 0.000065	 wd 0.0500	time 0.4823 (0.5463)	data time 0.0013 (0.0578)	model time 0.4809 (0.4870)	loss 0.6867 (0.6847)	grad_norm 0.3707 (0.6508)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:53:48 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][80/156]	eta 0:00:41 lr 0.000066	 wd 0.0500	time 0.5822 (0.5438)	data time 0.0542 (0.0531)	model time 0.5280 (0.4936)	loss 0.7048 (0.6847)	grad_norm 0.3245 (0.6354)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:53:53 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][90/156]	eta 0:00:35 lr 0.000066	 wd 0.0500	time 0.5694 (0.5404)	data time 0.0206 (0.0492)	model time 0.5488 (0.4940)	loss 0.6505 (0.6835)	grad_norm 0.4288 (0.6324)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:53:58 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][100/156]	eta 0:00:29 lr 0.000067	 wd 0.0500	time 0.4238 (0.5355)	data time 0.0008 (0.0454)	model time 0.4230 (0.4912)	loss 0.6994 (0.6834)	grad_norm 0.9495 (0.6314)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:54:02 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][110/156]	eta 0:00:24 lr 0.000067	 wd 0.0500	time 0.4782 (0.5296)	data time 0.0018 (0.0425)	model time 0.4765 (0.4854)	loss 0.7024 (0.6831)	grad_norm 0.6020 (0.6274)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:54:07 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][120/156]	eta 0:00:18 lr 0.000067	 wd 0.0500	time 0.6010 (0.5266)	data time 0.0348 (0.0408)	model time 0.5662 (0.4834)	loss 0.6636 (0.6828)	grad_norm 0.2311 (0.6367)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:54:12 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][130/156]	eta 0:00:13 lr 0.000068	 wd 0.0500	time 0.5093 (0.5235)	data time 0.0182 (0.0388)	model time 0.4911 (0.4820)	loss 0.6888 (0.6833)	grad_norm 0.5175 (0.6301)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:54:17 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][140/156]	eta 0:00:08 lr 0.000068	 wd 0.0500	time 0.4536 (0.5233)	data time 0.0008 (0.0370)	model time 0.4528 (0.4847)	loss 0.6831 (0.6834)	grad_norm 0.4817 (0.6195)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:54:22 vssm1_tiny_0230s](training.py 201): INFO Train: [10/300][150/156]	eta 0:00:03 lr 0.000069	 wd 0.0500	time 0.5436 (0.5214)	data time 0.0005 (0.0347)	model time 0.5431 (0.4854)	loss 0.6870 (0.6836)	grad_norm 0.5307 (0.6142)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:54:26 vssm1_tiny_0230s](training.py 212): INFO EPOCH 10 training takes 0:01:22
[2024-11-09 10:54:26 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_10.pth saving......
[2024-11-09 10:54:26 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_10.pth saved !!!
[2024-11-09 10:54:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.005 (3.005)	Loss 0.6797 (0.6797)	Acc@1 60.938 (60.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:54:32 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.861 (0.527)	Loss 0.6738 (0.6774)	Acc@1 66.406 (62.784)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:54:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.317 (0.379)	Loss 0.6050 (0.6750)	Acc@1 71.875 (62.463)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:54:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.326)	Loss 0.6318 (0.6593)	Acc@1 63.281 (63.962)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:54:39 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 64.340 Acc@5 100.000
[2024-11-09 10:54:39 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 64.3%
[2024-11-09 10:54:39 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 64.34%
[2024-11-09 10:54:43 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.400 (4.400)	Loss 0.7446 (0.7446)	Acc@1 3.125 (3.125)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:54:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.132 (0.570)	Loss 0.7490 (0.7434)	Acc@1 0.781 (3.338)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:54:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.289 (0.409)	Loss 0.6421 (0.7369)	Acc@1 100.000 (9.710)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:54:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.340)	Loss 0.6421 (0.7059)	Acc@1 96.875 (38.256)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:54:52 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 50.660 Acc@5 100.000
[2024-11-09 10:54:52 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 50.7%
[2024-11-09 10:54:52 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 50.66%
[2024-11-09 10:54:55 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][0/156]	eta 0:07:36 lr 0.000069	 wd 0.0500	time 2.9287 (2.9287)	data time 2.4773 (2.4773)	model time 0.0000 (0.0000)	loss 0.6740 (0.6740)	grad_norm 0.6233 (0.6233)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:00 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][10/156]	eta 0:01:42 lr 0.000069	 wd 0.0500	time 0.4269 (0.6993)	data time 0.0007 (0.2379)	model time 0.0000 (0.0000)	loss 0.6786 (0.6814)	grad_norm 0.5026 (0.6448)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:05 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][20/156]	eta 0:01:18 lr 0.000070	 wd 0.0500	time 0.4836 (0.5749)	data time 0.0005 (0.1279)	model time 0.0000 (0.0000)	loss 0.6753 (0.6802)	grad_norm 0.4355 (0.6504)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:10 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][30/156]	eta 0:01:10 lr 0.000070	 wd 0.0500	time 0.6069 (0.5604)	data time 0.0269 (0.0895)	model time 0.0000 (0.0000)	loss 0.6754 (0.6806)	grad_norm 0.3485 (0.6622)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:15 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][40/156]	eta 0:01:04 lr 0.000070	 wd 0.0500	time 0.5023 (0.5525)	data time 0.0204 (0.0732)	model time 0.0000 (0.0000)	loss 0.6806 (0.6796)	grad_norm 0.4812 (0.6526)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:21 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][50/156]	eta 0:00:58 lr 0.000071	 wd 0.0500	time 0.4226 (0.5514)	data time 0.0012 (0.0615)	model time 0.0000 (0.0000)	loss 0.6666 (0.6793)	grad_norm 0.6748 (0.6461)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:26 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][60/156]	eta 0:00:52 lr 0.000071	 wd 0.0500	time 0.5137 (0.5489)	data time 0.0164 (0.0547)	model time 0.4973 (0.5162)	loss 0.6713 (0.6804)	grad_norm 0.6229 (0.6409)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:31 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][70/156]	eta 0:00:46 lr 0.000072	 wd 0.0500	time 0.5163 (0.5454)	data time 0.0135 (0.0492)	model time 0.5028 (0.5127)	loss 0.6707 (0.6804)	grad_norm 0.4482 (0.6347)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:36 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][80/156]	eta 0:00:41 lr 0.000072	 wd 0.0500	time 0.5344 (0.5402)	data time 0.0025 (0.0454)	model time 0.5319 (0.5034)	loss 0.7025 (0.6811)	grad_norm 0.9550 (0.6308)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:41 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][90/156]	eta 0:00:35 lr 0.000072	 wd 0.0500	time 0.5366 (0.5345)	data time 0.0162 (0.0430)	model time 0.5203 (0.4937)	loss 0.6935 (0.6809)	grad_norm 0.4282 (0.6226)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:46 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][100/156]	eta 0:00:29 lr 0.000073	 wd 0.0500	time 0.4605 (0.5298)	data time 0.0008 (0.0402)	model time 0.4597 (0.4895)	loss 0.6868 (0.6807)	grad_norm 0.6312 (0.6206)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:51 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][110/156]	eta 0:00:24 lr 0.000073	 wd 0.0500	time 0.5211 (0.5315)	data time 0.0281 (0.0381)	model time 0.4930 (0.4964)	loss 0.6689 (0.6808)	grad_norm 0.5989 (0.6130)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:55:57 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][120/156]	eta 0:00:19 lr 0.000074	 wd 0.0500	time 0.5051 (0.5301)	data time 0.0079 (0.0357)	model time 0.4972 (0.4978)	loss 0.6533 (0.6807)	grad_norm 0.7846 (0.6010)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:56:02 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][130/156]	eta 0:00:13 lr 0.000074	 wd 0.0500	time 0.4681 (0.5272)	data time 0.0214 (0.0336)	model time 0.4467 (0.4960)	loss 0.6474 (0.6808)	grad_norm 0.6388 (0.6061)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:56:06 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][140/156]	eta 0:00:08 lr 0.000074	 wd 0.0500	time 0.4325 (0.5221)	data time 0.0007 (0.0315)	model time 0.4318 (0.4909)	loss 0.6581 (0.6807)	grad_norm 0.4654 (0.6052)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:56:10 vssm1_tiny_0230s](training.py 201): INFO Train: [11/300][150/156]	eta 0:00:03 lr 0.000075	 wd 0.0500	time 0.4142 (0.5152)	data time 0.0004 (0.0295)	model time 0.4138 (0.4837)	loss 0.6850 (0.6807)	grad_norm 0.7546 (0.6017)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:56:13 vssm1_tiny_0230s](training.py 212): INFO EPOCH 11 training takes 0:01:20
[2024-11-09 10:56:13 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_11.pth saving......
[2024-11-09 10:56:13 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_11.pth saved !!!
[2024-11-09 10:56:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.514 (3.514)	Loss 0.6860 (0.6860)	Acc@1 57.812 (57.812)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:56:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.184 (0.593)	Loss 0.6777 (0.6902)	Acc@1 62.500 (57.812)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:56:22 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.425)	Loss 0.5659 (0.6836)	Acc@1 78.906 (58.966)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:56:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.148 (0.366)	Loss 0.6030 (0.6544)	Acc@1 64.844 (62.576)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:56:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 64.240 Acc@5 100.000
[2024-11-09 10:56:27 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 64.2%
[2024-11-09 10:56:27 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 64.34%
[2024-11-09 10:56:30 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.234 (3.234)	Loss 0.7373 (0.7373)	Acc@1 6.250 (6.250)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:56:33 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.175 (0.533)	Loss 0.7417 (0.7361)	Acc@1 1.562 (6.108)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:56:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.324 (0.360)	Loss 0.6470 (0.7305)	Acc@1 97.656 (11.905)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:56:38 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.146 (0.347)	Loss 0.6475 (0.7033)	Acc@1 95.312 (39.189)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:56:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 51.060 Acc@5 100.000
[2024-11-09 10:56:40 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 51.1%
[2024-11-09 10:56:40 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 51.06%
[2024-11-09 10:56:45 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][0/156]	eta 0:14:05 lr 0.000075	 wd 0.0500	time 5.4211 (5.4211)	data time 5.0025 (5.0025)	model time 0.0000 (0.0000)	loss 0.6852 (0.6852)	grad_norm 0.5564 (0.5564)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:56:50 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][10/156]	eta 0:02:20 lr 0.000075	 wd 0.0500	time 0.5535 (0.9618)	data time 0.0224 (0.4724)	model time 0.0000 (0.0000)	loss 0.6680 (0.6785)	grad_norm 0.6851 (0.5833)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:56:55 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][20/156]	eta 0:01:42 lr 0.000076	 wd 0.0500	time 0.4816 (0.7519)	data time 0.0472 (0.2601)	model time 0.0000 (0.0000)	loss 0.6912 (0.6793)	grad_norm 0.5852 (0.6551)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:00 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][30/156]	eta 0:01:24 lr 0.000076	 wd 0.0500	time 0.4418 (0.6686)	data time 0.0029 (0.1802)	model time 0.0000 (0.0000)	loss 0.6884 (0.6805)	grad_norm 0.8369 (0.6107)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:05 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][40/156]	eta 0:01:12 lr 0.000077	 wd 0.0500	time 0.5262 (0.6243)	data time 0.0178 (0.1417)	model time 0.0000 (0.0000)	loss 0.6755 (0.6808)	grad_norm 0.7329 (0.5872)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:10 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][50/156]	eta 0:01:03 lr 0.000077	 wd 0.0500	time 0.5264 (0.5972)	data time 0.0175 (0.1163)	model time 0.0000 (0.0000)	loss 0.6845 (0.6800)	grad_norm 0.3829 (0.5753)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:15 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][60/156]	eta 0:00:55 lr 0.000077	 wd 0.0500	time 0.4085 (0.5790)	data time 0.0015 (0.1002)	model time 0.4071 (0.4678)	loss 0.6681 (0.6803)	grad_norm 0.5985 (0.5707)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:20 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][70/156]	eta 0:00:48 lr 0.000078	 wd 0.0500	time 0.4325 (0.5652)	data time 0.0153 (0.0880)	model time 0.4172 (0.4678)	loss 0.6628 (0.6800)	grad_norm 0.3889 (0.5571)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:25 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][80/156]	eta 0:00:42 lr 0.000078	 wd 0.0500	time 0.4380 (0.5537)	data time 0.0243 (0.0788)	model time 0.4137 (0.4647)	loss 0.6792 (0.6796)	grad_norm 0.5106 (0.5504)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:29 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][90/156]	eta 0:00:36 lr 0.000079	 wd 0.0500	time 0.5955 (0.5471)	data time 0.0334 (0.0727)	model time 0.5621 (0.4661)	loss 0.6735 (0.6802)	grad_norm 0.7023 (0.5588)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:35 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][100/156]	eta 0:00:30 lr 0.000079	 wd 0.0500	time 0.4726 (0.5433)	data time 0.0010 (0.0671)	model time 0.4717 (0.4715)	loss 0.6762 (0.6797)	grad_norm 1.1533 (0.5774)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:39 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][110/156]	eta 0:00:24 lr 0.000079	 wd 0.0500	time 0.4850 (0.5368)	data time 0.0005 (0.0623)	model time 0.4845 (0.4691)	loss 0.6755 (0.6796)	grad_norm 0.5884 (0.6165)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:44 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][120/156]	eta 0:00:19 lr 0.000080	 wd 0.0500	time 0.4366 (0.5316)	data time 0.0008 (0.0585)	model time 0.4359 (0.4674)	loss 0.6919 (0.6796)	grad_norm 0.9276 (0.6271)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 10:57:49 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][130/156]	eta 0:00:13 lr 0.000080	 wd 0.0500	time 0.5458 (0.5303)	data time 0.0363 (0.0551)	model time 0.5095 (0.4716)	loss 0.6827 (0.6801)	grad_norm 0.3652 (0.6295)	loss_scale 131072.0000 (67537.0992)	mem 13675MB
[2024-11-09 10:57:54 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][140/156]	eta 0:00:08 lr 0.000081	 wd 0.0500	time 0.4085 (0.5288)	data time 0.0009 (0.0537)	model time 0.4076 (0.4719)	loss 0.6877 (0.6806)	grad_norm 0.5930 (0.6360)	loss_scale 131072.0000 (72043.1206)	mem 13675MB
[2024-11-09 10:57:59 vssm1_tiny_0230s](training.py 201): INFO Train: [12/300][150/156]	eta 0:00:03 lr 0.000081	 wd 0.0500	time 0.5301 (0.5280)	data time 0.0007 (0.0503)	model time 0.5294 (0.4761)	loss 0.6698 (0.6802)	grad_norm 0.7158 (0.6239)	loss_scale 131072.0000 (75952.3179)	mem 13675MB
[2024-11-09 10:58:03 vssm1_tiny_0230s](training.py 212): INFO EPOCH 12 training takes 0:01:22
[2024-11-09 10:58:03 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_12.pth saving......
[2024-11-09 10:58:03 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_12.pth saved !!!
[2024-11-09 10:58:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.952 (2.952)	Loss 0.6201 (0.6201)	Acc@1 76.562 (76.562)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:58:08 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.484)	Loss 0.6079 (0.6166)	Acc@1 79.688 (75.284)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:58:11 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.388)	Loss 0.6191 (0.6211)	Acc@1 63.281 (72.805)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:58:13 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.331)	Loss 0.6567 (0.6311)	Acc@1 55.469 (66.734)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:58:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 63.820 Acc@5 100.000
[2024-11-09 10:58:16 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 63.8%
[2024-11-09 10:58:16 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 64.34%
[2024-11-09 10:58:19 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.410 (3.410)	Loss 0.7295 (0.7295)	Acc@1 10.938 (10.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:58:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.552)	Loss 0.7334 (0.7278)	Acc@1 6.250 (10.511)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:58:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.321 (0.413)	Loss 0.6523 (0.7234)	Acc@1 94.531 (15.216)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:58:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.335)	Loss 0.6538 (0.7004)	Acc@1 91.406 (40.549)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:58:29 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 51.440 Acc@5 100.000
[2024-11-09 10:58:29 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 51.4%
[2024-11-09 10:58:29 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 51.44%
[2024-11-09 10:58:33 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][0/156]	eta 0:10:22 lr 0.000081	 wd 0.0500	time 3.9915 (3.9915)	data time 3.5320 (3.5320)	model time 0.0000 (0.0000)	loss 0.6844 (0.6844)	grad_norm 0.3033 (0.3033)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:58:38 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][10/156]	eta 0:01:58 lr 0.000082	 wd 0.0500	time 0.5368 (0.8084)	data time 0.0007 (0.3269)	model time 0.0000 (0.0000)	loss 0.7070 (0.6798)	grad_norm 0.7159 (0.4919)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:58:43 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][20/156]	eta 0:01:29 lr 0.000082	 wd 0.0500	time 0.4511 (0.6560)	data time 0.0158 (0.1740)	model time 0.0000 (0.0000)	loss 0.6598 (0.6745)	grad_norm 0.3608 (0.5189)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:58:47 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][30/156]	eta 0:01:15 lr 0.000082	 wd 0.0500	time 0.4408 (0.6022)	data time 0.0056 (0.1211)	model time 0.0000 (0.0000)	loss 0.6619 (0.6752)	grad_norm 0.6445 (0.5277)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:58:52 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][40/156]	eta 0:01:06 lr 0.000083	 wd 0.0500	time 0.4693 (0.5723)	data time 0.0007 (0.0989)	model time 0.0000 (0.0000)	loss 0.6667 (0.6756)	grad_norm 0.6418 (0.5602)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:58:57 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][50/156]	eta 0:00:59 lr 0.000083	 wd 0.0500	time 0.6488 (0.5638)	data time 0.0914 (0.0835)	model time 0.0000 (0.0000)	loss 0.6862 (0.6772)	grad_norm 0.4457 (0.5913)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:03 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][60/156]	eta 0:00:53 lr 0.000084	 wd 0.0500	time 0.5762 (0.5600)	data time 0.0009 (0.0718)	model time 0.5753 (0.5278)	loss 0.6806 (0.6783)	grad_norm 0.2718 (0.5963)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:08 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][70/156]	eta 0:00:47 lr 0.000084	 wd 0.0500	time 0.4863 (0.5566)	data time 0.0218 (0.0637)	model time 0.4646 (0.5251)	loss 0.6784 (0.6785)	grad_norm 0.5269 (0.5943)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:13 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][80/156]	eta 0:00:41 lr 0.000084	 wd 0.0500	time 0.4315 (0.5463)	data time 0.0008 (0.0580)	model time 0.4307 (0.5017)	loss 0.6687 (0.6792)	grad_norm 0.4263 (0.5975)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:18 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][90/156]	eta 0:00:35 lr 0.000085	 wd 0.0500	time 0.4990 (0.5385)	data time 0.0385 (0.0532)	model time 0.4605 (0.4916)	loss 0.6758 (0.6789)	grad_norm 0.5159 (0.5852)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:23 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][100/156]	eta 0:00:29 lr 0.000085	 wd 0.0500	time 0.5134 (0.5336)	data time 0.0064 (0.0486)	model time 0.5071 (0.4898)	loss 0.6801 (0.6788)	grad_norm 0.4346 (0.5743)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:28 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][110/156]	eta 0:00:24 lr 0.000086	 wd 0.0500	time 0.5710 (0.5350)	data time 0.0106 (0.0459)	model time 0.5604 (0.4965)	loss 0.6541 (0.6791)	grad_norm 0.5347 (0.5673)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:34 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][120/156]	eta 0:00:19 lr 0.000086	 wd 0.0500	time 0.4311 (0.5360)	data time 0.0113 (0.0441)	model time 0.4198 (0.5004)	loss 0.6576 (0.6786)	grad_norm 0.3570 (0.5658)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:38 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][130/156]	eta 0:00:13 lr 0.000086	 wd 0.0500	time 0.4602 (0.5321)	data time 0.0154 (0.0421)	model time 0.4449 (0.4962)	loss 0.6597 (0.6789)	grad_norm 0.5249 (0.5726)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:43 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][140/156]	eta 0:00:08 lr 0.000087	 wd 0.0500	time 0.4679 (0.5291)	data time 0.0010 (0.0401)	model time 0.4669 (0.4939)	loss 0.6838 (0.6796)	grad_norm 0.8097 (0.5747)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:48 vssm1_tiny_0230s](training.py 201): INFO Train: [13/300][150/156]	eta 0:00:03 lr 0.000087	 wd 0.0500	time 0.5327 (0.5267)	data time 0.0005 (0.0376)	model time 0.5322 (0.4936)	loss 0.6654 (0.6798)	grad_norm 1.0694 (0.5808)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 10:59:51 vssm1_tiny_0230s](training.py 212): INFO EPOCH 13 training takes 0:01:22
[2024-11-09 10:59:51 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_13.pth saving......
[2024-11-09 10:59:51 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_13.pth saved !!!
[2024-11-09 10:59:55 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.413 (3.413)	Loss 0.5981 (0.5981)	Acc@1 77.344 (77.344)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 10:59:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.555)	Loss 0.5962 (0.5957)	Acc@1 77.344 (79.119)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:00:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.441)	Loss 0.6416 (0.6045)	Acc@1 59.375 (76.042)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:00:02 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.359)	Loss 0.6899 (0.6242)	Acc@1 50.781 (68.851)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:00:05 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 65.460 Acc@5 100.000
[2024-11-09 11:00:05 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 65.5%
[2024-11-09 11:00:05 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 65.46%
[2024-11-09 11:00:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.100 (3.100)	Loss 0.7192 (0.7192)	Acc@1 16.406 (16.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:00:11 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.270 (0.520)	Loss 0.7231 (0.7177)	Acc@1 18.750 (19.105)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:00:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.151 (0.385)	Loss 0.6602 (0.7146)	Acc@1 92.188 (23.251)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:00:16 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.345)	Loss 0.6616 (0.6970)	Acc@1 86.719 (44.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:00:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.040 Acc@5 100.000
[2024-11-09 11:00:18 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.0%
[2024-11-09 11:00:18 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 53.04%
[2024-11-09 11:00:22 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][0/156]	eta 0:11:48 lr 0.000088	 wd 0.0500	time 4.5397 (4.5397)	data time 3.9971 (3.9971)	model time 0.0000 (0.0000)	loss 0.6798 (0.6798)	grad_norm 0.5326 (0.5326)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:00:27 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][10/156]	eta 0:02:04 lr 0.000088	 wd 0.0500	time 0.5066 (0.8506)	data time 0.0007 (0.3739)	model time 0.0000 (0.0000)	loss 0.6835 (0.6846)	grad_norm 0.6769 (0.5634)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:00:32 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][20/156]	eta 0:01:32 lr 0.000088	 wd 0.0500	time 0.5362 (0.6777)	data time 0.0212 (0.2063)	model time 0.0000 (0.0000)	loss 0.6506 (0.6790)	grad_norm 0.3915 (0.6172)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:00:37 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][30/156]	eta 0:01:19 lr 0.000089	 wd 0.0500	time 0.4832 (0.6299)	data time 0.0336 (0.1442)	model time 0.0000 (0.0000)	loss 0.6876 (0.6801)	grad_norm 0.4840 (0.5946)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:00:42 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][40/156]	eta 0:01:09 lr 0.000089	 wd 0.0500	time 0.6109 (0.6023)	data time 0.0144 (0.1154)	model time 0.0000 (0.0000)	loss 0.6561 (0.6795)	grad_norm 0.6711 (0.5811)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:00:47 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][50/156]	eta 0:01:01 lr 0.000090	 wd 0.0500	time 0.5621 (0.5796)	data time 0.0332 (0.0946)	model time 0.0000 (0.0000)	loss 0.6710 (0.6778)	grad_norm 0.5099 (0.5821)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:00:52 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][60/156]	eta 0:00:54 lr 0.000090	 wd 0.0500	time 0.4286 (0.5669)	data time 0.0227 (0.0813)	model time 0.4059 (0.4887)	loss 0.6960 (0.6777)	grad_norm 0.9307 (0.5762)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:00:57 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][70/156]	eta 0:00:48 lr 0.000090	 wd 0.0500	time 0.4172 (0.5588)	data time 0.0073 (0.0725)	model time 0.4098 (0.4897)	loss 0.6667 (0.6776)	grad_norm 0.5180 (0.5887)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:01:02 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][80/156]	eta 0:00:41 lr 0.000091	 wd 0.0500	time 0.4909 (0.5491)	data time 0.0082 (0.0644)	model time 0.4827 (0.4840)	loss 0.6789 (0.6778)	grad_norm 0.5800 (0.5909)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:01:07 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][90/156]	eta 0:00:35 lr 0.000091	 wd 0.0500	time 0.4200 (0.5418)	data time 0.0089 (0.0588)	model time 0.4111 (0.4803)	loss 0.6811 (0.6770)	grad_norm 0.4569 (0.5899)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:01:12 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][100/156]	eta 0:00:30 lr 0.000092	 wd 0.0500	time 0.4882 (0.5389)	data time 0.0218 (0.0544)	model time 0.4664 (0.4841)	loss 0.6697 (0.6774)	grad_norm 0.3584 (0.6016)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:01:17 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][110/156]	eta 0:00:24 lr 0.000092	 wd 0.0500	time 0.4847 (0.5358)	data time 0.0008 (0.0512)	model time 0.4840 (0.4842)	loss 0.6640 (0.6780)	grad_norm 0.5294 (0.6237)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:01:22 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][120/156]	eta 0:00:19 lr 0.000092	 wd 0.0500	time 0.5710 (0.5337)	data time 0.0193 (0.0485)	model time 0.5516 (0.4853)	loss 0.6653 (0.6781)	grad_norm 0.5318 (0.6249)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:01:27 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][130/156]	eta 0:00:13 lr 0.000093	 wd 0.0500	time 0.4172 (0.5305)	data time 0.0057 (0.0460)	model time 0.4115 (0.4842)	loss 0.6931 (0.6783)	grad_norm 0.3204 (0.6189)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:01:32 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][140/156]	eta 0:00:08 lr 0.000093	 wd 0.0500	time 0.4727 (0.5281)	data time 0.0009 (0.0435)	model time 0.4719 (0.4842)	loss 0.6983 (0.6783)	grad_norm 0.7568 (0.6201)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:01:37 vssm1_tiny_0230s](training.py 201): INFO Train: [14/300][150/156]	eta 0:00:03 lr 0.000094	 wd 0.0500	time 0.4542 (0.5249)	data time 0.0006 (0.0408)	model time 0.4536 (0.4838)	loss 0.6972 (0.6788)	grad_norm 0.3375 (0.6139)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:01:40 vssm1_tiny_0230s](training.py 212): INFO EPOCH 14 training takes 0:01:22
[2024-11-09 11:01:40 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_14.pth saving......
[2024-11-09 11:01:40 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_14.pth saved !!!
[2024-11-09 11:01:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.669 (3.669)	Loss 0.7290 (0.7290)	Acc@1 37.500 (37.500)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:01:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.404 (0.517)	Loss 0.7207 (0.7376)	Acc@1 42.969 (37.571)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:01:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.161 (0.398)	Loss 0.5210 (0.7229)	Acc@1 92.188 (41.890)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:01:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.623 (0.353)	Loss 0.5552 (0.6650)	Acc@1 80.469 (56.578)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:01:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 63.180 Acc@5 100.000
[2024-11-09 11:01:53 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 63.2%
[2024-11-09 11:01:53 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 65.46%
[2024-11-09 11:01:56 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.501 (3.501)	Loss 0.7085 (0.7085)	Acc@1 31.250 (31.250)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:02:00 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.201 (0.638)	Loss 0.7119 (0.7065)	Acc@1 28.906 (31.818)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:02:03 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.473)	Loss 0.6685 (0.7048)	Acc@1 84.375 (34.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:02:05 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.393)	Loss 0.6709 (0.6933)	Acc@1 79.688 (49.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:02:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.400 Acc@5 100.000
[2024-11-09 11:02:08 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.4%
[2024-11-09 11:02:08 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 55.40%
[2024-11-09 11:02:12 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][0/156]	eta 0:11:06 lr 0.000094	 wd 0.0500	time 4.2737 (4.2737)	data time 3.8391 (3.8391)	model time 0.0000 (0.0000)	loss 0.6692 (0.6692)	grad_norm 0.2700 (0.2700)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:02:17 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][10/156]	eta 0:02:01 lr 0.000094	 wd 0.0500	time 0.4386 (0.8326)	data time 0.0041 (0.3601)	model time 0.0000 (0.0000)	loss 0.6526 (0.6788)	grad_norm 0.5271 (0.5458)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:02:22 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][20/156]	eta 0:01:31 lr 0.000095	 wd 0.0500	time 0.4541 (0.6762)	data time 0.0311 (0.1930)	model time 0.0000 (0.0000)	loss 0.6784 (0.6744)	grad_norm 0.6885 (0.5685)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:02:27 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][30/156]	eta 0:01:17 lr 0.000095	 wd 0.0500	time 0.5453 (0.6168)	data time 0.0009 (0.1352)	model time 0.0000 (0.0000)	loss 0.6719 (0.6752)	grad_norm 0.6085 (0.5691)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:02:32 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][40/156]	eta 0:01:08 lr 0.000095	 wd 0.0500	time 0.5874 (0.5899)	data time 0.0067 (0.1055)	model time 0.0000 (0.0000)	loss 0.6683 (0.6760)	grad_norm 0.8936 (0.5679)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:02:37 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][50/156]	eta 0:01:00 lr 0.000096	 wd 0.0500	time 0.5309 (0.5745)	data time 0.0041 (0.0883)	model time 0.0000 (0.0000)	loss 0.6744 (0.6766)	grad_norm 0.9935 (0.5912)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:02:42 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][60/156]	eta 0:00:54 lr 0.000096	 wd 0.0500	time 0.4611 (0.5642)	data time 0.0043 (0.0760)	model time 0.4568 (0.4986)	loss 0.6902 (0.6768)	grad_norm 0.3219 (0.5788)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:02:48 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][70/156]	eta 0:00:47 lr 0.000097	 wd 0.0500	time 0.5160 (0.5571)	data time 0.0308 (0.0676)	model time 0.4852 (0.4977)	loss 0.6705 (0.6770)	grad_norm 0.4243 (0.5611)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:02:53 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][80/156]	eta 0:00:41 lr 0.000097	 wd 0.0500	time 0.5268 (0.5494)	data time 0.0127 (0.0617)	model time 0.5141 (0.4900)	loss 0.6752 (0.6766)	grad_norm 0.3474 (0.5583)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:02:58 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][90/156]	eta 0:00:35 lr 0.000097	 wd 0.0500	time 0.4686 (0.5449)	data time 0.0007 (0.0562)	model time 0.4679 (0.4918)	loss 0.6759 (0.6765)	grad_norm 0.3858 (0.5599)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:03:02 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][100/156]	eta 0:00:30 lr 0.000098	 wd 0.0500	time 0.5042 (0.5379)	data time 0.0515 (0.0522)	model time 0.4527 (0.4851)	loss 0.6839 (0.6777)	grad_norm 0.6861 (0.5772)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:03:08 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][110/156]	eta 0:00:24 lr 0.000098	 wd 0.0500	time 0.5505 (0.5387)	data time 0.0193 (0.0485)	model time 0.5312 (0.4935)	loss 0.6763 (0.6778)	grad_norm 0.5104 (0.5694)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:03:13 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][120/156]	eta 0:00:19 lr 0.000099	 wd 0.0500	time 0.4241 (0.5354)	data time 0.0015 (0.0458)	model time 0.4226 (0.4921)	loss 0.6838 (0.6783)	grad_norm 0.3280 (0.5715)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:03:18 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][130/156]	eta 0:00:13 lr 0.000099	 wd 0.0500	time 0.5782 (0.5331)	data time 0.0532 (0.0434)	model time 0.5250 (0.4919)	loss 0.6842 (0.6781)	grad_norm 0.3459 (0.5682)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:03:23 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][140/156]	eta 0:00:08 lr 0.000099	 wd 0.0500	time 0.5510 (0.5348)	data time 0.0008 (0.0425)	model time 0.5502 (0.4959)	loss 0.6720 (0.6779)	grad_norm 0.4110 (0.5675)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:03:28 vssm1_tiny_0230s](training.py 201): INFO Train: [15/300][150/156]	eta 0:00:03 lr 0.000100	 wd 0.0500	time 0.4402 (0.5323)	data time 0.0005 (0.0398)	model time 0.4397 (0.4957)	loss 0.6714 (0.6781)	grad_norm 0.4588 (0.5737)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:03:31 vssm1_tiny_0230s](training.py 212): INFO EPOCH 15 training takes 0:01:23
[2024-11-09 11:03:31 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_15.pth saving......
[2024-11-09 11:03:32 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_15.pth saved !!!
[2024-11-09 11:03:35 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.629 (3.629)	Loss 0.6299 (0.6299)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:03:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.613)	Loss 0.6216 (0.6315)	Acc@1 70.312 (69.957)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:03:40 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.153 (0.405)	Loss 0.5894 (0.6328)	Acc@1 72.656 (69.457)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:03:42 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.168 (0.342)	Loss 0.6274 (0.6281)	Acc@1 58.594 (68.019)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:03:44 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 67.100 Acc@5 100.000
[2024-11-09 11:03:44 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 67.1%
[2024-11-09 11:03:44 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 67.10%
[2024-11-09 11:03:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.423 (2.423)	Loss 0.6968 (0.6968)	Acc@1 47.656 (47.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:03:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.792 (0.491)	Loss 0.7002 (0.6948)	Acc@1 43.750 (48.651)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:03:51 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.338)	Loss 0.6777 (0.6946)	Acc@1 67.188 (48.624)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:03:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.293)	Loss 0.6807 (0.6897)	Acc@1 64.844 (55.066)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:03:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 56.920 Acc@5 100.000
[2024-11-09 11:03:55 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 56.9%
[2024-11-09 11:03:55 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 56.92%
[2024-11-09 11:03:58 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][0/156]	eta 0:07:40 lr 0.000100	 wd 0.0500	time 2.9526 (2.9526)	data time 2.4666 (2.4666)	model time 0.0000 (0.0000)	loss 0.6752 (0.6752)	grad_norm 0.6939 (0.6939)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:04 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][10/156]	eta 0:01:50 lr 0.000100	 wd 0.0500	time 0.7291 (0.7562)	data time 0.0430 (0.2619)	model time 0.0000 (0.0000)	loss 0.6580 (0.6755)	grad_norm 1.0435 (0.6731)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:09 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][20/156]	eta 0:01:30 lr 0.000101	 wd 0.0500	time 0.4843 (0.6642)	data time 0.0006 (0.1417)	model time 0.0000 (0.0000)	loss 0.6862 (0.6772)	grad_norm 0.5570 (0.6546)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:16 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][30/156]	eta 0:01:23 lr 0.000101	 wd 0.0500	time 0.7697 (0.6623)	data time 0.0152 (0.1069)	model time 0.0000 (0.0000)	loss 0.6703 (0.6773)	grad_norm 0.3324 (0.6580)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:22 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][40/156]	eta 0:01:14 lr 0.000102	 wd 0.0500	time 0.5771 (0.6419)	data time 0.0171 (0.0835)	model time 0.0000 (0.0000)	loss 0.6860 (0.6779)	grad_norm 0.4432 (0.6467)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:28 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][50/156]	eta 0:01:07 lr 0.000102	 wd 0.0500	time 0.6382 (0.6404)	data time 0.0350 (0.0704)	model time 0.0000 (0.0000)	loss 0.7023 (0.6774)	grad_norm 0.6963 (0.6451)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:34 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][60/156]	eta 0:01:00 lr 0.000102	 wd 0.0500	time 0.6957 (0.6300)	data time 0.0779 (0.0616)	model time 0.6178 (0.5601)	loss 0.7020 (0.6779)	grad_norm 0.6496 (0.6409)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:39 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][70/156]	eta 0:00:53 lr 0.000103	 wd 0.0500	time 0.5494 (0.6181)	data time 0.0077 (0.0577)	model time 0.5417 (0.5358)	loss 0.6825 (0.6782)	grad_norm 0.5574 (0.6275)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:44 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][80/156]	eta 0:00:45 lr 0.000103	 wd 0.0500	time 0.5280 (0.6026)	data time 0.0007 (0.0518)	model time 0.5273 (0.5182)	loss 0.6608 (0.6779)	grad_norm 0.7434 (0.6226)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:49 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][90/156]	eta 0:00:38 lr 0.000104	 wd 0.0500	time 0.4337 (0.5891)	data time 0.0100 (0.0470)	model time 0.4237 (0.5066)	loss 0.6848 (0.6776)	grad_norm 0.5787 (0.6074)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:54 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][100/156]	eta 0:00:32 lr 0.000104	 wd 0.0500	time 0.4344 (0.5800)	data time 0.0092 (0.0437)	model time 0.4252 (0.5019)	loss 0.6820 (0.6772)	grad_norm 0.3267 (0.6067)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:04:59 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][110/156]	eta 0:00:26 lr 0.000104	 wd 0.0500	time 0.5638 (0.5748)	data time 0.0110 (0.0412)	model time 0.5527 (0.5027)	loss 0.6872 (0.6774)	grad_norm 0.5688 (0.6088)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:05:05 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][120/156]	eta 0:00:20 lr 0.000105	 wd 0.0500	time 0.4944 (0.5710)	data time 0.0212 (0.0396)	model time 0.4731 (0.5033)	loss 0.6827 (0.6769)	grad_norm 0.6877 (0.6087)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:05:10 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][130/156]	eta 0:00:14 lr 0.000105	 wd 0.0500	time 0.6346 (0.5719)	data time 0.0008 (0.0379)	model time 0.6338 (0.5110)	loss 0.6813 (0.6770)	grad_norm 0.3824 (0.6093)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:05:15 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][140/156]	eta 0:00:09 lr 0.000106	 wd 0.0500	time 0.4130 (0.5664)	data time 0.0007 (0.0358)	model time 0.4123 (0.5083)	loss 0.6626 (0.6766)	grad_norm 0.4378 (0.6086)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:05:20 vssm1_tiny_0230s](training.py 201): INFO Train: [16/300][150/156]	eta 0:00:03 lr 0.000106	 wd 0.0500	time 0.4615 (0.5616)	data time 0.0366 (0.0337)	model time 0.4249 (0.5065)	loss 0.6788 (0.6768)	grad_norm 0.6507 (0.6117)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:05:23 vssm1_tiny_0230s](training.py 212): INFO EPOCH 16 training takes 0:01:27
[2024-11-09 11:05:23 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_16.pth saving......
[2024-11-09 11:05:24 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_16.pth saved !!!
[2024-11-09 11:05:28 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.469 (4.469)	Loss 0.6177 (0.6177)	Acc@1 77.344 (77.344)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:05:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.240 (0.630)	Loss 0.6064 (0.6178)	Acc@1 78.906 (78.267)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:05:33 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.175 (0.434)	Loss 0.5830 (0.6170)	Acc@1 65.625 (76.562)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:05:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.380)	Loss 0.6465 (0.6170)	Acc@1 51.562 (71.321)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:05:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 68.680 Acc@5 100.000
[2024-11-09 11:05:38 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 68.7%
[2024-11-09 11:05:38 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 68.68%
[2024-11-09 11:05:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.301 (3.301)	Loss 0.6855 (0.6855)	Acc@1 58.594 (58.594)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:05:44 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.524 (0.542)	Loss 0.6885 (0.6834)	Acc@1 55.469 (64.134)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:05:46 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.278 (0.382)	Loss 0.6870 (0.6848)	Acc@1 52.344 (62.686)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:05:48 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.150 (0.332)	Loss 0.6904 (0.6861)	Acc@1 50.781 (60.030)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:05:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 58.140 Acc@5 100.000
[2024-11-09 11:05:51 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 58.1%
[2024-11-09 11:05:51 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.14%
[2024-11-09 11:05:54 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][0/156]	eta 0:09:32 lr 0.000106	 wd 0.0500	time 3.6713 (3.6713)	data time 3.2252 (3.2252)	model time 0.0000 (0.0000)	loss 0.6707 (0.6707)	grad_norm 0.4206 (0.4206)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:05:59 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][10/156]	eta 0:01:50 lr 0.000107	 wd 0.0500	time 0.4558 (0.7585)	data time 0.0056 (0.3192)	model time 0.0000 (0.0000)	loss 0.6703 (0.6771)	grad_norm 0.6918 (0.5872)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:04 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][20/156]	eta 0:01:24 lr 0.000107	 wd 0.0500	time 0.4235 (0.6224)	data time 0.0011 (0.1718)	model time 0.0000 (0.0000)	loss 0.6629 (0.6781)	grad_norm 0.5929 (0.5998)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:08 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][30/156]	eta 0:01:12 lr 0.000107	 wd 0.0500	time 0.4494 (0.5728)	data time 0.0007 (0.1212)	model time 0.0000 (0.0000)	loss 0.6773 (0.6792)	grad_norm 0.4650 (0.5839)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:14 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][40/156]	eta 0:01:04 lr 0.000108	 wd 0.0500	time 0.5039 (0.5567)	data time 0.0292 (0.0945)	model time 0.0000 (0.0000)	loss 0.6987 (0.6796)	grad_norm 0.5648 (0.5714)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:18 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][50/156]	eta 0:00:57 lr 0.000108	 wd 0.0500	time 0.4227 (0.5444)	data time 0.0008 (0.0786)	model time 0.0000 (0.0000)	loss 0.6762 (0.6794)	grad_norm 0.5536 (0.5765)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:24 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][60/156]	eta 0:00:52 lr 0.000109	 wd 0.0500	time 0.7830 (0.5457)	data time 0.0009 (0.0692)	model time 0.7821 (0.5314)	loss 0.6812 (0.6802)	grad_norm 1.0846 (0.5928)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:29 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][70/156]	eta 0:00:46 lr 0.000109	 wd 0.0500	time 0.4337 (0.5385)	data time 0.0007 (0.0612)	model time 0.4330 (0.5066)	loss 0.6750 (0.6793)	grad_norm 0.4526 (0.5901)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:34 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][80/156]	eta 0:00:40 lr 0.000109	 wd 0.0500	time 0.5506 (0.5358)	data time 0.0191 (0.0554)	model time 0.5315 (0.5053)	loss 0.6957 (0.6799)	grad_norm 0.4882 (0.5896)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:39 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][90/156]	eta 0:00:35 lr 0.000110	 wd 0.0500	time 0.4657 (0.5340)	data time 0.0033 (0.0515)	model time 0.4624 (0.5039)	loss 0.6863 (0.6790)	grad_norm 0.3115 (0.5782)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:45 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][100/156]	eta 0:00:29 lr 0.000110	 wd 0.0500	time 0.5824 (0.5329)	data time 0.0059 (0.0472)	model time 0.5766 (0.5059)	loss 0.6616 (0.6790)	grad_norm 0.6357 (0.5726)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:50 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][110/156]	eta 0:00:24 lr 0.000111	 wd 0.0500	time 0.4411 (0.5296)	data time 0.0020 (0.0442)	model time 0.4391 (0.5021)	loss 0.6893 (0.6788)	grad_norm 1.0396 (0.5866)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:06:55 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][120/156]	eta 0:00:19 lr 0.000111	 wd 0.0500	time 0.5981 (0.5293)	data time 0.0162 (0.0419)	model time 0.5818 (0.5031)	loss 0.6854 (0.6791)	grad_norm 0.4312 (0.5853)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:07:00 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][130/156]	eta 0:00:13 lr 0.000111	 wd 0.0500	time 0.4577 (0.5300)	data time 0.0018 (0.0398)	model time 0.4559 (0.5058)	loss 0.6932 (0.6785)	grad_norm 0.8904 (0.5829)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:07:05 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][140/156]	eta 0:00:08 lr 0.000112	 wd 0.0500	time 0.4789 (0.5291)	data time 0.0010 (0.0375)	model time 0.4779 (0.5061)	loss 0.6723 (0.6787)	grad_norm 0.5198 (0.5830)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:07:11 vssm1_tiny_0230s](training.py 201): INFO Train: [17/300][150/156]	eta 0:00:03 lr 0.000112	 wd 0.0500	time 0.5432 (0.5285)	data time 0.0007 (0.0351)	model time 0.5425 (0.5075)	loss 0.6976 (0.6784)	grad_norm 0.7696 (0.5869)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:07:14 vssm1_tiny_0230s](training.py 212): INFO EPOCH 17 training takes 0:01:22
[2024-11-09 11:07:14 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_17.pth saving......
[2024-11-09 11:07:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_17.pth saved !!!
[2024-11-09 11:07:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.605 (2.605)	Loss 0.5840 (0.5840)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:07:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.728 (0.541)	Loss 0.5640 (0.5816)	Acc@1 85.156 (85.085)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:07:23 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.154 (0.429)	Loss 0.6162 (0.5864)	Acc@1 57.031 (82.701)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:07:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.366)	Loss 0.6689 (0.6057)	Acc@1 48.438 (72.807)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:07:28 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 68.240 Acc@5 100.000
[2024-11-09 11:07:28 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 68.2%
[2024-11-09 11:07:28 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 68.68%
[2024-11-09 11:07:32 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.530 (3.530)	Loss 0.6743 (0.6743)	Acc@1 75.781 (75.781)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:07:35 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.595)	Loss 0.6768 (0.6719)	Acc@1 73.438 (79.474)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:07:37 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.131 (0.418)	Loss 0.6968 (0.6748)	Acc@1 38.281 (75.372)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:07:39 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.355)	Loss 0.7007 (0.6826)	Acc@1 42.969 (63.886)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:07:41 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 58.520 Acc@5 100.000
[2024-11-09 11:07:41 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 58.5%
[2024-11-09 11:07:41 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:07:45 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][0/156]	eta 0:10:02 lr 0.000113	 wd 0.0500	time 3.8647 (3.8647)	data time 3.3272 (3.3272)	model time 0.0000 (0.0000)	loss 0.6614 (0.6614)	grad_norm 0.5930 (0.5930)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:07:51 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][10/156]	eta 0:02:02 lr 0.000113	 wd 0.0500	time 0.5830 (0.8392)	data time 0.0248 (0.3111)	model time 0.0000 (0.0000)	loss 0.6689 (0.6706)	grad_norm 0.4075 (0.5870)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:07:55 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][20/156]	eta 0:01:31 lr 0.000113	 wd 0.0500	time 0.5093 (0.6729)	data time 0.0007 (0.1692)	model time 0.0000 (0.0000)	loss 0.6719 (0.6732)	grad_norm 0.5114 (0.5689)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:00 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][30/156]	eta 0:01:17 lr 0.000114	 wd 0.0500	time 0.4318 (0.6181)	data time 0.0242 (0.1195)	model time 0.0000 (0.0000)	loss 0.6702 (0.6723)	grad_norm 0.4357 (0.5605)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:05 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][40/156]	eta 0:01:08 lr 0.000114	 wd 0.0500	time 0.5194 (0.5864)	data time 0.0264 (0.0958)	model time 0.0000 (0.0000)	loss 0.6718 (0.6731)	grad_norm 0.4950 (0.6366)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:11 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][50/156]	eta 0:01:01 lr 0.000115	 wd 0.0500	time 0.6228 (0.5755)	data time 0.0128 (0.0806)	model time 0.0000 (0.0000)	loss 0.6691 (0.6731)	grad_norm 0.4433 (0.6266)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:16 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][60/156]	eta 0:00:54 lr 0.000115	 wd 0.0500	time 0.4306 (0.5629)	data time 0.0110 (0.0690)	model time 0.4195 (0.4883)	loss 0.6769 (0.6728)	grad_norm 1.0214 (0.6212)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:21 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][70/156]	eta 0:00:48 lr 0.000115	 wd 0.0500	time 0.4419 (0.5586)	data time 0.0214 (0.0625)	model time 0.4205 (0.4992)	loss 0.6919 (0.6732)	grad_norm 0.7523 (0.6272)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:26 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][80/156]	eta 0:00:41 lr 0.000116	 wd 0.0500	time 0.6041 (0.5521)	data time 0.0693 (0.0568)	model time 0.5348 (0.4959)	loss 0.6645 (0.6735)	grad_norm 0.8113 (0.6246)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:31 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][90/156]	eta 0:00:36 lr 0.000116	 wd 0.0500	time 0.4419 (0.5462)	data time 0.0226 (0.0523)	model time 0.4193 (0.4925)	loss 0.7002 (0.6740)	grad_norm 1.1321 (0.6653)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:36 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][100/156]	eta 0:00:30 lr 0.000117	 wd 0.0500	time 0.4795 (0.5427)	data time 0.0006 (0.0485)	model time 0.4789 (0.4936)	loss 0.6663 (0.6748)	grad_norm 0.6251 (0.6822)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:42 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][110/156]	eta 0:00:25 lr 0.000117	 wd 0.0500	time 0.6896 (0.5453)	data time 0.0202 (0.0462)	model time 0.6694 (0.5026)	loss 0.6746 (0.6749)	grad_norm 0.5797 (0.6712)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:47 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][120/156]	eta 0:00:19 lr 0.000117	 wd 0.0500	time 0.4913 (0.5430)	data time 0.0249 (0.0454)	model time 0.4664 (0.4997)	loss 0.6848 (0.6752)	grad_norm 1.0847 (0.6575)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:52 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][130/156]	eta 0:00:14 lr 0.000118	 wd 0.0500	time 0.5468 (0.5407)	data time 0.0325 (0.0434)	model time 0.5143 (0.4988)	loss 0.6832 (0.6756)	grad_norm 0.4936 (0.6451)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:08:57 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][140/156]	eta 0:00:08 lr 0.000118	 wd 0.0500	time 0.4478 (0.5363)	data time 0.0010 (0.0408)	model time 0.4468 (0.4958)	loss 0.6541 (0.6752)	grad_norm 0.3927 (0.6339)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:09:02 vssm1_tiny_0230s](training.py 201): INFO Train: [18/300][150/156]	eta 0:00:03 lr 0.000119	 wd 0.0500	time 0.4544 (0.5334)	data time 0.0005 (0.0382)	model time 0.4539 (0.4954)	loss 0.6582 (0.6749)	grad_norm 0.6937 (0.6308)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:09:05 vssm1_tiny_0230s](training.py 212): INFO EPOCH 18 training takes 0:01:23
[2024-11-09 11:09:05 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_18.pth saving......
[2024-11-09 11:09:05 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_18.pth saved !!!
[2024-11-09 11:09:09 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.286 (3.286)	Loss 0.5327 (0.5327)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:09:12 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.202 (0.634)	Loss 0.5132 (0.5326)	Acc@1 89.062 (84.730)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:09:15 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.158 (0.459)	Loss 0.6250 (0.5449)	Acc@1 59.375 (82.031)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:09:17 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.385)	Loss 0.6885 (0.5843)	Acc@1 53.125 (72.858)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:09:20 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 68.320 Acc@5 100.000
[2024-11-09 11:09:20 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 68.3%
[2024-11-09 11:09:20 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 68.68%
[2024-11-09 11:09:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.318 (3.318)	Loss 0.6631 (0.6631)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:09:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.148 (0.438)	Loss 0.6660 (0.6610)	Acc@1 85.156 (87.500)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:09:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.325)	Loss 0.7056 (0.6653)	Acc@1 28.125 (82.552)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:09:29 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.207 (0.277)	Loss 0.7104 (0.6793)	Acc@1 28.125 (65.146)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:09:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.400 Acc@5 100.000
[2024-11-09 11:09:31 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 57.4%
[2024-11-09 11:09:31 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:09:37 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][0/156]	eta 0:13:42 lr 0.000119	 wd 0.0500	time 5.2744 (5.2744)	data time 4.7715 (4.7715)	model time 0.0000 (0.0000)	loss 0.6600 (0.6600)	grad_norm 0.4848 (0.4848)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:09:42 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][10/156]	eta 0:02:15 lr 0.000119	 wd 0.0500	time 0.5398 (0.9262)	data time 0.0629 (0.4499)	model time 0.0000 (0.0000)	loss 0.6757 (0.6670)	grad_norm 0.2759 (0.5545)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:09:47 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][20/156]	eta 0:01:38 lr 0.000120	 wd 0.0500	time 0.5560 (0.7213)	data time 0.0167 (0.2403)	model time 0.0000 (0.0000)	loss 0.6662 (0.6715)	grad_norm 0.9434 (0.5324)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:09:52 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][30/156]	eta 0:01:22 lr 0.000120	 wd 0.0500	time 0.5817 (0.6583)	data time 0.0443 (0.1710)	model time 0.0000 (0.0000)	loss 0.6425 (0.6720)	grad_norm 0.6541 (0.5170)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:09:57 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][40/156]	eta 0:01:12 lr 0.000120	 wd 0.0500	time 0.5178 (0.6210)	data time 0.0058 (0.1319)	model time 0.0000 (0.0000)	loss 0.6756 (0.6732)	grad_norm 0.3819 (0.5319)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:02 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][50/156]	eta 0:01:02 lr 0.000121	 wd 0.0500	time 0.4498 (0.5899)	data time 0.0007 (0.1085)	model time 0.0000 (0.0000)	loss 0.6696 (0.6735)	grad_norm 0.5483 (0.5313)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:06 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][60/156]	eta 0:00:54 lr 0.000121	 wd 0.0500	time 0.4400 (0.5708)	data time 0.0009 (0.0921)	model time 0.4391 (0.4646)	loss 0.6627 (0.6726)	grad_norm 0.6433 (0.5187)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:11 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][70/156]	eta 0:00:47 lr 0.000122	 wd 0.0500	time 0.5587 (0.5578)	data time 0.0661 (0.0816)	model time 0.4926 (0.4629)	loss 0.6802 (0.6745)	grad_norm 0.9615 (0.5874)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:16 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][80/156]	eta 0:00:41 lr 0.000122	 wd 0.0500	time 0.4276 (0.5520)	data time 0.0226 (0.0730)	model time 0.4050 (0.4747)	loss 0.6981 (0.6748)	grad_norm 0.5620 (0.5933)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:21 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][90/156]	eta 0:00:35 lr 0.000122	 wd 0.0500	time 0.5290 (0.5443)	data time 0.0072 (0.0682)	model time 0.5218 (0.4694)	loss 0.6736 (0.6745)	grad_norm 0.7627 (0.5917)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:26 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][100/156]	eta 0:00:30 lr 0.000123	 wd 0.0500	time 0.6683 (0.5417)	data time 0.0077 (0.0625)	model time 0.6606 (0.4769)	loss 0.6604 (0.6743)	grad_norm 0.5530 (0.5965)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:31 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][110/156]	eta 0:00:24 lr 0.000123	 wd 0.0500	time 0.5150 (0.5344)	data time 0.0023 (0.0573)	model time 0.5127 (0.4733)	loss 0.6328 (0.6740)	grad_norm 0.5255 (0.5934)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:36 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][120/156]	eta 0:00:19 lr 0.000124	 wd 0.0500	time 0.5790 (0.5325)	data time 0.0005 (0.0533)	model time 0.5785 (0.4776)	loss 0.6919 (0.6734)	grad_norm 1.1165 (0.5986)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:41 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][130/156]	eta 0:00:13 lr 0.000124	 wd 0.0500	time 0.4321 (0.5303)	data time 0.0245 (0.0508)	model time 0.4076 (0.4783)	loss 0.6805 (0.6733)	grad_norm 0.4973 (0.6139)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:46 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][140/156]	eta 0:00:08 lr 0.000124	 wd 0.0500	time 0.5181 (0.5289)	data time 0.0208 (0.0481)	model time 0.4973 (0.4805)	loss 0.6940 (0.6736)	grad_norm 0.5124 (0.6175)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:51 vssm1_tiny_0230s](training.py 201): INFO Train: [19/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4259 (0.5244)	data time 0.0006 (0.0452)	model time 0.4253 (0.4781)	loss 0.7033 (0.6738)	grad_norm 0.4689 (0.6233)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:10:54 vssm1_tiny_0230s](training.py 212): INFO EPOCH 19 training takes 0:01:22
[2024-11-09 11:10:54 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_19.pth saving......
[2024-11-09 11:10:54 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_19.pth saved !!!
[2024-11-09 11:10:58 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.954 (3.954)	Loss 0.6235 (0.6235)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:11:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.149 (0.614)	Loss 0.6069 (0.6269)	Acc@1 76.562 (68.963)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:11:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.239 (0.433)	Loss 0.5547 (0.6262)	Acc@1 78.906 (69.494)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:11:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.392)	Loss 0.6128 (0.6167)	Acc@1 62.500 (69.128)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:11:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 68.640 Acc@5 100.000
[2024-11-09 11:11:10 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 68.6%
[2024-11-09 11:11:10 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 68.68%
[2024-11-09 11:11:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.227 (3.227)	Loss 0.6528 (0.6528)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:11:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.684 (0.497)	Loss 0.6558 (0.6509)	Acc@1 89.844 (92.330)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:11:17 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.293 (0.354)	Loss 0.7139 (0.6566)	Acc@1 21.875 (86.310)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:11:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.830 (0.346)	Loss 0.7197 (0.6763)	Acc@1 21.875 (65.423)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:11:23 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 56.380 Acc@5 100.000
[2024-11-09 11:11:23 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 56.4%
[2024-11-09 11:11:23 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:11:28 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][0/156]	eta 0:13:51 lr 0.000125	 wd 0.0500	time 5.3308 (5.3308)	data time 4.7847 (4.7847)	model time 0.0000 (0.0000)	loss 0.6533 (0.6533)	grad_norm 0.6462 (0.6462)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:11:33 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][10/156]	eta 0:02:15 lr 0.000125	 wd 0.0500	time 0.4922 (0.9291)	data time 0.0008 (0.4435)	model time 0.0000 (0.0000)	loss 0.6666 (0.6738)	grad_norm 0.3758 (0.6114)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:11:38 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][20/156]	eta 0:01:36 lr 0.000125	 wd 0.0500	time 0.4417 (0.7105)	data time 0.0113 (0.2447)	model time 0.0000 (0.0000)	loss 0.6795 (0.6733)	grad_norm 0.7895 (0.6806)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:11:42 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][30/156]	eta 0:01:20 lr 0.000125	 wd 0.0500	time 0.5049 (0.6371)	data time 0.0006 (0.1707)	model time 0.0000 (0.0000)	loss 0.6479 (0.6712)	grad_norm 0.7289 (0.6772)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:11:47 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][40/156]	eta 0:01:10 lr 0.000125	 wd 0.0500	time 0.5158 (0.6054)	data time 0.0039 (0.1320)	model time 0.0000 (0.0000)	loss 0.6896 (0.6729)	grad_norm 0.5984 (0.6610)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:11:52 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][50/156]	eta 0:01:01 lr 0.000125	 wd 0.0500	time 0.5140 (0.5849)	data time 0.0302 (0.1089)	model time 0.0000 (0.0000)	loss 0.6767 (0.6725)	grad_norm 0.2744 (0.6283)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:11:58 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][60/156]	eta 0:00:54 lr 0.000125	 wd 0.0500	time 0.5440 (0.5718)	data time 0.0019 (0.0920)	model time 0.5420 (0.4991)	loss 0.6856 (0.6737)	grad_norm 0.3893 (0.6152)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:12:03 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][70/156]	eta 0:00:48 lr 0.000125	 wd 0.0500	time 0.5289 (0.5658)	data time 0.0027 (0.0837)	model time 0.5262 (0.4975)	loss 0.6815 (0.6731)	grad_norm 0.8084 (0.6195)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:12:08 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][80/156]	eta 0:00:42 lr 0.000125	 wd 0.0500	time 0.4075 (0.5590)	data time 0.0007 (0.0757)	model time 0.4067 (0.4957)	loss 0.6868 (0.6732)	grad_norm 0.5102 (0.6002)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:12:13 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][90/156]	eta 0:00:36 lr 0.000125	 wd 0.0500	time 0.4282 (0.5502)	data time 0.0182 (0.0695)	model time 0.4100 (0.4867)	loss 0.7014 (0.6738)	grad_norm 0.4823 (0.5901)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:12:19 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][100/156]	eta 0:00:31 lr 0.000125	 wd 0.0500	time 0.6207 (0.5557)	data time 0.0089 (0.0644)	model time 0.6119 (0.5069)	loss 0.6933 (0.6743)	grad_norm 0.2944 (0.5779)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:12:24 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][110/156]	eta 0:00:25 lr 0.000125	 wd 0.0500	time 0.5457 (0.5524)	data time 0.0172 (0.0604)	model time 0.5284 (0.5056)	loss 0.6615 (0.6744)	grad_norm 0.3685 (0.5703)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:12:29 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][120/156]	eta 0:00:19 lr 0.000125	 wd 0.0500	time 0.4656 (0.5478)	data time 0.0392 (0.0567)	model time 0.4264 (0.5021)	loss 0.7068 (0.6753)	grad_norm 0.4777 (0.5623)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:12:34 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][130/156]	eta 0:00:14 lr 0.000125	 wd 0.0500	time 0.4473 (0.5445)	data time 0.0084 (0.0538)	model time 0.4389 (0.5001)	loss 0.6692 (0.6749)	grad_norm 0.3494 (0.5660)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:12:39 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.4645 (0.5406)	data time 0.0008 (0.0516)	model time 0.4637 (0.4964)	loss 0.6576 (0.6751)	grad_norm 0.6291 (0.5665)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:12:44 vssm1_tiny_0230s](training.py 201): INFO Train: [20/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4844 (0.5358)	data time 0.0006 (0.0482)	model time 0.4838 (0.4936)	loss 0.6719 (0.6751)	grad_norm 0.7310 (0.5730)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:12:46 vssm1_tiny_0230s](training.py 212): INFO EPOCH 20 training takes 0:01:23
[2024-11-09 11:12:46 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_20.pth saving......
[2024-11-09 11:12:47 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_20.pth saved !!!
[2024-11-09 11:12:51 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.265 (4.265)	Loss 0.6177 (0.6177)	Acc@1 74.219 (74.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:12:53 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.142 (0.595)	Loss 0.6050 (0.6257)	Acc@1 81.250 (75.142)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:12:56 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.190 (0.425)	Loss 0.5518 (0.6233)	Acc@1 72.656 (74.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:12:58 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.172 (0.378)	Loss 0.6064 (0.6108)	Acc@1 60.938 (71.724)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:13:01 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 70.820 Acc@5 100.000
[2024-11-09 11:13:01 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 70.8%
[2024-11-09 11:13:01 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 70.82%
[2024-11-09 11:13:04 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.750 (2.750)	Loss 0.6431 (0.6431)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:13:06 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.461)	Loss 0.6460 (0.6410)	Acc@1 91.406 (94.460)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:13:09 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.157 (0.355)	Loss 0.7227 (0.6481)	Acc@1 18.750 (88.542)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:13:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.168 (0.339)	Loss 0.7285 (0.6734)	Acc@1 19.531 (65.801)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:13:14 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.680 Acc@5 100.000
[2024-11-09 11:13:14 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.7%
[2024-11-09 11:13:14 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:13:19 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][0/156]	eta 0:13:07 lr 0.000125	 wd 0.0500	time 5.0461 (5.0461)	data time 4.6211 (4.6211)	model time 0.0000 (0.0000)	loss 0.6860 (0.6860)	grad_norm 0.4304 (0.4304)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:13:24 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][10/156]	eta 0:02:13 lr 0.000125	 wd 0.0500	time 0.4496 (0.9118)	data time 0.0006 (0.4404)	model time 0.0000 (0.0000)	loss 0.6837 (0.6791)	grad_norm 0.7467 (0.7463)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:13:29 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][20/156]	eta 0:01:39 lr 0.000125	 wd 0.0500	time 0.6245 (0.7296)	data time 0.0159 (0.2391)	model time 0.0000 (0.0000)	loss 0.6674 (0.6766)	grad_norm 0.8513 (0.6730)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:13:34 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][30/156]	eta 0:01:22 lr 0.000125	 wd 0.0500	time 0.5195 (0.6559)	data time 0.0122 (0.1674)	model time 0.0000 (0.0000)	loss 0.6929 (0.6767)	grad_norm 0.4523 (0.6492)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:13:40 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][40/156]	eta 0:01:12 lr 0.000125	 wd 0.0500	time 0.4973 (0.6233)	data time 0.0042 (0.1325)	model time 0.0000 (0.0000)	loss 0.6738 (0.6750)	grad_norm 0.7304 (0.6493)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:13:45 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][50/156]	eta 0:01:04 lr 0.000125	 wd 0.0500	time 0.4797 (0.6052)	data time 0.0044 (0.1098)	model time 0.0000 (0.0000)	loss 0.6237 (0.6731)	grad_norm 0.8603 (0.6572)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:13:50 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][60/156]	eta 0:00:56 lr 0.000125	 wd 0.0500	time 0.4938 (0.5926)	data time 0.0056 (0.0946)	model time 0.4882 (0.5113)	loss 0.6582 (0.6719)	grad_norm 0.4915 (0.7025)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:13:56 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][70/156]	eta 0:00:50 lr 0.000125	 wd 0.0500	time 0.5356 (0.5841)	data time 0.0128 (0.0856)	model time 0.5228 (0.5061)	loss 0.6908 (0.6715)	grad_norm 0.5892 (0.6923)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:14:01 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][80/156]	eta 0:00:43 lr 0.000125	 wd 0.0500	time 0.4943 (0.5757)	data time 0.0199 (0.0767)	model time 0.4744 (0.5051)	loss 0.6730 (0.6715)	grad_norm 0.5383 (0.6710)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:14:06 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][90/156]	eta 0:00:37 lr 0.000125	 wd 0.0500	time 0.6116 (0.5690)	data time 0.0218 (0.0709)	model time 0.5898 (0.5015)	loss 0.6918 (0.6727)	grad_norm 0.4850 (0.6804)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:14:11 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][100/156]	eta 0:00:31 lr 0.000125	 wd 0.0500	time 0.6125 (0.5634)	data time 0.0031 (0.0649)	model time 0.6093 (0.5017)	loss 0.6774 (0.6725)	grad_norm 0.4220 (0.6796)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:14:16 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][110/156]	eta 0:00:25 lr 0.000125	 wd 0.0500	time 0.4707 (0.5599)	data time 0.0454 (0.0617)	model time 0.4253 (0.5007)	loss 0.6561 (0.6726)	grad_norm 0.3448 (0.6565)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:14:21 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][120/156]	eta 0:00:19 lr 0.000125	 wd 0.0500	time 0.5970 (0.5541)	data time 0.0317 (0.0574)	model time 0.5653 (0.4976)	loss 0.6670 (0.6723)	grad_norm 0.4447 (0.6486)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:14:26 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][130/156]	eta 0:00:14 lr 0.000125	 wd 0.0500	time 0.4706 (0.5489)	data time 0.0166 (0.0534)	model time 0.4540 (0.4955)	loss 0.6463 (0.6720)	grad_norm 0.6824 (0.6400)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:14:31 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.6174 (0.5480)	data time 0.0007 (0.0509)	model time 0.6166 (0.4980)	loss 0.7072 (0.6726)	grad_norm 1.8506 (0.6440)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:14:36 vssm1_tiny_0230s](training.py 201): INFO Train: [21/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4408 (0.5442)	data time 0.0005 (0.0476)	model time 0.4403 (0.4972)	loss 0.6693 (0.6725)	grad_norm 1.0566 (0.6408)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:14:39 vssm1_tiny_0230s](training.py 212): INFO EPOCH 21 training takes 0:01:25
[2024-11-09 11:14:39 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_21.pth saving......
[2024-11-09 11:14:40 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_21.pth saved !!!
[2024-11-09 11:14:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.010 (4.010)	Loss 0.5415 (0.5415)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:14:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.261 (0.509)	Loss 0.5391 (0.5423)	Acc@1 88.281 (86.435)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:14:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.367)	Loss 0.6187 (0.5512)	Acc@1 57.031 (84.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:14:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.309)	Loss 0.6753 (0.5819)	Acc@1 50.781 (74.345)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:14:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 69.860 Acc@5 100.000
[2024-11-09 11:14:51 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 69.9%
[2024-11-09 11:14:51 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 70.82%
[2024-11-09 11:14:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.740 (1.740)	Loss 0.6323 (0.6323)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:14:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.372)	Loss 0.6353 (0.6305)	Acc@1 93.750 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:14:57 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.266)	Loss 0.7319 (0.6390)	Acc@1 14.062 (90.030)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:14:59 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.185 (0.236)	Loss 0.7388 (0.6704)	Acc@1 13.281 (65.398)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:15:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 54.740 Acc@5 100.000
[2024-11-09 11:15:00 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 54.7%
[2024-11-09 11:15:00 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:15:03 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][0/156]	eta 0:07:27 lr 0.000125	 wd 0.0500	time 2.8693 (2.8693)	data time 2.2237 (2.2237)	model time 0.0000 (0.0000)	loss 0.6731 (0.6731)	grad_norm 0.4430 (0.4430)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:15:09 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][10/156]	eta 0:01:57 lr 0.000125	 wd 0.0500	time 0.4598 (0.8061)	data time 0.0142 (0.2850)	model time 0.0000 (0.0000)	loss 0.6785 (0.6708)	grad_norm 0.4251 (0.7024)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:15:14 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][20/156]	eta 0:01:31 lr 0.000125	 wd 0.0500	time 0.5062 (0.6697)	data time 0.0060 (0.1531)	model time 0.0000 (0.0000)	loss 0.6696 (0.6728)	grad_norm 0.6188 (0.7324)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:15:19 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][30/156]	eta 0:01:17 lr 0.000125	 wd 0.0500	time 0.5167 (0.6114)	data time 0.0275 (0.1080)	model time 0.0000 (0.0000)	loss 0.7006 (0.6729)	grad_norm 1.0316 (0.7358)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:15:25 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][40/156]	eta 0:01:08 lr 0.000125	 wd 0.0500	time 0.5561 (0.5927)	data time 0.0187 (0.0881)	model time 0.0000 (0.0000)	loss 0.6523 (0.6712)	grad_norm 0.6224 (0.7272)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:15:30 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][50/156]	eta 0:01:01 lr 0.000125	 wd 0.0500	time 0.5643 (0.5760)	data time 0.0049 (0.0724)	model time 0.0000 (0.0000)	loss 0.6351 (0.6699)	grad_norm 0.5690 (0.7486)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:15:35 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][60/156]	eta 0:00:54 lr 0.000125	 wd 0.0500	time 0.4100 (0.5665)	data time 0.0006 (0.0632)	model time 0.4094 (0.5022)	loss 0.6596 (0.6706)	grad_norm 0.3920 (0.7381)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:15:40 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][70/156]	eta 0:00:48 lr 0.000125	 wd 0.0500	time 0.4922 (0.5582)	data time 0.0005 (0.0563)	model time 0.4917 (0.4974)	loss 0.6890 (0.6721)	grad_norm inf (inf)	loss_scale 65536.0000 (130148.9577)	mem 13675MB
[2024-11-09 11:15:45 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][80/156]	eta 0:00:41 lr 0.000125	 wd 0.0500	time 0.5291 (0.5513)	data time 0.0067 (0.0519)	model time 0.5224 (0.4923)	loss 0.6559 (0.6721)	grad_norm 0.4403 (inf)	loss_scale 65536.0000 (122172.0494)	mem 13675MB
[2024-11-09 11:15:50 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][90/156]	eta 0:00:36 lr 0.000125	 wd 0.0500	time 0.4597 (0.5466)	data time 0.0021 (0.0488)	model time 0.4576 (0.4905)	loss 0.6576 (0.6706)	grad_norm 0.6204 (inf)	loss_scale 65536.0000 (115948.3077)	mem 13675MB
[2024-11-09 11:15:55 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][100/156]	eta 0:00:30 lr 0.000125	 wd 0.0500	time 0.4460 (0.5378)	data time 0.0050 (0.0450)	model time 0.4409 (0.4819)	loss 0.6984 (0.6705)	grad_norm 0.9701 (inf)	loss_scale 65536.0000 (110956.9901)	mem 13675MB
[2024-11-09 11:16:00 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][110/156]	eta 0:00:24 lr 0.000125	 wd 0.0500	time 0.4664 (0.5334)	data time 0.0006 (0.0421)	model time 0.4658 (0.4808)	loss 0.6589 (0.6702)	grad_norm 0.8617 (inf)	loss_scale 65536.0000 (106865.0090)	mem 13675MB
[2024-11-09 11:16:05 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][120/156]	eta 0:00:19 lr 0.000125	 wd 0.0500	time 0.5637 (0.5333)	data time 0.0321 (0.0414)	model time 0.5316 (0.4834)	loss 0.6862 (0.6704)	grad_norm 0.2549 (inf)	loss_scale 65536.0000 (103449.3884)	mem 13675MB
[2024-11-09 11:16:10 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][130/156]	eta 0:00:13 lr 0.000125	 wd 0.0500	time 0.4573 (0.5342)	data time 0.0176 (0.0406)	model time 0.4397 (0.4874)	loss 0.6768 (0.6711)	grad_norm 0.5464 (inf)	loss_scale 65536.0000 (100555.2366)	mem 13675MB
[2024-11-09 11:16:16 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.4745 (0.5335)	data time 0.0008 (0.0392)	model time 0.4737 (0.4891)	loss 0.7008 (0.6714)	grad_norm 0.8655 (inf)	loss_scale 65536.0000 (98071.6028)	mem 13675MB
[2024-11-09 11:16:20 vssm1_tiny_0230s](training.py 201): INFO Train: [22/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4719 (0.5293)	data time 0.0005 (0.0367)	model time 0.4715 (0.4869)	loss 0.6561 (0.6718)	grad_norm 0.4251 (inf)	loss_scale 65536.0000 (95916.9272)	mem 13675MB
[2024-11-09 11:16:23 vssm1_tiny_0230s](training.py 212): INFO EPOCH 22 training takes 0:01:22
[2024-11-09 11:16:23 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_22.pth saving......
[2024-11-09 11:16:23 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_22.pth saved !!!
[2024-11-09 11:16:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.604 (3.604)	Loss 0.6006 (0.6006)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:16:30 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.193 (0.581)	Loss 0.5850 (0.6026)	Acc@1 85.156 (79.474)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:16:31 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.163 (0.376)	Loss 0.5664 (0.6051)	Acc@1 72.656 (77.976)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:16:34 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.228 (0.341)	Loss 0.6172 (0.6016)	Acc@1 58.594 (73.765)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:16:36 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 72.100 Acc@5 100.000
[2024-11-09 11:16:36 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 72.1%
[2024-11-09 11:16:36 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 72.10%
[2024-11-09 11:16:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.926 (3.926)	Loss 0.6216 (0.6216)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:16:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.218 (0.614)	Loss 0.6250 (0.6201)	Acc@1 94.531 (97.301)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:16:46 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.432)	Loss 0.7412 (0.6300)	Acc@1 13.281 (91.369)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:16:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.321 (0.391)	Loss 0.7490 (0.6675)	Acc@1 10.938 (65.575)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:16:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 54.400 Acc@5 100.000
[2024-11-09 11:16:51 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 54.4%
[2024-11-09 11:16:51 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:16:55 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][0/156]	eta 0:09:22 lr 0.000125	 wd 0.0500	time 3.6067 (3.6067)	data time 3.1917 (3.1917)	model time 0.0000 (0.0000)	loss 0.6756 (0.6756)	grad_norm 0.2504 (0.2504)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:00 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][10/156]	eta 0:01:58 lr 0.000125	 wd 0.0500	time 0.4239 (0.8136)	data time 0.0074 (0.3226)	model time 0.0000 (0.0000)	loss 0.6822 (0.6702)	grad_norm 0.5253 (0.5203)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:05 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][20/156]	eta 0:01:31 lr 0.000125	 wd 0.0500	time 0.4391 (0.6715)	data time 0.0082 (0.1721)	model time 0.0000 (0.0000)	loss 0.6391 (0.6691)	grad_norm 0.4145 (0.5423)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:11 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][30/156]	eta 0:01:18 lr 0.000125	 wd 0.0500	time 0.5229 (0.6212)	data time 0.0313 (0.1212)	model time 0.0000 (0.0000)	loss 0.6702 (0.6699)	grad_norm 0.3796 (0.5891)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:15 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][40/156]	eta 0:01:07 lr 0.000125	 wd 0.0500	time 0.4170 (0.5845)	data time 0.0089 (0.0936)	model time 0.0000 (0.0000)	loss 0.7163 (0.6718)	grad_norm 0.6612 (0.5966)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:20 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][50/156]	eta 0:01:00 lr 0.000125	 wd 0.0500	time 0.4549 (0.5705)	data time 0.0141 (0.0777)	model time 0.0000 (0.0000)	loss 0.6459 (0.6716)	grad_norm 0.5880 (0.5961)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:25 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][60/156]	eta 0:00:53 lr 0.000125	 wd 0.0500	time 0.4715 (0.5540)	data time 0.0228 (0.0671)	model time 0.4488 (0.4566)	loss 0.6761 (0.6720)	grad_norm 0.4846 (0.6076)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:30 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][70/156]	eta 0:00:46 lr 0.000125	 wd 0.0500	time 0.4777 (0.5441)	data time 0.0121 (0.0595)	model time 0.4656 (0.4637)	loss 0.6674 (0.6721)	grad_norm 0.7634 (0.6353)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:35 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][80/156]	eta 0:00:41 lr 0.000125	 wd 0.0500	time 0.6786 (0.5417)	data time 0.0041 (0.0536)	model time 0.6745 (0.4802)	loss 0.6626 (0.6722)	grad_norm 0.5992 (0.6219)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:41 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][90/156]	eta 0:00:35 lr 0.000125	 wd 0.0500	time 0.5271 (0.5418)	data time 0.0006 (0.0492)	model time 0.5265 (0.4925)	loss 0.6609 (0.6724)	grad_norm 0.4111 (0.6218)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:46 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][100/156]	eta 0:00:30 lr 0.000125	 wd 0.0500	time 0.4798 (0.5386)	data time 0.0062 (0.0462)	model time 0.4736 (0.4921)	loss 0.6931 (0.6729)	grad_norm 0.5759 (0.6218)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:51 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][110/156]	eta 0:00:24 lr 0.000125	 wd 0.0500	time 0.5419 (0.5353)	data time 0.0033 (0.0430)	model time 0.5386 (0.4918)	loss 0.6709 (0.6721)	grad_norm 0.2695 (0.6211)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:17:56 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][120/156]	eta 0:00:19 lr 0.000125	 wd 0.0500	time 0.6105 (0.5334)	data time 0.0033 (0.0406)	model time 0.6072 (0.4929)	loss 0.6798 (0.6719)	grad_norm 1.2879 (0.6358)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:18:01 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][130/156]	eta 0:00:13 lr 0.000125	 wd 0.0500	time 0.4600 (0.5304)	data time 0.0087 (0.0388)	model time 0.4513 (0.4909)	loss 0.6960 (0.6716)	grad_norm 0.6422 (0.6422)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:18:06 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.4828 (0.5291)	data time 0.0008 (0.0371)	model time 0.4820 (0.4916)	loss 0.6705 (0.6714)	grad_norm 0.7582 (0.6401)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:18:11 vssm1_tiny_0230s](training.py 201): INFO Train: [23/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4109 (0.5254)	data time 0.0005 (0.0347)	model time 0.4104 (0.4896)	loss 0.7096 (0.6716)	grad_norm 0.7041 (0.6349)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:18:13 vssm1_tiny_0230s](training.py 212): INFO EPOCH 23 training takes 0:01:22
[2024-11-09 11:18:13 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_23.pth saving......
[2024-11-09 11:18:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_23.pth saved !!!
[2024-11-09 11:18:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.695 (3.695)	Loss 0.5361 (0.5361)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:18:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.176 (0.569)	Loss 0.5225 (0.5395)	Acc@1 89.062 (87.571)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:18:23 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.549 (0.435)	Loss 0.6094 (0.5479)	Acc@1 62.500 (85.379)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:18:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.161 (0.366)	Loss 0.6826 (0.5820)	Acc@1 52.344 (75.756)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:18:28 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 71.260 Acc@5 100.000
[2024-11-09 11:18:28 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 71.3%
[2024-11-09 11:18:28 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 72.10%
[2024-11-09 11:18:32 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.319 (4.319)	Loss 0.6113 (0.6113)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:18:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.579)	Loss 0.6147 (0.6100)	Acc@1 94.531 (97.727)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:18:37 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.834 (0.434)	Loss 0.7505 (0.6213)	Acc@1 12.500 (91.741)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:18:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.373)	Loss 0.7588 (0.6647)	Acc@1 10.156 (65.348)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:18:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.900 Acc@5 100.000
[2024-11-09 11:18:42 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.9%
[2024-11-09 11:18:42 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:18:47 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][0/156]	eta 0:13:19 lr 0.000125	 wd 0.0500	time 5.1227 (5.1227)	data time 4.6930 (4.6930)	model time 0.0000 (0.0000)	loss 0.6647 (0.6647)	grad_norm 0.6513 (0.6513)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:18:52 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][10/156]	eta 0:02:14 lr 0.000125	 wd 0.0500	time 0.5739 (0.9238)	data time 0.0196 (0.4367)	model time 0.0000 (0.0000)	loss 0.6525 (0.6587)	grad_norm 0.3627 (0.5999)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:18:57 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][20/156]	eta 0:01:37 lr 0.000125	 wd 0.0500	time 0.4620 (0.7193)	data time 0.0247 (0.2378)	model time 0.0000 (0.0000)	loss 0.6928 (0.6612)	grad_norm 1.2122 (0.6519)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:02 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][30/156]	eta 0:01:21 lr 0.000125	 wd 0.0500	time 0.4166 (0.6433)	data time 0.0036 (0.1649)	model time 0.0000 (0.0000)	loss 0.6879 (0.6623)	grad_norm 1.0267 (0.6694)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:07 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][40/156]	eta 0:01:10 lr 0.000125	 wd 0.0500	time 0.4489 (0.6110)	data time 0.0188 (0.1273)	model time 0.0000 (0.0000)	loss 0.6561 (0.6630)	grad_norm 0.7855 (0.6356)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:12 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][50/156]	eta 0:01:02 lr 0.000125	 wd 0.0500	time 0.4545 (0.5860)	data time 0.0221 (0.1054)	model time 0.0000 (0.0000)	loss 0.6721 (0.6646)	grad_norm 1.4370 (0.6342)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:16 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][60/156]	eta 0:00:54 lr 0.000125	 wd 0.0500	time 0.4184 (0.5651)	data time 0.0028 (0.0898)	model time 0.4156 (0.4479)	loss 0.6449 (0.6664)	grad_norm 0.7166 (0.6315)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:21 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][70/156]	eta 0:00:47 lr 0.000125	 wd 0.0500	time 0.4979 (0.5546)	data time 0.0006 (0.0788)	model time 0.4974 (0.4635)	loss 0.6808 (0.6678)	grad_norm 1.2070 (0.6455)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:26 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][80/156]	eta 0:00:41 lr 0.000125	 wd 0.0500	time 0.4407 (0.5449)	data time 0.0331 (0.0699)	model time 0.4076 (0.4654)	loss 0.6812 (0.6691)	grad_norm 0.8874 (0.6386)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:31 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][90/156]	eta 0:00:35 lr 0.000125	 wd 0.0500	time 0.5130 (0.5387)	data time 0.0409 (0.0635)	model time 0.4720 (0.4682)	loss 0.6384 (0.6694)	grad_norm 1.0642 (0.6366)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:36 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][100/156]	eta 0:00:29 lr 0.000125	 wd 0.0500	time 0.4824 (0.5333)	data time 0.0007 (0.0581)	model time 0.4817 (0.4695)	loss 0.6763 (0.6701)	grad_norm 0.9142 (0.6432)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:41 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][110/156]	eta 0:00:24 lr 0.000125	 wd 0.0500	time 0.4739 (0.5300)	data time 0.0202 (0.0546)	model time 0.4537 (0.4710)	loss 0.6631 (0.6702)	grad_norm 0.7369 (0.6339)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:46 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][120/156]	eta 0:00:19 lr 0.000125	 wd 0.0500	time 0.4303 (0.5283)	data time 0.0006 (0.0510)	model time 0.4297 (0.4750)	loss 0.6652 (0.6703)	grad_norm 0.5023 (0.6330)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:51 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][130/156]	eta 0:00:13 lr 0.000125	 wd 0.0500	time 0.5679 (0.5285)	data time 0.0597 (0.0487)	model time 0.5082 (0.4791)	loss 0.6906 (0.6705)	grad_norm 0.3606 (0.6222)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:19:57 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.6418 (0.5290)	data time 0.0106 (0.0468)	model time 0.6312 (0.4830)	loss 0.6616 (0.6701)	grad_norm 0.8097 (0.6263)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:20:01 vssm1_tiny_0230s](training.py 201): INFO Train: [24/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.5452 (0.5266)	data time 0.0007 (0.0437)	model time 0.5444 (0.4840)	loss 0.6521 (0.6695)	grad_norm 0.8587 (0.6227)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:20:04 vssm1_tiny_0230s](training.py 212): INFO EPOCH 24 training takes 0:01:22
[2024-11-09 11:20:04 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_24.pth saving......
[2024-11-09 11:20:05 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_24.pth saved !!!
[2024-11-09 11:20:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.112 (3.112)	Loss 0.5820 (0.5820)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:20:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.247 (0.519)	Loss 0.5566 (0.5808)	Acc@1 81.250 (76.918)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:20:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.385)	Loss 0.5264 (0.5868)	Acc@1 75.000 (74.888)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:20:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.166 (0.342)	Loss 0.5942 (0.5790)	Acc@1 62.500 (72.807)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:20:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 71.380 Acc@5 100.000
[2024-11-09 11:20:18 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 71.4%
[2024-11-09 11:20:18 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 72.10%
[2024-11-09 11:20:22 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.851 (3.851)	Loss 0.6021 (0.6021)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:20:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.189 (0.562)	Loss 0.6055 (0.6009)	Acc@1 94.531 (98.295)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:20:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.156 (0.421)	Loss 0.7583 (0.6135)	Acc@1 10.938 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:20:29 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.354)	Loss 0.7676 (0.6622)	Acc@1 8.594 (65.423)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:20:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.620 Acc@5 100.000
[2024-11-09 11:20:31 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.6%
[2024-11-09 11:20:31 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:20:36 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][0/156]	eta 0:13:03 lr 0.000125	 wd 0.0500	time 5.0220 (5.0220)	data time 4.5113 (4.5113)	model time 0.0000 (0.0000)	loss 0.6789 (0.6789)	grad_norm 0.4378 (0.4378)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:20:41 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][10/156]	eta 0:02:11 lr 0.000125	 wd 0.0500	time 0.4607 (0.8998)	data time 0.0006 (0.4185)	model time 0.0000 (0.0000)	loss 0.6691 (0.6645)	grad_norm 0.3765 (0.6769)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:20:46 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][20/156]	eta 0:01:38 lr 0.000125	 wd 0.0500	time 0.6358 (0.7223)	data time 0.0615 (0.2286)	model time 0.0000 (0.0000)	loss 0.6858 (0.6664)	grad_norm 0.4597 (0.6076)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:20:51 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][30/156]	eta 0:01:21 lr 0.000125	 wd 0.0500	time 0.5034 (0.6460)	data time 0.0253 (0.1584)	model time 0.0000 (0.0000)	loss 0.6342 (0.6622)	grad_norm 0.6847 (0.6469)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:20:56 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][40/156]	eta 0:01:10 lr 0.000125	 wd 0.0500	time 0.4790 (0.6109)	data time 0.0182 (0.1238)	model time 0.0000 (0.0000)	loss 0.6584 (0.6627)	grad_norm 1.0328 (0.7138)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:01 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][50/156]	eta 0:01:02 lr 0.000125	 wd 0.0500	time 0.6106 (0.5930)	data time 0.0050 (0.1032)	model time 0.0000 (0.0000)	loss 0.6686 (0.6633)	grad_norm 0.4588 (0.7069)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:06 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][60/156]	eta 0:00:55 lr 0.000125	 wd 0.0500	time 0.4232 (0.5779)	data time 0.0047 (0.0878)	model time 0.4185 (0.4917)	loss 0.6637 (0.6654)	grad_norm 0.4230 (0.7001)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:11 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][70/156]	eta 0:00:48 lr 0.000125	 wd 0.0500	time 0.4295 (0.5666)	data time 0.0006 (0.0776)	model time 0.4289 (0.4872)	loss 0.6848 (0.6669)	grad_norm 0.3974 (0.6761)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:17 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][80/156]	eta 0:00:42 lr 0.000125	 wd 0.0500	time 0.4295 (0.5621)	data time 0.0215 (0.0704)	model time 0.4080 (0.4950)	loss 0.6681 (0.6681)	grad_norm 0.9769 (0.6573)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:22 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][90/156]	eta 0:00:36 lr 0.000125	 wd 0.0500	time 0.5322 (0.5591)	data time 0.0075 (0.0646)	model time 0.5247 (0.5006)	loss 0.6837 (0.6684)	grad_norm 0.4481 (0.6379)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:27 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][100/156]	eta 0:00:31 lr 0.000125	 wd 0.0500	time 0.5075 (0.5553)	data time 0.0233 (0.0590)	model time 0.4842 (0.5029)	loss 0.6828 (0.6685)	grad_norm 0.6247 (0.6276)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:32 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][110/156]	eta 0:00:25 lr 0.000125	 wd 0.0500	time 0.4127 (0.5461)	data time 0.0006 (0.0547)	model time 0.4121 (0.4928)	loss 0.6657 (0.6687)	grad_norm 0.8457 (0.6190)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:36 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][120/156]	eta 0:00:19 lr 0.000125	 wd 0.0500	time 0.5298 (0.5406)	data time 0.0178 (0.0513)	model time 0.5120 (0.4890)	loss 0.6793 (0.6683)	grad_norm 0.3832 (0.6140)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:42 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][130/156]	eta 0:00:14 lr 0.000125	 wd 0.0500	time 0.4114 (0.5397)	data time 0.0006 (0.0485)	model time 0.4108 (0.4922)	loss 0.6368 (0.6678)	grad_norm 0.7533 (0.6160)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:47 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.4494 (0.5372)	data time 0.0010 (0.0458)	model time 0.4485 (0.4923)	loss 0.6935 (0.6683)	grad_norm 0.8041 (0.6266)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:52 vssm1_tiny_0230s](training.py 201): INFO Train: [25/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4859 (0.5348)	data time 0.0037 (0.0429)	model time 0.4822 (0.4930)	loss 0.6391 (0.6680)	grad_norm 0.4873 (0.6211)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:21:54 vssm1_tiny_0230s](training.py 212): INFO EPOCH 25 training takes 0:01:23
[2024-11-09 11:21:54 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_25.pth saving......
[2024-11-09 11:21:55 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_25.pth saved !!!
[2024-11-09 11:22:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.892 (4.892)	Loss 0.5098 (0.5098)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:22:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.669)	Loss 0.5083 (0.5158)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:22:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.167 (0.473)	Loss 0.5918 (0.5278)	Acc@1 63.281 (86.161)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:22:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.424)	Loss 0.6704 (0.5621)	Acc@1 54.688 (76.285)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:22:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 71.980 Acc@5 100.000
[2024-11-09 11:22:10 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 72.0%
[2024-11-09 11:22:10 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 72.10%
[2024-11-09 11:22:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.827 (2.827)	Loss 0.5933 (0.5933)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:22:16 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.776 (0.513)	Loss 0.5972 (0.5923)	Acc@1 95.312 (98.509)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:22:19 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.406)	Loss 0.7661 (0.6060)	Acc@1 10.938 (92.374)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:22:22 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.262 (0.370)	Loss 0.7764 (0.6598)	Acc@1 8.594 (65.423)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:22:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.440 Acc@5 100.000
[2024-11-09 11:22:25 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.4%
[2024-11-09 11:22:25 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:22:28 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][0/156]	eta 0:09:00 lr 0.000125	 wd 0.0500	time 3.4648 (3.4648)	data time 2.9353 (2.9353)	model time 0.0000 (0.0000)	loss 0.6906 (0.6906)	grad_norm 0.7924 (0.7924)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:22:34 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][10/156]	eta 0:01:58 lr 0.000125	 wd 0.0500	time 0.4401 (0.8114)	data time 0.0187 (0.2848)	model time 0.0000 (0.0000)	loss 0.6757 (0.6663)	grad_norm 1.0830 (0.7607)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:22:39 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][20/156]	eta 0:01:31 lr 0.000125	 wd 0.0500	time 0.5838 (0.6728)	data time 0.0173 (0.1637)	model time 0.0000 (0.0000)	loss 0.6741 (0.6663)	grad_norm 0.8902 (0.7939)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:22:44 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][30/156]	eta 0:01:17 lr 0.000125	 wd 0.0500	time 0.4886 (0.6122)	data time 0.0006 (0.1150)	model time 0.0000 (0.0000)	loss 0.6554 (0.6663)	grad_norm 1.0800 (0.7942)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:22:49 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][40/156]	eta 0:01:07 lr 0.000125	 wd 0.0500	time 0.5587 (0.5851)	data time 0.0594 (0.0907)	model time 0.0000 (0.0000)	loss 0.6724 (0.6683)	grad_norm 0.6512 (0.7647)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:22:54 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][50/156]	eta 0:01:00 lr 0.000125	 wd 0.0500	time 0.4873 (0.5729)	data time 0.0460 (0.0758)	model time 0.0000 (0.0000)	loss 0.7109 (0.6682)	grad_norm 0.6714 (0.7245)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:22:59 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][60/156]	eta 0:00:54 lr 0.000125	 wd 0.0500	time 0.6235 (0.5634)	data time 0.0104 (0.0653)	model time 0.6131 (0.5027)	loss 0.6588 (0.6676)	grad_norm 0.6748 (0.7253)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:23:04 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][70/156]	eta 0:00:47 lr 0.000125	 wd 0.0500	time 0.4908 (0.5538)	data time 0.0088 (0.0585)	model time 0.4820 (0.4909)	loss 0.6567 (0.6674)	grad_norm 0.4769 (0.7357)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:23:09 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][80/156]	eta 0:00:41 lr 0.000125	 wd 0.0500	time 0.4589 (0.5464)	data time 0.0278 (0.0534)	model time 0.4311 (0.4859)	loss 0.6583 (0.6659)	grad_norm 0.6395 (0.7228)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:23:14 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][90/156]	eta 0:00:35 lr 0.000125	 wd 0.0500	time 0.4520 (0.5405)	data time 0.0207 (0.0498)	model time 0.4313 (0.4823)	loss 0.6703 (0.6651)	grad_norm 1.2137 (0.7327)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:23:19 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][100/156]	eta 0:00:29 lr 0.000125	 wd 0.0500	time 0.5819 (0.5352)	data time 0.0259 (0.0465)	model time 0.5560 (0.4801)	loss 0.7071 (0.6669)	grad_norm 1.1749 (0.7488)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:23:25 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][110/156]	eta 0:00:24 lr 0.000125	 wd 0.0500	time 0.5405 (0.5383)	data time 0.0015 (0.0436)	model time 0.5390 (0.4926)	loss 0.6638 (0.6670)	grad_norm 0.3957 (0.7424)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:23:30 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][120/156]	eta 0:00:19 lr 0.000125	 wd 0.0500	time 0.5099 (0.5352)	data time 0.0006 (0.0414)	model time 0.5094 (0.4914)	loss 0.6995 (0.6676)	grad_norm 0.9406 (0.7348)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:23:35 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][130/156]	eta 0:00:13 lr 0.000125	 wd 0.0500	time 0.4698 (0.5337)	data time 0.0294 (0.0406)	model time 0.4404 (0.4905)	loss 0.6721 (0.6677)	grad_norm 0.5144 (0.7235)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:23:40 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.5315 (0.5303)	data time 0.0008 (0.0383)	model time 0.5307 (0.4891)	loss 0.6794 (0.6674)	grad_norm 0.4236 (0.7057)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:23:44 vssm1_tiny_0230s](training.py 201): INFO Train: [26/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4149 (0.5267)	data time 0.0006 (0.0360)	model time 0.4143 (0.4876)	loss 0.6707 (0.6670)	grad_norm 0.7009 (0.7009)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:23:47 vssm1_tiny_0230s](training.py 212): INFO EPOCH 26 training takes 0:01:22
[2024-11-09 11:23:47 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_26.pth saving......
[2024-11-09 11:23:48 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_26.pth saved !!!
[2024-11-09 11:23:50 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.157 (2.157)	Loss 0.6104 (0.6104)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:23:53 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.205 (0.441)	Loss 0.5859 (0.6147)	Acc@1 78.906 (71.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:23:56 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.257 (0.401)	Loss 0.4756 (0.6119)	Acc@1 81.250 (71.652)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:23:59 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.219 (0.357)	Loss 0.5518 (0.5834)	Acc@1 67.969 (72.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:24:01 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 73.060 Acc@5 100.000
[2024-11-09 11:24:01 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 73.1%
[2024-11-09 11:24:01 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 73.06%
[2024-11-09 11:24:03 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.137 (2.137)	Loss 0.5864 (0.5864)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:24:07 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.132 (0.517)	Loss 0.5898 (0.5853)	Acc@1 96.094 (98.864)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:24:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.149 (0.391)	Loss 0.7725 (0.6000)	Acc@1 10.156 (92.560)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:24:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.377 (0.348)	Loss 0.7832 (0.6578)	Acc@1 8.594 (65.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:24:14 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.380 Acc@5 100.000
[2024-11-09 11:24:14 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.4%
[2024-11-09 11:24:14 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:24:18 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][0/156]	eta 0:11:10 lr 0.000125	 wd 0.0500	time 4.3011 (4.3011)	data time 3.8268 (3.8268)	model time 0.0000 (0.0000)	loss 0.6538 (0.6538)	grad_norm 0.8538 (0.8538)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:24:23 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][10/156]	eta 0:01:59 lr 0.000125	 wd 0.0500	time 0.5383 (0.8160)	data time 0.0007 (0.3544)	model time 0.0000 (0.0000)	loss 0.7273 (0.6769)	grad_norm 1.9402 (0.8337)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:24:28 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][20/156]	eta 0:01:27 lr 0.000125	 wd 0.0500	time 0.4907 (0.6438)	data time 0.0007 (0.1881)	model time 0.0000 (0.0000)	loss 0.6679 (0.6710)	grad_norm 0.4610 (0.8385)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:24:32 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][30/156]	eta 0:01:13 lr 0.000125	 wd 0.0500	time 0.5120 (0.5822)	data time 0.0051 (0.1305)	model time 0.0000 (0.0000)	loss 0.6671 (0.6723)	grad_norm 0.8888 (0.8742)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:24:37 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][40/156]	eta 0:01:03 lr 0.000125	 wd 0.0500	time 0.4880 (0.5484)	data time 0.0338 (0.1003)	model time 0.0000 (0.0000)	loss 0.6770 (0.6727)	grad_norm 0.7903 (0.8826)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:24:41 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][50/156]	eta 0:00:56 lr 0.000125	 wd 0.0500	time 0.4715 (0.5373)	data time 0.0005 (0.0827)	model time 0.0000 (0.0000)	loss 0.6503 (0.6728)	grad_norm 0.3380 (0.8072)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:24:47 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][60/156]	eta 0:00:51 lr 0.000125	 wd 0.0500	time 0.4296 (0.5355)	data time 0.0147 (0.0728)	model time 0.4149 (0.5041)	loss 0.6821 (0.6707)	grad_norm 0.2410 (0.7502)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:24:52 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][70/156]	eta 0:00:45 lr 0.000125	 wd 0.0500	time 0.6621 (0.5304)	data time 0.0566 (0.0646)	model time 0.6056 (0.4943)	loss 0.6842 (0.6702)	grad_norm 0.7646 (0.7480)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:24:57 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][80/156]	eta 0:00:40 lr 0.000125	 wd 0.0500	time 0.4918 (0.5273)	data time 0.0392 (0.0586)	model time 0.4526 (0.4928)	loss 0.6326 (0.6691)	grad_norm 0.8387 (0.7405)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:25:02 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][90/156]	eta 0:00:34 lr 0.000125	 wd 0.0500	time 0.5673 (0.5251)	data time 0.0062 (0.0544)	model time 0.5612 (0.4912)	loss 0.6506 (0.6687)	grad_norm 0.3829 (0.7299)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:25:07 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][100/156]	eta 0:00:29 lr 0.000125	 wd 0.0500	time 0.4484 (0.5245)	data time 0.0007 (0.0504)	model time 0.4477 (0.4941)	loss 0.6889 (0.6689)	grad_norm 0.3909 (0.7170)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:25:13 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][110/156]	eta 0:00:24 lr 0.000125	 wd 0.0500	time 0.7270 (0.5266)	data time 0.0262 (0.0481)	model time 0.7009 (0.4990)	loss 0.6611 (0.6686)	grad_norm 0.5499 (0.7037)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:25:18 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][120/156]	eta 0:00:18 lr 0.000125	 wd 0.0500	time 0.6189 (0.5262)	data time 0.0820 (0.0456)	model time 0.5369 (0.4996)	loss 0.6640 (0.6686)	grad_norm 0.4153 (0.7090)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:25:23 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][130/156]	eta 0:00:13 lr 0.000125	 wd 0.0500	time 0.5551 (0.5262)	data time 0.0008 (0.0429)	model time 0.5543 (0.5016)	loss 0.6581 (0.6682)	grad_norm 0.7045 (0.6996)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:25:29 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.5408 (0.5294)	data time 0.0008 (0.0417)	model time 0.5400 (0.5065)	loss 0.7180 (0.6683)	grad_norm 1.3848 (0.7031)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:25:33 vssm1_tiny_0230s](training.py 201): INFO Train: [27/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4834 (0.5253)	data time 0.0004 (0.0390)	model time 0.4830 (0.5026)	loss 0.6392 (0.6675)	grad_norm 0.5883 (0.6917)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:25:37 vssm1_tiny_0230s](training.py 212): INFO EPOCH 27 training takes 0:01:22
[2024-11-09 11:25:37 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_27.pth saving......
[2024-11-09 11:25:37 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_27.pth saved !!!
[2024-11-09 11:25:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.924 (3.924)	Loss 0.5190 (0.5190)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:25:44 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.142 (0.587)	Loss 0.4929 (0.5168)	Acc@1 88.281 (83.239)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:25:46 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.235 (0.444)	Loss 0.5596 (0.5291)	Acc@1 72.656 (81.324)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:25:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.375)	Loss 0.6377 (0.5577)	Acc@1 57.812 (74.572)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:25:50 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 71.380 Acc@5 100.000
[2024-11-09 11:25:50 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 71.4%
[2024-11-09 11:25:50 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 73.06%
[2024-11-09 11:25:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.544 (2.544)	Loss 0.5796 (0.5796)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:25:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.168 (0.488)	Loss 0.5835 (0.5787)	Acc@1 96.094 (98.864)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:25:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.377)	Loss 0.7778 (0.5943)	Acc@1 10.156 (92.671)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:26:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.154 (0.341)	Loss 0.7896 (0.6559)	Acc@1 8.594 (65.499)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:26:04 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.380 Acc@5 100.000
[2024-11-09 11:26:04 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.4%
[2024-11-09 11:26:04 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:26:10 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][0/156]	eta 0:14:00 lr 0.000125	 wd 0.0500	time 5.3858 (5.3858)	data time 4.8117 (4.8117)	model time 0.0000 (0.0000)	loss 0.6712 (0.6712)	grad_norm 0.9390 (0.9390)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:26:15 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][10/156]	eta 0:02:14 lr 0.000125	 wd 0.0500	time 0.5733 (0.9241)	data time 0.0014 (0.4424)	model time 0.0000 (0.0000)	loss 0.6581 (0.6625)	grad_norm 0.6752 (0.6573)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:26:20 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][20/156]	eta 0:01:43 lr 0.000125	 wd 0.0500	time 0.4278 (0.7582)	data time 0.0057 (0.2449)	model time 0.0000 (0.0000)	loss 0.6819 (0.6674)	grad_norm 0.4101 (0.6836)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:26:25 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][30/156]	eta 0:01:25 lr 0.000125	 wd 0.0500	time 0.5947 (0.6759)	data time 0.0081 (0.1707)	model time 0.0000 (0.0000)	loss 0.6768 (0.6693)	grad_norm 0.6910 (0.6853)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:26:30 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][40/156]	eta 0:01:13 lr 0.000125	 wd 0.0500	time 0.4738 (0.6341)	data time 0.0008 (0.1310)	model time 0.0000 (0.0000)	loss 0.6788 (0.6699)	grad_norm 0.5758 (0.6644)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:26:36 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][50/156]	eta 0:01:04 lr 0.000125	 wd 0.0500	time 0.4171 (0.6114)	data time 0.0144 (0.1082)	model time 0.0000 (0.0000)	loss 0.6557 (0.6690)	grad_norm 0.6368 (0.6832)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:26:41 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][60/156]	eta 0:00:56 lr 0.000125	 wd 0.0500	time 0.5089 (0.5936)	data time 0.0005 (0.0947)	model time 0.5084 (0.4769)	loss 0.6770 (0.6681)	grad_norm 0.6671 (0.6785)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:26:46 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][70/156]	eta 0:00:50 lr 0.000125	 wd 0.0500	time 0.4921 (0.5837)	data time 0.0019 (0.0844)	model time 0.4902 (0.4894)	loss 0.6447 (0.6678)	grad_norm 0.3995 (0.6802)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:26:51 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][80/156]	eta 0:00:43 lr 0.000125	 wd 0.0500	time 0.6004 (0.5757)	data time 0.0060 (0.0753)	model time 0.5944 (0.4958)	loss 0.6919 (0.6695)	grad_norm 0.6940 (0.6818)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:26:56 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][90/156]	eta 0:00:37 lr 0.000125	 wd 0.0500	time 0.4725 (0.5709)	data time 0.0225 (0.0679)	model time 0.4500 (0.5027)	loss 0.6656 (0.6698)	grad_norm 0.6685 (0.6834)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:27:01 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][100/156]	eta 0:00:31 lr 0.000125	 wd 0.0500	time 0.4325 (0.5590)	data time 0.0228 (0.0633)	model time 0.4097 (0.4881)	loss 0.6506 (0.6702)	grad_norm 0.5093 (0.6760)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:27:06 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][110/156]	eta 0:00:25 lr 0.000125	 wd 0.0500	time 0.4386 (0.5560)	data time 0.0097 (0.0587)	model time 0.4289 (0.4925)	loss 0.6734 (0.6699)	grad_norm 0.6865 (0.6571)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:27:11 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][120/156]	eta 0:00:19 lr 0.000125	 wd 0.0500	time 0.4749 (0.5513)	data time 0.0413 (0.0550)	model time 0.4335 (0.4913)	loss 0.6368 (0.6693)	grad_norm 0.4498 (0.6413)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:27:17 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][130/156]	eta 0:00:14 lr 0.000125	 wd 0.0500	time 0.5121 (0.5527)	data time 0.0174 (0.0517)	model time 0.4946 (0.4997)	loss 0.6496 (0.6685)	grad_norm 0.5182 (0.6329)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:27:22 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.5965 (0.5533)	data time 0.0010 (0.0498)	model time 0.5955 (0.5037)	loss 0.6419 (0.6673)	grad_norm 0.4210 (0.6364)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:27:27 vssm1_tiny_0230s](training.py 201): INFO Train: [28/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4253 (0.5492)	data time 0.0005 (0.0468)	model time 0.4248 (0.5020)	loss 0.7034 (0.6669)	grad_norm 0.6896 (0.6351)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:27:30 vssm1_tiny_0230s](training.py 212): INFO EPOCH 28 training takes 0:01:25
[2024-11-09 11:27:30 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_28.pth saving......
[2024-11-09 11:27:31 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_28.pth saved !!!
[2024-11-09 11:27:35 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.621 (3.621)	Loss 0.5522 (0.5522)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:27:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.168 (0.498)	Loss 0.5347 (0.5545)	Acc@1 87.500 (81.818)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:27:40 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.408)	Loss 0.5347 (0.5596)	Acc@1 75.000 (80.506)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:27:42 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.364)	Loss 0.6025 (0.5662)	Acc@1 60.938 (76.184)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:27:45 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 74.020 Acc@5 100.000
[2024-11-09 11:27:45 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 74.0%
[2024-11-09 11:27:45 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 74.02%
[2024-11-09 11:27:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.122 (4.122)	Loss 0.5728 (0.5728)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:27:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.190 (0.603)	Loss 0.5767 (0.5720)	Acc@1 96.875 (98.935)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:27:54 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.184 (0.426)	Loss 0.7832 (0.5885)	Acc@1 9.375 (92.746)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:27:56 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.358)	Loss 0.7954 (0.6539)	Acc@1 8.594 (65.575)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:27:58 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.420 Acc@5 100.000
[2024-11-09 11:27:58 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.4%
[2024-11-09 11:27:58 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:28:02 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][0/156]	eta 0:10:28 lr 0.000125	 wd 0.0500	time 4.0260 (4.0260)	data time 3.5750 (3.5750)	model time 0.0000 (0.0000)	loss 0.6502 (0.6502)	grad_norm 0.4535 (0.4535)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:07 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][10/156]	eta 0:01:55 lr 0.000125	 wd 0.0500	time 0.4819 (0.7895)	data time 0.0006 (0.3309)	model time 0.0000 (0.0000)	loss 0.6844 (0.6696)	grad_norm 1.5364 (0.7231)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:12 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][20/156]	eta 0:01:28 lr 0.000125	 wd 0.0500	time 0.5049 (0.6525)	data time 0.0794 (0.1823)	model time 0.0000 (0.0000)	loss 0.6292 (0.6691)	grad_norm 1.1898 (0.7347)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:17 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][30/156]	eta 0:01:15 lr 0.000125	 wd 0.0500	time 0.4213 (0.6031)	data time 0.0036 (0.1284)	model time 0.0000 (0.0000)	loss 0.7070 (0.6718)	grad_norm 1.3672 (0.7205)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:22 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][40/156]	eta 0:01:08 lr 0.000125	 wd 0.0500	time 0.4394 (0.5873)	data time 0.0331 (0.1008)	model time 0.0000 (0.0000)	loss 0.6968 (0.6703)	grad_norm 0.9792 (0.7128)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:28 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][50/156]	eta 0:01:00 lr 0.000125	 wd 0.0500	time 0.4663 (0.5754)	data time 0.0235 (0.0869)	model time 0.0000 (0.0000)	loss 0.6745 (0.6712)	grad_norm 0.6591 (0.6837)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:33 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][60/156]	eta 0:00:54 lr 0.000125	 wd 0.0500	time 0.5959 (0.5669)	data time 0.0242 (0.0749)	model time 0.5716 (0.5099)	loss 0.6743 (0.6708)	grad_norm 0.4797 (0.6791)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:38 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][70/156]	eta 0:00:48 lr 0.000125	 wd 0.0500	time 0.4268 (0.5630)	data time 0.0006 (0.0665)	model time 0.4261 (0.5169)	loss 0.6461 (0.6701)	grad_norm 0.4525 (0.6691)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:43 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][80/156]	eta 0:00:42 lr 0.000125	 wd 0.0500	time 0.6272 (0.5543)	data time 0.0151 (0.0594)	model time 0.6121 (0.5057)	loss 0.6538 (0.6696)	grad_norm 0.6542 (0.6442)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:48 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][90/156]	eta 0:00:36 lr 0.000125	 wd 0.0500	time 0.4978 (0.5461)	data time 0.0007 (0.0539)	model time 0.4971 (0.4970)	loss 0.6656 (0.6693)	grad_norm 0.3896 (0.6396)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:53 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][100/156]	eta 0:00:30 lr 0.000125	 wd 0.0500	time 0.5521 (0.5405)	data time 0.0074 (0.0494)	model time 0.5446 (0.4936)	loss 0.6321 (0.6682)	grad_norm 0.5441 (0.6335)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:28:58 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][110/156]	eta 0:00:24 lr 0.000125	 wd 0.0500	time 0.5776 (0.5348)	data time 0.0013 (0.0455)	model time 0.5764 (0.4900)	loss 0.6877 (0.6685)	grad_norm 0.7661 (0.6285)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:29:02 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][120/156]	eta 0:00:19 lr 0.000125	 wd 0.0500	time 0.4280 (0.5282)	data time 0.0184 (0.0425)	model time 0.4096 (0.4836)	loss 0.6371 (0.6675)	grad_norm 0.6186 (0.6218)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:29:07 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][130/156]	eta 0:00:13 lr 0.000125	 wd 0.0500	time 0.5148 (0.5283)	data time 0.0249 (0.0415)	model time 0.4900 (0.4856)	loss 0.6805 (0.6682)	grad_norm 0.9651 (0.6543)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:29:12 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.4602 (0.5267)	data time 0.0325 (0.0403)	model time 0.4277 (0.4853)	loss 0.6744 (0.6691)	grad_norm 0.3227 (0.6549)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:29:17 vssm1_tiny_0230s](training.py 201): INFO Train: [29/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4148 (0.5221)	data time 0.0007 (0.0378)	model time 0.4141 (0.4821)	loss 0.6585 (0.6692)	grad_norm 0.3370 (0.6481)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:29:20 vssm1_tiny_0230s](training.py 212): INFO EPOCH 29 training takes 0:01:21
[2024-11-09 11:29:20 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_29.pth saving......
[2024-11-09 11:29:20 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_29.pth saved !!!
[2024-11-09 11:29:22 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.108 (2.108)	Loss 0.6143 (0.6143)	Acc@1 73.438 (73.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:29:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.157 (0.352)	Loss 0.5991 (0.6218)	Acc@1 79.688 (73.082)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:29:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.284)	Loss 0.5083 (0.6200)	Acc@1 81.250 (72.768)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:29:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.256)	Loss 0.5674 (0.5977)	Acc@1 65.625 (73.110)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:29:30 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 73.320 Acc@5 100.000
[2024-11-09 11:29:30 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 73.3%
[2024-11-09 11:29:30 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 74.02%
[2024-11-09 11:29:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.331 (3.331)	Loss 0.5669 (0.5669)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:29:36 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.177 (0.550)	Loss 0.5708 (0.5662)	Acc@1 97.656 (99.077)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:29:39 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.158 (0.405)	Loss 0.7876 (0.5835)	Acc@1 10.156 (92.894)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:29:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.345)	Loss 0.8003 (0.6520)	Acc@1 8.594 (65.726)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:29:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.540 Acc@5 100.000
[2024-11-09 11:29:43 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.5%
[2024-11-09 11:29:43 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:29:48 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][0/156]	eta 0:11:45 lr 0.000125	 wd 0.0500	time 4.5195 (4.5195)	data time 4.1117 (4.1117)	model time 0.0000 (0.0000)	loss 0.6641 (0.6641)	grad_norm 0.3922 (0.3922)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:29:53 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][10/156]	eta 0:02:05 lr 0.000125	 wd 0.0500	time 0.5214 (0.8585)	data time 0.0008 (0.3828)	model time 0.0000 (0.0000)	loss 0.6684 (0.6667)	grad_norm 0.5063 (0.5714)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:29:57 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][20/156]	eta 0:01:32 lr 0.000125	 wd 0.0500	time 0.4454 (0.6810)	data time 0.0108 (0.2083)	model time 0.0000 (0.0000)	loss 0.6575 (0.6707)	grad_norm 0.4132 (0.5989)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:02 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][30/156]	eta 0:01:17 lr 0.000125	 wd 0.0500	time 0.4598 (0.6111)	data time 0.0228 (0.1448)	model time 0.0000 (0.0000)	loss 0.6723 (0.6687)	grad_norm 0.7725 (0.6204)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:07 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][40/156]	eta 0:01:06 lr 0.000125	 wd 0.0500	time 0.4220 (0.5753)	data time 0.0008 (0.1114)	model time 0.0000 (0.0000)	loss 0.6563 (0.6693)	grad_norm 0.5076 (0.5983)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:12 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][50/156]	eta 0:00:58 lr 0.000125	 wd 0.0500	time 0.4109 (0.5550)	data time 0.0007 (0.0915)	model time 0.0000 (0.0000)	loss 0.6427 (0.6675)	grad_norm 0.5276 (0.5971)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:16 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][60/156]	eta 0:00:52 lr 0.000125	 wd 0.0500	time 0.4134 (0.5448)	data time 0.0039 (0.0838)	model time 0.4095 (0.4480)	loss 0.6629 (0.6681)	grad_norm 0.4249 (0.5998)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:22 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][70/156]	eta 0:00:46 lr 0.000125	 wd 0.0500	time 0.4794 (0.5411)	data time 0.0011 (0.0750)	model time 0.4783 (0.4726)	loss 0.6555 (0.6677)	grad_norm 0.4853 (0.5995)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:27 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][80/156]	eta 0:00:40 lr 0.000125	 wd 0.0500	time 0.5362 (0.5346)	data time 0.0008 (0.0677)	model time 0.5354 (0.4729)	loss 0.6433 (0.6662)	grad_norm 0.7334 (0.6012)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:32 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][90/156]	eta 0:00:35 lr 0.000125	 wd 0.0500	time 0.5824 (0.5317)	data time 0.0019 (0.0629)	model time 0.5805 (0.4754)	loss 0.7028 (0.6664)	grad_norm 0.9318 (0.6312)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:37 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][100/156]	eta 0:00:29 lr 0.000125	 wd 0.0500	time 0.5402 (0.5287)	data time 0.0242 (0.0589)	model time 0.5160 (0.4761)	loss 0.6537 (0.6658)	grad_norm 0.3318 (0.6324)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:42 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][110/156]	eta 0:00:24 lr 0.000125	 wd 0.0500	time 0.5587 (0.5276)	data time 0.0006 (0.0550)	model time 0.5581 (0.4804)	loss 0.6946 (0.6667)	grad_norm 0.8581 (0.6311)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:47 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][120/156]	eta 0:00:18 lr 0.000125	 wd 0.0500	time 0.4695 (0.5263)	data time 0.0245 (0.0534)	model time 0.4450 (0.4797)	loss 0.6673 (0.6664)	grad_norm 0.4130 (0.6259)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:52 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][130/156]	eta 0:00:13 lr 0.000125	 wd 0.0500	time 0.4145 (0.5251)	data time 0.0032 (0.0506)	model time 0.4114 (0.4816)	loss 0.6451 (0.6659)	grad_norm 0.4696 (0.6229)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:30:57 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][140/156]	eta 0:00:08 lr 0.000125	 wd 0.0500	time 0.4899 (0.5242)	data time 0.0008 (0.0481)	model time 0.4891 (0.4831)	loss 0.6344 (0.6663)	grad_norm 0.5257 (0.6309)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:31:02 vssm1_tiny_0230s](training.py 201): INFO Train: [30/300][150/156]	eta 0:00:03 lr 0.000125	 wd 0.0500	time 0.4283 (0.5225)	data time 0.0007 (0.0451)	model time 0.4276 (0.4845)	loss 0.6699 (0.6659)	grad_norm 0.4423 (0.6337)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:31:05 vssm1_tiny_0230s](training.py 212): INFO EPOCH 30 training takes 0:01:21
[2024-11-09 11:31:05 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_30.pth saving......
[2024-11-09 11:31:06 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_30.pth saved !!!
[2024-11-09 11:31:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.275 (2.275)	Loss 0.5249 (0.5249)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:31:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.150 (0.396)	Loss 0.5063 (0.5190)	Acc@1 85.938 (82.102)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:31:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.164 (0.341)	Loss 0.5464 (0.5308)	Acc@1 75.000 (80.990)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:31:16 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.150 (0.326)	Loss 0.6304 (0.5534)	Acc@1 60.938 (76.235)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:31:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 73.780 Acc@5 100.000
[2024-11-09 11:31:18 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 73.8%
[2024-11-09 11:31:18 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 74.02%
[2024-11-09 11:31:21 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.287 (3.287)	Loss 0.5610 (0.5610)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:31:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.154 (0.527)	Loss 0.5654 (0.5608)	Acc@1 97.656 (99.077)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:31:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.180 (0.396)	Loss 0.7915 (0.5787)	Acc@1 10.156 (92.894)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:31:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.171 (0.342)	Loss 0.8052 (0.6502)	Acc@1 8.594 (65.801)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:31:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.620 Acc@5 100.000
[2024-11-09 11:31:31 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.6%
[2024-11-09 11:31:31 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:31:35 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][0/156]	eta 0:10:13 lr 0.000125	 wd 0.0500	time 3.9315 (3.9315)	data time 3.4751 (3.4751)	model time 0.0000 (0.0000)	loss 0.6526 (0.6526)	grad_norm 0.3851 (0.3851)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:31:40 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][10/156]	eta 0:02:00 lr 0.000125	 wd 0.0500	time 0.5591 (0.8255)	data time 0.0019 (0.3230)	model time 0.0000 (0.0000)	loss 0.6710 (0.6688)	grad_norm 0.9050 (0.8442)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:31:45 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][20/156]	eta 0:01:32 lr 0.000125	 wd 0.0500	time 0.5630 (0.6803)	data time 0.0211 (0.1867)	model time 0.0000 (0.0000)	loss 0.6437 (0.6634)	grad_norm 0.4614 (0.7572)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:31:50 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][30/156]	eta 0:01:17 lr 0.000125	 wd 0.0500	time 0.4481 (0.6130)	data time 0.0219 (0.1302)	model time 0.0000 (0.0000)	loss 0.6644 (0.6608)	grad_norm 0.4258 (0.7057)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:31:55 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][40/156]	eta 0:01:07 lr 0.000125	 wd 0.0500	time 0.4635 (0.5848)	data time 0.0192 (0.1035)	model time 0.0000 (0.0000)	loss 0.6597 (0.6610)	grad_norm 0.5959 (0.7138)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:00 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][50/156]	eta 0:01:00 lr 0.000125	 wd 0.0500	time 0.5174 (0.5692)	data time 0.0089 (0.0852)	model time 0.0000 (0.0000)	loss 0.6540 (0.6606)	grad_norm 0.6906 (0.7160)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:05 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][60/156]	eta 0:00:53 lr 0.000124	 wd 0.0500	time 0.5506 (0.5585)	data time 0.0332 (0.0731)	model time 0.5174 (0.4929)	loss 0.6546 (0.6603)	grad_norm 0.7960 (0.6981)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:10 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][70/156]	eta 0:00:48 lr 0.000124	 wd 0.0500	time 0.4236 (0.5586)	data time 0.0160 (0.0654)	model time 0.4076 (0.5169)	loss 0.7072 (0.6607)	grad_norm 0.7651 (0.6972)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:16 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][80/156]	eta 0:00:42 lr 0.000124	 wd 0.0500	time 0.4582 (0.5544)	data time 0.0025 (0.0610)	model time 0.4557 (0.5095)	loss 0.6827 (0.6615)	grad_norm 0.7263 (0.6908)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:20 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][90/156]	eta 0:00:35 lr 0.000124	 wd 0.0500	time 0.4222 (0.5454)	data time 0.0120 (0.0561)	model time 0.4102 (0.4960)	loss 0.6546 (0.6619)	grad_norm 0.3822 (0.6789)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:25 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][100/156]	eta 0:00:30 lr 0.000124	 wd 0.0500	time 0.5876 (0.5421)	data time 0.0171 (0.0530)	model time 0.5705 (0.4943)	loss 0.6685 (0.6628)	grad_norm 0.7780 (0.6823)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:30 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][110/156]	eta 0:00:24 lr 0.000124	 wd 0.0500	time 0.4525 (0.5379)	data time 0.0035 (0.0493)	model time 0.4490 (0.4925)	loss 0.6416 (0.6630)	grad_norm 0.6179 (0.6724)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:36 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][120/156]	eta 0:00:19 lr 0.000124	 wd 0.0500	time 0.5815 (0.5384)	data time 0.0278 (0.0465)	model time 0.5538 (0.4978)	loss 0.6621 (0.6626)	grad_norm 0.5488 (0.6644)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:41 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][130/156]	eta 0:00:14 lr 0.000124	 wd 0.0500	time 0.6558 (0.5386)	data time 0.0351 (0.0442)	model time 0.6207 (0.5011)	loss 0.6499 (0.6629)	grad_norm 0.5174 (0.6556)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:46 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][140/156]	eta 0:00:08 lr 0.000124	 wd 0.0500	time 0.4520 (0.5357)	data time 0.0008 (0.0422)	model time 0.4512 (0.4990)	loss 0.6765 (0.6634)	grad_norm 0.6360 (0.6644)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:51 vssm1_tiny_0230s](training.py 201): INFO Train: [31/300][150/156]	eta 0:00:03 lr 0.000124	 wd 0.0500	time 0.4319 (0.5329)	data time 0.0004 (0.0397)	model time 0.4315 (0.4978)	loss 0.6628 (0.6634)	grad_norm 0.7063 (0.6595)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:32:54 vssm1_tiny_0230s](training.py 212): INFO EPOCH 31 training takes 0:01:23
[2024-11-09 11:32:54 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_31.pth saving......
[2024-11-09 11:32:55 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_31.pth saved !!!
[2024-11-09 11:32:59 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.984 (3.984)	Loss 0.5176 (0.5176)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:33:00 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.525)	Loss 0.5005 (0.5208)	Acc@1 85.156 (83.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:33:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.427)	Loss 0.5269 (0.5299)	Acc@1 72.656 (81.659)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:33:05 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.343)	Loss 0.6108 (0.5454)	Acc@1 63.281 (77.092)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:33:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 74.820 Acc@5 100.000
[2024-11-09 11:33:08 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 74.8%
[2024-11-09 11:33:08 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 74.82%
[2024-11-09 11:33:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.535 (3.535)	Loss 0.5557 (0.5557)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:33:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.139 (0.505)	Loss 0.5601 (0.5558)	Acc@1 97.656 (99.077)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:33:16 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.367)	Loss 0.7949 (0.5743)	Acc@1 11.719 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:33:18 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.315)	Loss 0.8096 (0.6486)	Acc@1 7.812 (65.852)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:33:20 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.700 Acc@5 100.000
[2024-11-09 11:33:20 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.7%
[2024-11-09 11:33:20 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:33:24 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][0/156]	eta 0:10:56 lr 0.000124	 wd 0.0500	time 4.2069 (4.2069)	data time 3.5929 (3.5929)	model time 0.0000 (0.0000)	loss 0.6676 (0.6676)	grad_norm 0.5444 (0.5444)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:33:29 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][10/156]	eta 0:02:04 lr 0.000124	 wd 0.0500	time 0.4267 (0.8558)	data time 0.0006 (0.3465)	model time 0.0000 (0.0000)	loss 0.6380 (0.6700)	grad_norm 0.7750 (0.6986)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:33:34 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][20/156]	eta 0:01:34 lr 0.000124	 wd 0.0500	time 0.4127 (0.6951)	data time 0.0068 (0.1945)	model time 0.0000 (0.0000)	loss 0.6749 (0.6672)	grad_norm 0.5793 (0.6311)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:33:39 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][30/156]	eta 0:01:18 lr 0.000124	 wd 0.0500	time 0.4278 (0.6199)	data time 0.0241 (0.1356)	model time 0.0000 (0.0000)	loss 0.6508 (0.6666)	grad_norm 0.4289 (0.6573)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:33:44 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][40/156]	eta 0:01:07 lr 0.000124	 wd 0.0500	time 0.4296 (0.5847)	data time 0.0008 (0.1063)	model time 0.0000 (0.0000)	loss 0.6357 (0.6663)	grad_norm 0.5020 (0.6819)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:33:48 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][50/156]	eta 0:00:58 lr 0.000124	 wd 0.0500	time 0.4087 (0.5565)	data time 0.0007 (0.0860)	model time 0.0000 (0.0000)	loss 0.6641 (0.6664)	grad_norm 1.0839 (0.6881)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:33:53 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][60/156]	eta 0:00:52 lr 0.000124	 wd 0.0500	time 0.5063 (0.5476)	data time 0.0755 (0.0745)	model time 0.4308 (0.4866)	loss 0.6484 (0.6665)	grad_norm 0.5633 (0.6827)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:33:59 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][70/156]	eta 0:00:47 lr 0.000124	 wd 0.0500	time 0.5008 (0.5466)	data time 0.0205 (0.0663)	model time 0.4802 (0.5054)	loss 0.6494 (0.6667)	grad_norm 0.6722 (0.6731)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:34:04 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][80/156]	eta 0:00:41 lr 0.000124	 wd 0.0500	time 0.5134 (0.5404)	data time 0.0007 (0.0597)	model time 0.5128 (0.4981)	loss 0.6318 (0.6650)	grad_norm 0.8265 (0.6600)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:34:08 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][90/156]	eta 0:00:35 lr 0.000124	 wd 0.0500	time 0.4472 (0.5311)	data time 0.0146 (0.0541)	model time 0.4326 (0.4853)	loss 0.6692 (0.6650)	grad_norm 0.7966 (0.6678)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:34:13 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][100/156]	eta 0:00:29 lr 0.000124	 wd 0.0500	time 0.5450 (0.5298)	data time 0.0512 (0.0507)	model time 0.4938 (0.4879)	loss 0.6509 (0.6642)	grad_norm 0.5996 (0.6775)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:34:18 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][110/156]	eta 0:00:24 lr 0.000124	 wd 0.0500	time 0.5342 (0.5254)	data time 0.0007 (0.0471)	model time 0.5334 (0.4850)	loss 0.6714 (0.6640)	grad_norm 0.4402 (0.6751)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:34:23 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][120/156]	eta 0:00:18 lr 0.000124	 wd 0.0500	time 0.4541 (0.5258)	data time 0.0090 (0.0447)	model time 0.4451 (0.4889)	loss 0.6630 (0.6645)	grad_norm 0.5011 (0.6713)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:34:28 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][130/156]	eta 0:00:13 lr 0.000124	 wd 0.0500	time 0.4363 (0.5240)	data time 0.0018 (0.0419)	model time 0.4345 (0.4895)	loss 0.6499 (0.6630)	grad_norm 0.7916 (0.6680)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:34:33 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][140/156]	eta 0:00:08 lr 0.000124	 wd 0.0500	time 0.4455 (0.5200)	data time 0.0010 (0.0401)	model time 0.4445 (0.4852)	loss 0.6739 (0.6633)	grad_norm 0.5710 (0.6757)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:34:38 vssm1_tiny_0230s](training.py 201): INFO Train: [32/300][150/156]	eta 0:00:03 lr 0.000124	 wd 0.0500	time 0.4155 (0.5188)	data time 0.0006 (0.0375)	model time 0.4149 (0.4869)	loss 0.6687 (0.6631)	grad_norm 0.4606 (0.6733)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:34:41 vssm1_tiny_0230s](training.py 212): INFO EPOCH 32 training takes 0:01:21
[2024-11-09 11:34:41 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_32.pth saving......
[2024-11-09 11:34:42 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_32.pth saved !!!
[2024-11-09 11:34:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.475 (3.475)	Loss 0.6045 (0.6045)	Acc@1 69.531 (69.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:34:47 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.379 (0.510)	Loss 0.5874 (0.6068)	Acc@1 78.906 (71.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:34:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.393)	Loss 0.4502 (0.6015)	Acc@1 82.812 (71.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:34:52 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.144 (0.343)	Loss 0.5156 (0.5662)	Acc@1 72.656 (73.891)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:34:56 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 75.140 Acc@5 100.000
[2024-11-09 11:34:56 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 75.1%
[2024-11-09 11:34:56 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 75.14%
[2024-11-09 11:34:58 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.153 (2.153)	Loss 0.5503 (0.5503)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:35:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.189 (0.527)	Loss 0.5552 (0.5507)	Acc@1 97.656 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:35:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.153 (0.408)	Loss 0.7983 (0.5699)	Acc@1 11.719 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:35:06 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.349)	Loss 0.8135 (0.6468)	Acc@1 7.812 (65.927)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:35:09 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.780 Acc@5 100.000
[2024-11-09 11:35:09 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.8%
[2024-11-09 11:35:09 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:35:14 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][0/156]	eta 0:11:57 lr 0.000124	 wd 0.0500	time 4.6024 (4.6024)	data time 4.1432 (4.1432)	model time 0.0000 (0.0000)	loss 0.6495 (0.6495)	grad_norm 0.8950 (0.8950)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:35:19 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][10/156]	eta 0:02:07 lr 0.000124	 wd 0.0500	time 0.5503 (0.8740)	data time 0.0032 (0.3901)	model time 0.0000 (0.0000)	loss 0.6841 (0.6719)	grad_norm 1.6385 (0.8940)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:35:24 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][20/156]	eta 0:01:35 lr 0.000124	 wd 0.0500	time 0.4536 (0.7024)	data time 0.0007 (0.2182)	model time 0.0000 (0.0000)	loss 0.6250 (0.6653)	grad_norm 0.5750 (0.8541)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:35:29 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][30/156]	eta 0:01:20 lr 0.000124	 wd 0.0500	time 0.5012 (0.6409)	data time 0.0169 (0.1526)	model time 0.0000 (0.0000)	loss 0.6627 (0.6695)	grad_norm 0.6201 (0.9571)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:35:34 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][40/156]	eta 0:01:10 lr 0.000124	 wd 0.0500	time 0.5574 (0.6105)	data time 0.0187 (0.1207)	model time 0.0000 (0.0000)	loss 0.6812 (0.6681)	grad_norm 0.6022 (0.8867)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:35:39 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][50/156]	eta 0:01:02 lr 0.000124	 wd 0.0500	time 0.4854 (0.5875)	data time 0.0240 (0.1002)	model time 0.0000 (0.0000)	loss 0.6043 (0.6661)	grad_norm 0.6890 (0.8124)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:35:44 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][60/156]	eta 0:00:55 lr 0.000124	 wd 0.0500	time 0.4082 (0.5769)	data time 0.0009 (0.0868)	model time 0.4073 (0.5052)	loss 0.6698 (0.6653)	grad_norm 0.3591 (0.7680)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:35:49 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][70/156]	eta 0:00:48 lr 0.000124	 wd 0.0500	time 0.5250 (0.5652)	data time 0.0411 (0.0754)	model time 0.4839 (0.4964)	loss 0.6872 (0.6662)	grad_norm 1.3910 (0.7613)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:35:54 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][80/156]	eta 0:00:42 lr 0.000124	 wd 0.0500	time 0.5180 (0.5562)	data time 0.0069 (0.0678)	model time 0.5111 (0.4904)	loss 0.6234 (0.6650)	grad_norm 0.4460 (0.7405)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:35:59 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][90/156]	eta 0:00:36 lr 0.000124	 wd 0.0500	time 0.4439 (0.5486)	data time 0.0005 (0.0627)	model time 0.4434 (0.4842)	loss 0.6870 (0.6652)	grad_norm 0.6029 (0.7304)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:36:04 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][100/156]	eta 0:00:30 lr 0.000124	 wd 0.0500	time 0.4666 (0.5410)	data time 0.0229 (0.0572)	model time 0.4437 (0.4803)	loss 0.6651 (0.6656)	grad_norm 1.0652 (0.7274)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:36:09 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][110/156]	eta 0:00:24 lr 0.000124	 wd 0.0500	time 0.6962 (0.5410)	data time 0.0378 (0.0534)	model time 0.6584 (0.4879)	loss 0.6750 (0.6656)	grad_norm 0.4185 (0.7004)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:36:14 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][120/156]	eta 0:00:19 lr 0.000124	 wd 0.0500	time 0.4492 (0.5378)	data time 0.0289 (0.0513)	model time 0.4202 (0.4860)	loss 0.6487 (0.6655)	grad_norm 0.6717 (0.6912)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:36:19 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][130/156]	eta 0:00:13 lr 0.000124	 wd 0.0500	time 0.5156 (0.5326)	data time 0.0059 (0.0491)	model time 0.5096 (0.4810)	loss 0.6702 (0.6650)	grad_norm 0.3783 (0.6892)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:36:24 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][140/156]	eta 0:00:08 lr 0.000124	 wd 0.0500	time 0.4400 (0.5308)	data time 0.0007 (0.0466)	model time 0.4393 (0.4824)	loss 0.6513 (0.6646)	grad_norm 0.8193 (0.6864)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:36:29 vssm1_tiny_0230s](training.py 201): INFO Train: [33/300][150/156]	eta 0:00:03 lr 0.000124	 wd 0.0500	time 0.4790 (0.5272)	data time 0.0007 (0.0436)	model time 0.4784 (0.4818)	loss 0.6812 (0.6645)	grad_norm 1.1529 (0.6846)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:36:32 vssm1_tiny_0230s](training.py 212): INFO EPOCH 33 training takes 0:01:22
[2024-11-09 11:36:32 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_33.pth saving......
[2024-11-09 11:36:33 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_33.pth saved !!!
[2024-11-09 11:36:37 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.473 (4.473)	Loss 0.4504 (0.4504)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:36:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.149 (0.568)	Loss 0.4565 (0.4531)	Acc@1 91.406 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:36:41 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.406)	Loss 0.6260 (0.4692)	Acc@1 57.812 (88.951)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:36:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.341)	Loss 0.7109 (0.5343)	Acc@1 51.562 (77.243)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:36:47 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 71.900 Acc@5 100.000
[2024-11-09 11:36:47 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 71.9%
[2024-11-09 11:36:47 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 75.14%
[2024-11-09 11:36:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.077 (4.077)	Loss 0.5459 (0.5459)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:36:54 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.687 (0.554)	Loss 0.5508 (0.5467)	Acc@1 97.656 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:36:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.480)	Loss 0.8008 (0.5663)	Acc@1 11.719 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:36:59 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.152 (0.374)	Loss 0.8169 (0.6453)	Acc@1 7.812 (66.003)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:37:01 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 53.900 Acc@5 100.000
[2024-11-09 11:37:01 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 53.9%
[2024-11-09 11:37:01 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:37:06 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][0/156]	eta 0:13:30 lr 0.000124	 wd 0.0500	time 5.1951 (5.1951)	data time 4.7314 (4.7314)	model time 0.0000 (0.0000)	loss 0.6596 (0.6596)	grad_norm 1.3196 (1.3196)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:37:11 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][10/156]	eta 0:02:15 lr 0.000124	 wd 0.0500	time 0.4588 (0.9261)	data time 0.0009 (0.4409)	model time 0.0000 (0.0000)	loss 0.6679 (0.6557)	grad_norm 0.8449 (0.7639)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:37:16 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][20/156]	eta 0:01:38 lr 0.000124	 wd 0.0500	time 0.5419 (0.7248)	data time 0.0219 (0.2360)	model time 0.0000 (0.0000)	loss 0.6860 (0.6588)	grad_norm 0.4489 (0.7311)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:37:22 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][30/156]	eta 0:01:23 lr 0.000124	 wd 0.0500	time 0.5709 (0.6629)	data time 0.0183 (0.1721)	model time 0.0000 (0.0000)	loss 0.6677 (0.6598)	grad_norm 0.6927 (0.7825)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:37:27 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][40/156]	eta 0:01:11 lr 0.000124	 wd 0.0500	time 0.4102 (0.6203)	data time 0.0057 (0.1320)	model time 0.0000 (0.0000)	loss 0.6372 (0.6611)	grad_norm 0.4406 (0.7403)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:37:31 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][50/156]	eta 0:01:02 lr 0.000124	 wd 0.0500	time 0.4184 (0.5906)	data time 0.0009 (0.1077)	model time 0.0000 (0.0000)	loss 0.6561 (0.6624)	grad_norm 0.3577 (0.7122)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:37:37 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][60/156]	eta 0:00:55 lr 0.000124	 wd 0.0500	time 0.5985 (0.5813)	data time 0.0277 (0.0933)	model time 0.5708 (0.5146)	loss 0.6643 (0.6612)	grad_norm 0.5835 (0.6808)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:37:42 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][70/156]	eta 0:00:49 lr 0.000124	 wd 0.0500	time 0.5288 (0.5716)	data time 0.0211 (0.0819)	model time 0.5076 (0.5072)	loss 0.7036 (0.6612)	grad_norm 0.9747 (0.6889)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:37:47 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][80/156]	eta 0:00:42 lr 0.000124	 wd 0.0500	time 0.4756 (0.5631)	data time 0.0135 (0.0739)	model time 0.4621 (0.5002)	loss 0.6799 (0.6613)	grad_norm 0.3537 (0.6894)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:37:52 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][90/156]	eta 0:00:36 lr 0.000124	 wd 0.0500	time 0.5190 (0.5535)	data time 0.0022 (0.0667)	model time 0.5168 (0.4918)	loss 0.6582 (0.6611)	grad_norm 0.4596 (0.7063)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:37:56 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][100/156]	eta 0:00:30 lr 0.000124	 wd 0.0500	time 0.5830 (0.5458)	data time 0.0288 (0.0613)	model time 0.5542 (0.4860)	loss 0.6513 (0.6615)	grad_norm 1.3001 (0.7227)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:38:01 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][110/156]	eta 0:00:24 lr 0.000124	 wd 0.0500	time 0.4687 (0.5421)	data time 0.0050 (0.0582)	model time 0.4637 (0.4847)	loss 0.6731 (0.6614)	grad_norm 0.5077 (0.7219)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:38:06 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][120/156]	eta 0:00:19 lr 0.000124	 wd 0.0500	time 0.4635 (0.5389)	data time 0.0165 (0.0557)	model time 0.4470 (0.4834)	loss 0.6469 (0.6610)	grad_norm 0.5887 (0.7254)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:38:11 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][130/156]	eta 0:00:13 lr 0.000124	 wd 0.0500	time 0.5246 (0.5348)	data time 0.0303 (0.0523)	model time 0.4943 (0.4823)	loss 0.6938 (0.6618)	grad_norm 0.6956 (0.7338)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:38:16 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][140/156]	eta 0:00:08 lr 0.000124	 wd 0.0500	time 0.4394 (0.5292)	data time 0.0009 (0.0493)	model time 0.4385 (0.4783)	loss 0.6463 (0.6617)	grad_norm 0.5594 (0.7482)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:38:21 vssm1_tiny_0230s](training.py 201): INFO Train: [34/300][150/156]	eta 0:00:03 lr 0.000124	 wd 0.0500	time 0.4692 (0.5278)	data time 0.0005 (0.0460)	model time 0.4687 (0.4813)	loss 0.6210 (0.6618)	grad_norm 0.5477 (0.7490)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:38:24 vssm1_tiny_0230s](training.py 212): INFO EPOCH 34 training takes 0:01:22
[2024-11-09 11:38:24 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_34.pth saving......
[2024-11-09 11:38:24 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_34.pth saved !!!
[2024-11-09 11:38:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.989 (2.989)	Loss 0.5161 (0.5161)	Acc@1 82.031 (82.031)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:38:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.132 (0.580)	Loss 0.4895 (0.5132)	Acc@1 85.938 (83.168)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:38:33 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.427)	Loss 0.5337 (0.5223)	Acc@1 71.875 (82.143)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:38:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.148 (0.388)	Loss 0.6191 (0.5461)	Acc@1 59.375 (76.184)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:38:39 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 73.600 Acc@5 100.000
[2024-11-09 11:38:39 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 73.6%
[2024-11-09 11:38:39 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 75.14%
[2024-11-09 11:38:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.081 (3.081)	Loss 0.5420 (0.5420)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:38:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.185 (0.549)	Loss 0.5469 (0.5427)	Acc@1 97.656 (99.290)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:38:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.409)	Loss 0.8027 (0.5628)	Acc@1 11.719 (93.155)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:38:50 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.365)	Loss 0.8198 (0.6437)	Acc@1 8.594 (66.154)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:38:52 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 54.060 Acc@5 100.000
[2024-11-09 11:38:52 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 54.1%
[2024-11-09 11:38:52 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:38:55 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][0/156]	eta 0:09:00 lr 0.000124	 wd 0.0500	time 3.4665 (3.4665)	data time 3.0267 (3.0267)	model time 0.0000 (0.0000)	loss 0.6407 (0.6407)	grad_norm 0.5852 (0.5852)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:39:00 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][10/156]	eta 0:01:52 lr 0.000124	 wd 0.0500	time 0.5811 (0.7673)	data time 0.0712 (0.2882)	model time 0.0000 (0.0000)	loss 0.6818 (0.6728)	grad_norm 0.9547 (0.7441)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:39:06 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][20/156]	eta 0:01:28 lr 0.000124	 wd 0.0500	time 0.4485 (0.6527)	data time 0.0009 (0.1622)	model time 0.0000 (0.0000)	loss 0.6660 (0.6687)	grad_norm 0.4133 (0.6290)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:39:11 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][30/156]	eta 0:01:16 lr 0.000124	 wd 0.0500	time 0.5303 (0.6088)	data time 0.0047 (0.1150)	model time 0.0000 (0.0000)	loss 0.6674 (0.6688)	grad_norm 0.4566 (0.6054)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:39:16 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][40/156]	eta 0:01:07 lr 0.000124	 wd 0.0500	time 0.4826 (0.5856)	data time 0.0056 (0.0891)	model time 0.0000 (0.0000)	loss 0.6636 (0.6643)	grad_norm 0.5500 (0.5709)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:39:21 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][50/156]	eta 0:00:59 lr 0.000124	 wd 0.0500	time 0.4585 (0.5632)	data time 0.0254 (0.0759)	model time 0.0000 (0.0000)	loss 0.6671 (0.6632)	grad_norm 0.6057 (0.5757)	loss_scale 131072.0000 (77101.1765)	mem 13675MB
[2024-11-09 11:39:26 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][60/156]	eta 0:00:54 lr 0.000124	 wd 0.0500	time 0.5572 (0.5639)	data time 0.0018 (0.0650)	model time 0.5555 (0.5582)	loss 0.7072 (0.6624)	grad_norm 0.5364 (0.5770)	loss_scale 131072.0000 (85948.8525)	mem 13675MB
[2024-11-09 11:39:32 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][70/156]	eta 0:00:47 lr 0.000124	 wd 0.0500	time 0.5304 (0.5571)	data time 0.0222 (0.0605)	model time 0.5082 (0.5203)	loss 0.7145 (0.6623)	grad_norm 1.4290 (0.6031)	loss_scale 131072.0000 (92304.2254)	mem 13675MB
[2024-11-09 11:39:37 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][80/156]	eta 0:00:41 lr 0.000124	 wd 0.0500	time 0.6183 (0.5506)	data time 0.0302 (0.0556)	model time 0.5881 (0.5081)	loss 0.6805 (0.6625)	grad_norm 1.0661 (0.6290)	loss_scale 131072.0000 (97090.3704)	mem 13675MB
[2024-11-09 11:39:42 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][90/156]	eta 0:00:36 lr 0.000124	 wd 0.0500	time 0.5649 (0.5473)	data time 0.0230 (0.0511)	model time 0.5419 (0.5075)	loss 0.6536 (0.6614)	grad_norm 0.4018 (0.6200)	loss_scale 131072.0000 (100824.6154)	mem 13675MB
[2024-11-09 11:39:47 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][100/156]	eta 0:00:30 lr 0.000124	 wd 0.0500	time 0.5291 (0.5434)	data time 0.0066 (0.0485)	model time 0.5225 (0.5025)	loss 0.6722 (0.6617)	grad_norm 0.5046 (0.6291)	loss_scale 131072.0000 (103819.4059)	mem 13675MB
[2024-11-09 11:39:52 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][110/156]	eta 0:00:24 lr 0.000124	 wd 0.0500	time 0.4775 (0.5391)	data time 0.0581 (0.0456)	model time 0.4194 (0.4989)	loss 0.6039 (0.6616)	grad_norm 0.7408 (0.6288)	loss_scale 131072.0000 (106274.5946)	mem 13675MB
[2024-11-09 11:39:57 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][120/156]	eta 0:00:19 lr 0.000124	 wd 0.0500	time 0.5949 (0.5388)	data time 0.0016 (0.0437)	model time 0.5933 (0.5008)	loss 0.6902 (0.6619)	grad_norm 0.9259 (0.6337)	loss_scale 131072.0000 (108323.9669)	mem 13675MB
[2024-11-09 11:40:02 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][130/156]	eta 0:00:13 lr 0.000124	 wd 0.0500	time 0.5830 (0.5381)	data time 0.0016 (0.0411)	model time 0.5814 (0.5031)	loss 0.6565 (0.6616)	grad_norm 0.6817 (0.6331)	loss_scale 131072.0000 (110060.4580)	mem 13675MB
[2024-11-09 11:40:08 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][140/156]	eta 0:00:08 lr 0.000124	 wd 0.0500	time 0.4196 (0.5361)	data time 0.0008 (0.0391)	model time 0.4188 (0.5025)	loss 0.6296 (0.6612)	grad_norm 1.0570 (0.6462)	loss_scale 131072.0000 (111550.6383)	mem 13675MB
[2024-11-09 11:40:12 vssm1_tiny_0230s](training.py 201): INFO Train: [35/300][150/156]	eta 0:00:03 lr 0.000124	 wd 0.0500	time 0.5987 (0.5332)	data time 0.0005 (0.0366)	model time 0.5982 (0.5012)	loss 0.6283 (0.6612)	grad_norm 0.7549 (0.6650)	loss_scale 131072.0000 (112843.4437)	mem 13675MB
[2024-11-09 11:40:16 vssm1_tiny_0230s](training.py 212): INFO EPOCH 35 training takes 0:01:23
[2024-11-09 11:40:16 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_35.pth saving......
[2024-11-09 11:40:17 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_35.pth saved !!!
[2024-11-09 11:40:19 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.646 (2.646)	Loss 0.5562 (0.5562)	Acc@1 80.469 (80.469)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:40:23 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.615 (0.525)	Loss 0.5405 (0.5502)	Acc@1 82.031 (79.190)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:40:25 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.177 (0.416)	Loss 0.4780 (0.5538)	Acc@1 79.688 (78.646)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:40:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.369)	Loss 0.5615 (0.5472)	Acc@1 64.844 (76.512)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:40:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 75.300 Acc@5 100.000
[2024-11-09 11:40:31 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 75.3%
[2024-11-09 11:40:31 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 75.30%
[2024-11-09 11:40:33 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.530 (2.530)	Loss 0.5386 (0.5386)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:40:36 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.252 (0.461)	Loss 0.5439 (0.5396)	Acc@1 97.656 (99.290)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:40:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.351)	Loss 0.8042 (0.5600)	Acc@1 12.500 (93.192)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:40:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.143 (0.318)	Loss 0.8218 (0.6423)	Acc@1 8.594 (66.255)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:40:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 54.180 Acc@5 100.000
[2024-11-09 11:40:43 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 54.2%
[2024-11-09 11:40:43 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:40:47 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][0/156]	eta 0:10:34 lr 0.000124	 wd 0.0500	time 4.0683 (4.0683)	data time 3.5581 (3.5581)	model time 0.0000 (0.0000)	loss 0.6672 (0.6672)	grad_norm 0.5739 (0.5739)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:40:52 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][10/156]	eta 0:01:59 lr 0.000124	 wd 0.0500	time 0.4125 (0.8170)	data time 0.0061 (0.3456)	model time 0.0000 (0.0000)	loss 0.6918 (0.6589)	grad_norm 0.6654 (0.7080)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:40:58 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][20/156]	eta 0:01:37 lr 0.000124	 wd 0.0500	time 0.4366 (0.7194)	data time 0.0065 (0.1874)	model time 0.0000 (0.0000)	loss 0.6254 (0.6602)	grad_norm 0.6586 (0.7109)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:04 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][30/156]	eta 0:01:23 lr 0.000124	 wd 0.0500	time 0.5207 (0.6611)	data time 0.0009 (0.1306)	model time 0.0000 (0.0000)	loss 0.6641 (0.6614)	grad_norm 1.4568 (0.7342)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:09 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][40/156]	eta 0:01:13 lr 0.000124	 wd 0.0500	time 0.4481 (0.6309)	data time 0.0214 (0.1053)	model time 0.0000 (0.0000)	loss 0.6291 (0.6622)	grad_norm 0.8837 (0.7365)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:14 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][50/156]	eta 0:01:04 lr 0.000124	 wd 0.0500	time 0.4655 (0.6100)	data time 0.0142 (0.0877)	model time 0.0000 (0.0000)	loss 0.6332 (0.6614)	grad_norm 0.4645 (0.7017)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:19 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][60/156]	eta 0:00:56 lr 0.000124	 wd 0.0500	time 0.4662 (0.5910)	data time 0.0467 (0.0760)	model time 0.4194 (0.4780)	loss 0.6547 (0.6614)	grad_norm 0.7522 (0.6877)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:25 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][70/156]	eta 0:00:50 lr 0.000124	 wd 0.0500	time 0.5298 (0.5822)	data time 0.0049 (0.0675)	model time 0.5249 (0.4955)	loss 0.6458 (0.6611)	grad_norm 0.4313 (0.6762)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:30 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][80/156]	eta 0:00:44 lr 0.000124	 wd 0.0500	time 0.8031 (0.5804)	data time 0.0079 (0.0612)	model time 0.7952 (0.5138)	loss 0.6613 (0.6607)	grad_norm 0.4063 (0.6781)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:35 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][90/156]	eta 0:00:37 lr 0.000124	 wd 0.0500	time 0.5807 (0.5709)	data time 0.0955 (0.0574)	model time 0.4852 (0.5022)	loss 0.6290 (0.6597)	grad_norm 0.7645 (0.6964)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:40 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][100/156]	eta 0:00:31 lr 0.000124	 wd 0.0500	time 0.5136 (0.5671)	data time 0.0179 (0.0537)	model time 0.4957 (0.5044)	loss 0.6436 (0.6589)	grad_norm 0.8692 (0.7172)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:46 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][110/156]	eta 0:00:25 lr 0.000124	 wd 0.0500	time 0.5011 (0.5628)	data time 0.0013 (0.0499)	model time 0.4998 (0.5050)	loss 0.6678 (0.6587)	grad_norm 0.6534 (0.7389)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:51 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][120/156]	eta 0:00:20 lr 0.000124	 wd 0.0500	time 0.5492 (0.5601)	data time 0.0781 (0.0499)	model time 0.4711 (0.5014)	loss 0.6545 (0.6597)	grad_norm 0.7241 (0.7747)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:41:56 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][130/156]	eta 0:00:14 lr 0.000124	 wd 0.0500	time 0.5585 (0.5580)	data time 0.0165 (0.0483)	model time 0.5420 (0.5018)	loss 0.6530 (0.6596)	grad_norm 0.5546 (0.7604)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:42:01 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][140/156]	eta 0:00:08 lr 0.000124	 wd 0.0500	time 0.4822 (0.5537)	data time 0.0007 (0.0452)	model time 0.4815 (0.5007)	loss 0.6656 (0.6598)	grad_norm 0.4753 (0.7412)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:42:06 vssm1_tiny_0230s](training.py 201): INFO Train: [36/300][150/156]	eta 0:00:03 lr 0.000124	 wd 0.0500	time 0.4414 (0.5499)	data time 0.0004 (0.0424)	model time 0.4410 (0.4999)	loss 0.6718 (0.6605)	grad_norm 0.7200 (0.7328)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:42:09 vssm1_tiny_0230s](training.py 212): INFO EPOCH 36 training takes 0:01:25
[2024-11-09 11:42:09 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_36.pth saving......
[2024-11-09 11:42:09 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_36.pth saved !!!
[2024-11-09 11:42:12 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.424 (2.424)	Loss 0.4746 (0.4746)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:42:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.155 (0.416)	Loss 0.4485 (0.4698)	Acc@1 91.406 (88.494)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:42:16 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.312)	Loss 0.5947 (0.4862)	Acc@1 64.844 (85.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:42:18 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.152 (0.265)	Loss 0.6763 (0.5427)	Acc@1 53.125 (76.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:42:19 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 72.320 Acc@5 100.000
[2024-11-09 11:42:19 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 72.3%
[2024-11-09 11:42:19 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 75.30%
[2024-11-09 11:42:21 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.534 (1.534)	Loss 0.5347 (0.5347)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:42:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.274)	Loss 0.5400 (0.5360)	Acc@1 98.438 (99.432)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:42:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.211)	Loss 0.8057 (0.5568)	Acc@1 12.500 (93.266)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:42:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.147 (0.189)	Loss 0.8237 (0.6407)	Acc@1 8.594 (66.356)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:42:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 54.340 Acc@5 100.000
[2024-11-09 11:42:27 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 54.3%
[2024-11-09 11:42:27 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:42:31 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][0/156]	eta 0:09:38 lr 0.000124	 wd 0.0500	time 3.7100 (3.7100)	data time 3.2576 (3.2576)	model time 0.0000 (0.0000)	loss 0.6729 (0.6729)	grad_norm 1.1838 (1.1838)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:42:36 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][10/156]	eta 0:01:56 lr 0.000124	 wd 0.0500	time 0.7114 (0.7974)	data time 0.0221 (0.3082)	model time 0.0000 (0.0000)	loss 0.6447 (0.6619)	grad_norm 0.7055 (0.6786)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:42:41 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][20/156]	eta 0:01:29 lr 0.000124	 wd 0.0500	time 0.5893 (0.6603)	data time 0.0186 (0.1667)	model time 0.0000 (0.0000)	loss 0.6579 (0.6590)	grad_norm 0.5859 (0.6687)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:42:46 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][30/156]	eta 0:01:16 lr 0.000124	 wd 0.0500	time 0.5458 (0.6072)	data time 0.0011 (0.1168)	model time 0.0000 (0.0000)	loss 0.6427 (0.6568)	grad_norm 0.4803 (0.6727)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:42:51 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][40/156]	eta 0:01:08 lr 0.000124	 wd 0.0500	time 0.5837 (0.5914)	data time 0.0078 (0.0949)	model time 0.0000 (0.0000)	loss 0.6435 (0.6573)	grad_norm 0.9697 (0.6860)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:42:56 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][50/156]	eta 0:01:00 lr 0.000124	 wd 0.0500	time 0.5089 (0.5689)	data time 0.0149 (0.0780)	model time 0.0000 (0.0000)	loss 0.6533 (0.6583)	grad_norm 0.6806 (0.6940)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:01 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][60/156]	eta 0:00:53 lr 0.000124	 wd 0.0500	time 0.5351 (0.5581)	data time 0.0055 (0.0667)	model time 0.5296 (0.4939)	loss 0.6471 (0.6583)	grad_norm 0.8292 (0.7032)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:06 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][70/156]	eta 0:00:47 lr 0.000124	 wd 0.0500	time 0.4494 (0.5490)	data time 0.0221 (0.0598)	model time 0.4273 (0.4851)	loss 0.6644 (0.6582)	grad_norm 0.4869 (0.6908)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:11 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][80/156]	eta 0:00:41 lr 0.000124	 wd 0.0500	time 0.5598 (0.5463)	data time 0.0240 (0.0537)	model time 0.5357 (0.4956)	loss 0.6725 (0.6580)	grad_norm 0.8437 (0.6904)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:16 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][90/156]	eta 0:00:35 lr 0.000124	 wd 0.0500	time 0.5239 (0.5441)	data time 0.0111 (0.0505)	model time 0.5128 (0.4971)	loss 0.6786 (0.6584)	grad_norm 0.6473 (0.6898)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:22 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][100/156]	eta 0:00:30 lr 0.000124	 wd 0.0500	time 0.4377 (0.5450)	data time 0.0261 (0.0481)	model time 0.4115 (0.5030)	loss 0.6536 (0.6595)	grad_norm 0.5296 (0.6975)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:28 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][110/156]	eta 0:00:25 lr 0.000124	 wd 0.0500	time 0.4842 (0.5467)	data time 0.0023 (0.0456)	model time 0.4819 (0.5096)	loss 0.6698 (0.6610)	grad_norm 0.8716 (0.6937)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:33 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][120/156]	eta 0:00:19 lr 0.000124	 wd 0.0500	time 0.7566 (0.5478)	data time 0.0234 (0.0432)	model time 0.7332 (0.5145)	loss 0.6588 (0.6604)	grad_norm 1.1653 (0.6908)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:38 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][130/156]	eta 0:00:14 lr 0.000124	 wd 0.0500	time 0.5910 (0.5439)	data time 0.0019 (0.0404)	model time 0.5891 (0.5115)	loss 0.6810 (0.6588)	grad_norm 0.7819 (0.6982)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:43 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][140/156]	eta 0:00:08 lr 0.000124	 wd 0.0500	time 0.4348 (0.5382)	data time 0.0007 (0.0385)	model time 0.4341 (0.5047)	loss 0.6820 (0.6589)	grad_norm 1.1621 (0.7057)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:47 vssm1_tiny_0230s](training.py 201): INFO Train: [37/300][150/156]	eta 0:00:03 lr 0.000124	 wd 0.0500	time 0.5371 (0.5323)	data time 0.0006 (0.0360)	model time 0.5365 (0.4991)	loss 0.6478 (0.6591)	grad_norm 0.4758 (0.7063)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:43:50 vssm1_tiny_0230s](training.py 212): INFO EPOCH 37 training takes 0:01:22
[2024-11-09 11:43:50 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_37.pth saving......
[2024-11-09 11:43:50 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_37.pth saved !!!
[2024-11-09 11:43:54 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.720 (3.720)	Loss 0.4763 (0.4763)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:43:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.570)	Loss 0.4731 (0.4774)	Acc@1 86.719 (87.074)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:43:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.419)	Loss 0.5356 (0.4867)	Acc@1 67.969 (85.789)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:44:02 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.379)	Loss 0.6167 (0.5174)	Acc@1 62.500 (79.637)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:44:05 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 76.580 Acc@5 100.000
[2024-11-09 11:44:05 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 76.6%
[2024-11-09 11:44:05 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 76.58%
[2024-11-09 11:44:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.990 (2.990)	Loss 0.5308 (0.5308)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:44:11 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.131 (0.583)	Loss 0.5366 (0.5327)	Acc@1 99.219 (99.432)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:44:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.420)	Loss 0.8066 (0.5538)	Acc@1 13.281 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:44:16 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.355)	Loss 0.8257 (0.6391)	Acc@1 10.938 (66.608)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:44:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 54.580 Acc@5 100.000
[2024-11-09 11:44:18 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 54.6%
[2024-11-09 11:44:18 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:44:21 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][0/156]	eta 0:09:47 lr 0.000124	 wd 0.0500	time 3.7675 (3.7675)	data time 3.2829 (3.2829)	model time 0.0000 (0.0000)	loss 0.6593 (0.6593)	grad_norm 0.6520 (0.6520)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:44:27 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][10/156]	eta 0:02:05 lr 0.000124	 wd 0.0500	time 0.4266 (0.8568)	data time 0.0007 (0.3372)	model time 0.0000 (0.0000)	loss 0.6554 (0.6619)	grad_norm 0.4869 (0.7499)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:44:32 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][20/156]	eta 0:01:32 lr 0.000124	 wd 0.0500	time 0.4986 (0.6812)	data time 0.0200 (0.1844)	model time 0.0000 (0.0000)	loss 0.6771 (0.6633)	grad_norm 0.4426 (0.7063)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:44:37 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][30/156]	eta 0:01:18 lr 0.000124	 wd 0.0500	time 0.4160 (0.6248)	data time 0.0094 (0.1321)	model time 0.0000 (0.0000)	loss 0.6531 (0.6600)	grad_norm 0.6817 (0.7235)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:44:42 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][40/156]	eta 0:01:08 lr 0.000124	 wd 0.0500	time 0.5495 (0.5910)	data time 0.0007 (0.1027)	model time 0.0000 (0.0000)	loss 0.6505 (0.6614)	grad_norm 0.5686 (0.7026)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:44:47 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][50/156]	eta 0:01:01 lr 0.000124	 wd 0.0500	time 0.4192 (0.5795)	data time 0.0124 (0.0866)	model time 0.0000 (0.0000)	loss 0.6913 (0.6603)	grad_norm 1.2955 (0.7268)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:44:53 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][60/156]	eta 0:00:55 lr 0.000124	 wd 0.0500	time 0.4618 (0.5748)	data time 0.0274 (0.0793)	model time 0.4343 (0.5088)	loss 0.6887 (0.6592)	grad_norm 0.8265 (0.7280)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:44:58 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][70/156]	eta 0:00:48 lr 0.000124	 wd 0.0500	time 0.5832 (0.5669)	data time 0.0193 (0.0703)	model time 0.5638 (0.5062)	loss 0.6613 (0.6582)	grad_norm 1.4293 (0.7611)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:45:03 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][80/156]	eta 0:00:42 lr 0.000124	 wd 0.0500	time 0.4474 (0.5601)	data time 0.0010 (0.0633)	model time 0.4464 (0.5035)	loss 0.6481 (0.6578)	grad_norm 0.5758 (0.7517)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:45:08 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][90/156]	eta 0:00:36 lr 0.000124	 wd 0.0500	time 0.4922 (0.5572)	data time 0.0331 (0.0580)	model time 0.4591 (0.5071)	loss 0.6554 (0.6567)	grad_norm 0.8762 (0.7536)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:45:14 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][100/156]	eta 0:00:31 lr 0.000124	 wd 0.0500	time 0.5299 (0.5536)	data time 0.0392 (0.0549)	model time 0.4906 (0.5047)	loss 0.6450 (0.6573)	grad_norm 0.5680 (0.7782)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:45:19 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][110/156]	eta 0:00:25 lr 0.000124	 wd 0.0500	time 0.6120 (0.5514)	data time 0.0265 (0.0515)	model time 0.5855 (0.5059)	loss 0.6313 (0.6565)	grad_norm 0.6640 (0.7848)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:45:24 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][120/156]	eta 0:00:19 lr 0.000124	 wd 0.0500	time 0.4154 (0.5459)	data time 0.0038 (0.0480)	model time 0.4117 (0.5015)	loss 0.6217 (0.6567)	grad_norm 0.9348 (0.8152)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:45:29 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][130/156]	eta 0:00:14 lr 0.000124	 wd 0.0500	time 0.4704 (0.5445)	data time 0.0208 (0.0457)	model time 0.4496 (0.5026)	loss 0.6212 (0.6565)	grad_norm 0.7890 (0.7998)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:45:34 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][140/156]	eta 0:00:08 lr 0.000124	 wd 0.0500	time 0.4976 (0.5439)	data time 0.0092 (0.0443)	model time 0.4884 (0.5033)	loss 0.6773 (0.6572)	grad_norm 0.7333 (0.7885)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:45:39 vssm1_tiny_0230s](training.py 201): INFO Train: [38/300][150/156]	eta 0:00:03 lr 0.000124	 wd 0.0500	time 0.4692 (0.5407)	data time 0.0005 (0.0414)	model time 0.4688 (0.5025)	loss 0.6308 (0.6572)	grad_norm 0.5977 (0.7837)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:45:42 vssm1_tiny_0230s](training.py 212): INFO EPOCH 38 training takes 0:01:24
[2024-11-09 11:45:42 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_38.pth saving......
[2024-11-09 11:45:43 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_38.pth saved !!!
[2024-11-09 11:45:46 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.607 (3.607)	Loss 0.6230 (0.6230)	Acc@1 67.188 (67.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:45:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.147 (0.529)	Loss 0.6021 (0.6314)	Acc@1 74.219 (67.330)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:45:52 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.436)	Loss 0.4111 (0.6227)	Acc@1 91.406 (68.564)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:45:54 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.144 (0.361)	Loss 0.4829 (0.5700)	Acc@1 75.000 (73.034)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:45:56 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 75.040 Acc@5 100.000
[2024-11-09 11:45:56 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 75.0%
[2024-11-09 11:45:56 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 76.58%
[2024-11-09 11:46:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.820 (3.820)	Loss 0.5273 (0.5273)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:46:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.356 (0.605)	Loss 0.5332 (0.5293)	Acc@1 100.000 (99.432)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:46:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.158 (0.418)	Loss 0.8081 (0.5507)	Acc@1 14.062 (93.341)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:46:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.148 (0.359)	Loss 0.8276 (0.6375)	Acc@1 10.938 (66.734)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:46:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 54.720 Acc@5 100.000
[2024-11-09 11:46:10 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 54.7%
[2024-11-09 11:46:10 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:46:13 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][0/156]	eta 0:10:06 lr 0.000124	 wd 0.0500	time 3.8896 (3.8896)	data time 3.3955 (3.3955)	model time 0.0000 (0.0000)	loss 0.6103 (0.6103)	grad_norm 0.4449 (0.4449)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:46:19 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][10/156]	eta 0:02:00 lr 0.000124	 wd 0.0500	time 0.4496 (0.8224)	data time 0.0007 (0.3574)	model time 0.0000 (0.0000)	loss 0.6629 (0.6529)	grad_norm 0.8562 (0.6255)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:46:24 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][20/156]	eta 0:01:33 lr 0.000124	 wd 0.0500	time 0.5326 (0.6910)	data time 0.0141 (0.1965)	model time 0.0000 (0.0000)	loss 0.6072 (0.6506)	grad_norm 0.6864 (0.7476)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:46:29 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][30/156]	eta 0:01:18 lr 0.000124	 wd 0.0500	time 0.4945 (0.6260)	data time 0.0249 (0.1409)	model time 0.0000 (0.0000)	loss 0.7030 (0.6504)	grad_norm 1.7584 (0.9191)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:46:34 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][40/156]	eta 0:01:08 lr 0.000124	 wd 0.0500	time 0.4457 (0.5912)	data time 0.0149 (0.1127)	model time 0.0000 (0.0000)	loss 0.6881 (0.6525)	grad_norm 0.6728 (0.9483)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:46:38 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][50/156]	eta 0:01:00 lr 0.000124	 wd 0.0500	time 0.4504 (0.5661)	data time 0.0009 (0.0921)	model time 0.0000 (0.0000)	loss 0.6706 (0.6536)	grad_norm 1.0636 (0.9226)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:46:44 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][60/156]	eta 0:00:53 lr 0.000124	 wd 0.0500	time 0.4882 (0.5608)	data time 0.0020 (0.0806)	model time 0.4862 (0.5117)	loss 0.6632 (0.6536)	grad_norm 0.5724 (0.9266)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:46:49 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][70/156]	eta 0:00:47 lr 0.000124	 wd 0.0500	time 0.5477 (0.5521)	data time 0.0018 (0.0716)	model time 0.5459 (0.4971)	loss 0.6767 (0.6551)	grad_norm 0.4557 (0.8940)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:46:54 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][80/156]	eta 0:00:41 lr 0.000124	 wd 0.0500	time 0.5597 (0.5485)	data time 0.0308 (0.0644)	model time 0.5290 (0.5013)	loss 0.6811 (0.6548)	grad_norm 0.8204 (0.8781)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:46:59 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][90/156]	eta 0:00:35 lr 0.000124	 wd 0.0500	time 0.6600 (0.5452)	data time 0.1600 (0.0611)	model time 0.5000 (0.4970)	loss 0.6384 (0.6554)	grad_norm 0.8974 (0.8670)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:47:04 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][100/156]	eta 0:00:30 lr 0.000124	 wd 0.0500	time 0.4849 (0.5382)	data time 0.0115 (0.0558)	model time 0.4733 (0.4908)	loss 0.6872 (0.6550)	grad_norm 0.8072 (0.8515)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:47:09 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][110/156]	eta 0:00:24 lr 0.000123	 wd 0.0500	time 0.4736 (0.5372)	data time 0.0437 (0.0526)	model time 0.4300 (0.4935)	loss 0.6331 (0.6546)	grad_norm 0.7998 (0.8308)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:47:15 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][120/156]	eta 0:00:19 lr 0.000123	 wd 0.0500	time 0.6178 (0.5370)	data time 0.0009 (0.0499)	model time 0.6169 (0.4967)	loss 0.6220 (0.6553)	grad_norm 0.8881 (0.8275)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:47:20 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][130/156]	eta 0:00:13 lr 0.000123	 wd 0.0500	time 0.5605 (0.5353)	data time 0.0180 (0.0480)	model time 0.5425 (0.4958)	loss 0.6547 (0.6549)	grad_norm 0.7109 (0.8214)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:47:25 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][140/156]	eta 0:00:08 lr 0.000123	 wd 0.0500	time 0.5524 (0.5344)	data time 0.0009 (0.0460)	model time 0.5514 (0.4966)	loss 0.6632 (0.6557)	grad_norm 1.2892 (0.8232)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:47:29 vssm1_tiny_0230s](training.py 201): INFO Train: [39/300][150/156]	eta 0:00:03 lr 0.000123	 wd 0.0500	time 0.5079 (0.5292)	data time 0.0010 (0.0430)	model time 0.5070 (0.4925)	loss 0.6512 (0.6551)	grad_norm 0.7929 (0.8221)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:47:32 vssm1_tiny_0230s](training.py 212): INFO EPOCH 39 training takes 0:01:22
[2024-11-09 11:47:32 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_39.pth saving......
[2024-11-09 11:47:33 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_39.pth saved !!!
[2024-11-09 11:47:36 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.256 (3.256)	Loss 0.6284 (0.6284)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:47:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.962 (0.527)	Loss 0.6274 (0.6362)	Acc@1 68.750 (65.909)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:47:41 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.157 (0.394)	Loss 0.3765 (0.6236)	Acc@1 92.969 (67.411)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:47:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.345)	Loss 0.4536 (0.5579)	Acc@1 80.469 (73.513)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:47:47 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 76.360 Acc@5 100.000
[2024-11-09 11:47:47 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 76.4%
[2024-11-09 11:47:47 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 76.58%
[2024-11-09 11:47:50 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.516 (3.516)	Loss 0.5234 (0.5234)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:47:54 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.980 (0.658)	Loss 0.5298 (0.5254)	Acc@1 100.000 (99.432)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:47:57 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.181 (0.470)	Loss 0.8096 (0.5473)	Acc@1 14.844 (93.341)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:47:59 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.163 (0.402)	Loss 0.8306 (0.6359)	Acc@1 11.719 (66.809)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:48:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 54.820 Acc@5 100.000
[2024-11-09 11:48:02 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 54.8%
[2024-11-09 11:48:02 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:48:06 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][0/156]	eta 0:10:00 lr 0.000123	 wd 0.0500	time 3.8511 (3.8511)	data time 3.3797 (3.3797)	model time 0.0000 (0.0000)	loss 0.6544 (0.6544)	grad_norm 0.7596 (0.7596)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:48:11 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][10/156]	eta 0:02:02 lr 0.000123	 wd 0.0500	time 0.4240 (0.8404)	data time 0.0014 (0.3407)	model time 0.0000 (0.0000)	loss 0.6396 (0.6558)	grad_norm 0.7732 (0.7539)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:48:17 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][20/156]	eta 0:01:34 lr 0.000123	 wd 0.0500	time 0.4509 (0.6938)	data time 0.0082 (0.1992)	model time 0.0000 (0.0000)	loss 0.6854 (0.6581)	grad_norm 0.6509 (0.7419)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:48:21 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][30/156]	eta 0:01:17 lr 0.000123	 wd 0.0500	time 0.4635 (0.6184)	data time 0.0025 (0.1378)	model time 0.0000 (0.0000)	loss 0.6488 (0.6649)	grad_norm 0.8454 (0.7640)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:48:26 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][40/156]	eta 0:01:07 lr 0.000123	 wd 0.0500	time 0.4907 (0.5854)	data time 0.0043 (0.1070)	model time 0.0000 (0.0000)	loss 0.6807 (0.6625)	grad_norm 0.6583 (0.7451)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:48:31 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][50/156]	eta 0:00:59 lr 0.000123	 wd 0.0500	time 0.4361 (0.5629)	data time 0.0260 (0.0891)	model time 0.0000 (0.0000)	loss 0.6555 (0.6610)	grad_norm 0.7273 (0.7430)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:48:36 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][60/156]	eta 0:00:52 lr 0.000123	 wd 0.0500	time 0.5259 (0.5485)	data time 0.0425 (0.0768)	model time 0.4834 (0.4606)	loss 0.7022 (0.6630)	grad_norm 1.0736 (0.7535)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:48:40 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][70/156]	eta 0:00:46 lr 0.000123	 wd 0.0500	time 0.4417 (0.5386)	data time 0.0302 (0.0684)	model time 0.4115 (0.4610)	loss 0.6874 (0.6630)	grad_norm 0.7386 (0.7441)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:48:45 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][80/156]	eta 0:00:40 lr 0.000123	 wd 0.0500	time 0.4908 (0.5302)	data time 0.0206 (0.0614)	model time 0.4703 (0.4602)	loss 0.6617 (0.6619)	grad_norm 1.0430 (0.7356)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:48:50 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][90/156]	eta 0:00:34 lr 0.000123	 wd 0.0500	time 0.4321 (0.5278)	data time 0.0233 (0.0577)	model time 0.4088 (0.4653)	loss 0.6542 (0.6611)	grad_norm 0.6139 (0.7272)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:48:55 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][100/156]	eta 0:00:29 lr 0.000123	 wd 0.0500	time 0.4510 (0.5230)	data time 0.0132 (0.0535)	model time 0.4377 (0.4652)	loss 0.6317 (0.6601)	grad_norm 0.7953 (0.7264)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:49:00 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][110/156]	eta 0:00:23 lr 0.000123	 wd 0.0500	time 0.4667 (0.5194)	data time 0.0015 (0.0496)	model time 0.4653 (0.4664)	loss 0.6403 (0.6597)	grad_norm 0.4506 (0.7316)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:49:05 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][120/156]	eta 0:00:18 lr 0.000123	 wd 0.0500	time 0.4878 (0.5192)	data time 0.0019 (0.0470)	model time 0.4859 (0.4709)	loss 0.6823 (0.6596)	grad_norm 0.5631 (0.7319)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:49:10 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][130/156]	eta 0:00:13 lr 0.000123	 wd 0.0500	time 0.5087 (0.5160)	data time 0.0510 (0.0454)	model time 0.4577 (0.4686)	loss 0.6779 (0.6596)	grad_norm 0.4128 (0.7333)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:49:15 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][140/156]	eta 0:00:08 lr 0.000123	 wd 0.0500	time 0.4749 (0.5139)	data time 0.0008 (0.0427)	model time 0.4742 (0.4696)	loss 0.6650 (0.6600)	grad_norm 0.6190 (0.7393)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:49:19 vssm1_tiny_0230s](training.py 201): INFO Train: [40/300][150/156]	eta 0:00:03 lr 0.000123	 wd 0.0500	time 0.4285 (0.5094)	data time 0.0005 (0.0399)	model time 0.4280 (0.4672)	loss 0.6444 (0.6598)	grad_norm 0.8341 (0.7355)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:49:22 vssm1_tiny_0230s](training.py 212): INFO EPOCH 40 training takes 0:01:19
[2024-11-09 11:49:22 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_40.pth saving......
[2024-11-09 11:49:22 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_40.pth saved !!!
[2024-11-09 11:49:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.886 (4.886)	Loss 0.5942 (0.5942)	Acc@1 67.969 (67.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:49:29 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.581)	Loss 0.5713 (0.5991)	Acc@1 74.219 (70.384)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:49:31 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.184 (0.404)	Loss 0.3982 (0.5951)	Acc@1 89.844 (71.652)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:49:33 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.347)	Loss 0.4792 (0.5514)	Acc@1 75.000 (74.345)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:49:36 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 75.440 Acc@5 100.000
[2024-11-09 11:49:36 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 75.4%
[2024-11-09 11:49:36 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 76.58%
[2024-11-09 11:49:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.162 (3.162)	Loss 0.5190 (0.5190)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:49:42 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.217 (0.479)	Loss 0.5254 (0.5214)	Acc@1 100.000 (99.432)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:49:44 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.370)	Loss 0.8115 (0.5437)	Acc@1 14.844 (93.341)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:49:47 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.340)	Loss 0.8330 (0.6342)	Acc@1 11.719 (66.986)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:49:50 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.040 Acc@5 100.000
[2024-11-09 11:49:50 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.0%
[2024-11-09 11:49:50 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:49:55 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][0/156]	eta 0:11:58 lr 0.000123	 wd 0.0500	time 4.6057 (4.6057)	data time 4.0215 (4.0215)	model time 0.0000 (0.0000)	loss 0.6773 (0.6773)	grad_norm 0.4537 (0.4537)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:50:00 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][10/156]	eta 0:02:11 lr 0.000123	 wd 0.0500	time 0.4945 (0.9003)	data time 0.0160 (0.4223)	model time 0.0000 (0.0000)	loss 0.6223 (0.6491)	grad_norm 1.0716 (0.8047)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:50:05 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][20/156]	eta 0:01:37 lr 0.000123	 wd 0.0500	time 0.4732 (0.7177)	data time 0.0059 (0.2254)	model time 0.0000 (0.0000)	loss 0.6652 (0.6538)	grad_norm 0.9231 (0.8631)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:50:11 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][30/156]	eta 0:01:23 lr 0.000123	 wd 0.0500	time 0.7063 (0.6618)	data time 0.0730 (0.1582)	model time 0.0000 (0.0000)	loss 0.6464 (0.6544)	grad_norm 0.5637 (0.8420)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:50:16 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][40/156]	eta 0:01:13 lr 0.000123	 wd 0.0500	time 0.5550 (0.6306)	data time 0.0191 (0.1228)	model time 0.0000 (0.0000)	loss 0.6475 (0.6525)	grad_norm 0.5654 (0.8382)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:50:21 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][50/156]	eta 0:01:03 lr 0.000123	 wd 0.0500	time 0.5275 (0.5990)	data time 0.0008 (0.1010)	model time 0.0000 (0.0000)	loss 0.6121 (0.6516)	grad_norm 0.7011 (0.8772)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:50:26 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][60/156]	eta 0:00:55 lr 0.000123	 wd 0.0500	time 0.5220 (0.5833)	data time 0.0033 (0.0872)	model time 0.5187 (0.4865)	loss 0.5998 (0.6514)	grad_norm 0.7653 (0.8827)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:50:31 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][70/156]	eta 0:00:49 lr 0.000123	 wd 0.0500	time 0.5189 (0.5716)	data time 0.0007 (0.0771)	model time 0.5182 (0.4857)	loss 0.6805 (0.6514)	grad_norm 1.6104 (0.8985)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:50:36 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][80/156]	eta 0:00:42 lr 0.000123	 wd 0.0500	time 0.5436 (0.5641)	data time 0.0177 (0.0694)	model time 0.5259 (0.4892)	loss 0.6439 (0.6509)	grad_norm 1.1386 (0.9088)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:50:41 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][90/156]	eta 0:00:36 lr 0.000123	 wd 0.0500	time 0.5446 (0.5566)	data time 0.0188 (0.0653)	model time 0.5258 (0.4830)	loss 0.6734 (0.6539)	grad_norm 1.1131 (0.9593)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 11:50:46 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][100/156]	eta 0:00:31 lr 0.000123	 wd 0.0500	time 0.5609 (0.5568)	data time 0.0009 (0.0603)	model time 0.5600 (0.4950)	loss 0.6411 (0.6557)	grad_norm 0.7127 (inf)	loss_scale 65536.0000 (126529.9010)	mem 13675MB
[2024-11-09 11:50:51 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][110/156]	eta 0:00:25 lr 0.000123	 wd 0.0500	time 0.4805 (0.5535)	data time 0.0242 (0.0558)	model time 0.4562 (0.4977)	loss 0.6558 (0.6562)	grad_norm 0.5859 (inf)	loss_scale 65536.0000 (121034.9550)	mem 13675MB
[2024-11-09 11:50:56 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][120/156]	eta 0:00:19 lr 0.000123	 wd 0.0500	time 0.5157 (0.5491)	data time 0.0072 (0.0523)	model time 0.5085 (0.4958)	loss 0.6646 (0.6566)	grad_norm 0.5905 (inf)	loss_scale 65536.0000 (116448.2645)	mem 13675MB
[2024-11-09 11:51:01 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][130/156]	eta 0:00:14 lr 0.000123	 wd 0.0500	time 0.4948 (0.5435)	data time 0.0051 (0.0490)	model time 0.4897 (0.4923)	loss 0.6186 (0.6552)	grad_norm 0.5722 (inf)	loss_scale 65536.0000 (112561.8321)	mem 13675MB
[2024-11-09 11:51:06 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][140/156]	eta 0:00:08 lr 0.000123	 wd 0.0500	time 0.4338 (0.5393)	data time 0.0007 (0.0465)	model time 0.4331 (0.4898)	loss 0.6711 (0.6552)	grad_norm 0.7241 (inf)	loss_scale 65536.0000 (109226.6667)	mem 13675MB
[2024-11-09 11:51:11 vssm1_tiny_0230s](training.py 201): INFO Train: [41/300][150/156]	eta 0:00:03 lr 0.000123	 wd 0.0500	time 0.4110 (0.5362)	data time 0.0006 (0.0435)	model time 0.4104 (0.4899)	loss 0.6417 (0.6556)	grad_norm 0.6586 (inf)	loss_scale 65536.0000 (106333.2450)	mem 13675MB
[2024-11-09 11:51:14 vssm1_tiny_0230s](training.py 212): INFO EPOCH 41 training takes 0:01:23
[2024-11-09 11:51:14 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_41.pth saving......
[2024-11-09 11:51:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_41.pth saved !!!
[2024-11-09 11:51:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.502 (2.502)	Loss 0.5205 (0.5205)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:51:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.154 (0.512)	Loss 0.5249 (0.5257)	Acc@1 82.812 (80.753)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:51:22 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.401)	Loss 0.4788 (0.5288)	Acc@1 80.469 (79.725)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:51:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.356)	Loss 0.5430 (0.5237)	Acc@1 71.875 (78.705)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:51:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 78.140 Acc@5 100.000
[2024-11-09 11:51:27 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 78.1%
[2024-11-09 11:51:27 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 78.14%
[2024-11-09 11:51:32 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.310 (4.310)	Loss 0.5156 (0.5156)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:51:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.206 (0.572)	Loss 0.5220 (0.5181)	Acc@1 100.000 (99.432)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:51:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.352 (0.394)	Loss 0.8125 (0.5407)	Acc@1 14.844 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:51:38 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.349)	Loss 0.8350 (0.6326)	Acc@1 11.719 (67.036)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:51:41 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.120 Acc@5 100.000
[2024-11-09 11:51:41 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.1%
[2024-11-09 11:51:41 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:51:45 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][0/156]	eta 0:11:07 lr 0.000123	 wd 0.0500	time 4.2820 (4.2820)	data time 3.8753 (3.8753)	model time 0.0000 (0.0000)	loss 0.6325 (0.6325)	grad_norm 0.7689 (0.7689)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:51:50 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][10/156]	eta 0:02:02 lr 0.000123	 wd 0.0500	time 0.5233 (0.8420)	data time 0.0208 (0.3716)	model time 0.0000 (0.0000)	loss 0.6292 (0.6470)	grad_norm 0.9808 (0.7749)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:51:55 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][20/156]	eta 0:01:31 lr 0.000123	 wd 0.0500	time 0.4268 (0.6696)	data time 0.0026 (0.1984)	model time 0.0000 (0.0000)	loss 0.6753 (0.6540)	grad_norm 0.8325 (0.8650)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:00 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][30/156]	eta 0:01:17 lr 0.000123	 wd 0.0500	time 0.4165 (0.6183)	data time 0.0008 (0.1387)	model time 0.0000 (0.0000)	loss 0.6547 (0.6513)	grad_norm 0.7672 (0.8767)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:06 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][40/156]	eta 0:01:09 lr 0.000123	 wd 0.0500	time 0.4921 (0.5990)	data time 0.0209 (0.1143)	model time 0.0000 (0.0000)	loss 0.6307 (0.6545)	grad_norm 0.8527 (0.9130)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:11 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][50/156]	eta 0:01:01 lr 0.000123	 wd 0.0500	time 0.5254 (0.5847)	data time 0.0230 (0.0954)	model time 0.0000 (0.0000)	loss 0.6203 (0.6539)	grad_norm 0.9410 (0.8923)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:16 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][60/156]	eta 0:00:54 lr 0.000123	 wd 0.0500	time 0.4756 (0.5671)	data time 0.0313 (0.0823)	model time 0.4443 (0.4624)	loss 0.6515 (0.6527)	grad_norm 0.6978 (0.8738)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:21 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][70/156]	eta 0:00:47 lr 0.000123	 wd 0.0500	time 0.5277 (0.5579)	data time 0.0007 (0.0721)	model time 0.5270 (0.4771)	loss 0.6683 (0.6545)	grad_norm 0.7019 (0.8610)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:25 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][80/156]	eta 0:00:41 lr 0.000123	 wd 0.0500	time 0.4544 (0.5483)	data time 0.0462 (0.0643)	model time 0.4082 (0.4752)	loss 0.6579 (0.6538)	grad_norm 0.7453 (0.8721)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:31 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][90/156]	eta 0:00:36 lr 0.000123	 wd 0.0500	time 0.6644 (0.5507)	data time 0.0073 (0.0588)	model time 0.6571 (0.4952)	loss 0.6539 (0.6543)	grad_norm 1.0031 (0.8933)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:36 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][100/156]	eta 0:00:30 lr 0.000123	 wd 0.0500	time 0.5574 (0.5494)	data time 0.0395 (0.0543)	model time 0.5178 (0.5010)	loss 0.6477 (0.6542)	grad_norm 1.0626 (0.8919)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:41 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][110/156]	eta 0:00:25 lr 0.000123	 wd 0.0500	time 0.5368 (0.5439)	data time 0.0074 (0.0508)	model time 0.5294 (0.4964)	loss 0.6226 (0.6550)	grad_norm 1.3836 (0.8897)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:46 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][120/156]	eta 0:00:19 lr 0.000123	 wd 0.0500	time 0.5572 (0.5388)	data time 0.0173 (0.0479)	model time 0.5399 (0.4921)	loss 0.7062 (0.6547)	grad_norm 1.1292 (0.8909)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:51 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][130/156]	eta 0:00:13 lr 0.000123	 wd 0.0500	time 0.4352 (0.5361)	data time 0.0026 (0.0448)	model time 0.4326 (0.4926)	loss 0.6738 (0.6538)	grad_norm 0.4118 (0.8744)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:52:56 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][140/156]	eta 0:00:08 lr 0.000123	 wd 0.0500	time 0.5653 (0.5354)	data time 0.0039 (0.0423)	model time 0.5614 (0.4953)	loss 0.6735 (0.6527)	grad_norm 0.6273 (0.8813)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:53:01 vssm1_tiny_0230s](training.py 201): INFO Train: [42/300][150/156]	eta 0:00:03 lr 0.000123	 wd 0.0500	time 0.4128 (0.5326)	data time 0.0005 (0.0397)	model time 0.4123 (0.4947)	loss 0.6931 (0.6538)	grad_norm 1.2259 (0.8746)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:53:04 vssm1_tiny_0230s](training.py 212): INFO EPOCH 42 training takes 0:01:23
[2024-11-09 11:53:04 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_42.pth saving......
[2024-11-09 11:53:05 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_42.pth saved !!!
[2024-11-09 11:53:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.418 (3.418)	Loss 0.5493 (0.5493)	Acc@1 80.469 (80.469)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:53:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.233 (0.495)	Loss 0.5493 (0.5544)	Acc@1 78.125 (79.048)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:53:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.391)	Loss 0.4512 (0.5542)	Acc@1 82.812 (78.906)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:53:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.319)	Loss 0.5112 (0.5336)	Acc@1 72.656 (78.654)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:53:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 78.600 Acc@5 100.000
[2024-11-09 11:53:18 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 78.6%
[2024-11-09 11:53:18 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 78.60%
[2024-11-09 11:53:21 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.110 (3.110)	Loss 0.5122 (0.5122)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:53:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.412)	Loss 0.5190 (0.5148)	Acc@1 100.000 (99.361)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:53:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.286)	Loss 0.8135 (0.5377)	Acc@1 14.844 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:53:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.160 (0.242)	Loss 0.8369 (0.6309)	Acc@1 11.719 (67.162)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:53:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.240 Acc@5 100.000
[2024-11-09 11:53:27 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.2%
[2024-11-09 11:53:27 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:53:30 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][0/156]	eta 0:08:57 lr 0.000123	 wd 0.0500	time 3.4427 (3.4427)	data time 2.9126 (2.9126)	model time 0.0000 (0.0000)	loss 0.6596 (0.6596)	grad_norm 0.5028 (0.5028)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:53:36 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][10/156]	eta 0:02:03 lr 0.000123	 wd 0.0500	time 0.8477 (0.8486)	data time 0.0268 (0.3446)	model time 0.0000 (0.0000)	loss 0.6794 (0.6582)	grad_norm 0.9262 (0.7019)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:53:41 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][20/156]	eta 0:01:32 lr 0.000123	 wd 0.0500	time 0.5154 (0.6801)	data time 0.0033 (0.1928)	model time 0.0000 (0.0000)	loss 0.6525 (0.6604)	grad_norm 0.5990 (0.7157)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:53:46 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][30/156]	eta 0:01:18 lr 0.000123	 wd 0.0500	time 0.5214 (0.6194)	data time 0.0008 (0.1350)	model time 0.0000 (0.0000)	loss 0.6600 (0.6591)	grad_norm 0.5456 (0.7525)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:53:51 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][40/156]	eta 0:01:08 lr 0.000123	 wd 0.0500	time 0.4332 (0.5873)	data time 0.0088 (0.1058)	model time 0.0000 (0.0000)	loss 0.6216 (0.6532)	grad_norm 0.6980 (0.7811)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:53:56 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][50/156]	eta 0:01:00 lr 0.000123	 wd 0.0500	time 0.5185 (0.5699)	data time 0.0683 (0.0902)	model time 0.0000 (0.0000)	loss 0.6349 (0.6545)	grad_norm 1.1565 (0.7864)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:01 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][60/156]	eta 0:00:53 lr 0.000123	 wd 0.0500	time 0.4874 (0.5590)	data time 0.0200 (0.0792)	model time 0.4674 (0.4805)	loss 0.6568 (0.6539)	grad_norm 0.9954 (0.7994)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:06 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][70/156]	eta 0:00:47 lr 0.000123	 wd 0.0500	time 0.6836 (0.5514)	data time 0.0007 (0.0704)	model time 0.6828 (0.4843)	loss 0.6057 (0.6540)	grad_norm 0.6192 (0.8141)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:11 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][80/156]	eta 0:00:41 lr 0.000123	 wd 0.0500	time 0.5576 (0.5476)	data time 0.0389 (0.0638)	model time 0.5187 (0.4907)	loss 0.6570 (0.6552)	grad_norm 1.2973 (0.8233)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:16 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][90/156]	eta 0:00:35 lr 0.000123	 wd 0.0500	time 0.4623 (0.5425)	data time 0.0045 (0.0598)	model time 0.4578 (0.4866)	loss 0.6209 (0.6556)	grad_norm 0.6570 (0.8131)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:21 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][100/156]	eta 0:00:30 lr 0.000123	 wd 0.0500	time 0.5859 (0.5360)	data time 0.0084 (0.0546)	model time 0.5775 (0.4830)	loss 0.6975 (0.6541)	grad_norm 1.2953 (0.8238)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:26 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][110/156]	eta 0:00:24 lr 0.000123	 wd 0.0500	time 0.4920 (0.5350)	data time 0.0006 (0.0508)	model time 0.4913 (0.4880)	loss 0.5940 (0.6533)	grad_norm 1.0480 (0.8271)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:31 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][120/156]	eta 0:00:19 lr 0.000123	 wd 0.0500	time 0.4288 (0.5321)	data time 0.0071 (0.0477)	model time 0.4217 (0.4878)	loss 0.6913 (0.6530)	grad_norm 1.0592 (0.8314)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:36 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][130/156]	eta 0:00:13 lr 0.000123	 wd 0.0500	time 0.5709 (0.5310)	data time 0.0019 (0.0451)	model time 0.5690 (0.4899)	loss 0.6747 (0.6531)	grad_norm 0.5541 (0.8419)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:41 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][140/156]	eta 0:00:08 lr 0.000123	 wd 0.0500	time 0.4616 (0.5288)	data time 0.0008 (0.0425)	model time 0.4608 (0.4900)	loss 0.6448 (0.6528)	grad_norm 0.5348 (0.8336)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:46 vssm1_tiny_0230s](training.py 201): INFO Train: [43/300][150/156]	eta 0:00:03 lr 0.000123	 wd 0.0500	time 0.4284 (0.5249)	data time 0.0005 (0.0397)	model time 0.4279 (0.4879)	loss 0.6898 (0.6520)	grad_norm 0.8860 (0.8371)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:54:49 vssm1_tiny_0230s](training.py 212): INFO EPOCH 43 training takes 0:01:22
[2024-11-09 11:54:49 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_43.pth saving......
[2024-11-09 11:54:50 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_43.pth saved !!!
[2024-11-09 11:54:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.881 (3.881)	Loss 0.3928 (0.3928)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:54:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.132 (0.561)	Loss 0.3987 (0.3984)	Acc@1 88.281 (90.980)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:54:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.217 (0.424)	Loss 0.5381 (0.4158)	Acc@1 66.406 (88.839)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:55:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.196 (0.354)	Loss 0.6553 (0.4781)	Acc@1 57.031 (80.998)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:55:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 77.100 Acc@5 100.000
[2024-11-09 11:55:03 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 77.1%
[2024-11-09 11:55:03 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 78.60%
[2024-11-09 11:55:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.411 (3.411)	Loss 0.5083 (0.5083)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:55:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.577)	Loss 0.5156 (0.5115)	Acc@1 100.000 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:55:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.152 (0.448)	Loss 0.8140 (0.5347)	Acc@1 14.844 (93.229)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:55:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.156 (0.367)	Loss 0.8384 (0.6293)	Acc@1 11.719 (67.263)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:55:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.400 Acc@5 100.000
[2024-11-09 11:55:17 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.4%
[2024-11-09 11:55:17 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:55:21 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][0/156]	eta 0:09:06 lr 0.000123	 wd 0.0500	time 3.5026 (3.5026)	data time 3.0856 (3.0856)	model time 0.0000 (0.0000)	loss 0.6416 (0.6416)	grad_norm 0.7429 (0.7429)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:55:27 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][10/156]	eta 0:02:02 lr 0.000123	 wd 0.0500	time 0.5450 (0.8395)	data time 0.0221 (0.3828)	model time 0.0000 (0.0000)	loss 0.6633 (0.6535)	grad_norm 0.9443 (0.8942)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:55:32 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][20/156]	eta 0:01:34 lr 0.000123	 wd 0.0500	time 0.5158 (0.6935)	data time 0.0321 (0.2061)	model time 0.0000 (0.0000)	loss 0.6064 (0.6500)	grad_norm 0.9423 (0.9703)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:55:37 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][30/156]	eta 0:01:20 lr 0.000123	 wd 0.0500	time 0.4500 (0.6385)	data time 0.0066 (0.1435)	model time 0.0000 (0.0000)	loss 0.6631 (0.6524)	grad_norm 1.0243 (0.9508)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:55:42 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][40/156]	eta 0:01:10 lr 0.000123	 wd 0.0500	time 0.4101 (0.6035)	data time 0.0007 (0.1111)	model time 0.0000 (0.0000)	loss 0.6191 (0.6490)	grad_norm 0.6327 (0.9237)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:55:47 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][50/156]	eta 0:01:01 lr 0.000123	 wd 0.0500	time 0.5115 (0.5837)	data time 0.0060 (0.0934)	model time 0.0000 (0.0000)	loss 0.6846 (0.6494)	grad_norm 0.8523 (0.9252)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:55:52 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][60/156]	eta 0:00:54 lr 0.000123	 wd 0.0500	time 0.4803 (0.5720)	data time 0.0025 (0.0806)	model time 0.4777 (0.4969)	loss 0.6767 (0.6490)	grad_norm 0.8829 (0.9316)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:55:57 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][70/156]	eta 0:00:48 lr 0.000123	 wd 0.0500	time 0.6009 (0.5657)	data time 0.0133 (0.0756)	model time 0.5876 (0.4897)	loss 0.6369 (0.6499)	grad_norm 0.7917 (0.9200)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:56:03 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][80/156]	eta 0:00:42 lr 0.000123	 wd 0.0500	time 0.6103 (0.5577)	data time 0.0008 (0.0681)	model time 0.6096 (0.4882)	loss 0.6328 (0.6508)	grad_norm 0.8948 (0.9126)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:56:07 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][90/156]	eta 0:00:36 lr 0.000123	 wd 0.0500	time 0.5193 (0.5499)	data time 0.0469 (0.0629)	model time 0.4724 (0.4828)	loss 0.6252 (0.6510)	grad_norm 0.7938 (0.9271)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:56:12 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][100/156]	eta 0:00:30 lr 0.000123	 wd 0.0500	time 0.4212 (0.5462)	data time 0.0046 (0.0582)	model time 0.4166 (0.4856)	loss 0.6481 (0.6506)	grad_norm 0.6128 (0.9024)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:56:18 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][110/156]	eta 0:00:24 lr 0.000123	 wd 0.0500	time 0.4484 (0.5422)	data time 0.0131 (0.0544)	model time 0.4353 (0.4855)	loss 0.6074 (0.6494)	grad_norm 0.7443 (0.8926)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:56:22 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][120/156]	eta 0:00:19 lr 0.000123	 wd 0.0500	time 0.4185 (0.5369)	data time 0.0057 (0.0509)	model time 0.4128 (0.4827)	loss 0.6458 (0.6493)	grad_norm 0.5981 (0.8928)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:56:27 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][130/156]	eta 0:00:13 lr 0.000123	 wd 0.0500	time 0.5412 (0.5339)	data time 0.0006 (0.0491)	model time 0.5406 (0.4813)	loss 0.6339 (0.6489)	grad_norm 0.9077 (0.9108)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:56:32 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][140/156]	eta 0:00:08 lr 0.000123	 wd 0.0500	time 0.5166 (0.5301)	data time 0.0007 (0.0462)	model time 0.5159 (0.4802)	loss 0.6479 (0.6484)	grad_norm 0.7569 (0.9472)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:56:37 vssm1_tiny_0230s](training.py 201): INFO Train: [44/300][150/156]	eta 0:00:03 lr 0.000123	 wd 0.0500	time 0.4609 (0.5266)	data time 0.0007 (0.0432)	model time 0.4602 (0.4799)	loss 0.6763 (0.6483)	grad_norm 1.1098 (0.9437)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:56:40 vssm1_tiny_0230s](training.py 212): INFO EPOCH 44 training takes 0:01:23
[2024-11-09 11:56:40 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_44.pth saving......
[2024-11-09 11:56:42 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_44.pth saved !!!
[2024-11-09 11:56:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.652 (3.652)	Loss 0.4873 (0.4873)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:56:49 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.148 (0.650)	Loss 0.4807 (0.5068)	Acc@1 85.938 (80.682)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:56:51 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.461)	Loss 0.4573 (0.5090)	Acc@1 78.125 (79.911)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:56:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.384)	Loss 0.5625 (0.5094)	Acc@1 67.188 (77.873)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:56:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 77.100 Acc@5 100.000
[2024-11-09 11:56:55 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 77.1%
[2024-11-09 11:56:55 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 78.60%
[2024-11-09 11:56:59 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.254 (3.254)	Loss 0.5049 (0.5049)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:57:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.812 (0.540)	Loss 0.5122 (0.5080)	Acc@1 100.000 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:57:03 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.369)	Loss 0.8154 (0.5315)	Acc@1 15.625 (93.155)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:57:06 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.349)	Loss 0.8403 (0.6276)	Acc@1 12.500 (67.288)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:57:09 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.520 Acc@5 100.000
[2024-11-09 11:57:09 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.5%
[2024-11-09 11:57:09 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:57:13 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][0/156]	eta 0:10:28 lr 0.000123	 wd 0.0500	time 4.0290 (4.0290)	data time 3.5390 (3.5390)	model time 0.0000 (0.0000)	loss 0.6705 (0.6705)	grad_norm 0.9859 (0.9859)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:57:18 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][10/156]	eta 0:02:03 lr 0.000123	 wd 0.0500	time 0.4288 (0.8459)	data time 0.0017 (0.3304)	model time 0.0000 (0.0000)	loss 0.6625 (0.6545)	grad_norm 1.0171 (0.7888)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:57:23 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][20/156]	eta 0:01:33 lr 0.000123	 wd 0.0500	time 0.4091 (0.6910)	data time 0.0015 (0.1838)	model time 0.0000 (0.0000)	loss 0.6475 (0.6517)	grad_norm 1.4763 (0.8274)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:57:29 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][30/156]	eta 0:01:20 lr 0.000123	 wd 0.0500	time 0.6334 (0.6379)	data time 0.0054 (0.1288)	model time 0.0000 (0.0000)	loss 0.6320 (0.6501)	grad_norm 0.7535 (0.7959)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:57:34 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][40/156]	eta 0:01:11 lr 0.000123	 wd 0.0500	time 0.5049 (0.6144)	data time 0.0007 (0.1025)	model time 0.0000 (0.0000)	loss 0.6845 (0.6523)	grad_norm 0.7959 (0.8149)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:57:39 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][50/156]	eta 0:01:02 lr 0.000123	 wd 0.0500	time 0.4884 (0.5935)	data time 0.0174 (0.0875)	model time 0.0000 (0.0000)	loss 0.6831 (0.6513)	grad_norm 0.4274 (0.8014)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:57:44 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][60/156]	eta 0:00:55 lr 0.000123	 wd 0.0500	time 0.5449 (0.5784)	data time 0.0108 (0.0744)	model time 0.5341 (0.4940)	loss 0.6624 (0.6513)	grad_norm 1.7510 (0.8758)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:57:50 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][70/156]	eta 0:00:49 lr 0.000122	 wd 0.0500	time 0.5382 (0.5739)	data time 0.0172 (0.0683)	model time 0.5210 (0.5048)	loss 0.6318 (0.6514)	grad_norm 0.5905 (0.8771)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:57:55 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][80/156]	eta 0:00:42 lr 0.000122	 wd 0.0500	time 0.4953 (0.5639)	data time 0.0248 (0.0634)	model time 0.4705 (0.4912)	loss 0.6837 (0.6533)	grad_norm 0.5058 (0.8691)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:57:59 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][90/156]	eta 0:00:36 lr 0.000122	 wd 0.0500	time 0.4595 (0.5555)	data time 0.0291 (0.0581)	model time 0.4304 (0.4867)	loss 0.6129 (0.6512)	grad_norm 0.5742 (0.8530)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:58:05 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][100/156]	eta 0:00:30 lr 0.000122	 wd 0.0500	time 0.5308 (0.5535)	data time 0.0079 (0.0547)	model time 0.5229 (0.4916)	loss 0.6627 (0.6515)	grad_norm 1.5984 (0.8497)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:58:10 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][110/156]	eta 0:00:25 lr 0.000122	 wd 0.0500	time 0.6126 (0.5489)	data time 0.0221 (0.0510)	model time 0.5905 (0.4910)	loss 0.6727 (0.6526)	grad_norm 0.5025 (0.8806)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:58:15 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][120/156]	eta 0:00:19 lr 0.000122	 wd 0.0500	time 0.5063 (0.5448)	data time 0.0008 (0.0487)	model time 0.5055 (0.4890)	loss 0.6307 (0.6526)	grad_norm 0.8227 (0.8805)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:58:20 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][130/156]	eta 0:00:14 lr 0.000122	 wd 0.0500	time 0.4667 (0.5407)	data time 0.0046 (0.0460)	model time 0.4621 (0.4877)	loss 0.6131 (0.6523)	grad_norm 0.6828 (0.8789)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:58:25 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][140/156]	eta 0:00:08 lr 0.000122	 wd 0.0500	time 0.4388 (0.5371)	data time 0.0010 (0.0434)	model time 0.4378 (0.4868)	loss 0.6542 (0.6532)	grad_norm 0.5915 (0.8788)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:58:29 vssm1_tiny_0230s](training.py 201): INFO Train: [45/300][150/156]	eta 0:00:03 lr 0.000122	 wd 0.0500	time 0.4123 (0.5322)	data time 0.0004 (0.0408)	model time 0.4119 (0.4840)	loss 0.6712 (0.6534)	grad_norm 0.7817 (0.8768)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:58:32 vssm1_tiny_0230s](training.py 212): INFO EPOCH 45 training takes 0:01:23
[2024-11-09 11:58:32 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_45.pth saving......
[2024-11-09 11:58:33 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_45.pth saved !!!
[2024-11-09 11:58:36 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.002 (3.002)	Loss 0.5942 (0.5942)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:58:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.483 (0.556)	Loss 0.5781 (0.6044)	Acc@1 72.656 (70.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:58:42 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.201 (0.432)	Loss 0.3865 (0.5929)	Acc@1 89.062 (71.652)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:58:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.161 (0.349)	Loss 0.4568 (0.5403)	Acc@1 79.688 (75.958)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:58:47 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 77.800 Acc@5 100.000
[2024-11-09 11:58:47 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 77.8%
[2024-11-09 11:58:47 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 78.60%
[2024-11-09 11:58:50 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.588 (3.588)	Loss 0.5015 (0.5015)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:58:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.299 (0.493)	Loss 0.5088 (0.5048)	Acc@1 100.000 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:58:54 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.365)	Loss 0.8159 (0.5286)	Acc@1 15.625 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:58:56 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.157 (0.311)	Loss 0.8418 (0.6259)	Acc@1 12.500 (67.263)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 11:58:59 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.560 Acc@5 100.000
[2024-11-09 11:58:59 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.6%
[2024-11-09 11:58:59 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 11:59:04 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][0/156]	eta 0:13:59 lr 0.000122	 wd 0.0500	time 5.3800 (5.3800)	data time 4.8954 (4.8954)	model time 0.0000 (0.0000)	loss 0.6400 (0.6400)	grad_norm 0.9989 (0.9989)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:09 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][10/156]	eta 0:02:19 lr 0.000122	 wd 0.0500	time 0.5603 (0.9543)	data time 0.0212 (0.4579)	model time 0.0000 (0.0000)	loss 0.6021 (0.6397)	grad_norm 0.8524 (0.8877)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:14 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][20/156]	eta 0:01:37 lr 0.000122	 wd 0.0500	time 0.5522 (0.7154)	data time 0.0282 (0.2445)	model time 0.0000 (0.0000)	loss 0.6692 (0.6494)	grad_norm 0.7957 (0.9473)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:18 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][30/156]	eta 0:01:19 lr 0.000122	 wd 0.0500	time 0.4082 (0.6297)	data time 0.0007 (0.1681)	model time 0.0000 (0.0000)	loss 0.6213 (0.6491)	grad_norm 1.0356 (0.9311)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:23 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][40/156]	eta 0:01:08 lr 0.000122	 wd 0.0500	time 0.4728 (0.5946)	data time 0.0006 (0.1300)	model time 0.0000 (0.0000)	loss 0.6693 (0.6488)	grad_norm 0.4171 (0.9167)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:28 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][50/156]	eta 0:01:00 lr 0.000122	 wd 0.0500	time 0.4882 (0.5724)	data time 0.0019 (0.1067)	model time 0.0000 (0.0000)	loss 0.6541 (0.6503)	grad_norm 1.6551 (0.9228)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:33 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][60/156]	eta 0:00:53 lr 0.000122	 wd 0.0500	time 0.4851 (0.5572)	data time 0.0008 (0.0917)	model time 0.4843 (0.4647)	loss 0.6465 (0.6494)	grad_norm 1.6815 (0.9224)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:38 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][70/156]	eta 0:00:47 lr 0.000122	 wd 0.0500	time 0.4590 (0.5568)	data time 0.0009 (0.0807)	model time 0.4582 (0.5023)	loss 0.6198 (0.6505)	grad_norm 0.8225 (0.9125)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:44 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][80/156]	eta 0:00:42 lr 0.000122	 wd 0.0500	time 0.6043 (0.5528)	data time 0.0221 (0.0720)	model time 0.5822 (0.5065)	loss 0.6493 (0.6508)	grad_norm 0.7692 (0.8928)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:49 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][90/156]	eta 0:00:36 lr 0.000122	 wd 0.0500	time 0.4860 (0.5482)	data time 0.0098 (0.0653)	model time 0.4762 (0.5048)	loss 0.6242 (0.6503)	grad_norm 0.9344 (0.8794)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:54 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][100/156]	eta 0:00:30 lr 0.000122	 wd 0.0500	time 0.4547 (0.5424)	data time 0.0154 (0.0598)	model time 0.4393 (0.4997)	loss 0.6633 (0.6512)	grad_norm 1.3484 (0.8989)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 11:59:59 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][110/156]	eta 0:00:24 lr 0.000122	 wd 0.0500	time 0.4293 (0.5384)	data time 0.0008 (0.0562)	model time 0.4285 (0.4963)	loss 0.6179 (0.6486)	grad_norm 0.6725 (0.8988)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:00:04 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][120/156]	eta 0:00:19 lr 0.000122	 wd 0.0500	time 0.4956 (0.5373)	data time 0.0057 (0.0534)	model time 0.4899 (0.4971)	loss 0.6448 (0.6495)	grad_norm 1.1665 (0.9192)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:00:09 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][130/156]	eta 0:00:13 lr 0.000122	 wd 0.0500	time 0.5682 (0.5359)	data time 0.0264 (0.0506)	model time 0.5418 (0.4978)	loss 0.6294 (0.6494)	grad_norm 0.6795 (0.9242)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:00:14 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][140/156]	eta 0:00:08 lr 0.000122	 wd 0.0500	time 0.4951 (0.5340)	data time 0.0010 (0.0485)	model time 0.4941 (0.4967)	loss 0.6627 (0.6500)	grad_norm 0.7197 (0.9204)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:00:19 vssm1_tiny_0230s](training.py 201): INFO Train: [46/300][150/156]	eta 0:00:03 lr 0.000122	 wd 0.0500	time 0.4940 (0.5296)	data time 0.0005 (0.0454)	model time 0.4935 (0.4936)	loss 0.5917 (0.6491)	grad_norm 0.8035 (0.9151)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:00:22 vssm1_tiny_0230s](training.py 212): INFO EPOCH 46 training takes 0:01:23
[2024-11-09 12:00:22 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_46.pth saving......
[2024-11-09 12:00:22 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_46.pth saved !!!
[2024-11-09 12:00:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.514 (3.514)	Loss 0.5576 (0.5576)	Acc@1 78.906 (78.906)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:00:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.341 (0.559)	Loss 0.5391 (0.5568)	Acc@1 74.219 (75.568)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:00:31 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.421)	Loss 0.3696 (0.5509)	Acc@1 90.625 (75.707)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:00:33 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.359)	Loss 0.4622 (0.5115)	Acc@1 77.344 (77.949)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:00:35 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 79.080 Acc@5 100.000
[2024-11-09 12:00:35 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 79.1%
[2024-11-09 12:00:35 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 79.08%
[2024-11-09 12:00:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.777 (2.777)	Loss 0.4980 (0.4980)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:00:41 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.219 (0.544)	Loss 0.5054 (0.5014)	Acc@1 100.000 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:00:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.388)	Loss 0.8169 (0.5254)	Acc@1 15.625 (93.155)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:00:45 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.325)	Loss 0.8438 (0.6241)	Acc@1 12.500 (67.440)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:00:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.720 Acc@5 100.000
[2024-11-09 12:00:48 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.7%
[2024-11-09 12:00:48 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:00:52 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][0/156]	eta 0:11:06 lr 0.000122	 wd 0.0500	time 4.2726 (4.2726)	data time 3.7154 (3.7154)	model time 0.0000 (0.0000)	loss 0.6266 (0.6266)	grad_norm 0.5604 (0.5604)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:00:58 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][10/156]	eta 0:02:12 lr 0.000122	 wd 0.0500	time 0.6022 (0.9098)	data time 0.0139 (0.3745)	model time 0.0000 (0.0000)	loss 0.6646 (0.6489)	grad_norm 0.4847 (1.0140)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:03 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][20/156]	eta 0:01:39 lr 0.000122	 wd 0.0500	time 0.6403 (0.7280)	data time 0.0069 (0.1981)	model time 0.0000 (0.0000)	loss 0.6612 (0.6507)	grad_norm 0.6416 (0.9337)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:08 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][30/156]	eta 0:01:22 lr 0.000122	 wd 0.0500	time 0.5168 (0.6520)	data time 0.0147 (0.1372)	model time 0.0000 (0.0000)	loss 0.6378 (0.6516)	grad_norm 1.0433 (0.8770)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:13 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][40/156]	eta 0:01:11 lr 0.000122	 wd 0.0500	time 0.5650 (0.6178)	data time 0.0262 (0.1085)	model time 0.0000 (0.0000)	loss 0.6090 (0.6495)	grad_norm 0.6207 (0.8332)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:18 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][50/156]	eta 0:01:03 lr 0.000122	 wd 0.0500	time 0.5167 (0.6008)	data time 0.0027 (0.0900)	model time 0.0000 (0.0000)	loss 0.6461 (0.6494)	grad_norm 0.7295 (0.8155)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:23 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][60/156]	eta 0:00:55 lr 0.000122	 wd 0.0500	time 0.4858 (0.5817)	data time 0.0010 (0.0781)	model time 0.4847 (0.4669)	loss 0.6312 (0.6519)	grad_norm 0.6450 (0.8274)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:28 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][70/156]	eta 0:00:49 lr 0.000122	 wd 0.0500	time 0.4259 (0.5722)	data time 0.0041 (0.0682)	model time 0.4218 (0.4867)	loss 0.6319 (0.6503)	grad_norm 1.0339 (0.8524)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:33 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][80/156]	eta 0:00:42 lr 0.000122	 wd 0.0500	time 0.4634 (0.5589)	data time 0.0035 (0.0611)	model time 0.4599 (0.4758)	loss 0.6603 (0.6506)	grad_norm 0.7986 (0.8420)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:38 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][90/156]	eta 0:00:36 lr 0.000122	 wd 0.0500	time 0.5007 (0.5480)	data time 0.0044 (0.0558)	model time 0.4963 (0.4685)	loss 0.6304 (0.6507)	grad_norm 1.1371 (0.8492)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:43 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][100/156]	eta 0:00:30 lr 0.000122	 wd 0.0500	time 0.4485 (0.5419)	data time 0.0182 (0.0515)	model time 0.4302 (0.4695)	loss 0.6628 (0.6500)	grad_norm 0.6269 (0.8377)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:48 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][110/156]	eta 0:00:24 lr 0.000122	 wd 0.0500	time 0.5846 (0.5402)	data time 0.0006 (0.0476)	model time 0.5840 (0.4773)	loss 0.6137 (0.6492)	grad_norm 0.7603 (0.8389)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:53 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][120/156]	eta 0:00:19 lr 0.000122	 wd 0.0500	time 0.6171 (0.5365)	data time 0.0270 (0.0447)	model time 0.5901 (0.4780)	loss 0.6598 (0.6482)	grad_norm 0.9053 (0.8483)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:01:58 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][130/156]	eta 0:00:13 lr 0.000122	 wd 0.0500	time 0.6001 (0.5362)	data time 0.0098 (0.0434)	model time 0.5903 (0.4813)	loss 0.6774 (0.6482)	grad_norm 1.0621 (0.8491)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:02:03 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][140/156]	eta 0:00:08 lr 0.000122	 wd 0.0500	time 0.5796 (0.5345)	data time 0.0008 (0.0418)	model time 0.5788 (0.4825)	loss 0.6407 (0.6480)	grad_norm 1.0915 (0.8506)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:02:08 vssm1_tiny_0230s](training.py 201): INFO Train: [47/300][150/156]	eta 0:00:03 lr 0.000122	 wd 0.0500	time 0.5562 (0.5338)	data time 0.0007 (0.0391)	model time 0.5554 (0.4865)	loss 0.6293 (0.6479)	grad_norm 0.5750 (0.8501)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:02:11 vssm1_tiny_0230s](training.py 212): INFO EPOCH 47 training takes 0:01:23
[2024-11-09 12:02:11 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_47.pth saving......
[2024-11-09 12:02:11 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_47.pth saved !!!
[2024-11-09 12:02:15 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.814 (3.814)	Loss 0.4819 (0.4819)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:02:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.187 (0.540)	Loss 0.4802 (0.4902)	Acc@1 83.594 (81.534)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:02:20 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.169 (0.417)	Loss 0.4185 (0.4951)	Acc@1 82.812 (80.246)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:02:23 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.167 (0.362)	Loss 0.5146 (0.4857)	Acc@1 69.531 (79.637)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:02:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 79.220 Acc@5 100.000
[2024-11-09 12:02:25 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 79.2%
[2024-11-09 12:02:25 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 79.22%
[2024-11-09 12:02:28 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.845 (3.845)	Loss 0.4941 (0.4941)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:02:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.151 (0.603)	Loss 0.5020 (0.4976)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:02:33 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.287 (0.411)	Loss 0.8179 (0.5220)	Acc@1 15.625 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:02:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.365)	Loss 0.8457 (0.6224)	Acc@1 13.281 (67.465)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:02:39 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.800 Acc@5 100.000
[2024-11-09 12:02:39 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.8%
[2024-11-09 12:02:39 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:02:43 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][0/156]	eta 0:10:24 lr 0.000122	 wd 0.0500	time 4.0005 (4.0005)	data time 3.5905 (3.5905)	model time 0.0000 (0.0000)	loss 0.7014 (0.7014)	grad_norm 0.8408 (0.8408)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:02:48 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][10/156]	eta 0:02:04 lr 0.000122	 wd 0.0500	time 0.5141 (0.8515)	data time 0.0035 (0.3418)	model time 0.0000 (0.0000)	loss 0.6188 (0.6501)	grad_norm 0.7230 (0.9374)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:02:54 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][20/156]	eta 0:01:39 lr 0.000122	 wd 0.0500	time 0.7967 (0.7287)	data time 0.0799 (0.1936)	model time 0.0000 (0.0000)	loss 0.6555 (0.6508)	grad_norm 1.0220 (1.0541)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:02:59 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][30/156]	eta 0:01:22 lr 0.000122	 wd 0.0500	time 0.4469 (0.6569)	data time 0.0079 (0.1384)	model time 0.0000 (0.0000)	loss 0.6583 (0.6515)	grad_norm 0.6255 (1.0310)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:05 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][40/156]	eta 0:01:12 lr 0.000122	 wd 0.0500	time 0.6368 (0.6287)	data time 0.0022 (0.1062)	model time 0.0000 (0.0000)	loss 0.6726 (0.6499)	grad_norm 0.7225 (0.9650)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:10 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][50/156]	eta 0:01:04 lr 0.000122	 wd 0.0500	time 0.4733 (0.6093)	data time 0.0008 (0.0887)	model time 0.0000 (0.0000)	loss 0.6676 (0.6497)	grad_norm 0.9003 (0.9180)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:15 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][60/156]	eta 0:00:56 lr 0.000122	 wd 0.0500	time 0.5018 (0.5863)	data time 0.0186 (0.0767)	model time 0.4832 (0.4536)	loss 0.6575 (0.6506)	grad_norm 0.9766 (0.8841)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:19 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][70/156]	eta 0:00:49 lr 0.000122	 wd 0.0500	time 0.4368 (0.5701)	data time 0.0221 (0.0696)	model time 0.4147 (0.4494)	loss 0.6153 (0.6492)	grad_norm 0.4937 (0.9029)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:24 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][80/156]	eta 0:00:42 lr 0.000122	 wd 0.0500	time 0.4158 (0.5534)	data time 0.0082 (0.0623)	model time 0.4076 (0.4411)	loss 0.6480 (0.6468)	grad_norm 0.7293 (0.9200)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:28 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][90/156]	eta 0:00:35 lr 0.000122	 wd 0.0500	time 0.4361 (0.5450)	data time 0.0129 (0.0570)	model time 0.4233 (0.4465)	loss 0.6360 (0.6479)	grad_norm 0.9446 (0.9446)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:33 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][100/156]	eta 0:00:30 lr 0.000122	 wd 0.0500	time 0.5062 (0.5374)	data time 0.0091 (0.0522)	model time 0.4971 (0.4490)	loss 0.6351 (0.6479)	grad_norm 1.9339 (0.9548)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:38 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][110/156]	eta 0:00:24 lr 0.000122	 wd 0.0500	time 0.4440 (0.5326)	data time 0.0297 (0.0494)	model time 0.4143 (0.4513)	loss 0.6202 (0.6470)	grad_norm 1.0794 (0.9393)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:43 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][120/156]	eta 0:00:19 lr 0.000122	 wd 0.0500	time 0.4500 (0.5289)	data time 0.0007 (0.0467)	model time 0.4493 (0.4543)	loss 0.6106 (0.6462)	grad_norm 0.8613 (0.9486)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:48 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][130/156]	eta 0:00:13 lr 0.000122	 wd 0.0500	time 0.4443 (0.5273)	data time 0.0006 (0.0447)	model time 0.4437 (0.4585)	loss 0.6448 (0.6468)	grad_norm 0.8925 (0.9663)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:53 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][140/156]	eta 0:00:08 lr 0.000122	 wd 0.0500	time 0.6346 (0.5262)	data time 0.0009 (0.0425)	model time 0.6337 (0.4628)	loss 0.6929 (0.6476)	grad_norm 1.4066 (0.9704)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:03:58 vssm1_tiny_0230s](training.py 201): INFO Train: [48/300][150/156]	eta 0:00:03 lr 0.000122	 wd 0.0500	time 0.4807 (0.5223)	data time 0.0006 (0.0399)	model time 0.4801 (0.4630)	loss 0.6537 (0.6474)	grad_norm 0.4784 (0.9571)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:04:01 vssm1_tiny_0230s](training.py 212): INFO EPOCH 48 training takes 0:01:21
[2024-11-09 12:04:01 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_48.pth saving......
[2024-11-09 12:04:01 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_48.pth saved !!!
[2024-11-09 12:04:03 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.615 (2.615)	Loss 0.4792 (0.4792)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:04:06 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.293 (0.492)	Loss 0.4758 (0.4835)	Acc@1 88.281 (84.730)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:04:08 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.170 (0.362)	Loss 0.4465 (0.4877)	Acc@1 79.688 (83.445)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:04:11 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.327)	Loss 0.5210 (0.4902)	Acc@1 77.344 (81.376)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:04:13 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 80.600 Acc@5 100.000
[2024-11-09 12:04:13 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 80.6%
[2024-11-09 12:04:13 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 80.60%
[2024-11-09 12:04:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.955 (3.955)	Loss 0.4902 (0.4902)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:04:18 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.517)	Loss 0.4980 (0.4937)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:04:20 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.206 (0.374)	Loss 0.8193 (0.5185)	Acc@1 15.625 (93.080)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:04:23 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.786 (0.337)	Loss 0.8481 (0.6206)	Acc@1 13.281 (67.465)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:04:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 55.920 Acc@5 100.000
[2024-11-09 12:04:25 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 55.9%
[2024-11-09 12:04:25 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:04:30 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][0/156]	eta 0:10:50 lr 0.000122	 wd 0.0500	time 4.1706 (4.1706)	data time 3.6006 (3.6006)	model time 0.0000 (0.0000)	loss 0.6400 (0.6400)	grad_norm 0.7380 (0.7380)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:04:34 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][10/156]	eta 0:02:00 lr 0.000122	 wd 0.0500	time 0.4389 (0.8255)	data time 0.0062 (0.3366)	model time 0.0000 (0.0000)	loss 0.6230 (0.6388)	grad_norm 0.4724 (0.7581)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:04:40 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][20/156]	eta 0:01:33 lr 0.000122	 wd 0.0500	time 0.4933 (0.6857)	data time 0.0007 (0.1835)	model time 0.0000 (0.0000)	loss 0.6589 (0.6450)	grad_norm 0.5981 (0.7951)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:04:45 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][30/156]	eta 0:01:18 lr 0.000122	 wd 0.0500	time 0.4818 (0.6257)	data time 0.0008 (0.1292)	model time 0.0000 (0.0000)	loss 0.6803 (0.6433)	grad_norm 1.1765 (0.8402)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:04:49 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][40/156]	eta 0:01:08 lr 0.000122	 wd 0.0500	time 0.4789 (0.5867)	data time 0.0281 (0.1014)	model time 0.0000 (0.0000)	loss 0.6314 (0.6409)	grad_norm 0.9383 (0.8577)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:04:55 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][50/156]	eta 0:01:00 lr 0.000122	 wd 0.0500	time 0.5350 (0.5735)	data time 0.0523 (0.0859)	model time 0.0000 (0.0000)	loss 0.6714 (0.6413)	grad_norm 0.7130 (0.8652)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:04:59 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][60/156]	eta 0:00:53 lr 0.000122	 wd 0.0500	time 0.5339 (0.5582)	data time 0.0007 (0.0729)	model time 0.5332 (0.4733)	loss 0.6563 (0.6408)	grad_norm 1.3531 (0.8706)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:05:04 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][70/156]	eta 0:00:47 lr 0.000122	 wd 0.0500	time 0.4412 (0.5493)	data time 0.0143 (0.0660)	model time 0.4269 (0.4721)	loss 0.6450 (0.6431)	grad_norm 0.7115 (0.8746)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:05:09 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][80/156]	eta 0:00:41 lr 0.000122	 wd 0.0500	time 0.4523 (0.5446)	data time 0.0029 (0.0594)	model time 0.4495 (0.4808)	loss 0.6944 (0.6417)	grad_norm 1.0427 (0.8877)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:05:15 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][90/156]	eta 0:00:35 lr 0.000122	 wd 0.0500	time 0.4514 (0.5432)	data time 0.0395 (0.0555)	model time 0.4120 (0.4877)	loss 0.6283 (0.6415)	grad_norm 0.6706 (0.8799)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:05:20 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][100/156]	eta 0:00:30 lr 0.000122	 wd 0.0500	time 0.5495 (0.5386)	data time 0.0022 (0.0508)	model time 0.5473 (0.4879)	loss 0.6251 (0.6422)	grad_norm 0.5748 (0.8794)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:05:25 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][110/156]	eta 0:00:24 lr 0.000122	 wd 0.0500	time 0.4661 (0.5387)	data time 0.0023 (0.0466)	model time 0.4638 (0.4957)	loss 0.6315 (0.6431)	grad_norm 0.7518 (0.8880)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:05:30 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][120/156]	eta 0:00:19 lr 0.000122	 wd 0.0500	time 0.4726 (0.5357)	data time 0.0006 (0.0449)	model time 0.4721 (0.4930)	loss 0.6096 (0.6420)	grad_norm 1.4465 (0.9034)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:05:35 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][130/156]	eta 0:00:13 lr 0.000122	 wd 0.0500	time 0.4325 (0.5315)	data time 0.0006 (0.0421)	model time 0.4318 (0.4905)	loss 0.6772 (0.6416)	grad_norm 0.8962 (0.9152)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:05:40 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][140/156]	eta 0:00:08 lr 0.000122	 wd 0.0500	time 0.4457 (0.5290)	data time 0.0009 (0.0408)	model time 0.4447 (0.4886)	loss 0.6925 (0.6428)	grad_norm 1.3728 (0.9362)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:05:45 vssm1_tiny_0230s](training.py 201): INFO Train: [49/300][150/156]	eta 0:00:03 lr 0.000122	 wd 0.0500	time 0.6779 (0.5296)	data time 0.0007 (0.0382)	model time 0.6772 (0.4934)	loss 0.6793 (0.6436)	grad_norm 0.8287 (0.9328)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:05:49 vssm1_tiny_0230s](training.py 212): INFO EPOCH 49 training takes 0:01:23
[2024-11-09 12:05:49 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_49.pth saving......
[2024-11-09 12:05:49 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_49.pth saved !!!
[2024-11-09 12:05:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.583 (2.583)	Loss 0.4097 (0.4097)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:05:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.197 (0.503)	Loss 0.4070 (0.4184)	Acc@1 92.969 (90.412)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:05:57 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.391)	Loss 0.5332 (0.4332)	Acc@1 70.312 (88.021)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:06:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.148 (0.340)	Loss 0.6157 (0.4818)	Acc@1 63.281 (81.729)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:06:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 79.080 Acc@5 100.000
[2024-11-09 12:06:02 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 79.1%
[2024-11-09 12:06:02 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 80.60%
[2024-11-09 12:06:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.505 (3.505)	Loss 0.4858 (0.4858)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:06:08 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.161 (0.548)	Loss 0.4939 (0.4895)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:06:11 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.180 (0.394)	Loss 0.8213 (0.5148)	Acc@1 15.625 (93.080)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:06:13 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.343)	Loss 0.8511 (0.6188)	Acc@1 13.281 (67.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:06:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 56.060 Acc@5 100.000
[2024-11-09 12:06:16 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 56.1%
[2024-11-09 12:06:16 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:06:21 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][0/156]	eta 0:12:10 lr 0.000122	 wd 0.0500	time 4.6815 (4.6815)	data time 4.2016 (4.2016)	model time 0.0000 (0.0000)	loss 0.6702 (0.6702)	grad_norm 0.8716 (0.8716)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:06:26 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][10/156]	eta 0:02:08 lr 0.000122	 wd 0.0500	time 0.4087 (0.8769)	data time 0.0036 (0.3976)	model time 0.0000 (0.0000)	loss 0.6455 (0.6525)	grad_norm 0.6572 (0.9056)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:06:31 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][20/156]	eta 0:01:35 lr 0.000121	 wd 0.0500	time 0.5534 (0.7058)	data time 0.0178 (0.2138)	model time 0.0000 (0.0000)	loss 0.6576 (0.6465)	grad_norm 1.0897 (1.0064)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:06:36 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][30/156]	eta 0:01:21 lr 0.000121	 wd 0.0500	time 0.6046 (0.6470)	data time 0.0282 (0.1511)	model time 0.0000 (0.0000)	loss 0.6061 (0.6449)	grad_norm 1.2195 (1.0264)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:06:41 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][40/156]	eta 0:01:11 lr 0.000121	 wd 0.0500	time 0.4112 (0.6129)	data time 0.0026 (0.1171)	model time 0.0000 (0.0000)	loss 0.7043 (0.6459)	grad_norm 1.2414 (1.0223)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:06:47 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][50/156]	eta 0:01:03 lr 0.000121	 wd 0.0500	time 0.4769 (0.5984)	data time 0.0007 (0.0972)	model time 0.0000 (0.0000)	loss 0.6541 (0.6472)	grad_norm 0.8188 (0.9960)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:06:52 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][60/156]	eta 0:00:55 lr 0.000121	 wd 0.0500	time 0.4268 (0.5827)	data time 0.0067 (0.0833)	model time 0.4201 (0.4896)	loss 0.6220 (0.6462)	grad_norm 1.1473 (1.0347)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:06:56 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][70/156]	eta 0:00:48 lr 0.000121	 wd 0.0500	time 0.4422 (0.5696)	data time 0.0009 (0.0741)	model time 0.4413 (0.4809)	loss 0.6675 (0.6457)	grad_norm 0.8938 (1.0207)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:07:02 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][80/156]	eta 0:00:42 lr 0.000121	 wd 0.0500	time 0.4642 (0.5640)	data time 0.0382 (0.0671)	model time 0.4260 (0.4895)	loss 0.6259 (0.6458)	grad_norm 0.7271 (0.9917)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:07:07 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][90/156]	eta 0:00:37 lr 0.000121	 wd 0.0500	time 0.4140 (0.5610)	data time 0.0067 (0.0638)	model time 0.4074 (0.4920)	loss 0.6690 (0.6468)	grad_norm 0.7937 (0.9779)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:07:12 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][100/156]	eta 0:00:31 lr 0.000121	 wd 0.0500	time 0.5882 (0.5573)	data time 0.1108 (0.0607)	model time 0.4774 (0.4918)	loss 0.6437 (0.6471)	grad_norm 0.6835 (0.9555)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:07:17 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][110/156]	eta 0:00:25 lr 0.000121	 wd 0.0500	time 0.4226 (0.5508)	data time 0.0140 (0.0570)	model time 0.4086 (0.4876)	loss 0.6361 (0.6476)	grad_norm 0.8952 (0.9537)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:07:22 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][120/156]	eta 0:00:19 lr 0.000121	 wd 0.0500	time 0.7426 (0.5484)	data time 0.0054 (0.0534)	model time 0.7371 (0.4905)	loss 0.6078 (0.6466)	grad_norm 0.6769 (0.9449)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:07:27 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][130/156]	eta 0:00:14 lr 0.000121	 wd 0.0500	time 0.4809 (0.5435)	data time 0.0140 (0.0501)	model time 0.4668 (0.4885)	loss 0.6565 (0.6472)	grad_norm 1.2597 (0.9655)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:07:32 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][140/156]	eta 0:00:08 lr 0.000121	 wd 0.0500	time 0.4168 (0.5404)	data time 0.0008 (0.0479)	model time 0.4160 (0.4875)	loss 0.6840 (0.6474)	grad_norm 1.0465 (0.9934)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:07:37 vssm1_tiny_0230s](training.py 201): INFO Train: [50/300][150/156]	eta 0:00:03 lr 0.000121	 wd 0.0500	time 0.4259 (0.5388)	data time 0.0007 (0.0448)	model time 0.4253 (0.4902)	loss 0.6732 (0.6479)	grad_norm 1.4263 (0.9928)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:07:40 vssm1_tiny_0230s](training.py 212): INFO EPOCH 50 training takes 0:01:24
[2024-11-09 12:07:40 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_50.pth saving......
[2024-11-09 12:07:41 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_50.pth saved !!!
[2024-11-09 12:07:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.839 (3.839)	Loss 0.6294 (0.6294)	Acc@1 66.406 (66.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:07:47 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.561 (0.562)	Loss 0.6099 (0.6313)	Acc@1 66.406 (66.477)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:07:49 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.197 (0.383)	Loss 0.2913 (0.6188)	Acc@1 92.188 (66.667)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:07:52 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.177 (0.352)	Loss 0.3679 (0.5295)	Acc@1 85.156 (74.042)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:07:54 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 77.180 Acc@5 100.000
[2024-11-09 12:07:54 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 77.2%
[2024-11-09 12:07:54 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 80.60%
[2024-11-09 12:07:58 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.487 (3.487)	Loss 0.4817 (0.4817)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:08:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.156 (0.585)	Loss 0.4897 (0.4854)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:08:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.454)	Loss 0.8232 (0.5110)	Acc@1 16.406 (93.080)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:08:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.397)	Loss 0.8540 (0.6169)	Acc@1 13.281 (67.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:08:09 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 56.180 Acc@5 100.000
[2024-11-09 12:08:09 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 56.2%
[2024-11-09 12:08:09 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:08:13 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][0/156]	eta 0:11:25 lr 0.000121	 wd 0.0500	time 4.3971 (4.3971)	data time 3.8721 (3.8721)	model time 0.0000 (0.0000)	loss 0.6408 (0.6408)	grad_norm 0.5425 (0.5425)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:08:18 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][10/156]	eta 0:01:58 lr 0.000121	 wd 0.0500	time 0.4259 (0.8119)	data time 0.0035 (0.3547)	model time 0.0000 (0.0000)	loss 0.5667 (0.6431)	grad_norm 0.9968 (1.1894)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:08:23 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][20/156]	eta 0:01:29 lr 0.000121	 wd 0.0500	time 0.4275 (0.6565)	data time 0.0010 (0.1916)	model time 0.0000 (0.0000)	loss 0.6711 (0.6500)	grad_norm 1.1193 (1.2389)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:08:27 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][30/156]	eta 0:01:14 lr 0.000121	 wd 0.0500	time 0.4638 (0.5945)	data time 0.0030 (0.1332)	model time 0.0000 (0.0000)	loss 0.6744 (0.6488)	grad_norm 1.4060 (1.1690)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:08:32 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][40/156]	eta 0:01:05 lr 0.000121	 wd 0.0500	time 0.5134 (0.5669)	data time 0.0285 (0.1057)	model time 0.0000 (0.0000)	loss 0.6062 (0.6486)	grad_norm 0.9030 (1.0962)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:08:38 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][50/156]	eta 0:01:00 lr 0.000121	 wd 0.0500	time 0.5378 (0.5734)	data time 0.0105 (0.0880)	model time 0.0000 (0.0000)	loss 0.6354 (0.6482)	grad_norm 0.8498 (1.0879)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:08:44 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][60/156]	eta 0:00:55 lr 0.000121	 wd 0.0500	time 0.4323 (0.5788)	data time 0.0008 (0.0775)	model time 0.4314 (0.5823)	loss 0.6046 (0.6454)	grad_norm 0.7007 (1.0726)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:08:50 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][70/156]	eta 0:00:49 lr 0.000121	 wd 0.0500	time 0.4562 (0.5753)	data time 0.0164 (0.0702)	model time 0.4398 (0.5555)	loss 0.6437 (0.6443)	grad_norm 0.8335 (1.1023)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:08:55 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][80/156]	eta 0:00:43 lr 0.000121	 wd 0.0500	time 0.7360 (0.5684)	data time 0.1592 (0.0661)	model time 0.5769 (0.5309)	loss 0.6966 (0.6459)	grad_norm 1.0634 (1.1106)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:09:00 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][90/156]	eta 0:00:37 lr 0.000121	 wd 0.0500	time 0.4396 (0.5654)	data time 0.0073 (0.0631)	model time 0.4323 (0.5238)	loss 0.6626 (0.6450)	grad_norm 0.6561 (1.0776)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:09:06 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][100/156]	eta 0:00:31 lr 0.000121	 wd 0.0500	time 0.5294 (0.5647)	data time 0.0006 (0.0599)	model time 0.5289 (0.5247)	loss 0.6173 (0.6428)	grad_norm 1.1987 (1.0564)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:09:11 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][110/156]	eta 0:00:25 lr 0.000121	 wd 0.0500	time 0.4523 (0.5576)	data time 0.0463 (0.0556)	model time 0.4060 (0.5161)	loss 0.7108 (0.6427)	grad_norm 1.9281 (1.0645)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:09:16 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][120/156]	eta 0:00:19 lr 0.000121	 wd 0.0500	time 0.4433 (0.5497)	data time 0.0202 (0.0519)	model time 0.4231 (0.5068)	loss 0.6708 (0.6432)	grad_norm 0.9517 (1.0625)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:09:20 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][130/156]	eta 0:00:14 lr 0.000121	 wd 0.0500	time 0.4976 (0.5447)	data time 0.0378 (0.0488)	model time 0.4598 (0.5025)	loss 0.6459 (0.6434)	grad_norm 1.0552 (1.0618)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:09:26 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][140/156]	eta 0:00:08 lr 0.000121	 wd 0.0500	time 0.4599 (0.5425)	data time 0.0008 (0.0465)	model time 0.4591 (0.5019)	loss 0.6811 (0.6442)	grad_norm 1.6024 (1.0615)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:09:30 vssm1_tiny_0230s](training.py 201): INFO Train: [51/300][150/156]	eta 0:00:03 lr 0.000121	 wd 0.0500	time 0.4127 (0.5373)	data time 0.0043 (0.0435)	model time 0.4084 (0.4981)	loss 0.6837 (0.6445)	grad_norm 0.7169 (1.0676)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:09:33 vssm1_tiny_0230s](training.py 212): INFO EPOCH 51 training takes 0:01:24
[2024-11-09 12:09:33 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_51.pth saving......
[2024-11-09 12:09:33 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_51.pth saved !!!
[2024-11-09 12:09:37 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.461 (3.461)	Loss 0.4160 (0.4160)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:09:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.517)	Loss 0.4082 (0.4241)	Acc@1 91.406 (89.560)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:09:41 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.183 (0.374)	Loss 0.5078 (0.4407)	Acc@1 77.344 (87.426)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:09:44 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.341)	Loss 0.5889 (0.4818)	Acc@1 67.969 (81.678)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:09:47 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 79.280 Acc@5 100.000
[2024-11-09 12:09:47 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 79.3%
[2024-11-09 12:09:47 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 80.60%
[2024-11-09 12:09:50 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.393 (3.393)	Loss 0.4778 (0.4778)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:09:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.528)	Loss 0.4858 (0.4814)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:09:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.411)	Loss 0.8247 (0.5075)	Acc@1 16.406 (93.080)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:09:58 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.358)	Loss 0.8560 (0.6151)	Acc@1 14.062 (67.717)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:10:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 56.320 Acc@5 100.000
[2024-11-09 12:10:00 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 56.3%
[2024-11-09 12:10:00 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:10:05 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][0/156]	eta 0:11:32 lr 0.000121	 wd 0.0500	time 4.4367 (4.4367)	data time 4.0112 (4.0112)	model time 0.0000 (0.0000)	loss 0.6579 (0.6579)	grad_norm 0.8085 (0.8085)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:10:10 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][10/156]	eta 0:02:09 lr 0.000121	 wd 0.0500	time 0.4712 (0.8880)	data time 0.0028 (0.3915)	model time 0.0000 (0.0000)	loss 0.6780 (0.6407)	grad_norm 0.7892 (0.9403)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:10:16 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][20/156]	eta 0:01:38 lr 0.000121	 wd 0.0500	time 0.4421 (0.7258)	data time 0.0199 (0.2160)	model time 0.0000 (0.0000)	loss 0.6439 (0.6396)	grad_norm 1.4913 (1.0555)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:10:20 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][30/156]	eta 0:01:21 lr 0.000121	 wd 0.0500	time 0.4080 (0.6506)	data time 0.0008 (0.1517)	model time 0.0000 (0.0000)	loss 0.6390 (0.6443)	grad_norm 0.6016 (0.9988)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:10:25 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][40/156]	eta 0:01:11 lr 0.000121	 wd 0.0500	time 0.4777 (0.6142)	data time 0.0279 (0.1178)	model time 0.0000 (0.0000)	loss 0.6268 (0.6456)	grad_norm 0.9478 (0.9708)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:10:31 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][50/156]	eta 0:01:03 lr 0.000121	 wd 0.0500	time 0.5881 (0.5975)	data time 0.0147 (0.0991)	model time 0.0000 (0.0000)	loss 0.6241 (0.6469)	grad_norm 0.8509 (1.0171)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:10:36 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][60/156]	eta 0:00:55 lr 0.000121	 wd 0.0500	time 0.5587 (0.5789)	data time 0.0191 (0.0858)	model time 0.5396 (0.4659)	loss 0.6450 (0.6468)	grad_norm 0.8528 (1.0043)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:10:41 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][70/156]	eta 0:00:49 lr 0.000121	 wd 0.0500	time 0.5258 (0.5708)	data time 0.0548 (0.0773)	model time 0.4710 (0.4808)	loss 0.6105 (0.6458)	grad_norm 0.8930 (0.9697)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:10:46 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][80/156]	eta 0:00:42 lr 0.000121	 wd 0.0500	time 0.4771 (0.5594)	data time 0.0010 (0.0692)	model time 0.4761 (0.4761)	loss 0.6294 (0.6445)	grad_norm 0.5743 (0.9617)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:10:51 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][90/156]	eta 0:00:36 lr 0.000121	 wd 0.0500	time 0.5651 (0.5531)	data time 0.0202 (0.0633)	model time 0.5449 (0.4789)	loss 0.6644 (0.6447)	grad_norm 1.0913 (0.9697)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:10:55 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][100/156]	eta 0:00:30 lr 0.000121	 wd 0.0500	time 0.4510 (0.5450)	data time 0.0273 (0.0580)	model time 0.4237 (0.4754)	loss 0.6375 (0.6448)	grad_norm 0.8708 (0.9736)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:11:01 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][110/156]	eta 0:00:25 lr 0.000121	 wd 0.0500	time 0.4994 (0.5441)	data time 0.0243 (0.0541)	model time 0.4751 (0.4828)	loss 0.6524 (0.6446)	grad_norm 0.5930 (0.9865)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:11:05 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][120/156]	eta 0:00:19 lr 0.000121	 wd 0.0500	time 0.4357 (0.5387)	data time 0.0206 (0.0521)	model time 0.4152 (0.4782)	loss 0.6118 (0.6433)	grad_norm 1.0160 (0.9923)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:11:11 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][130/156]	eta 0:00:13 lr 0.000121	 wd 0.0500	time 0.4825 (0.5362)	data time 0.0008 (0.0494)	model time 0.4817 (0.4794)	loss 0.5695 (0.6430)	grad_norm 1.0298 (0.9932)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:11:15 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][140/156]	eta 0:00:08 lr 0.000121	 wd 0.0500	time 0.4333 (0.5333)	data time 0.0008 (0.0468)	model time 0.4324 (0.4796)	loss 0.6305 (0.6437)	grad_norm 1.1619 (0.9899)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:11:21 vssm1_tiny_0230s](training.py 201): INFO Train: [52/300][150/156]	eta 0:00:03 lr 0.000121	 wd 0.0500	time 0.5297 (0.5319)	data time 0.0006 (0.0439)	model time 0.5291 (0.4827)	loss 0.6720 (0.6446)	grad_norm 0.8167 (0.9803)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:11:23 vssm1_tiny_0230s](training.py 212): INFO EPOCH 52 training takes 0:01:23
[2024-11-09 12:11:24 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_52.pth saving......
[2024-11-09 12:11:24 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_52.pth saved !!!
[2024-11-09 12:11:28 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.239 (4.239)	Loss 0.5620 (0.5620)	Acc@1 74.219 (74.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:11:30 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.173 (0.547)	Loss 0.5430 (0.5751)	Acc@1 76.562 (72.017)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:11:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.183 (0.402)	Loss 0.3608 (0.5696)	Acc@1 90.625 (72.098)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:11:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.355)	Loss 0.4346 (0.5186)	Acc@1 82.812 (76.613)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:11:37 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 78.400 Acc@5 100.000
[2024-11-09 12:11:37 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 78.4%
[2024-11-09 12:11:37 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 80.60%
[2024-11-09 12:11:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.995 (2.995)	Loss 0.4744 (0.4744)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:11:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.658 (0.547)	Loss 0.4824 (0.4780)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:11:46 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.207 (0.422)	Loss 0.8257 (0.5043)	Acc@1 17.188 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:11:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.148 (0.379)	Loss 0.8579 (0.6134)	Acc@1 14.844 (67.843)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:11:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 56.500 Acc@5 100.000
[2024-11-09 12:11:51 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 56.5%
[2024-11-09 12:11:51 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:11:55 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][0/156]	eta 0:11:05 lr 0.000121	 wd 0.0500	time 4.2636 (4.2636)	data time 3.8576 (3.8576)	model time 0.0000 (0.0000)	loss 0.6772 (0.6772)	grad_norm 0.7136 (0.7136)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:01 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][10/156]	eta 0:02:08 lr 0.000121	 wd 0.0500	time 0.4106 (0.8804)	data time 0.0041 (0.3912)	model time 0.0000 (0.0000)	loss 0.6477 (0.6502)	grad_norm 0.6008 (0.9211)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:06 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][20/156]	eta 0:01:35 lr 0.000121	 wd 0.0500	time 0.4939 (0.7024)	data time 0.0029 (0.2137)	model time 0.0000 (0.0000)	loss 0.6742 (0.6462)	grad_norm 0.6705 (0.9198)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:10 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][30/156]	eta 0:01:18 lr 0.000121	 wd 0.0500	time 0.4340 (0.6268)	data time 0.0012 (0.1469)	model time 0.0000 (0.0000)	loss 0.6350 (0.6439)	grad_norm 0.7897 (0.9041)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:16 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][40/156]	eta 0:01:09 lr 0.000121	 wd 0.0500	time 0.4844 (0.6020)	data time 0.0009 (0.1185)	model time 0.0000 (0.0000)	loss 0.6244 (0.6424)	grad_norm 0.9003 (0.9149)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:21 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][50/156]	eta 0:01:02 lr 0.000121	 wd 0.0500	time 0.4716 (0.5872)	data time 0.0039 (0.0968)	model time 0.0000 (0.0000)	loss 0.6369 (0.6430)	grad_norm 1.5430 (1.0375)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:26 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][60/156]	eta 0:00:55 lr 0.000121	 wd 0.0500	time 0.4962 (0.5737)	data time 0.0056 (0.0826)	model time 0.4906 (0.4948)	loss 0.6159 (0.6426)	grad_norm 1.2185 (1.0083)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:31 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][70/156]	eta 0:00:48 lr 0.000121	 wd 0.0500	time 0.4093 (0.5654)	data time 0.0005 (0.0724)	model time 0.4088 (0.4993)	loss 0.6563 (0.6432)	grad_norm 1.1812 (1.0158)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:37 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][80/156]	eta 0:00:42 lr 0.000121	 wd 0.0500	time 0.5926 (0.5633)	data time 0.0112 (0.0675)	model time 0.5814 (0.5050)	loss 0.6251 (0.6400)	grad_norm 0.8032 (1.0025)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:42 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][90/156]	eta 0:00:36 lr 0.000121	 wd 0.0500	time 0.6498 (0.5552)	data time 0.0275 (0.0619)	model time 0.6223 (0.4969)	loss 0.6313 (0.6411)	grad_norm 0.9651 (1.0176)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:46 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][100/156]	eta 0:00:30 lr 0.000121	 wd 0.0500	time 0.5400 (0.5496)	data time 0.0020 (0.0572)	model time 0.5380 (0.4943)	loss 0.5942 (0.6411)	grad_norm 1.0571 (1.0161)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:52 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][110/156]	eta 0:00:25 lr 0.000121	 wd 0.0500	time 0.4563 (0.5489)	data time 0.0026 (0.0529)	model time 0.4537 (0.5009)	loss 0.6108 (0.6415)	grad_norm 1.0452 (1.0188)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:12:57 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][120/156]	eta 0:00:19 lr 0.000121	 wd 0.0500	time 0.4421 (0.5457)	data time 0.0135 (0.0502)	model time 0.4286 (0.4992)	loss 0.6530 (0.6417)	grad_norm 0.6944 (1.0477)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:13:02 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][130/156]	eta 0:00:14 lr 0.000121	 wd 0.0500	time 0.5627 (0.5425)	data time 0.0006 (0.0473)	model time 0.5621 (0.4982)	loss 0.6032 (0.6419)	grad_norm 0.9370 (1.0446)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:13:07 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][140/156]	eta 0:00:08 lr 0.000121	 wd 0.0500	time 0.4634 (0.5409)	data time 0.0009 (0.0443)	model time 0.4626 (0.5000)	loss 0.6316 (0.6419)	grad_norm 0.7309 (1.0449)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:13:12 vssm1_tiny_0230s](training.py 201): INFO Train: [53/300][150/156]	eta 0:00:03 lr 0.000121	 wd 0.0500	time 0.4122 (0.5348)	data time 0.0006 (0.0414)	model time 0.4117 (0.4949)	loss 0.6554 (0.6412)	grad_norm 0.7816 (1.0400)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:13:14 vssm1_tiny_0230s](training.py 212): INFO EPOCH 53 training takes 0:01:23
[2024-11-09 12:13:14 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_53.pth saving......
[2024-11-09 12:13:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_53.pth saved !!!
[2024-11-09 12:13:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.300 (2.300)	Loss 0.3811 (0.3811)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:13:19 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.165 (0.440)	Loss 0.3816 (0.3870)	Acc@1 90.625 (89.915)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:13:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.177 (0.330)	Loss 0.4648 (0.4044)	Acc@1 78.125 (87.984)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:13:23 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.294)	Loss 0.5640 (0.4429)	Acc@1 68.750 (82.535)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:13:26 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 80.140 Acc@5 100.000
[2024-11-09 12:13:26 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 80.1%
[2024-11-09 12:13:26 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 80.60%
[2024-11-09 12:13:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.582 (2.582)	Loss 0.4702 (0.4702)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:13:32 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.507)	Loss 0.4785 (0.4741)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:13:35 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.179 (0.422)	Loss 0.8271 (0.5008)	Acc@1 17.188 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:13:38 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.475 (0.384)	Loss 0.8604 (0.6115)	Acc@1 14.844 (68.044)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:13:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 56.720 Acc@5 100.000
[2024-11-09 12:13:40 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 56.7%
[2024-11-09 12:13:40 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:13:45 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][0/156]	eta 0:11:24 lr 0.000121	 wd 0.0500	time 4.3893 (4.3893)	data time 3.7660 (3.7660)	model time 0.0000 (0.0000)	loss 0.6208 (0.6208)	grad_norm 3.0695 (3.0695)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:13:50 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][10/156]	eta 0:02:05 lr 0.000121	 wd 0.0500	time 0.4684 (0.8605)	data time 0.0110 (0.3600)	model time 0.0000 (0.0000)	loss 0.5933 (0.6258)	grad_norm 0.7833 (1.3525)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:13:55 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][20/156]	eta 0:01:36 lr 0.000121	 wd 0.0500	time 0.5899 (0.7089)	data time 0.0006 (0.1972)	model time 0.0000 (0.0000)	loss 0.6278 (0.6395)	grad_norm 1.3204 (1.4651)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:14:00 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][30/156]	eta 0:01:21 lr 0.000121	 wd 0.0500	time 0.6328 (0.6471)	data time 0.0154 (0.1393)	model time 0.0000 (0.0000)	loss 0.6570 (0.6405)	grad_norm 0.6091 (1.3246)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:14:05 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][40/156]	eta 0:01:11 lr 0.000120	 wd 0.0500	time 0.5566 (0.6154)	data time 0.0577 (0.1093)	model time 0.0000 (0.0000)	loss 0.6145 (0.6420)	grad_norm 1.0782 (1.2599)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:14:11 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][50/156]	eta 0:01:02 lr 0.000120	 wd 0.0500	time 0.4437 (0.5935)	data time 0.0006 (0.0893)	model time 0.0000 (0.0000)	loss 0.6741 (0.6405)	grad_norm 1.1350 (1.2136)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:14:16 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][60/156]	eta 0:00:55 lr 0.000120	 wd 0.0500	time 0.4625 (0.5797)	data time 0.0007 (0.0771)	model time 0.4618 (0.4942)	loss 0.6128 (0.6388)	grad_norm 0.9599 (1.2026)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:14:20 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][70/156]	eta 0:00:48 lr 0.000120	 wd 0.0500	time 0.5261 (0.5660)	data time 0.0203 (0.0679)	model time 0.5058 (0.4828)	loss 0.6452 (0.6414)	grad_norm 1.2475 (1.1810)	loss_scale 131072.0000 (70151.2113)	mem 13675MB
[2024-11-09 12:14:26 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][80/156]	eta 0:00:42 lr 0.000120	 wd 0.0500	time 0.5730 (0.5599)	data time 0.0032 (0.0607)	model time 0.5697 (0.4908)	loss 0.6468 (0.6430)	grad_norm 1.0783 (1.1435)	loss_scale 131072.0000 (77672.2963)	mem 13675MB
[2024-11-09 12:14:30 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][90/156]	eta 0:00:36 lr 0.000120	 wd 0.0500	time 0.4114 (0.5519)	data time 0.0014 (0.0551)	model time 0.4099 (0.4874)	loss 0.6201 (0.6437)	grad_norm 0.8741 (1.1145)	loss_scale 131072.0000 (83540.3956)	mem 13675MB
[2024-11-09 12:14:35 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][100/156]	eta 0:00:30 lr 0.000120	 wd 0.0500	time 0.6203 (0.5462)	data time 0.0228 (0.0508)	model time 0.5976 (0.4866)	loss 0.6618 (0.6436)	grad_norm 0.7625 (1.1015)	loss_scale 131072.0000 (88246.4950)	mem 13675MB
[2024-11-09 12:14:40 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][110/156]	eta 0:00:24 lr 0.000120	 wd 0.0500	time 0.4688 (0.5417)	data time 0.0184 (0.0472)	model time 0.4503 (0.4862)	loss 0.6178 (0.6437)	grad_norm 0.8402 (1.0768)	loss_scale 131072.0000 (92104.6486)	mem 13675MB
[2024-11-09 12:14:45 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][120/156]	eta 0:00:19 lr 0.000120	 wd 0.0500	time 0.5061 (0.5361)	data time 0.0229 (0.0446)	model time 0.4832 (0.4822)	loss 0.6409 (0.6444)	grad_norm 1.6524 (1.0960)	loss_scale 131072.0000 (95325.0909)	mem 13675MB
[2024-11-09 12:14:51 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][130/156]	eta 0:00:13 lr 0.000120	 wd 0.0500	time 0.5712 (0.5372)	data time 0.0224 (0.0430)	model time 0.5488 (0.4880)	loss 0.5852 (0.6444)	grad_norm 1.0946 (1.0909)	loss_scale 131072.0000 (98053.8626)	mem 13675MB
[2024-11-09 12:14:56 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][140/156]	eta 0:00:08 lr 0.000120	 wd 0.0500	time 0.6050 (0.5366)	data time 0.0210 (0.0413)	model time 0.5840 (0.4903)	loss 0.6476 (0.6434)	grad_norm 0.6511 (1.0834)	loss_scale 131072.0000 (100395.5745)	mem 13675MB
[2024-11-09 12:15:01 vssm1_tiny_0230s](training.py 201): INFO Train: [54/300][150/156]	eta 0:00:03 lr 0.000120	 wd 0.0500	time 0.5519 (0.5330)	data time 0.0004 (0.0386)	model time 0.5515 (0.4895)	loss 0.7079 (0.6435)	grad_norm 1.7117 (1.0911)	loss_scale 131072.0000 (102427.1258)	mem 13675MB
[2024-11-09 12:15:04 vssm1_tiny_0230s](training.py 212): INFO EPOCH 54 training takes 0:01:23
[2024-11-09 12:15:04 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_54.pth saving......
[2024-11-09 12:15:04 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_54.pth saved !!!
[2024-11-09 12:15:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.851 (3.851)	Loss 0.5986 (0.5986)	Acc@1 70.312 (70.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:15:11 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.225 (0.593)	Loss 0.6025 (0.6259)	Acc@1 64.844 (65.412)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:15:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.132 (0.419)	Loss 0.2615 (0.6102)	Acc@1 96.094 (66.890)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:15:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.354)	Loss 0.3408 (0.5164)	Acc@1 89.062 (74.773)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:15:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 78.260 Acc@5 100.000
[2024-11-09 12:15:18 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 78.3%
[2024-11-09 12:15:18 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 80.60%
[2024-11-09 12:15:21 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.220 (3.220)	Loss 0.4666 (0.4666)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:15:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.150 (0.579)	Loss 0.4746 (0.4703)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:15:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.388)	Loss 0.8281 (0.4974)	Acc@1 17.969 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:15:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.341)	Loss 0.8628 (0.6098)	Acc@1 14.844 (68.145)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:15:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 56.840 Acc@5 100.000
[2024-11-09 12:15:31 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 56.8%
[2024-11-09 12:15:31 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:15:35 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][0/156]	eta 0:08:20 lr 0.000120	 wd 0.0500	time 3.2080 (3.2080)	data time 2.6448 (2.6448)	model time 0.0000 (0.0000)	loss 0.6417 (0.6417)	grad_norm 1.3701 (1.3701)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:15:40 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][10/156]	eta 0:01:56 lr 0.000120	 wd 0.0500	time 0.4949 (0.7957)	data time 0.0006 (0.2854)	model time 0.0000 (0.0000)	loss 0.6556 (0.6384)	grad_norm 0.8237 (1.1862)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:15:45 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][20/156]	eta 0:01:30 lr 0.000120	 wd 0.0500	time 0.5491 (0.6661)	data time 0.0007 (0.1659)	model time 0.0000 (0.0000)	loss 0.6848 (0.6453)	grad_norm 1.3850 (1.1129)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:15:51 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][30/156]	eta 0:01:18 lr 0.000120	 wd 0.0500	time 0.5580 (0.6262)	data time 0.0459 (0.1197)	model time 0.0000 (0.0000)	loss 0.6309 (0.6440)	grad_norm 0.7535 (1.0611)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:15:56 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][40/156]	eta 0:01:10 lr 0.000120	 wd 0.0500	time 0.6325 (0.6035)	data time 0.0278 (0.0935)	model time 0.0000 (0.0000)	loss 0.6388 (0.6430)	grad_norm 0.8749 (1.0895)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:02 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][50/156]	eta 0:01:03 lr 0.000120	 wd 0.0500	time 0.6631 (0.5961)	data time 0.0197 (0.0788)	model time 0.0000 (0.0000)	loss 0.6480 (0.6429)	grad_norm 0.7806 (1.1580)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:07 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][60/156]	eta 0:00:56 lr 0.000120	 wd 0.0500	time 0.6215 (0.5890)	data time 0.0032 (0.0680)	model time 0.6182 (0.5398)	loss 0.6453 (0.6414)	grad_norm 0.7957 (1.1323)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:12 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][70/156]	eta 0:00:49 lr 0.000120	 wd 0.0500	time 0.4758 (0.5738)	data time 0.0067 (0.0596)	model time 0.4691 (0.5062)	loss 0.6681 (0.6416)	grad_norm 1.0254 (1.1216)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:17 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][80/156]	eta 0:00:42 lr 0.000120	 wd 0.0500	time 0.5465 (0.5621)	data time 0.0299 (0.0547)	model time 0.5166 (0.4905)	loss 0.6402 (0.6401)	grad_norm 0.7391 (1.0893)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:22 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][90/156]	eta 0:00:36 lr 0.000120	 wd 0.0500	time 0.4447 (0.5575)	data time 0.0028 (0.0510)	model time 0.4419 (0.4927)	loss 0.6052 (0.6404)	grad_norm 1.0135 (1.1020)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:27 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][100/156]	eta 0:00:30 lr 0.000120	 wd 0.0500	time 0.5405 (0.5531)	data time 0.0489 (0.0480)	model time 0.4916 (0.4927)	loss 0.6503 (0.6396)	grad_norm 1.0041 (1.0933)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:32 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][110/156]	eta 0:00:25 lr 0.000120	 wd 0.0500	time 0.4623 (0.5463)	data time 0.0292 (0.0449)	model time 0.4331 (0.4879)	loss 0.6425 (0.6388)	grad_norm 2.9101 (1.1316)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:37 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][120/156]	eta 0:00:19 lr 0.000120	 wd 0.0500	time 0.4275 (0.5461)	data time 0.0005 (0.0422)	model time 0.4269 (0.4943)	loss 0.6729 (0.6386)	grad_norm 1.5456 (1.1391)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:42 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][130/156]	eta 0:00:14 lr 0.000120	 wd 0.0500	time 0.6553 (0.5433)	data time 0.0013 (0.0401)	model time 0.6540 (0.4942)	loss 0.6691 (0.6398)	grad_norm 1.6154 (1.1369)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:48 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][140/156]	eta 0:00:08 lr 0.000120	 wd 0.0500	time 0.6177 (0.5418)	data time 0.0009 (0.0377)	model time 0.6169 (0.4966)	loss 0.6296 (0.6398)	grad_norm 1.0408 (1.1251)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:52 vssm1_tiny_0230s](training.py 201): INFO Train: [55/300][150/156]	eta 0:00:03 lr 0.000120	 wd 0.0500	time 0.4363 (0.5370)	data time 0.0005 (0.0353)	model time 0.4359 (0.4937)	loss 0.6842 (0.6397)	grad_norm 1.4007 (1.1147)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:16:55 vssm1_tiny_0230s](training.py 212): INFO EPOCH 55 training takes 0:01:23
[2024-11-09 12:16:55 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_55.pth saving......
[2024-11-09 12:16:56 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_55.pth saved !!!
[2024-11-09 12:16:59 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.998 (2.998)	Loss 0.5703 (0.5703)	Acc@1 71.875 (71.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:17:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.471 (0.564)	Loss 0.5557 (0.5674)	Acc@1 75.000 (73.082)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:17:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.398)	Loss 0.2947 (0.5642)	Acc@1 92.188 (73.140)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:17:06 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.173 (0.348)	Loss 0.3662 (0.4934)	Acc@1 83.594 (77.898)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:17:09 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 80.120 Acc@5 100.000
[2024-11-09 12:17:09 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 80.1%
[2024-11-09 12:17:09 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 80.60%
[2024-11-09 12:17:12 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.369 (3.369)	Loss 0.4629 (0.4629)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:17:16 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.253 (0.635)	Loss 0.4709 (0.4666)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:17:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.154 (0.410)	Loss 0.8296 (0.4940)	Acc@1 17.969 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:17:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.356)	Loss 0.8647 (0.6079)	Acc@1 14.844 (68.296)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:17:23 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.020 Acc@5 100.000
[2024-11-09 12:17:23 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 57.0%
[2024-11-09 12:17:23 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:17:28 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][0/156]	eta 0:11:06 lr 0.000120	 wd 0.0500	time 4.2750 (4.2750)	data time 3.8325 (3.8325)	model time 0.0000 (0.0000)	loss 0.6535 (0.6535)	grad_norm 1.9474 (1.9474)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:17:33 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][10/156]	eta 0:02:04 lr 0.000120	 wd 0.0500	time 0.5258 (0.8523)	data time 0.0034 (0.3564)	model time 0.0000 (0.0000)	loss 0.6665 (0.6510)	grad_norm 0.7485 (1.1416)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:17:38 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][20/156]	eta 0:01:33 lr 0.000120	 wd 0.0500	time 0.5744 (0.6877)	data time 0.0222 (0.1906)	model time 0.0000 (0.0000)	loss 0.6680 (0.6523)	grad_norm 0.8676 (1.0579)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:17:43 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][30/156]	eta 0:01:20 lr 0.000120	 wd 0.0500	time 0.5146 (0.6394)	data time 0.0661 (0.1353)	model time 0.0000 (0.0000)	loss 0.6368 (0.6474)	grad_norm 0.8326 (1.0136)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:17:48 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][40/156]	eta 0:01:10 lr 0.000120	 wd 0.0500	time 0.4903 (0.6055)	data time 0.0767 (0.1058)	model time 0.0000 (0.0000)	loss 0.5951 (0.6435)	grad_norm 0.7770 (0.9725)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:17:53 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][50/156]	eta 0:01:01 lr 0.000120	 wd 0.0500	time 0.4353 (0.5806)	data time 0.0134 (0.0882)	model time 0.0000 (0.0000)	loss 0.6798 (0.6437)	grad_norm 1.0095 (0.9910)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:17:58 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][60/156]	eta 0:00:54 lr 0.000120	 wd 0.0500	time 0.4772 (0.5649)	data time 0.0217 (0.0753)	model time 0.4554 (0.4757)	loss 0.6087 (0.6459)	grad_norm 1.1136 (0.9776)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:18:03 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][70/156]	eta 0:00:47 lr 0.000120	 wd 0.0500	time 0.5737 (0.5530)	data time 0.0011 (0.0661)	model time 0.5726 (0.4727)	loss 0.5981 (0.6424)	grad_norm 0.8233 (0.9697)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:18:08 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][80/156]	eta 0:00:41 lr 0.000120	 wd 0.0500	time 0.6510 (0.5455)	data time 0.0051 (0.0593)	model time 0.6459 (0.4755)	loss 0.6256 (0.6428)	grad_norm 0.7283 (0.9686)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:18:12 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][90/156]	eta 0:00:35 lr 0.000120	 wd 0.0500	time 0.4420 (0.5394)	data time 0.0037 (0.0545)	model time 0.4383 (0.4753)	loss 0.5968 (0.6416)	grad_norm 1.6524 (0.9889)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:18:18 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][100/156]	eta 0:00:30 lr 0.000120	 wd 0.0500	time 0.5942 (0.5380)	data time 0.0267 (0.0509)	model time 0.5675 (0.4818)	loss 0.6422 (0.6417)	grad_norm 0.6314 (0.9936)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:18:23 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][110/156]	eta 0:00:24 lr 0.000120	 wd 0.0500	time 0.5670 (0.5357)	data time 0.0165 (0.0478)	model time 0.5505 (0.4842)	loss 0.6611 (0.6431)	grad_norm 0.8121 (0.9963)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:18:28 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][120/156]	eta 0:00:19 lr 0.000120	 wd 0.0500	time 0.4331 (0.5356)	data time 0.0032 (0.0452)	model time 0.4299 (0.4890)	loss 0.6624 (0.6426)	grad_norm 0.7722 (1.0109)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:18:33 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][130/156]	eta 0:00:13 lr 0.000120	 wd 0.0500	time 0.4961 (0.5340)	data time 0.0014 (0.0424)	model time 0.4947 (0.4912)	loss 0.6126 (0.6419)	grad_norm 1.4286 (1.0222)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:18:38 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][140/156]	eta 0:00:08 lr 0.000120	 wd 0.0500	time 0.4616 (0.5318)	data time 0.0008 (0.0400)	model time 0.4608 (0.4915)	loss 0.6035 (0.6418)	grad_norm 0.8612 (1.0310)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:18:43 vssm1_tiny_0230s](training.py 201): INFO Train: [56/300][150/156]	eta 0:00:03 lr 0.000120	 wd 0.0500	time 0.6083 (0.5303)	data time 0.0007 (0.0375)	model time 0.6076 (0.4931)	loss 0.6285 (0.6418)	grad_norm 1.3503 (1.0238)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:18:46 vssm1_tiny_0230s](training.py 212): INFO EPOCH 56 training takes 0:01:22
[2024-11-09 12:18:46 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_56.pth saving......
[2024-11-09 12:18:47 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_56.pth saved !!!
[2024-11-09 12:18:50 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.032 (3.032)	Loss 0.4438 (0.4438)	Acc@1 82.031 (82.031)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:18:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.142 (0.535)	Loss 0.4268 (0.4635)	Acc@1 86.719 (81.321)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:18:54 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.212 (0.361)	Loss 0.3450 (0.4682)	Acc@1 89.062 (80.506)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:18:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.326)	Loss 0.4600 (0.4522)	Acc@1 76.562 (80.645)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:18:59 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 81.000 Acc@5 100.000
[2024-11-09 12:18:59 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 81.0%
[2024-11-09 12:18:59 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 81.00%
[2024-11-09 12:19:02 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.170 (3.170)	Loss 0.4590 (0.4590)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:19:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.187 (0.511)	Loss 0.4673 (0.4629)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:19:07 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.390)	Loss 0.8306 (0.4906)	Acc@1 17.969 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:19:10 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.175 (0.351)	Loss 0.8672 (0.6062)	Acc@1 15.625 (68.347)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:19:12 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.120 Acc@5 100.000
[2024-11-09 12:19:12 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 57.1%
[2024-11-09 12:19:12 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:19:17 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][0/156]	eta 0:13:12 lr 0.000120	 wd 0.0500	time 5.0830 (5.0830)	data time 4.5862 (4.5862)	model time 0.0000 (0.0000)	loss 0.5891 (0.5891)	grad_norm 1.4550 (1.4550)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:19:22 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][10/156]	eta 0:02:14 lr 0.000120	 wd 0.0500	time 0.5508 (0.9208)	data time 0.0422 (0.4262)	model time 0.0000 (0.0000)	loss 0.5794 (0.6272)	grad_norm 1.1399 (1.1849)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:19:28 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][20/156]	eta 0:01:39 lr 0.000120	 wd 0.0500	time 0.4704 (0.7291)	data time 0.0204 (0.2281)	model time 0.0000 (0.0000)	loss 0.6395 (0.6348)	grad_norm 0.8551 (1.1021)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:19:33 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][30/156]	eta 0:01:22 lr 0.000120	 wd 0.0500	time 0.4078 (0.6536)	data time 0.0006 (0.1584)	model time 0.0000 (0.0000)	loss 0.6250 (0.6372)	grad_norm 0.9734 (1.0950)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:19:37 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][40/156]	eta 0:01:10 lr 0.000120	 wd 0.0500	time 0.4854 (0.6059)	data time 0.0048 (0.1217)	model time 0.0000 (0.0000)	loss 0.6229 (0.6376)	grad_norm 0.9449 (1.0814)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:19:42 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][50/156]	eta 0:01:02 lr 0.000120	 wd 0.0500	time 0.6096 (0.5913)	data time 0.0083 (0.0997)	model time 0.0000 (0.0000)	loss 0.6076 (0.6372)	grad_norm 0.8907 (1.0672)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:19:48 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][60/156]	eta 0:00:55 lr 0.000120	 wd 0.0500	time 0.7021 (0.5813)	data time 0.0374 (0.0858)	model time 0.6646 (0.5154)	loss 0.6325 (0.6372)	grad_norm 1.9279 (1.0824)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:19:52 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][70/156]	eta 0:00:48 lr 0.000120	 wd 0.0500	time 0.4519 (0.5659)	data time 0.0145 (0.0756)	model time 0.4374 (0.4869)	loss 0.6885 (0.6387)	grad_norm 1.3147 (1.0902)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:19:58 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][80/156]	eta 0:00:42 lr 0.000120	 wd 0.0500	time 0.5938 (0.5598)	data time 0.0334 (0.0682)	model time 0.5605 (0.4917)	loss 0.6942 (0.6418)	grad_norm 0.6248 (1.0878)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:20:02 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][90/156]	eta 0:00:36 lr 0.000120	 wd 0.0500	time 0.4353 (0.5513)	data time 0.0064 (0.0630)	model time 0.4289 (0.4841)	loss 0.6698 (0.6408)	grad_norm 0.9795 (1.0791)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:20:08 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][100/156]	eta 0:00:30 lr 0.000120	 wd 0.0500	time 0.5096 (0.5475)	data time 0.0169 (0.0583)	model time 0.4927 (0.4868)	loss 0.5789 (0.6397)	grad_norm 2.1715 (1.0846)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:20:13 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][110/156]	eta 0:00:24 lr 0.000120	 wd 0.0500	time 0.4920 (0.5425)	data time 0.0161 (0.0545)	model time 0.4760 (0.4849)	loss 0.6181 (0.6374)	grad_norm 1.3724 (1.0929)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:20:18 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][120/156]	eta 0:00:19 lr 0.000120	 wd 0.0500	time 0.4367 (0.5420)	data time 0.0147 (0.0516)	model time 0.4220 (0.4896)	loss 0.5988 (0.6383)	grad_norm 1.2838 (1.1616)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:20:23 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][130/156]	eta 0:00:14 lr 0.000120	 wd 0.0500	time 0.6264 (0.5405)	data time 0.0025 (0.0486)	model time 0.6239 (0.4920)	loss 0.6330 (0.6399)	grad_norm 0.7677 (1.1618)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:20:28 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][140/156]	eta 0:00:08 lr 0.000119	 wd 0.0500	time 0.5107 (0.5398)	data time 0.0008 (0.0471)	model time 0.5099 (0.4933)	loss 0.5679 (0.6400)	grad_norm 0.9422 (1.1405)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:20:33 vssm1_tiny_0230s](training.py 201): INFO Train: [57/300][150/156]	eta 0:00:03 lr 0.000119	 wd 0.0500	time 0.4345 (0.5350)	data time 0.0006 (0.0443)	model time 0.4339 (0.4902)	loss 0.6509 (0.6398)	grad_norm 0.9571 (1.1255)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:20:36 vssm1_tiny_0230s](training.py 212): INFO EPOCH 57 training takes 0:01:24
[2024-11-09 12:20:36 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_57.pth saving......
[2024-11-09 12:20:37 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_57.pth saved !!!
[2024-11-09 12:20:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.327 (3.327)	Loss 0.4338 (0.4338)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:20:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.159 (0.509)	Loss 0.4331 (0.4460)	Acc@1 85.938 (83.878)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:20:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.357)	Loss 0.3628 (0.4527)	Acc@1 86.719 (82.589)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:20:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.154 (0.296)	Loss 0.4602 (0.4423)	Acc@1 76.562 (82.258)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:20:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 82.180 Acc@5 100.000
[2024-11-09 12:20:49 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 82.2%
[2024-11-09 12:20:49 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 82.18%
[2024-11-09 12:20:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.003 (4.003)	Loss 0.4551 (0.4551)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:20:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.292 (0.618)	Loss 0.4631 (0.4589)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:20:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.200 (0.418)	Loss 0.8320 (0.4870)	Acc@1 17.969 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:21:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.378)	Loss 0.8696 (0.6043)	Acc@1 15.625 (68.372)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:21:04 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.180 Acc@5 100.000
[2024-11-09 12:21:04 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 57.2%
[2024-11-09 12:21:04 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:21:07 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][0/156]	eta 0:09:58 lr 0.000119	 wd 0.0500	time 3.8361 (3.8361)	data time 3.3955 (3.3955)	model time 0.0000 (0.0000)	loss 0.6169 (0.6169)	grad_norm 1.2060 (1.2060)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:21:12 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][10/156]	eta 0:01:54 lr 0.000119	 wd 0.0500	time 0.4594 (0.7812)	data time 0.0040 (0.3383)	model time 0.0000 (0.0000)	loss 0.5931 (0.6326)	grad_norm 0.8174 (1.0027)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:21:17 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][20/156]	eta 0:01:26 lr 0.000119	 wd 0.0500	time 0.4894 (0.6390)	data time 0.0052 (0.1803)	model time 0.0000 (0.0000)	loss 0.5696 (0.6315)	grad_norm 0.7472 (1.0263)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:21:22 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][30/156]	eta 0:01:15 lr 0.000119	 wd 0.0500	time 0.5585 (0.5997)	data time 0.0227 (0.1271)	model time 0.0000 (0.0000)	loss 0.6181 (0.6335)	grad_norm 1.2894 (1.0885)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:21:27 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][40/156]	eta 0:01:06 lr 0.000119	 wd 0.0500	time 0.4463 (0.5720)	data time 0.0295 (0.0994)	model time 0.0000 (0.0000)	loss 0.6564 (0.6322)	grad_norm 0.6749 (1.0847)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:21:32 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][50/156]	eta 0:00:58 lr 0.000119	 wd 0.0500	time 0.5689 (0.5546)	data time 0.0007 (0.0808)	model time 0.0000 (0.0000)	loss 0.6568 (0.6355)	grad_norm 1.7086 (1.1051)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:21:37 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][60/156]	eta 0:00:52 lr 0.000119	 wd 0.0500	time 0.5271 (0.5472)	data time 0.0305 (0.0725)	model time 0.4966 (0.4783)	loss 0.6321 (0.6387)	grad_norm 1.1020 (1.1264)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:21:42 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][70/156]	eta 0:00:46 lr 0.000119	 wd 0.0500	time 0.4560 (0.5380)	data time 0.0131 (0.0656)	model time 0.4429 (0.4686)	loss 0.6250 (0.6380)	grad_norm 0.9561 (1.0977)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:21:47 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][80/156]	eta 0:00:40 lr 0.000119	 wd 0.0500	time 0.4179 (0.5330)	data time 0.0023 (0.0593)	model time 0.4156 (0.4733)	loss 0.6283 (0.6375)	grad_norm 2.1403 (1.0854)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:21:52 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][90/156]	eta 0:00:34 lr 0.000119	 wd 0.0500	time 0.5168 (0.5273)	data time 0.0084 (0.0545)	model time 0.5084 (0.4715)	loss 0.6634 (0.6385)	grad_norm 1.2787 (1.1074)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:21:57 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][100/156]	eta 0:00:29 lr 0.000119	 wd 0.0500	time 0.6717 (0.5263)	data time 0.0008 (0.0501)	model time 0.6709 (0.4784)	loss 0.5985 (0.6392)	grad_norm 0.7424 (1.1166)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:22:02 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][110/156]	eta 0:00:24 lr 0.000119	 wd 0.0500	time 0.4730 (0.5281)	data time 0.0154 (0.0474)	model time 0.4577 (0.4865)	loss 0.6191 (0.6378)	grad_norm 0.8966 (1.1012)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:22:07 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][120/156]	eta 0:00:18 lr 0.000119	 wd 0.0500	time 0.4778 (0.5246)	data time 0.0094 (0.0443)	model time 0.4684 (0.4849)	loss 0.6114 (0.6388)	grad_norm 1.1835 (1.1021)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:22:12 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][130/156]	eta 0:00:13 lr 0.000119	 wd 0.0500	time 0.4927 (0.5215)	data time 0.0514 (0.0422)	model time 0.4413 (0.4827)	loss 0.6256 (0.6389)	grad_norm 1.3396 (1.0992)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:22:17 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][140/156]	eta 0:00:08 lr 0.000119	 wd 0.0500	time 0.5013 (0.5173)	data time 0.0010 (0.0402)	model time 0.5003 (0.4790)	loss 0.6727 (0.6383)	grad_norm 2.1221 (1.1230)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:22:21 vssm1_tiny_0230s](training.py 201): INFO Train: [58/300][150/156]	eta 0:00:03 lr 0.000119	 wd 0.0500	time 0.4428 (0.5150)	data time 0.0071 (0.0376)	model time 0.4358 (0.4792)	loss 0.6134 (0.6383)	grad_norm 1.7434 (1.1325)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:22:24 vssm1_tiny_0230s](training.py 212): INFO EPOCH 58 training takes 0:01:20
[2024-11-09 12:22:24 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_58.pth saving......
[2024-11-09 12:22:24 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_58.pth saved !!!
[2024-11-09 12:22:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.940 (1.940)	Loss 0.5107 (0.5107)	Acc@1 77.344 (77.344)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:22:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.371)	Loss 0.4868 (0.5158)	Acc@1 83.594 (78.480)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:22:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.164 (0.372)	Loss 0.3059 (0.5127)	Acc@1 89.844 (77.827)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:22:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.210 (0.345)	Loss 0.3979 (0.4667)	Acc@1 78.906 (80.368)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:22:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 81.840 Acc@5 100.000
[2024-11-09 12:22:38 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 81.8%
[2024-11-09 12:22:38 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 82.18%
[2024-11-09 12:22:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.968 (3.968)	Loss 0.4509 (0.4509)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:22:44 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.423 (0.577)	Loss 0.4592 (0.4549)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:22:46 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.152 (0.420)	Loss 0.8335 (0.4834)	Acc@1 17.188 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:22:48 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.351)	Loss 0.8726 (0.6026)	Acc@1 15.625 (68.473)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:22:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.360 Acc@5 100.000
[2024-11-09 12:22:51 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 57.4%
[2024-11-09 12:22:51 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:22:54 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][0/156]	eta 0:09:11 lr 0.000119	 wd 0.0500	time 3.5380 (3.5380)	data time 3.0981 (3.0981)	model time 0.0000 (0.0000)	loss 0.6131 (0.6131)	grad_norm 1.0222 (1.0222)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:22:59 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][10/156]	eta 0:01:47 lr 0.000119	 wd 0.0500	time 0.4317 (0.7362)	data time 0.0072 (0.2914)	model time 0.0000 (0.0000)	loss 0.6544 (0.6301)	grad_norm 0.7546 (1.1017)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:23:03 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][20/156]	eta 0:01:21 lr 0.000119	 wd 0.0500	time 0.4850 (0.6008)	data time 0.0224 (0.1571)	model time 0.0000 (0.0000)	loss 0.6563 (0.6362)	grad_norm 1.4111 (1.1252)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:23:08 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][30/156]	eta 0:01:08 lr 0.000119	 wd 0.0500	time 0.4348 (0.5469)	data time 0.0008 (0.1090)	model time 0.0000 (0.0000)	loss 0.6360 (0.6356)	grad_norm 1.3062 (inf)	loss_scale 65536.0000 (112045.4194)	mem 13675MB
[2024-11-09 12:23:13 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][40/156]	eta 0:01:02 lr 0.000119	 wd 0.0500	time 0.4333 (0.5362)	data time 0.0006 (0.0846)	model time 0.0000 (0.0000)	loss 0.6398 (0.6337)	grad_norm 0.9316 (inf)	loss_scale 65536.0000 (100701.6585)	mem 13675MB
[2024-11-09 12:23:18 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][50/156]	eta 0:00:56 lr 0.000119	 wd 0.0500	time 0.5411 (0.5293)	data time 0.0101 (0.0723)	model time 0.0000 (0.0000)	loss 0.6816 (0.6363)	grad_norm 0.8343 (inf)	loss_scale 65536.0000 (93806.4314)	mem 13675MB
[2024-11-09 12:23:23 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][60/156]	eta 0:00:51 lr 0.000119	 wd 0.0500	time 0.5325 (0.5352)	data time 0.0027 (0.0668)	model time 0.5298 (0.5263)	loss 0.6258 (0.6358)	grad_norm 1.3631 (inf)	loss_scale 65536.0000 (89171.9344)	mem 13675MB
[2024-11-09 12:23:28 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][70/156]	eta 0:00:45 lr 0.000119	 wd 0.0500	time 0.4800 (0.5263)	data time 0.0205 (0.0593)	model time 0.4595 (0.4923)	loss 0.5997 (0.6357)	grad_norm 0.7946 (inf)	loss_scale 65536.0000 (85842.9296)	mem 13675MB
[2024-11-09 12:23:33 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][80/156]	eta 0:00:39 lr 0.000119	 wd 0.0500	time 0.4641 (0.5208)	data time 0.0323 (0.0545)	model time 0.4318 (0.4823)	loss 0.6158 (0.6372)	grad_norm 1.9030 (inf)	loss_scale 65536.0000 (83335.9012)	mem 13675MB
[2024-11-09 12:23:38 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][90/156]	eta 0:00:33 lr 0.000119	 wd 0.0500	time 0.5498 (0.5149)	data time 0.0259 (0.0494)	model time 0.5240 (0.4763)	loss 0.6466 (0.6374)	grad_norm 1.0239 (inf)	loss_scale 65536.0000 (81379.8681)	mem 13675MB
[2024-11-09 12:23:43 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][100/156]	eta 0:00:28 lr 0.000119	 wd 0.0500	time 0.6308 (0.5156)	data time 0.0106 (0.0459)	model time 0.6202 (0.4826)	loss 0.5836 (0.6362)	grad_norm 1.3106 (inf)	loss_scale 65536.0000 (79811.1683)	mem 13675MB
[2024-11-09 12:23:48 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][110/156]	eta 0:00:23 lr 0.000119	 wd 0.0500	time 0.4453 (0.5181)	data time 0.0339 (0.0433)	model time 0.4114 (0.4899)	loss 0.6664 (0.6360)	grad_norm 1.0430 (inf)	loss_scale 65536.0000 (78525.1171)	mem 13675MB
[2024-11-09 12:23:53 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][120/156]	eta 0:00:18 lr 0.000119	 wd 0.0500	time 0.4839 (0.5137)	data time 0.0199 (0.0410)	model time 0.4640 (0.4842)	loss 0.6370 (0.6365)	grad_norm 0.9287 (inf)	loss_scale 65536.0000 (77451.6364)	mem 13675MB
[2024-11-09 12:23:58 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][130/156]	eta 0:00:13 lr 0.000119	 wd 0.0500	time 0.4690 (0.5106)	data time 0.0257 (0.0388)	model time 0.4433 (0.4813)	loss 0.7079 (0.6356)	grad_norm 2.7458 (inf)	loss_scale 65536.0000 (76542.0458)	mem 13675MB
[2024-11-09 12:24:02 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][140/156]	eta 0:00:08 lr 0.000119	 wd 0.0500	time 0.4340 (0.5082)	data time 0.0032 (0.0365)	model time 0.4308 (0.4800)	loss 0.6228 (0.6360)	grad_norm 1.1532 (inf)	loss_scale 65536.0000 (75761.4752)	mem 13675MB
[2024-11-09 12:24:07 vssm1_tiny_0230s](training.py 201): INFO Train: [59/300][150/156]	eta 0:00:03 lr 0.000119	 wd 0.0500	time 0.5103 (0.5076)	data time 0.0007 (0.0343)	model time 0.5096 (0.4816)	loss 0.6323 (0.6365)	grad_norm 0.8924 (inf)	loss_scale 65536.0000 (75084.2914)	mem 13675MB
[2024-11-09 12:24:10 vssm1_tiny_0230s](training.py 212): INFO EPOCH 59 training takes 0:01:19
[2024-11-09 12:24:10 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_59.pth saving......
[2024-11-09 12:24:10 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_59.pth saved !!!
[2024-11-09 12:24:12 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.553 (1.553)	Loss 0.3638 (0.3638)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:24:13 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.285)	Loss 0.3477 (0.3721)	Acc@1 92.969 (90.767)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:24:15 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.181 (0.218)	Loss 0.4341 (0.3894)	Acc@1 80.469 (88.430)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:24:16 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.179 (0.195)	Loss 0.5337 (0.4263)	Acc@1 71.875 (83.795)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:24:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 81.700 Acc@5 100.000
[2024-11-09 12:24:18 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 81.7%
[2024-11-09 12:24:18 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 82.18%
[2024-11-09 12:24:22 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.996 (3.996)	Loss 0.4470 (0.4470)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:24:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.235 (0.635)	Loss 0.4551 (0.4508)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:24:28 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.149 (0.470)	Loss 0.8354 (0.4798)	Acc@1 17.188 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:24:30 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.400)	Loss 0.8750 (0.6008)	Acc@1 15.625 (68.498)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:24:33 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.480 Acc@5 100.000
[2024-11-09 12:24:33 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 57.5%
[2024-11-09 12:24:33 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:24:38 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][0/156]	eta 0:13:43 lr 0.000119	 wd 0.0500	time 5.2775 (5.2775)	data time 4.8541 (4.8541)	model time 0.0000 (0.0000)	loss 0.6679 (0.6679)	grad_norm 1.2745 (1.2745)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:24:43 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][10/156]	eta 0:02:20 lr 0.000119	 wd 0.0500	time 0.5645 (0.9604)	data time 0.0119 (0.4533)	model time 0.0000 (0.0000)	loss 0.6914 (0.6436)	grad_norm 1.0316 (1.0438)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:24:48 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][20/156]	eta 0:01:40 lr 0.000119	 wd 0.0500	time 0.4532 (0.7378)	data time 0.0180 (0.2465)	model time 0.0000 (0.0000)	loss 0.6932 (0.6446)	grad_norm 0.9327 (0.9666)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:24:53 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][30/156]	eta 0:01:21 lr 0.000119	 wd 0.0500	time 0.4068 (0.6445)	data time 0.0009 (0.1685)	model time 0.0000 (0.0000)	loss 0.6480 (0.6425)	grad_norm 0.8922 (0.9868)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:24:57 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][40/156]	eta 0:01:09 lr 0.000119	 wd 0.0500	time 0.4556 (0.5963)	data time 0.0108 (0.1297)	model time 0.0000 (0.0000)	loss 0.6644 (0.6440)	grad_norm 0.5011 (1.0034)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:02 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][50/156]	eta 0:01:01 lr 0.000119	 wd 0.0500	time 0.4984 (0.5805)	data time 0.0122 (0.1079)	model time 0.0000 (0.0000)	loss 0.6793 (0.6455)	grad_norm 0.9794 (1.0468)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:08 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][60/156]	eta 0:00:55 lr 0.000119	 wd 0.0500	time 0.5278 (0.5754)	data time 0.0025 (0.0938)	model time 0.5253 (0.5273)	loss 0.6550 (0.6458)	grad_norm 0.7326 (1.0279)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:13 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][70/156]	eta 0:00:48 lr 0.000119	 wd 0.0500	time 0.4944 (0.5670)	data time 0.0044 (0.0850)	model time 0.4900 (0.5057)	loss 0.6690 (0.6443)	grad_norm 1.0068 (1.0201)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:18 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][80/156]	eta 0:00:42 lr 0.000119	 wd 0.0500	time 0.5966 (0.5601)	data time 0.0017 (0.0760)	model time 0.5949 (0.5036)	loss 0.6749 (0.6450)	grad_norm 1.2930 (1.0146)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:23 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][90/156]	eta 0:00:36 lr 0.000119	 wd 0.0500	time 0.5932 (0.5498)	data time 0.0308 (0.0692)	model time 0.5624 (0.4908)	loss 0.6343 (0.6448)	grad_norm 0.8071 (1.0169)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:28 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][100/156]	eta 0:00:30 lr 0.000119	 wd 0.0500	time 0.4692 (0.5435)	data time 0.0265 (0.0649)	model time 0.4427 (0.4847)	loss 0.5760 (0.6432)	grad_norm 1.0377 (1.0226)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:33 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][110/156]	eta 0:00:24 lr 0.000119	 wd 0.0500	time 0.4272 (0.5406)	data time 0.0034 (0.0597)	model time 0.4238 (0.4879)	loss 0.6730 (0.6442)	grad_norm 1.9483 (1.0660)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:37 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][120/156]	eta 0:00:19 lr 0.000119	 wd 0.0500	time 0.5494 (0.5343)	data time 0.0007 (0.0555)	model time 0.5487 (0.4833)	loss 0.6241 (0.6433)	grad_norm 0.8960 (1.0643)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:43 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][130/156]	eta 0:00:13 lr 0.000119	 wd 0.0500	time 0.5154 (0.5347)	data time 0.0052 (0.0519)	model time 0.5102 (0.4891)	loss 0.5745 (0.6430)	grad_norm 1.1132 (1.0651)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:48 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][140/156]	eta 0:00:08 lr 0.000119	 wd 0.0500	time 0.4214 (0.5312)	data time 0.0008 (0.0490)	model time 0.4206 (0.4876)	loss 0.6119 (0.6421)	grad_norm 1.5706 (1.0588)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:53 vssm1_tiny_0230s](training.py 201): INFO Train: [60/300][150/156]	eta 0:00:03 lr 0.000119	 wd 0.0500	time 0.4291 (0.5282)	data time 0.0006 (0.0464)	model time 0.4284 (0.4864)	loss 0.6124 (0.6401)	grad_norm 2.1199 (1.0775)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:25:55 vssm1_tiny_0230s](training.py 212): INFO EPOCH 60 training takes 0:01:22
[2024-11-09 12:25:55 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_60.pth saving......
[2024-11-09 12:25:56 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_60.pth saved !!!
[2024-11-09 12:25:57 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.770 (1.770)	Loss 0.3376 (0.3376)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:26:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.395 (0.494)	Loss 0.3240 (0.3434)	Acc@1 94.531 (89.986)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:26:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.440)	Loss 0.4226 (0.3633)	Acc@1 82.031 (88.021)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:26:06 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.219 (0.349)	Loss 0.5342 (0.4073)	Acc@1 69.531 (83.619)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:26:09 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 81.800 Acc@5 100.000
[2024-11-09 12:26:09 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 81.8%
[2024-11-09 12:26:09 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 82.18%
[2024-11-09 12:26:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.042 (2.042)	Loss 0.4431 (0.4431)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:26:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.504)	Loss 0.4512 (0.4470)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:26:17 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.356)	Loss 0.8369 (0.4763)	Acc@1 17.969 (93.155)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:26:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.336)	Loss 0.8774 (0.5991)	Acc@1 15.625 (68.548)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:26:21 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.560 Acc@5 100.000
[2024-11-09 12:26:21 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 57.6%
[2024-11-09 12:26:21 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:26:25 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][0/156]	eta 0:09:07 lr 0.000119	 wd 0.0500	time 3.5109 (3.5109)	data time 3.0437 (3.0437)	model time 0.0000 (0.0000)	loss 0.6665 (0.6665)	grad_norm 1.3957 (1.3957)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:26:30 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][10/156]	eta 0:01:54 lr 0.000119	 wd 0.0500	time 0.4104 (0.7832)	data time 0.0020 (0.2924)	model time 0.0000 (0.0000)	loss 0.6878 (0.6540)	grad_norm 1.2655 (1.1262)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:26:35 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][20/156]	eta 0:01:27 lr 0.000119	 wd 0.0500	time 0.4474 (0.6462)	data time 0.0047 (0.1568)	model time 0.0000 (0.0000)	loss 0.6580 (0.6515)	grad_norm 1.4979 (1.1828)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:26:40 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][30/156]	eta 0:01:16 lr 0.000119	 wd 0.0500	time 0.6285 (0.6038)	data time 0.0169 (0.1131)	model time 0.0000 (0.0000)	loss 0.6178 (0.6435)	grad_norm 0.7806 (1.0862)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:26:45 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][40/156]	eta 0:01:08 lr 0.000118	 wd 0.0500	time 0.5063 (0.5865)	data time 0.0174 (0.0885)	model time 0.0000 (0.0000)	loss 0.6559 (0.6424)	grad_norm 1.5661 (1.1276)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:26:50 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][50/156]	eta 0:01:00 lr 0.000118	 wd 0.0500	time 0.4797 (0.5671)	data time 0.0205 (0.0738)	model time 0.0000 (0.0000)	loss 0.6376 (0.6411)	grad_norm 0.7812 (1.1309)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:26:55 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][60/156]	eta 0:00:53 lr 0.000118	 wd 0.0500	time 0.4565 (0.5546)	data time 0.0180 (0.0638)	model time 0.4385 (0.4777)	loss 0.6384 (0.6387)	grad_norm 1.3134 (1.1021)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:27:00 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][70/156]	eta 0:00:46 lr 0.000118	 wd 0.0500	time 0.4686 (0.5451)	data time 0.0008 (0.0560)	model time 0.4677 (0.4783)	loss 0.6260 (0.6371)	grad_norm 0.8956 (1.1176)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:27:06 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][80/156]	eta 0:00:41 lr 0.000118	 wd 0.0500	time 0.7618 (0.5443)	data time 0.0131 (0.0503)	model time 0.7486 (0.4952)	loss 0.5745 (0.6350)	grad_norm 1.6632 (1.1576)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:27:11 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][90/156]	eta 0:00:35 lr 0.000118	 wd 0.0500	time 0.4536 (0.5425)	data time 0.0005 (0.0463)	model time 0.4530 (0.4998)	loss 0.6009 (0.6340)	grad_norm 0.8963 (1.1629)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:27:16 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][100/156]	eta 0:00:30 lr 0.000118	 wd 0.0500	time 0.5900 (0.5379)	data time 0.0007 (0.0434)	model time 0.5893 (0.4957)	loss 0.5624 (0.6336)	grad_norm 0.8969 (1.1851)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:27:21 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][110/156]	eta 0:00:24 lr 0.000118	 wd 0.0500	time 0.4834 (0.5337)	data time 0.0006 (0.0418)	model time 0.4828 (0.4905)	loss 0.6491 (0.6337)	grad_norm 0.8378 (1.1703)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:27:26 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][120/156]	eta 0:00:19 lr 0.000118	 wd 0.0500	time 0.4960 (0.5297)	data time 0.0168 (0.0394)	model time 0.4792 (0.4880)	loss 0.5843 (0.6337)	grad_norm 1.1663 (1.1603)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:27:30 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][130/156]	eta 0:00:13 lr 0.000118	 wd 0.0500	time 0.4525 (0.5228)	data time 0.0224 (0.0373)	model time 0.4301 (0.4804)	loss 0.5799 (0.6335)	grad_norm 1.6724 (1.1915)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:27:35 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][140/156]	eta 0:00:08 lr 0.000118	 wd 0.0500	time 0.6545 (0.5219)	data time 0.0310 (0.0362)	model time 0.6235 (0.4813)	loss 0.6641 (0.6339)	grad_norm 1.9702 (1.1984)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:27:40 vssm1_tiny_0230s](training.py 201): INFO Train: [61/300][150/156]	eta 0:00:03 lr 0.000118	 wd 0.0500	time 0.4065 (0.5196)	data time 0.0006 (0.0351)	model time 0.4059 (0.4800)	loss 0.6545 (0.6341)	grad_norm 1.3346 (1.2114)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:27:42 vssm1_tiny_0230s](training.py 212): INFO EPOCH 61 training takes 0:01:20
[2024-11-09 12:27:42 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_61.pth saving......
[2024-11-09 12:27:42 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_61.pth saved !!!
[2024-11-09 12:27:43 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 0.896 (0.896)	Loss 0.3674 (0.3674)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:27:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.270)	Loss 0.3628 (0.3753)	Acc@1 91.406 (89.986)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:27:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.153 (0.210)	Loss 0.4172 (0.3946)	Acc@1 81.250 (87.128)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:27:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.144 (0.198)	Loss 0.4976 (0.4233)	Acc@1 72.656 (83.392)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:27:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 81.900 Acc@5 100.000
[2024-11-09 12:27:51 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 81.9%
[2024-11-09 12:27:51 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 82.18%
[2024-11-09 12:27:55 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.483 (4.483)	Loss 0.4390 (0.4390)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:27:59 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.195 (0.683)	Loss 0.4470 (0.4429)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:28:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.197 (0.477)	Loss 0.8384 (0.4727)	Acc@1 18.750 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:28:03 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.393)	Loss 0.8799 (0.5972)	Acc@1 15.625 (68.725)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:28:06 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.740 Acc@5 100.000
[2024-11-09 12:28:06 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 57.7%
[2024-11-09 12:28:06 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:28:10 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][0/156]	eta 0:11:41 lr 0.000118	 wd 0.0500	time 4.4994 (4.4994)	data time 4.0040 (4.0040)	model time 0.0000 (0.0000)	loss 0.6431 (0.6431)	grad_norm 2.0683 (2.0683)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:28:16 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][10/156]	eta 0:02:16 lr 0.000118	 wd 0.0500	time 0.4524 (0.9377)	data time 0.0338 (0.3784)	model time 0.0000 (0.0000)	loss 0.6586 (0.6484)	grad_norm 0.6763 (1.1598)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:28:22 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][20/156]	eta 0:01:41 lr 0.000118	 wd 0.0500	time 0.6502 (0.7478)	data time 0.0083 (0.2058)	model time 0.0000 (0.0000)	loss 0.6794 (0.6431)	grad_norm 1.0358 (1.0283)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:28:27 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][30/156]	eta 0:01:24 lr 0.000118	 wd 0.0500	time 0.6002 (0.6706)	data time 0.0194 (0.1435)	model time 0.0000 (0.0000)	loss 0.6305 (0.6432)	grad_norm 0.8058 (1.0817)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:28:32 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][40/156]	eta 0:01:13 lr 0.000118	 wd 0.0500	time 0.5048 (0.6325)	data time 0.0042 (0.1130)	model time 0.0000 (0.0000)	loss 0.6619 (0.6464)	grad_norm 1.9211 (1.1563)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:28:37 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][50/156]	eta 0:01:03 lr 0.000118	 wd 0.0500	time 0.5715 (0.6035)	data time 0.0391 (0.0938)	model time 0.0000 (0.0000)	loss 0.6497 (0.6442)	grad_norm 1.2703 (1.1752)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:28:41 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][60/156]	eta 0:00:55 lr 0.000118	 wd 0.0500	time 0.4104 (0.5791)	data time 0.0010 (0.0810)	model time 0.4095 (0.4386)	loss 0.6549 (0.6450)	grad_norm 1.1682 (1.1719)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:28:47 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][70/156]	eta 0:00:49 lr 0.000118	 wd 0.0500	time 0.4644 (0.5728)	data time 0.0006 (0.0704)	model time 0.4638 (0.4836)	loss 0.5783 (0.6433)	grad_norm 0.9008 (1.1570)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:28:52 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][80/156]	eta 0:00:42 lr 0.000118	 wd 0.0500	time 0.4356 (0.5656)	data time 0.0218 (0.0636)	model time 0.4138 (0.4889)	loss 0.5641 (0.6414)	grad_norm 1.1760 (1.1380)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:28:56 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][90/156]	eta 0:00:36 lr 0.000118	 wd 0.0500	time 0.4231 (0.5551)	data time 0.0034 (0.0591)	model time 0.4197 (0.4785)	loss 0.6493 (0.6392)	grad_norm 1.3376 (1.1318)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:29:01 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][100/156]	eta 0:00:30 lr 0.000118	 wd 0.0500	time 0.4299 (0.5459)	data time 0.0041 (0.0543)	model time 0.4258 (0.4730)	loss 0.6351 (0.6374)	grad_norm 0.9844 (1.1314)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:29:05 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][110/156]	eta 0:00:24 lr 0.000118	 wd 0.0500	time 0.4223 (0.5353)	data time 0.0042 (0.0499)	model time 0.4180 (0.4648)	loss 0.6543 (0.6368)	grad_norm 0.8471 (1.1283)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:29:10 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][120/156]	eta 0:00:19 lr 0.000118	 wd 0.0500	time 0.6781 (0.5305)	data time 0.0056 (0.0465)	model time 0.6725 (0.4651)	loss 0.5934 (0.6364)	grad_norm 1.2575 (1.1192)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:29:15 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][130/156]	eta 0:00:13 lr 0.000118	 wd 0.0500	time 0.5130 (0.5270)	data time 0.0130 (0.0437)	model time 0.5000 (0.4663)	loss 0.5943 (0.6356)	grad_norm 1.1442 (1.1176)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:29:20 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][140/156]	eta 0:00:08 lr 0.000118	 wd 0.0500	time 0.4137 (0.5227)	data time 0.0007 (0.0412)	model time 0.4130 (0.4655)	loss 0.5717 (0.6358)	grad_norm 1.1859 (1.1118)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:29:24 vssm1_tiny_0230s](training.py 201): INFO Train: [62/300][150/156]	eta 0:00:03 lr 0.000118	 wd 0.0500	time 0.4898 (0.5186)	data time 0.0005 (0.0387)	model time 0.4893 (0.4647)	loss 0.6172 (0.6357)	grad_norm 1.1062 (1.1124)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:29:27 vssm1_tiny_0230s](training.py 212): INFO EPOCH 62 training takes 0:01:21
[2024-11-09 12:29:27 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_62.pth saving......
[2024-11-09 12:29:28 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_62.pth saved !!!
[2024-11-09 12:29:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.761 (3.761)	Loss 0.4180 (0.4180)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:29:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.197 (0.540)	Loss 0.4316 (0.4376)	Acc@1 88.281 (84.588)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:29:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.412)	Loss 0.3491 (0.4470)	Acc@1 85.938 (82.924)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:29:39 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.156 (0.350)	Loss 0.4368 (0.4327)	Acc@1 82.812 (83.266)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:29:41 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 83.600 Acc@5 100.000
[2024-11-09 12:29:41 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 83.6%
[2024-11-09 12:29:41 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 83.60%
[2024-11-09 12:29:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.200 (3.200)	Loss 0.4351 (0.4351)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:29:47 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.372 (0.514)	Loss 0.4429 (0.4390)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:29:51 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.436)	Loss 0.8403 (0.4691)	Acc@1 19.531 (93.155)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:29:54 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.393)	Loss 0.8828 (0.5955)	Acc@1 15.625 (68.775)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:29:56 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.820 Acc@5 100.000
[2024-11-09 12:29:56 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 57.8%
[2024-11-09 12:29:56 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:30:00 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][0/156]	eta 0:12:41 lr 0.000118	 wd 0.0500	time 4.8844 (4.8844)	data time 4.3794 (4.3794)	model time 0.0000 (0.0000)	loss 0.6035 (0.6035)	grad_norm 1.8558 (1.8558)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:05 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][10/156]	eta 0:02:08 lr 0.000118	 wd 0.0500	time 0.4118 (0.8792)	data time 0.0008 (0.4072)	model time 0.0000 (0.0000)	loss 0.6162 (0.6231)	grad_norm 1.7527 (1.2611)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:10 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][20/156]	eta 0:01:31 lr 0.000118	 wd 0.0500	time 0.4657 (0.6727)	data time 0.0044 (0.2165)	model time 0.0000 (0.0000)	loss 0.6221 (0.6264)	grad_norm 0.9466 (1.2127)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:14 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][30/156]	eta 0:01:16 lr 0.000118	 wd 0.0500	time 0.5574 (0.6069)	data time 0.0260 (0.1485)	model time 0.0000 (0.0000)	loss 0.6679 (0.6273)	grad_norm 1.3982 (1.2367)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:19 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][40/156]	eta 0:01:07 lr 0.000118	 wd 0.0500	time 0.4436 (0.5792)	data time 0.0182 (0.1147)	model time 0.0000 (0.0000)	loss 0.6717 (0.6276)	grad_norm 1.4924 (1.2959)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:24 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][50/156]	eta 0:00:58 lr 0.000118	 wd 0.0500	time 0.4851 (0.5561)	data time 0.0006 (0.0957)	model time 0.0000 (0.0000)	loss 0.6407 (0.6295)	grad_norm 1.6489 (1.3184)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:29 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][60/156]	eta 0:00:52 lr 0.000118	 wd 0.0500	time 0.5309 (0.5508)	data time 0.0068 (0.0830)	model time 0.5241 (0.5060)	loss 0.6371 (0.6323)	grad_norm 1.5197 (1.3163)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:34 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][70/156]	eta 0:00:46 lr 0.000118	 wd 0.0500	time 0.4498 (0.5422)	data time 0.0008 (0.0732)	model time 0.4489 (0.4907)	loss 0.6366 (0.6313)	grad_norm 1.0631 (1.2693)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:39 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][80/156]	eta 0:00:40 lr 0.000118	 wd 0.0500	time 0.4615 (0.5346)	data time 0.0329 (0.0660)	model time 0.4287 (0.4827)	loss 0.6352 (0.6303)	grad_norm 1.1302 (1.2464)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:44 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][90/156]	eta 0:00:35 lr 0.000118	 wd 0.0500	time 0.4693 (0.5321)	data time 0.0234 (0.0599)	model time 0.4459 (0.4874)	loss 0.5865 (0.6312)	grad_norm 1.1359 (1.2240)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:49 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][100/156]	eta 0:00:29 lr 0.000118	 wd 0.0500	time 0.5640 (0.5292)	data time 0.0166 (0.0553)	model time 0.5474 (0.4876)	loss 0.5781 (0.6300)	grad_norm 1.6256 (1.2148)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:54 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][110/156]	eta 0:00:24 lr 0.000118	 wd 0.0500	time 0.5382 (0.5263)	data time 0.0350 (0.0532)	model time 0.5032 (0.4839)	loss 0.6188 (0.6303)	grad_norm 1.2451 (1.2059)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:30:59 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][120/156]	eta 0:00:18 lr 0.000118	 wd 0.0500	time 0.5411 (0.5231)	data time 0.0189 (0.0497)	model time 0.5222 (0.4830)	loss 0.6002 (0.6307)	grad_norm 0.7219 (1.1940)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:31:04 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][130/156]	eta 0:00:13 lr 0.000118	 wd 0.0500	time 0.4328 (0.5218)	data time 0.0180 (0.0471)	model time 0.4148 (0.4839)	loss 0.6162 (0.6300)	grad_norm 0.7868 (1.1928)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:31:09 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][140/156]	eta 0:00:08 lr 0.000118	 wd 0.0500	time 0.4527 (0.5232)	data time 0.0011 (0.0448)	model time 0.4516 (0.4886)	loss 0.6301 (0.6298)	grad_norm 1.0292 (1.2027)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:31:14 vssm1_tiny_0230s](training.py 201): INFO Train: [63/300][150/156]	eta 0:00:03 lr 0.000118	 wd 0.0500	time 0.5727 (0.5177)	data time 0.0006 (0.0419)	model time 0.5721 (0.4835)	loss 0.5949 (0.6291)	grad_norm 0.7531 (1.1990)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:31:17 vssm1_tiny_0230s](training.py 212): INFO EPOCH 63 training takes 0:01:21
[2024-11-09 12:31:17 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_63.pth saving......
[2024-11-09 12:31:17 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_63.pth saved !!!
[2024-11-09 12:31:21 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.393 (3.393)	Loss 0.4431 (0.4431)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:31:23 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.532)	Loss 0.4321 (0.4427)	Acc@1 85.938 (82.741)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:31:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.390)	Loss 0.3281 (0.4489)	Acc@1 89.062 (81.771)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:31:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.330)	Loss 0.3850 (0.4233)	Acc@1 82.031 (83.191)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:31:30 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 83.620 Acc@5 100.000
[2024-11-09 12:31:30 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 83.6%
[2024-11-09 12:31:30 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 83.62%
[2024-11-09 12:31:35 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.264 (4.264)	Loss 0.4312 (0.4312)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:31:36 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.523)	Loss 0.4387 (0.4349)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:31:39 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.391)	Loss 0.8418 (0.4655)	Acc@1 19.531 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:31:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.349)	Loss 0.8857 (0.5937)	Acc@1 15.625 (68.800)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:31:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 57.880 Acc@5 100.000
[2024-11-09 12:31:43 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 57.9%
[2024-11-09 12:31:43 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:31:49 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][0/156]	eta 0:15:40 lr 0.000118	 wd 0.0500	time 6.0292 (6.0292)	data time 5.3312 (5.3312)	model time 0.0000 (0.0000)	loss 0.6039 (0.6039)	grad_norm 1.6505 (1.6505)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:31:54 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][10/156]	eta 0:02:21 lr 0.000118	 wd 0.0500	time 0.5961 (0.9697)	data time 0.0022 (0.4874)	model time 0.0000 (0.0000)	loss 0.6230 (0.6222)	grad_norm 1.9083 (1.2152)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:31:59 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][20/156]	eta 0:01:41 lr 0.000118	 wd 0.0500	time 0.4666 (0.7463)	data time 0.0008 (0.2674)	model time 0.0000 (0.0000)	loss 0.6315 (0.6266)	grad_norm 1.0849 (1.1986)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:04 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][30/156]	eta 0:01:23 lr 0.000118	 wd 0.0500	time 0.4914 (0.6662)	data time 0.0201 (0.1835)	model time 0.0000 (0.0000)	loss 0.6571 (0.6275)	grad_norm 1.3240 (1.1857)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:09 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][40/156]	eta 0:01:11 lr 0.000118	 wd 0.0500	time 0.4893 (0.6199)	data time 0.0214 (0.1437)	model time 0.0000 (0.0000)	loss 0.6012 (0.6289)	grad_norm 0.8949 (1.1755)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:14 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][50/156]	eta 0:01:03 lr 0.000118	 wd 0.0500	time 0.5301 (0.6008)	data time 0.0038 (0.1196)	model time 0.0000 (0.0000)	loss 0.6156 (0.6331)	grad_norm 0.8664 (1.1558)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:19 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][60/156]	eta 0:00:56 lr 0.000117	 wd 0.0500	time 0.5651 (0.5874)	data time 0.0048 (0.1033)	model time 0.5604 (0.4994)	loss 0.6291 (0.6347)	grad_norm 0.9605 (1.1541)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:24 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][70/156]	eta 0:00:49 lr 0.000117	 wd 0.0500	time 0.4797 (0.5723)	data time 0.0255 (0.0904)	model time 0.4541 (0.4840)	loss 0.6598 (0.6346)	grad_norm 0.9440 (1.1549)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:29 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][80/156]	eta 0:00:42 lr 0.000117	 wd 0.0500	time 0.5303 (0.5637)	data time 0.0012 (0.0810)	model time 0.5291 (0.4853)	loss 0.6521 (0.6367)	grad_norm 1.8414 (1.1788)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:34 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][90/156]	eta 0:00:36 lr 0.000117	 wd 0.0500	time 0.4781 (0.5538)	data time 0.0197 (0.0731)	model time 0.4584 (0.4802)	loss 0.6745 (0.6365)	grad_norm 1.0630 (1.1797)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:39 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][100/156]	eta 0:00:30 lr 0.000117	 wd 0.0500	time 0.5739 (0.5514)	data time 0.0211 (0.0680)	model time 0.5528 (0.4857)	loss 0.6269 (0.6363)	grad_norm 1.0903 (1.1766)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:44 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][110/156]	eta 0:00:25 lr 0.000117	 wd 0.0500	time 0.5417 (0.5482)	data time 0.0421 (0.0633)	model time 0.4996 (0.4881)	loss 0.6496 (0.6366)	grad_norm 0.9932 (1.1980)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:49 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][120/156]	eta 0:00:19 lr 0.000117	 wd 0.0500	time 0.5134 (0.5454)	data time 0.0111 (0.0595)	model time 0.5023 (0.4892)	loss 0.6623 (0.6358)	grad_norm 0.7322 (1.2094)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:55 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][130/156]	eta 0:00:14 lr 0.000117	 wd 0.0500	time 0.5335 (0.5430)	data time 0.0314 (0.0569)	model time 0.5021 (0.4892)	loss 0.6059 (0.6353)	grad_norm 1.1086 (1.2086)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:32:59 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][140/156]	eta 0:00:08 lr 0.000117	 wd 0.0500	time 0.5103 (0.5395)	data time 0.0006 (0.0539)	model time 0.5097 (0.4881)	loss 0.6007 (0.6348)	grad_norm 0.9783 (1.1944)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:33:04 vssm1_tiny_0230s](training.py 201): INFO Train: [64/300][150/156]	eta 0:00:03 lr 0.000117	 wd 0.0500	time 0.4695 (0.5357)	data time 0.0005 (0.0512)	model time 0.4690 (0.4863)	loss 0.6335 (0.6343)	grad_norm 1.3026 (1.1966)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:33:08 vssm1_tiny_0230s](training.py 212): INFO EPOCH 64 training takes 0:01:24
[2024-11-09 12:33:08 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_64.pth saving......
[2024-11-09 12:33:08 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_64.pth saved !!!
[2024-11-09 12:33:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.888 (2.888)	Loss 0.4009 (0.4009)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:33:13 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.317 (0.476)	Loss 0.3931 (0.4035)	Acc@1 88.281 (86.151)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:33:16 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.287 (0.394)	Loss 0.3638 (0.4158)	Acc@1 87.500 (84.784)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:33:19 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.143 (0.340)	Loss 0.4421 (0.4159)	Acc@1 80.469 (83.644)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:33:21 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 83.000 Acc@5 100.000
[2024-11-09 12:33:21 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 83.0%
[2024-11-09 12:33:21 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 83.62%
[2024-11-09 12:33:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.235 (3.235)	Loss 0.4272 (0.4272)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:33:26 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.508)	Loss 0.4351 (0.4311)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:33:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.875 (0.418)	Loss 0.8433 (0.4621)	Acc@1 20.312 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:33:32 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.362)	Loss 0.8882 (0.5920)	Acc@1 15.625 (68.926)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:33:34 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 58.040 Acc@5 100.000
[2024-11-09 12:33:34 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 58.0%
[2024-11-09 12:33:34 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:33:38 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][0/156]	eta 0:10:35 lr 0.000117	 wd 0.0500	time 4.0720 (4.0720)	data time 3.6117 (3.6117)	model time 0.0000 (0.0000)	loss 0.6232 (0.6232)	grad_norm 1.0589 (1.0589)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:33:44 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][10/156]	eta 0:02:06 lr 0.000117	 wd 0.0500	time 0.6789 (0.8695)	data time 0.0108 (0.3542)	model time 0.0000 (0.0000)	loss 0.6296 (0.6211)	grad_norm 1.1040 (1.2054)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:33:49 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][20/156]	eta 0:01:36 lr 0.000117	 wd 0.0500	time 0.4320 (0.7131)	data time 0.0163 (0.1903)	model time 0.0000 (0.0000)	loss 0.6638 (0.6224)	grad_norm 1.3043 (1.2429)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:33:54 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][30/156]	eta 0:01:21 lr 0.000117	 wd 0.0500	time 0.4942 (0.6502)	data time 0.0179 (0.1336)	model time 0.0000 (0.0000)	loss 0.6455 (0.6286)	grad_norm 1.7417 (1.2499)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:00 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][40/156]	eta 0:01:12 lr 0.000117	 wd 0.0500	time 0.4598 (0.6269)	data time 0.0061 (0.1093)	model time 0.0000 (0.0000)	loss 0.6291 (0.6311)	grad_norm 0.8999 (1.2132)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:05 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][50/156]	eta 0:01:03 lr 0.000117	 wd 0.0500	time 0.4787 (0.6032)	data time 0.0545 (0.0947)	model time 0.0000 (0.0000)	loss 0.6389 (0.6313)	grad_norm 0.9321 (1.2176)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:10 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][60/156]	eta 0:00:56 lr 0.000117	 wd 0.0500	time 0.4888 (0.5932)	data time 0.0378 (0.0822)	model time 0.4510 (0.5233)	loss 0.6638 (0.6331)	grad_norm 0.7966 (1.1833)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:15 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][70/156]	eta 0:00:49 lr 0.000117	 wd 0.0500	time 0.4237 (0.5763)	data time 0.0008 (0.0729)	model time 0.4230 (0.4907)	loss 0.6731 (0.6344)	grad_norm 0.9410 (1.1980)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:20 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][80/156]	eta 0:00:42 lr 0.000117	 wd 0.0500	time 0.4119 (0.5600)	data time 0.0038 (0.0647)	model time 0.4081 (0.4728)	loss 0.5896 (0.6329)	grad_norm 1.2190 (1.1988)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:25 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][90/156]	eta 0:00:36 lr 0.000117	 wd 0.0500	time 0.4956 (0.5525)	data time 0.0173 (0.0592)	model time 0.4782 (0.4739)	loss 0.5831 (0.6328)	grad_norm 0.9058 (1.1986)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:30 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][100/156]	eta 0:00:30 lr 0.000117	 wd 0.0500	time 0.4737 (0.5499)	data time 0.0191 (0.0545)	model time 0.4546 (0.4819)	loss 0.6379 (0.6320)	grad_norm 1.5344 (1.2162)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:35 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][110/156]	eta 0:00:25 lr 0.000117	 wd 0.0500	time 0.5080 (0.5487)	data time 0.0021 (0.0505)	model time 0.5059 (0.4894)	loss 0.6337 (0.6336)	grad_norm 1.0258 (1.2060)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:40 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][120/156]	eta 0:00:19 lr 0.000117	 wd 0.0500	time 0.4665 (0.5456)	data time 0.0382 (0.0490)	model time 0.4282 (0.4879)	loss 0.6286 (0.6344)	grad_norm 0.6247 (1.1906)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:45 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][130/156]	eta 0:00:14 lr 0.000117	 wd 0.0500	time 0.4417 (0.5424)	data time 0.0196 (0.0462)	model time 0.4222 (0.4884)	loss 0.6057 (0.6349)	grad_norm 0.9228 (1.1702)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:50 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][140/156]	eta 0:00:08 lr 0.000117	 wd 0.0500	time 0.4098 (0.5393)	data time 0.0009 (0.0436)	model time 0.4089 (0.4884)	loss 0.6705 (0.6348)	grad_norm 1.2506 (1.1774)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:55 vssm1_tiny_0230s](training.py 201): INFO Train: [65/300][150/156]	eta 0:00:03 lr 0.000117	 wd 0.0500	time 0.4975 (0.5369)	data time 0.0009 (0.0415)	model time 0.4966 (0.4887)	loss 0.6514 (0.6352)	grad_norm 1.5691 (1.1777)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:34:58 vssm1_tiny_0230s](training.py 212): INFO EPOCH 65 training takes 0:01:23
[2024-11-09 12:34:58 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_65.pth saving......
[2024-11-09 12:34:59 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_65.pth saved !!!
[2024-11-09 12:35:03 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.020 (4.020)	Loss 0.3677 (0.3677)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:35:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.581)	Loss 0.3730 (0.3849)	Acc@1 89.844 (88.494)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:35:08 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.180 (0.428)	Loss 0.3804 (0.3966)	Acc@1 85.156 (86.979)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:35:10 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.362)	Loss 0.4824 (0.4118)	Acc@1 77.344 (84.904)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:35:13 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 83.840 Acc@5 100.000
[2024-11-09 12:35:13 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 83.8%
[2024-11-09 12:35:13 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 83.84%
[2024-11-09 12:35:15 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.721 (2.721)	Loss 0.4236 (0.4236)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:35:18 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.145 (0.527)	Loss 0.4312 (0.4274)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:35:20 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.349)	Loss 0.8447 (0.4587)	Acc@1 20.312 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:35:22 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.306)	Loss 0.8901 (0.5902)	Acc@1 15.625 (69.052)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:35:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 58.200 Acc@5 100.000
[2024-11-09 12:35:24 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 58.2%
[2024-11-09 12:35:24 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:35:27 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][0/156]	eta 0:08:55 lr 0.000117	 wd 0.0500	time 3.4343 (3.4343)	data time 3.0230 (3.0230)	model time 0.0000 (0.0000)	loss 0.5999 (0.5999)	grad_norm 1.2346 (1.2346)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:35:32 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][10/156]	eta 0:01:51 lr 0.000117	 wd 0.0500	time 0.4473 (0.7641)	data time 0.0032 (0.2862)	model time 0.0000 (0.0000)	loss 0.7018 (0.6507)	grad_norm 1.5008 (1.2843)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:35:37 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][20/156]	eta 0:01:24 lr 0.000117	 wd 0.0500	time 0.6339 (0.6237)	data time 0.0138 (0.1548)	model time 0.0000 (0.0000)	loss 0.6602 (0.6366)	grad_norm 1.2596 (1.3568)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:35:42 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][30/156]	eta 0:01:13 lr 0.000117	 wd 0.0500	time 0.5083 (0.5849)	data time 0.0157 (0.1138)	model time 0.0000 (0.0000)	loss 0.6519 (0.6331)	grad_norm 0.6945 (1.3165)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:35:47 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][40/156]	eta 0:01:05 lr 0.000117	 wd 0.0500	time 0.5051 (0.5621)	data time 0.0239 (0.0895)	model time 0.0000 (0.0000)	loss 0.6277 (0.6315)	grad_norm 1.0353 (1.2797)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:35:52 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][50/156]	eta 0:00:59 lr 0.000117	 wd 0.0500	time 0.5441 (0.5583)	data time 0.0049 (0.0754)	model time 0.0000 (0.0000)	loss 0.6618 (0.6345)	grad_norm 1.3585 (1.2536)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:35:58 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][60/156]	eta 0:00:53 lr 0.000117	 wd 0.0500	time 0.5269 (0.5537)	data time 0.0081 (0.0678)	model time 0.5188 (0.5015)	loss 0.6380 (0.6346)	grad_norm 1.2137 (1.2572)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:36:03 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][70/156]	eta 0:00:47 lr 0.000117	 wd 0.0500	time 0.5666 (0.5473)	data time 0.1004 (0.0621)	model time 0.4662 (0.4911)	loss 0.6615 (0.6355)	grad_norm 1.4721 (1.2658)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:36:08 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][80/156]	eta 0:00:41 lr 0.000117	 wd 0.0500	time 0.7675 (0.5442)	data time 0.0040 (0.0569)	model time 0.7635 (0.4948)	loss 0.5733 (0.6334)	grad_norm 1.3824 (1.2699)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:36:13 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][90/156]	eta 0:00:35 lr 0.000117	 wd 0.0500	time 0.4674 (0.5388)	data time 0.0082 (0.0525)	model time 0.4593 (0.4906)	loss 0.5619 (0.6302)	grad_norm 1.4816 (1.2665)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:36:18 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][100/156]	eta 0:00:30 lr 0.000117	 wd 0.0500	time 0.4979 (0.5383)	data time 0.0058 (0.0492)	model time 0.4921 (0.4954)	loss 0.5901 (0.6297)	grad_norm 1.0228 (1.2418)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:36:24 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][110/156]	eta 0:00:24 lr 0.000117	 wd 0.0500	time 0.4542 (0.5394)	data time 0.0168 (0.0474)	model time 0.4373 (0.4998)	loss 0.6021 (0.6271)	grad_norm 1.1744 (1.2608)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:36:29 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][120/156]	eta 0:00:19 lr 0.000117	 wd 0.0500	time 0.5157 (0.5383)	data time 0.0010 (0.0449)	model time 0.5147 (0.5011)	loss 0.5993 (0.6282)	grad_norm 1.1580 (1.2430)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:36:35 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][130/156]	eta 0:00:13 lr 0.000117	 wd 0.0500	time 0.6253 (0.5382)	data time 0.0345 (0.0422)	model time 0.5908 (0.5043)	loss 0.6069 (0.6278)	grad_norm 1.2571 (1.2314)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:36:40 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][140/156]	eta 0:00:08 lr 0.000117	 wd 0.0500	time 0.4985 (0.5381)	data time 0.0010 (0.0415)	model time 0.4976 (0.5043)	loss 0.6336 (0.6281)	grad_norm 1.3492 (1.2477)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:36:45 vssm1_tiny_0230s](training.py 201): INFO Train: [66/300][150/156]	eta 0:00:03 lr 0.000117	 wd 0.0500	time 0.5263 (0.5334)	data time 0.0006 (0.0388)	model time 0.5257 (0.5005)	loss 0.6317 (0.6282)	grad_norm 1.0268 (1.2440)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:36:47 vssm1_tiny_0230s](training.py 212): INFO EPOCH 66 training takes 0:01:23
[2024-11-09 12:36:47 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_66.pth saving......
[2024-11-09 12:36:48 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_66.pth saved !!!
[2024-11-09 12:36:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.818 (4.818)	Loss 0.3196 (0.3196)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:36:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.640)	Loss 0.3164 (0.3293)	Acc@1 92.188 (91.264)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:36:57 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.149 (0.433)	Loss 0.4165 (0.3507)	Acc@1 80.469 (88.988)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:37:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.148 (0.390)	Loss 0.5356 (0.3905)	Acc@1 74.219 (84.803)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:37:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 83.060 Acc@5 100.000
[2024-11-09 12:37:02 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 83.1%
[2024-11-09 12:37:02 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 83.84%
[2024-11-09 12:37:05 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.023 (3.023)	Loss 0.4197 (0.4197)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:37:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.293 (0.604)	Loss 0.4272 (0.4235)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:37:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.400)	Loss 0.8462 (0.4552)	Acc@1 20.312 (93.192)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:37:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.326)	Loss 0.8931 (0.5885)	Acc@1 15.625 (69.229)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:37:14 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 58.400 Acc@5 100.000
[2024-11-09 12:37:14 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 58.4%
[2024-11-09 12:37:14 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.52%
[2024-11-09 12:37:18 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][0/156]	eta 0:09:57 lr 0.000117	 wd 0.0500	time 3.8324 (3.8324)	data time 3.3298 (3.3298)	model time 0.0000 (0.0000)	loss 0.6395 (0.6395)	grad_norm 1.5450 (1.5450)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:37:23 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][10/156]	eta 0:01:55 lr 0.000117	 wd 0.0500	time 0.5659 (0.7939)	data time 0.0026 (0.3126)	model time 0.0000 (0.0000)	loss 0.6584 (0.6298)	grad_norm 1.0453 (1.4121)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:37:28 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][20/156]	eta 0:01:28 lr 0.000117	 wd 0.0500	time 0.5403 (0.6532)	data time 0.0268 (0.1738)	model time 0.0000 (0.0000)	loss 0.6076 (0.6334)	grad_norm 1.0602 (1.2111)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:37:34 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][30/156]	eta 0:01:17 lr 0.000117	 wd 0.0500	time 0.5494 (0.6164)	data time 0.0006 (0.1226)	model time 0.0000 (0.0000)	loss 0.6423 (0.6324)	grad_norm 1.5467 (1.1911)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:37:39 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][40/156]	eta 0:01:09 lr 0.000117	 wd 0.0500	time 0.5762 (0.5972)	data time 0.0008 (0.0958)	model time 0.0000 (0.0000)	loss 0.6479 (0.6342)	grad_norm 0.8420 (1.1951)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:37:44 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][50/156]	eta 0:01:00 lr 0.000116	 wd 0.0500	time 0.5330 (0.5704)	data time 0.0007 (0.0786)	model time 0.0000 (0.0000)	loss 0.6302 (0.6342)	grad_norm 0.7462 (1.2102)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:37:49 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][60/156]	eta 0:00:53 lr 0.000116	 wd 0.0500	time 0.4861 (0.5598)	data time 0.0332 (0.0689)	model time 0.4529 (0.4861)	loss 0.6145 (0.6374)	grad_norm 0.7777 (1.2482)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:37:54 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][70/156]	eta 0:00:47 lr 0.000116	 wd 0.0500	time 0.5972 (0.5536)	data time 0.0021 (0.0621)	model time 0.5951 (0.4904)	loss 0.6465 (0.6368)	grad_norm 0.9798 (1.2489)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:37:59 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][80/156]	eta 0:00:41 lr 0.000116	 wd 0.0500	time 0.4281 (0.5447)	data time 0.0021 (0.0560)	model time 0.4260 (0.4834)	loss 0.6106 (0.6376)	grad_norm 0.8696 (1.2669)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:38:04 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][90/156]	eta 0:00:35 lr 0.000116	 wd 0.0500	time 0.5898 (0.5446)	data time 0.0130 (0.0519)	model time 0.5769 (0.4939)	loss 0.6588 (0.6363)	grad_norm 1.1256 (1.2318)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:38:09 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][100/156]	eta 0:00:30 lr 0.000116	 wd 0.0500	time 0.4315 (0.5417)	data time 0.0008 (0.0485)	model time 0.4307 (0.4946)	loss 0.6270 (0.6355)	grad_norm 0.9272 (1.2483)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:38:14 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][110/156]	eta 0:00:24 lr 0.000116	 wd 0.0500	time 0.4415 (0.5382)	data time 0.0005 (0.0451)	model time 0.4409 (0.4941)	loss 0.5649 (0.6325)	grad_norm 1.2180 (1.2575)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:38:20 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][120/156]	eta 0:00:19 lr 0.000116	 wd 0.0500	time 0.4239 (0.5383)	data time 0.0047 (0.0426)	model time 0.4192 (0.4986)	loss 0.6052 (0.6304)	grad_norm 1.1382 (1.2541)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:38:25 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][130/156]	eta 0:00:13 lr 0.000116	 wd 0.0500	time 0.4927 (0.5361)	data time 0.0831 (0.0413)	model time 0.4097 (0.4966)	loss 0.6329 (0.6297)	grad_norm 1.7789 (1.2690)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:38:30 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][140/156]	eta 0:00:08 lr 0.000116	 wd 0.0500	time 0.4107 (0.5344)	data time 0.0010 (0.0394)	model time 0.4097 (0.4967)	loss 0.6735 (0.6283)	grad_norm 1.3708 (1.2699)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:38:35 vssm1_tiny_0230s](training.py 201): INFO Train: [67/300][150/156]	eta 0:00:03 lr 0.000116	 wd 0.0500	time 0.5418 (0.5336)	data time 0.0007 (0.0371)	model time 0.5411 (0.4990)	loss 0.6684 (0.6275)	grad_norm 1.2597 (1.2995)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:38:38 vssm1_tiny_0230s](training.py 212): INFO EPOCH 67 training takes 0:01:23
[2024-11-09 12:38:38 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_67.pth saving......
[2024-11-09 12:38:39 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_67.pth saved !!!
[2024-11-09 12:38:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.438 (3.438)	Loss 0.3923 (0.3923)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:38:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.259 (0.522)	Loss 0.3840 (0.4001)	Acc@1 87.500 (85.724)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:38:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.153 (0.419)	Loss 0.3296 (0.4093)	Acc@1 89.062 (84.673)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:38:50 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.362)	Loss 0.4082 (0.4024)	Acc@1 79.688 (84.451)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:38:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 84.600 Acc@5 100.000
[2024-11-09 12:38:53 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 84.6%
[2024-11-09 12:38:53 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 84.60%
[2024-11-09 12:38:56 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.894 (2.894)	Loss 0.4160 (0.4160)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:38:58 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.145 (0.530)	Loss 0.4236 (0.4199)	Acc@1 98.438 (99.148)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:39:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.174 (0.391)	Loss 0.8472 (0.4520)	Acc@1 20.312 (93.192)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:39:03 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.198 (0.349)	Loss 0.8950 (0.5867)	Acc@1 16.406 (69.380)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:39:06 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 58.580 Acc@5 100.000
[2024-11-09 12:39:06 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 58.6%
[2024-11-09 12:39:06 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.58%
[2024-11-09 12:39:09 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][0/156]	eta 0:09:27 lr 0.000116	 wd 0.0500	time 3.6366 (3.6366)	data time 3.1533 (3.1533)	model time 0.0000 (0.0000)	loss 0.7188 (0.7188)	grad_norm 1.5728 (1.5728)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:39:15 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][10/156]	eta 0:01:58 lr 0.000116	 wd 0.0500	time 0.4945 (0.8123)	data time 0.0195 (0.2963)	model time 0.0000 (0.0000)	loss 0.6221 (0.6445)	grad_norm 0.8618 (1.7589)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:39:19 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][20/156]	eta 0:01:28 lr 0.000116	 wd 0.0500	time 0.4272 (0.6512)	data time 0.0005 (0.1616)	model time 0.0000 (0.0000)	loss 0.6445 (0.6316)	grad_norm 0.6906 (1.4624)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:39:24 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][30/156]	eta 0:01:14 lr 0.000116	 wd 0.0500	time 0.4581 (0.5895)	data time 0.0232 (0.1109)	model time 0.0000 (0.0000)	loss 0.6173 (0.6363)	grad_norm 1.2576 (1.4081)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:39:29 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][40/156]	eta 0:01:05 lr 0.000116	 wd 0.0500	time 0.4983 (0.5655)	data time 0.0153 (0.0887)	model time 0.0000 (0.0000)	loss 0.6568 (0.6364)	grad_norm 1.5679 (1.4616)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:39:34 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][50/156]	eta 0:00:58 lr 0.000116	 wd 0.0500	time 0.4710 (0.5519)	data time 0.0258 (0.0757)	model time 0.0000 (0.0000)	loss 0.6356 (0.6297)	grad_norm 1.5873 (1.4830)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:39:39 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][60/156]	eta 0:00:52 lr 0.000116	 wd 0.0500	time 0.4579 (0.5439)	data time 0.0050 (0.0653)	model time 0.4528 (0.4909)	loss 0.5780 (0.6309)	grad_norm 1.0948 (1.4930)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:39:44 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][70/156]	eta 0:00:46 lr 0.000116	 wd 0.0500	time 0.7054 (0.5372)	data time 0.0194 (0.0578)	model time 0.6860 (0.4877)	loss 0.6461 (0.6301)	grad_norm 1.6465 (1.4659)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:39:49 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][80/156]	eta 0:00:40 lr 0.000116	 wd 0.0500	time 0.5677 (0.5350)	data time 0.0184 (0.0526)	model time 0.5492 (0.4929)	loss 0.6375 (0.6308)	grad_norm 1.1205 (1.4103)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:39:54 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][90/156]	eta 0:00:35 lr 0.000116	 wd 0.0500	time 0.5432 (0.5343)	data time 0.0174 (0.0490)	model time 0.5259 (0.4970)	loss 0.6054 (0.6302)	grad_norm 1.1496 (1.3898)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:39:59 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][100/156]	eta 0:00:29 lr 0.000116	 wd 0.0500	time 0.4747 (0.5319)	data time 0.0144 (0.0453)	model time 0.4602 (0.4971)	loss 0.6125 (0.6306)	grad_norm 1.7083 (1.3874)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:40:05 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][110/156]	eta 0:00:24 lr 0.000116	 wd 0.0500	time 0.6970 (0.5328)	data time 0.0078 (0.0425)	model time 0.6892 (0.5023)	loss 0.5988 (0.6305)	grad_norm 1.0766 (1.3625)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:40:10 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][120/156]	eta 0:00:19 lr 0.000116	 wd 0.0500	time 0.5453 (0.5320)	data time 0.0171 (0.0399)	model time 0.5282 (0.5036)	loss 0.6441 (0.6301)	grad_norm 1.1328 (1.3572)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:40:16 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][130/156]	eta 0:00:13 lr 0.000116	 wd 0.0500	time 0.5971 (0.5343)	data time 0.0151 (0.0387)	model time 0.5819 (0.5079)	loss 0.6337 (0.6299)	grad_norm 1.4024 (1.3594)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:40:21 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][140/156]	eta 0:00:08 lr 0.000116	 wd 0.0500	time 0.4491 (0.5347)	data time 0.0010 (0.0375)	model time 0.4481 (0.5090)	loss 0.6561 (0.6300)	grad_norm 1.7407 (1.3601)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:40:26 vssm1_tiny_0230s](training.py 201): INFO Train: [68/300][150/156]	eta 0:00:03 lr 0.000116	 wd 0.0500	time 0.5801 (0.5331)	data time 0.0007 (0.0351)	model time 0.5794 (0.5091)	loss 0.5938 (0.6300)	grad_norm 2.6046 (1.3643)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:40:29 vssm1_tiny_0230s](training.py 212): INFO EPOCH 68 training takes 0:01:23
[2024-11-09 12:40:29 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_68.pth saving......
[2024-11-09 12:40:29 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_68.pth saved !!!
[2024-11-09 12:40:33 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.560 (3.560)	Loss 0.3127 (0.3127)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:40:35 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.146 (0.549)	Loss 0.3105 (0.3151)	Acc@1 92.188 (92.685)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:40:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.161 (0.389)	Loss 0.4543 (0.3383)	Acc@1 78.906 (90.067)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:40:39 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.320)	Loss 0.5537 (0.3945)	Acc@1 70.312 (84.803)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:40:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 82.520 Acc@5 100.000
[2024-11-09 12:40:42 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 82.5%
[2024-11-09 12:40:42 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 84.60%
[2024-11-09 12:40:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.720 (3.720)	Loss 0.4121 (0.4121)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:40:47 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.555 (0.515)	Loss 0.4197 (0.4161)	Acc@1 98.438 (99.077)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:40:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.387)	Loss 0.8486 (0.4486)	Acc@1 20.312 (93.155)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:40:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.353)	Loss 0.8975 (0.5850)	Acc@1 16.406 (69.481)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:40:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 58.740 Acc@5 100.000
[2024-11-09 12:40:55 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 58.7%
[2024-11-09 12:40:55 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.74%
[2024-11-09 12:41:00 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][0/156]	eta 0:12:27 lr 0.000116	 wd 0.0500	time 4.7899 (4.7899)	data time 4.2945 (4.2945)	model time 0.0000 (0.0000)	loss 0.5886 (0.5886)	grad_norm 1.0493 (1.0493)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:41:04 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][10/156]	eta 0:02:04 lr 0.000116	 wd 0.0500	time 0.4759 (0.8548)	data time 0.0011 (0.4055)	model time 0.0000 (0.0000)	loss 0.6302 (0.6295)	grad_norm 1.3477 (1.3031)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:41:09 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][20/156]	eta 0:01:30 lr 0.000116	 wd 0.0500	time 0.4422 (0.6640)	data time 0.0008 (0.2206)	model time 0.0000 (0.0000)	loss 0.5897 (0.6218)	grad_norm 2.3883 (1.3665)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:41:14 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][30/156]	eta 0:01:15 lr 0.000116	 wd 0.0500	time 0.4357 (0.6030)	data time 0.0084 (0.1547)	model time 0.0000 (0.0000)	loss 0.6356 (0.6266)	grad_norm 1.0018 (1.3903)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:41:19 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][40/156]	eta 0:01:07 lr 0.000116	 wd 0.0500	time 0.4920 (0.5795)	data time 0.0296 (0.1207)	model time 0.0000 (0.0000)	loss 0.6624 (0.6255)	grad_norm 1.4225 (1.3476)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:41:23 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][50/156]	eta 0:00:58 lr 0.000116	 wd 0.0500	time 0.4493 (0.5551)	data time 0.0008 (0.0985)	model time 0.0000 (0.0000)	loss 0.7059 (0.6288)	grad_norm 1.3643 (1.3377)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:41:29 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][60/156]	eta 0:00:53 lr 0.000116	 wd 0.0500	time 0.5775 (0.5549)	data time 0.0050 (0.0855)	model time 0.5725 (0.5345)	loss 0.5936 (0.6267)	grad_norm 1.1131 (1.3272)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:41:35 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][70/156]	eta 0:00:47 lr 0.000116	 wd 0.0500	time 0.4569 (0.5568)	data time 0.0140 (0.0779)	model time 0.4429 (0.5354)	loss 0.6069 (0.6246)	grad_norm 0.6920 (1.2949)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:41:42 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][80/156]	eta 0:00:44 lr 0.000116	 wd 0.0500	time 0.8929 (0.5810)	data time 0.0216 (0.0731)	model time 0.8712 (0.5950)	loss 0.6300 (0.6257)	grad_norm 1.2695 (1.2898)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:41:49 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][90/156]	eta 0:00:38 lr 0.000116	 wd 0.0500	time 0.5270 (0.5890)	data time 0.0008 (0.0684)	model time 0.5262 (0.6020)	loss 0.6275 (0.6263)	grad_norm 1.6947 (1.2863)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:41:55 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][100/156]	eta 0:00:33 lr 0.000116	 wd 0.0500	time 0.8063 (0.5904)	data time 0.0007 (0.0646)	model time 0.8056 (0.5965)	loss 0.6497 (0.6280)	grad_norm 0.8428 (1.3293)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:42:00 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][110/156]	eta 0:00:26 lr 0.000116	 wd 0.0500	time 0.4234 (0.5829)	data time 0.0006 (0.0613)	model time 0.4228 (0.5769)	loss 0.6743 (0.6290)	grad_norm 2.7059 (1.3285)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:42:05 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][120/156]	eta 0:00:20 lr 0.000116	 wd 0.0500	time 0.6295 (0.5747)	data time 0.0197 (0.0571)	model time 0.6098 (0.5620)	loss 0.6313 (0.6288)	grad_norm 1.1478 (1.3178)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:42:09 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][130/156]	eta 0:00:14 lr 0.000116	 wd 0.0500	time 0.4595 (0.5666)	data time 0.0230 (0.0534)	model time 0.4364 (0.5492)	loss 0.5737 (0.6285)	grad_norm 1.5235 (1.3148)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:42:14 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][140/156]	eta 0:00:08 lr 0.000116	 wd 0.0500	time 0.4420 (0.5606)	data time 0.0008 (0.0500)	model time 0.4412 (0.5411)	loss 0.6660 (0.6275)	grad_norm 2.5082 (1.3279)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:42:19 vssm1_tiny_0230s](training.py 201): INFO Train: [69/300][150/156]	eta 0:00:03 lr 0.000116	 wd 0.0500	time 0.4307 (0.5530)	data time 0.0006 (0.0470)	model time 0.4301 (0.5311)	loss 0.6705 (0.6273)	grad_norm 1.7328 (1.3366)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:42:21 vssm1_tiny_0230s](training.py 212): INFO EPOCH 69 training takes 0:01:26
[2024-11-09 12:42:21 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_69.pth saving......
[2024-11-09 12:42:22 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_69.pth saved !!!
[2024-11-09 12:42:25 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.415 (3.415)	Loss 0.4868 (0.4868)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:42:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.143 (0.784)	Loss 0.4956 (0.4879)	Acc@1 77.344 (78.480)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:42:33 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.156 (0.548)	Loss 0.2803 (0.4854)	Acc@1 92.188 (78.125)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:42:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.459)	Loss 0.3401 (0.4342)	Acc@1 85.156 (81.729)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:42:39 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 83.540 Acc@5 100.000
[2024-11-09 12:42:39 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 83.5%
[2024-11-09 12:42:39 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 84.60%
[2024-11-09 12:42:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.996 (4.996)	Loss 0.4089 (0.4089)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:42:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.172 (0.650)	Loss 0.4163 (0.4128)	Acc@1 98.438 (99.006)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:42:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.153 (0.453)	Loss 0.8491 (0.4456)	Acc@1 20.312 (93.155)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:42:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.152 (0.373)	Loss 0.8989 (0.5833)	Acc@1 17.188 (69.607)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:42:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 58.900 Acc@5 100.000
[2024-11-09 12:42:53 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 58.9%
[2024-11-09 12:42:53 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 58.90%
[2024-11-09 12:42:58 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][0/156]	eta 0:11:19 lr 0.000116	 wd 0.0500	time 4.3578 (4.3578)	data time 3.8590 (3.8590)	model time 0.0000 (0.0000)	loss 0.6126 (0.6126)	grad_norm 1.3243 (1.3243)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:02 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][10/156]	eta 0:02:00 lr 0.000115	 wd 0.0500	time 0.4837 (0.8244)	data time 0.0220 (0.3589)	model time 0.0000 (0.0000)	loss 0.5644 (0.6135)	grad_norm 1.0061 (1.3688)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:07 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][20/156]	eta 0:01:32 lr 0.000115	 wd 0.0500	time 0.4953 (0.6783)	data time 0.0007 (0.1917)	model time 0.0000 (0.0000)	loss 0.5886 (0.6224)	grad_norm 0.9006 (1.4601)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:13 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][30/156]	eta 0:01:19 lr 0.000115	 wd 0.0500	time 0.4738 (0.6342)	data time 0.0201 (0.1360)	model time 0.0000 (0.0000)	loss 0.6821 (0.6263)	grad_norm 1.5488 (1.3822)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:18 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][40/156]	eta 0:01:09 lr 0.000115	 wd 0.0500	time 0.5855 (0.6020)	data time 0.0127 (0.1060)	model time 0.0000 (0.0000)	loss 0.6436 (0.6235)	grad_norm 1.8577 (1.3611)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:23 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][50/156]	eta 0:01:01 lr 0.000115	 wd 0.0500	time 0.4305 (0.5796)	data time 0.0007 (0.0884)	model time 0.0000 (0.0000)	loss 0.5756 (0.6259)	grad_norm 1.7118 (1.3445)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:28 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][60/156]	eta 0:00:54 lr 0.000115	 wd 0.0500	time 0.5095 (0.5694)	data time 0.0670 (0.0761)	model time 0.4425 (0.5040)	loss 0.6217 (0.6277)	grad_norm 0.8490 (1.3183)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:33 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][70/156]	eta 0:00:48 lr 0.000115	 wd 0.0500	time 0.4379 (0.5607)	data time 0.0008 (0.0671)	model time 0.4371 (0.4997)	loss 0.5612 (0.6238)	grad_norm 1.0839 (1.2670)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:38 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][80/156]	eta 0:00:42 lr 0.000115	 wd 0.0500	time 0.4356 (0.5553)	data time 0.0014 (0.0597)	model time 0.4342 (0.5031)	loss 0.6014 (0.6250)	grad_norm 0.8741 (1.3142)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:43 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][90/156]	eta 0:00:36 lr 0.000115	 wd 0.0500	time 0.4714 (0.5517)	data time 0.0388 (0.0571)	model time 0.4326 (0.4988)	loss 0.6067 (0.6277)	grad_norm 0.9177 (1.3028)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:49 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][100/156]	eta 0:00:30 lr 0.000115	 wd 0.0500	time 0.4211 (0.5479)	data time 0.0094 (0.0533)	model time 0.4117 (0.4981)	loss 0.6198 (0.6288)	grad_norm 1.1840 (1.2929)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:54 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][110/156]	eta 0:00:24 lr 0.000115	 wd 0.0500	time 0.4588 (0.5434)	data time 0.0046 (0.0498)	model time 0.4541 (0.4957)	loss 0.6338 (0.6280)	grad_norm 1.3774 (1.2709)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:43:58 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][120/156]	eta 0:00:19 lr 0.000115	 wd 0.0500	time 0.4241 (0.5364)	data time 0.0023 (0.0465)	model time 0.4219 (0.4890)	loss 0.6235 (0.6274)	grad_norm 1.0154 (1.2732)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:44:03 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][130/156]	eta 0:00:13 lr 0.000115	 wd 0.0500	time 0.4450 (0.5362)	data time 0.0331 (0.0446)	model time 0.4119 (0.4919)	loss 0.5791 (0.6279)	grad_norm 1.1965 (1.2823)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:44:10 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][140/156]	eta 0:00:08 lr 0.000115	 wd 0.0500	time 0.5033 (0.5411)	data time 0.0009 (0.0422)	model time 0.5024 (0.5033)	loss 0.6729 (0.6281)	grad_norm 1.1613 (1.3139)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:44:14 vssm1_tiny_0230s](training.py 201): INFO Train: [70/300][150/156]	eta 0:00:03 lr 0.000115	 wd 0.0500	time 0.6539 (0.5370)	data time 0.0005 (0.0395)	model time 0.6534 (0.5007)	loss 0.6102 (0.6291)	grad_norm 0.8968 (1.2975)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:44:17 vssm1_tiny_0230s](training.py 212): INFO EPOCH 70 training takes 0:01:23
[2024-11-09 12:44:17 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_70.pth saving......
[2024-11-09 12:44:18 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_70.pth saved !!!
[2024-11-09 12:44:21 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.208 (3.208)	Loss 0.3789 (0.3789)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:44:23 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.165 (0.466)	Loss 0.3750 (0.3914)	Acc@1 91.406 (87.997)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:44:25 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.220 (0.332)	Loss 0.3594 (0.4028)	Acc@1 85.938 (86.384)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:44:27 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.300)	Loss 0.4277 (0.4058)	Acc@1 80.469 (85.207)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:44:29 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 84.880 Acc@5 100.000
[2024-11-09 12:44:29 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 84.9%
[2024-11-09 12:44:29 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 84.88%
[2024-11-09 12:44:32 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.253 (3.253)	Loss 0.4058 (0.4058)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:44:35 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.153 (0.521)	Loss 0.4131 (0.4096)	Acc@1 98.438 (99.006)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:44:37 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.484 (0.397)	Loss 0.8501 (0.4427)	Acc@1 20.312 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:44:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.158 (0.347)	Loss 0.9004 (0.5817)	Acc@1 17.188 (69.657)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:44:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 59.060 Acc@5 100.000
[2024-11-09 12:44:43 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 59.1%
[2024-11-09 12:44:43 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 59.06%
[2024-11-09 12:44:47 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][0/156]	eta 0:11:04 lr 0.000115	 wd 0.0500	time 4.2620 (4.2620)	data time 3.6173 (3.6173)	model time 0.0000 (0.0000)	loss 0.6685 (0.6685)	grad_norm 1.3748 (1.3748)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:44:52 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][10/156]	eta 0:02:06 lr 0.000115	 wd 0.0500	time 0.5721 (0.8680)	data time 0.0895 (0.3629)	model time 0.0000 (0.0000)	loss 0.6208 (0.6288)	grad_norm 1.1947 (1.2672)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:44:57 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][20/156]	eta 0:01:36 lr 0.000115	 wd 0.0500	time 0.4694 (0.7080)	data time 0.0434 (0.2001)	model time 0.0000 (0.0000)	loss 0.6880 (0.6320)	grad_norm 2.0774 (1.2997)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:03 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][30/156]	eta 0:01:20 lr 0.000115	 wd 0.0500	time 0.6336 (0.6419)	data time 0.0271 (0.1399)	model time 0.0000 (0.0000)	loss 0.6026 (0.6290)	grad_norm 1.3606 (1.3188)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:08 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][40/156]	eta 0:01:11 lr 0.000115	 wd 0.0500	time 0.6308 (0.6145)	data time 0.0154 (0.1145)	model time 0.0000 (0.0000)	loss 0.6818 (0.6286)	grad_norm 1.3716 (1.2807)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:13 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][50/156]	eta 0:01:02 lr 0.000115	 wd 0.0500	time 0.4979 (0.5888)	data time 0.0438 (0.0959)	model time 0.0000 (0.0000)	loss 0.6214 (0.6299)	grad_norm 0.9754 (1.2601)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:17 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][60/156]	eta 0:00:54 lr 0.000115	 wd 0.0500	time 0.5314 (0.5691)	data time 0.0341 (0.0817)	model time 0.4973 (0.4590)	loss 0.6667 (0.6297)	grad_norm 1.3155 (1.2281)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:22 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][70/156]	eta 0:00:47 lr 0.000115	 wd 0.0500	time 0.4570 (0.5574)	data time 0.0008 (0.0709)	model time 0.4562 (0.4703)	loss 0.6286 (0.6297)	grad_norm 1.1078 (1.2168)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:28 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][80/156]	eta 0:00:42 lr 0.000115	 wd 0.0500	time 0.4162 (0.5550)	data time 0.0080 (0.0640)	model time 0.4082 (0.4876)	loss 0.6653 (0.6277)	grad_norm 2.5742 (1.2677)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:33 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][90/156]	eta 0:00:36 lr 0.000115	 wd 0.0500	time 0.4457 (0.5512)	data time 0.0364 (0.0590)	model time 0.4093 (0.4912)	loss 0.5949 (0.6265)	grad_norm 1.1425 (1.2715)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:37 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][100/156]	eta 0:00:30 lr 0.000115	 wd 0.0500	time 0.4837 (0.5433)	data time 0.0058 (0.0540)	model time 0.4779 (0.4856)	loss 0.6944 (0.6266)	grad_norm 1.4773 (1.2915)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:42 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][110/156]	eta 0:00:24 lr 0.000115	 wd 0.0500	time 0.5392 (0.5378)	data time 0.0131 (0.0504)	model time 0.5261 (0.4828)	loss 0.6233 (0.6245)	grad_norm 1.0253 (1.2916)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:48 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][120/156]	eta 0:00:19 lr 0.000115	 wd 0.0500	time 0.4283 (0.5364)	data time 0.0138 (0.0482)	model time 0.4144 (0.4848)	loss 0.6349 (0.6243)	grad_norm 1.7071 (1.2944)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:53 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][130/156]	eta 0:00:14 lr 0.000115	 wd 0.0500	time 0.5387 (0.5385)	data time 0.0370 (0.0457)	model time 0.5016 (0.4927)	loss 0.6044 (0.6237)	grad_norm 1.0322 (1.3038)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:45:58 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][140/156]	eta 0:00:08 lr 0.000115	 wd 0.0500	time 0.5416 (0.5372)	data time 0.0008 (0.0443)	model time 0.5408 (0.4930)	loss 0.6470 (0.6241)	grad_norm 1.0816 (1.3154)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:46:03 vssm1_tiny_0230s](training.py 201): INFO Train: [71/300][150/156]	eta 0:00:03 lr 0.000115	 wd 0.0500	time 0.4343 (0.5332)	data time 0.0005 (0.0415)	model time 0.4338 (0.4910)	loss 0.6240 (0.6240)	grad_norm 1.4182 (1.3340)	loss_scale 131072.0000 (65970.0132)	mem 13675MB
[2024-11-09 12:46:06 vssm1_tiny_0230s](training.py 212): INFO EPOCH 71 training takes 0:01:23
[2024-11-09 12:46:06 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_71.pth saving......
[2024-11-09 12:46:06 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_71.pth saved !!!
[2024-11-09 12:46:09 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.680 (2.680)	Loss 0.4180 (0.4180)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:46:12 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.239 (0.546)	Loss 0.4158 (0.4305)	Acc@1 81.250 (83.168)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:46:14 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.163 (0.361)	Loss 0.3345 (0.4377)	Acc@1 90.625 (82.626)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:46:16 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.301)	Loss 0.3833 (0.4194)	Acc@1 85.938 (83.745)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:46:19 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 84.300 Acc@5 100.000
[2024-11-09 12:46:19 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 84.3%
[2024-11-09 12:46:19 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 84.88%
[2024-11-09 12:46:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.164 (4.164)	Loss 0.4023 (0.4023)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:46:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.568)	Loss 0.4097 (0.4063)	Acc@1 98.438 (99.006)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:46:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.205 (0.410)	Loss 0.8506 (0.4397)	Acc@1 21.094 (93.155)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:46:30 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.157 (0.357)	Loss 0.9023 (0.5800)	Acc@1 18.750 (69.834)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:46:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 59.260 Acc@5 100.000
[2024-11-09 12:46:32 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 59.3%
[2024-11-09 12:46:32 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 59.26%
[2024-11-09 12:46:35 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][0/156]	eta 0:08:07 lr 0.000115	 wd 0.0500	time 3.1239 (3.1239)	data time 2.5242 (2.5242)	model time 0.0000 (0.0000)	loss 0.6657 (0.6657)	grad_norm 1.3555 (1.3555)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:46:40 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][10/156]	eta 0:01:49 lr 0.000115	 wd 0.0500	time 0.4378 (0.7498)	data time 0.0059 (0.2700)	model time 0.0000 (0.0000)	loss 0.6645 (0.6244)	grad_norm 1.3133 (1.5675)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:46:45 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][20/156]	eta 0:01:24 lr 0.000115	 wd 0.0500	time 0.4798 (0.6228)	data time 0.0064 (0.1511)	model time 0.0000 (0.0000)	loss 0.6308 (0.6173)	grad_norm 1.2003 (1.5158)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:46:50 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][30/156]	eta 0:01:12 lr 0.000115	 wd 0.0500	time 0.4817 (0.5760)	data time 0.0276 (0.1080)	model time 0.0000 (0.0000)	loss 0.5318 (0.6147)	grad_norm 1.4852 (1.4927)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:46:55 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][40/156]	eta 0:01:06 lr 0.000115	 wd 0.0500	time 0.4676 (0.5743)	data time 0.0006 (0.0904)	model time 0.0000 (0.0000)	loss 0.7150 (0.6204)	grad_norm 2.0155 (1.5245)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:00 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][50/156]	eta 0:00:58 lr 0.000115	 wd 0.0500	time 0.4807 (0.5513)	data time 0.0024 (0.0752)	model time 0.0000 (0.0000)	loss 0.6430 (0.6178)	grad_norm 0.5801 (1.4700)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:05 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][60/156]	eta 0:00:52 lr 0.000115	 wd 0.0500	time 0.4928 (0.5436)	data time 0.0005 (0.0666)	model time 0.4924 (0.4814)	loss 0.6589 (0.6221)	grad_norm 0.7820 (1.4865)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:10 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][70/156]	eta 0:00:46 lr 0.000115	 wd 0.0500	time 0.4356 (0.5353)	data time 0.0007 (0.0590)	model time 0.4349 (0.4767)	loss 0.7171 (0.6247)	grad_norm 2.2894 (1.4662)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:16 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][80/156]	eta 0:00:40 lr 0.000115	 wd 0.0500	time 0.5115 (0.5378)	data time 0.0346 (0.0540)	model time 0.4769 (0.4969)	loss 0.6739 (0.6257)	grad_norm 0.7786 (1.4249)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:21 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][90/156]	eta 0:00:35 lr 0.000115	 wd 0.0500	time 0.5162 (0.5338)	data time 0.0038 (0.0490)	model time 0.5124 (0.4959)	loss 0.6544 (0.6258)	grad_norm 0.9640 (1.4040)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:25 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][100/156]	eta 0:00:29 lr 0.000115	 wd 0.0500	time 0.5575 (0.5283)	data time 0.0022 (0.0450)	model time 0.5553 (0.4907)	loss 0.6415 (0.6246)	grad_norm 1.6613 (1.3879)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:30 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][110/156]	eta 0:00:24 lr 0.000114	 wd 0.0500	time 0.4572 (0.5257)	data time 0.0085 (0.0421)	model time 0.4487 (0.4899)	loss 0.6188 (0.6260)	grad_norm 1.2674 (1.3871)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:35 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][120/156]	eta 0:00:18 lr 0.000114	 wd 0.0500	time 0.4757 (0.5233)	data time 0.0053 (0.0401)	model time 0.4703 (0.4883)	loss 0.5458 (0.6261)	grad_norm 1.7483 (1.3871)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:40 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][130/156]	eta 0:00:13 lr 0.000114	 wd 0.0500	time 0.6100 (0.5219)	data time 0.0009 (0.0390)	model time 0.6091 (0.4872)	loss 0.6281 (0.6255)	grad_norm 1.2571 (1.3800)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:45 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][140/156]	eta 0:00:08 lr 0.000114	 wd 0.0500	time 0.6090 (0.5197)	data time 0.0008 (0.0367)	model time 0.6082 (0.4869)	loss 0.6365 (0.6257)	grad_norm 1.1861 (1.3612)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:50 vssm1_tiny_0230s](training.py 201): INFO Train: [72/300][150/156]	eta 0:00:03 lr 0.000114	 wd 0.0500	time 0.5005 (0.5175)	data time 0.0005 (0.0344)	model time 0.5000 (0.4866)	loss 0.5538 (0.6252)	grad_norm 1.7175 (1.3606)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 12:47:53 vssm1_tiny_0230s](training.py 212): INFO EPOCH 72 training takes 0:01:21
[2024-11-09 12:47:53 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_72.pth saving......
[2024-11-09 12:47:54 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_72.pth saved !!!
[2024-11-09 12:47:57 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.667 (2.667)	Loss 0.3528 (0.3528)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:47:59 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.153 (0.498)	Loss 0.3503 (0.3659)	Acc@1 87.500 (87.358)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:48:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.257 (0.351)	Loss 0.3416 (0.3788)	Acc@1 89.062 (85.826)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:48:03 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.211 (0.298)	Loss 0.4036 (0.3841)	Acc@1 81.250 (84.929)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:48:05 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 84.620 Acc@5 100.000
[2024-11-09 12:48:05 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 84.6%
[2024-11-09 12:48:05 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 84.88%
[2024-11-09 12:48:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.734 (2.734)	Loss 0.3992 (0.3992)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:48:11 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.536)	Loss 0.4065 (0.4031)	Acc@1 98.438 (98.935)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:48:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.393)	Loss 0.8511 (0.4368)	Acc@1 21.875 (93.192)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:48:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.330)	Loss 0.9038 (0.5783)	Acc@1 18.750 (69.909)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:48:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 59.340 Acc@5 100.000
[2024-11-09 12:48:18 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 59.3%
[2024-11-09 12:48:18 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 59.34%
[2024-11-09 12:48:23 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][0/156]	eta 0:11:20 lr 0.000114	 wd 0.0500	time 4.3605 (4.3605)	data time 3.8083 (3.8083)	model time 0.0000 (0.0000)	loss 0.6494 (0.6494)	grad_norm 1.5076 (1.5076)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:48:28 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][10/156]	eta 0:02:08 lr 0.000114	 wd 0.0500	time 0.6168 (0.8820)	data time 0.0061 (0.3568)	model time 0.0000 (0.0000)	loss 0.6148 (0.6211)	grad_norm 1.6865 (1.2962)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:48:33 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][20/156]	eta 0:01:37 lr 0.000114	 wd 0.0500	time 0.5458 (0.7149)	data time 0.0059 (0.1914)	model time 0.0000 (0.0000)	loss 0.6404 (0.6226)	grad_norm 0.6349 (1.2657)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:48:38 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][30/156]	eta 0:01:22 lr 0.000114	 wd 0.0500	time 0.5066 (0.6512)	data time 0.0114 (0.1322)	model time 0.0000 (0.0000)	loss 0.6904 (0.6306)	grad_norm 1.4721 (1.2966)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:48:44 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][40/156]	eta 0:01:11 lr 0.000114	 wd 0.0500	time 0.5287 (0.6183)	data time 0.0009 (0.1027)	model time 0.0000 (0.0000)	loss 0.6037 (0.6282)	grad_norm 2.3963 (1.3482)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:48:49 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][50/156]	eta 0:01:04 lr 0.000114	 wd 0.0500	time 0.4766 (0.6108)	data time 0.0033 (0.0844)	model time 0.0000 (0.0000)	loss 0.6310 (0.6295)	grad_norm 1.2707 (1.3604)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:48:54 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][60/156]	eta 0:00:56 lr 0.000114	 wd 0.0500	time 0.5127 (0.5896)	data time 0.0416 (0.0729)	model time 0.4711 (0.4667)	loss 0.6648 (0.6285)	grad_norm 1.3633 (1.3795)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:48:59 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][70/156]	eta 0:00:49 lr 0.000114	 wd 0.0500	time 0.4440 (0.5755)	data time 0.0006 (0.0647)	model time 0.4434 (0.4709)	loss 0.6313 (0.6286)	grad_norm 1.6157 (1.4228)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:49:04 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][80/156]	eta 0:00:43 lr 0.000114	 wd 0.0500	time 0.4772 (0.5680)	data time 0.0007 (0.0600)	model time 0.4765 (0.4765)	loss 0.5793 (0.6297)	grad_norm 0.9527 (1.3820)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:49:09 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][90/156]	eta 0:00:37 lr 0.000114	 wd 0.0500	time 0.4950 (0.5620)	data time 0.0173 (0.0558)	model time 0.4776 (0.4804)	loss 0.6067 (0.6299)	grad_norm 1.8182 (1.3735)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:49:14 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][100/156]	eta 0:00:31 lr 0.000114	 wd 0.0500	time 0.5197 (0.5545)	data time 0.0241 (0.0520)	model time 0.4956 (0.4782)	loss 0.6610 (0.6310)	grad_norm 1.7543 (1.3494)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:49:19 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][110/156]	eta 0:00:25 lr 0.000114	 wd 0.0500	time 0.4399 (0.5475)	data time 0.0017 (0.0489)	model time 0.4381 (0.4749)	loss 0.6403 (0.6320)	grad_norm 1.4355 (1.3252)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:49:24 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][120/156]	eta 0:00:19 lr 0.000114	 wd 0.0500	time 0.6199 (0.5428)	data time 0.0007 (0.0462)	model time 0.6192 (0.4748)	loss 0.6137 (0.6322)	grad_norm 0.9777 (1.3043)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:49:29 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][130/156]	eta 0:00:13 lr 0.000114	 wd 0.0500	time 0.4500 (0.5377)	data time 0.0035 (0.0437)	model time 0.4465 (0.4733)	loss 0.6511 (0.6320)	grad_norm 0.8258 (1.2873)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:49:34 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][140/156]	eta 0:00:08 lr 0.000114	 wd 0.0500	time 0.4605 (0.5336)	data time 0.0009 (0.0417)	model time 0.4596 (0.4724)	loss 0.5384 (0.6309)	grad_norm 1.4533 (1.2992)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:49:39 vssm1_tiny_0230s](training.py 201): INFO Train: [73/300][150/156]	eta 0:00:03 lr 0.000114	 wd 0.0500	time 0.4485 (0.5322)	data time 0.0007 (0.0390)	model time 0.4478 (0.4762)	loss 0.6137 (0.6296)	grad_norm 1.1083 (1.3080)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:49:42 vssm1_tiny_0230s](training.py 212): INFO EPOCH 73 training takes 0:01:23
[2024-11-09 12:49:42 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_73.pth saving......
[2024-11-09 12:49:42 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_73.pth saved !!!
[2024-11-09 12:49:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.917 (1.917)	Loss 0.2986 (0.2986)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:49:47 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 1.031 (0.515)	Loss 0.2981 (0.3078)	Acc@1 92.969 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:49:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.269 (0.369)	Loss 0.3879 (0.3291)	Acc@1 83.594 (89.286)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:49:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.544 (0.353)	Loss 0.4688 (0.3629)	Acc@1 79.688 (86.341)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:49:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 85.000 Acc@5 100.000
[2024-11-09 12:49:55 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 85.0%
[2024-11-09 12:49:55 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 85.00%
[2024-11-09 12:49:59 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.613 (3.613)	Loss 0.3960 (0.3960)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:50:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.554)	Loss 0.4033 (0.4000)	Acc@1 98.438 (98.864)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:50:03 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.398)	Loss 0.8511 (0.4339)	Acc@1 21.875 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:50:06 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.143 (0.342)	Loss 0.9048 (0.5766)	Acc@1 18.750 (70.035)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:50:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 59.560 Acc@5 100.000
[2024-11-09 12:50:08 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 59.6%
[2024-11-09 12:50:08 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 59.56%
[2024-11-09 12:50:12 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][0/156]	eta 0:08:53 lr 0.000114	 wd 0.0500	time 3.4171 (3.4171)	data time 2.8612 (2.8612)	model time 0.0000 (0.0000)	loss 0.6635 (0.6635)	grad_norm 1.3892 (1.3892)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:50:17 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][10/156]	eta 0:01:53 lr 0.000114	 wd 0.0500	time 0.4661 (0.7796)	data time 0.0221 (0.3070)	model time 0.0000 (0.0000)	loss 0.5947 (0.6425)	grad_norm 0.7588 (1.2179)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:50:22 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][20/156]	eta 0:01:29 lr 0.000114	 wd 0.0500	time 0.5901 (0.6564)	data time 0.0396 (0.1670)	model time 0.0000 (0.0000)	loss 0.6246 (0.6219)	grad_norm 1.9127 (1.3479)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:50:27 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][30/156]	eta 0:01:16 lr 0.000114	 wd 0.0500	time 0.5121 (0.6110)	data time 0.0735 (0.1206)	model time 0.0000 (0.0000)	loss 0.6315 (0.6190)	grad_norm 1.6444 (1.3860)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:50:32 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][40/156]	eta 0:01:07 lr 0.000114	 wd 0.0500	time 0.5180 (0.5861)	data time 0.0257 (0.0959)	model time 0.0000 (0.0000)	loss 0.6169 (0.6155)	grad_norm 1.5426 (1.4810)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:50:37 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][50/156]	eta 0:01:00 lr 0.000114	 wd 0.0500	time 0.5209 (0.5703)	data time 0.0614 (0.0811)	model time 0.0000 (0.0000)	loss 0.5662 (0.6169)	grad_norm 1.3507 (1.4940)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:50:43 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][60/156]	eta 0:00:54 lr 0.000114	 wd 0.0500	time 0.4827 (0.5648)	data time 0.0082 (0.0722)	model time 0.4745 (0.5097)	loss 0.5895 (0.6175)	grad_norm 1.0856 (1.5090)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:50:48 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][70/156]	eta 0:00:48 lr 0.000114	 wd 0.0500	time 0.7556 (0.5641)	data time 0.0196 (0.0633)	model time 0.7360 (0.5303)	loss 0.6052 (0.6181)	grad_norm 1.4479 (1.4940)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:50:53 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][80/156]	eta 0:00:42 lr 0.000114	 wd 0.0500	time 0.4814 (0.5538)	data time 0.0064 (0.0579)	model time 0.4750 (0.5075)	loss 0.6757 (0.6169)	grad_norm 1.3044 (1.4917)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:50:58 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][90/156]	eta 0:00:35 lr 0.000114	 wd 0.0500	time 0.5222 (0.5452)	data time 0.0089 (0.0522)	model time 0.5132 (0.4977)	loss 0.6231 (0.6150)	grad_norm 1.1570 (1.4705)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:51:03 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][100/156]	eta 0:00:30 lr 0.000114	 wd 0.0500	time 0.4617 (0.5409)	data time 0.0024 (0.0479)	model time 0.4593 (0.4970)	loss 0.5853 (0.6164)	grad_norm 2.3836 (1.4739)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:51:08 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][110/156]	eta 0:00:24 lr 0.000114	 wd 0.0500	time 0.6283 (0.5408)	data time 0.0022 (0.0457)	model time 0.6261 (0.5001)	loss 0.6604 (0.6176)	grad_norm 1.4641 (1.4853)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:51:14 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][120/156]	eta 0:00:19 lr 0.000114	 wd 0.0500	time 0.4414 (0.5399)	data time 0.0107 (0.0442)	model time 0.4307 (0.5003)	loss 0.6313 (0.6205)	grad_norm 0.8587 (1.4960)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:51:19 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][130/156]	eta 0:00:14 lr 0.000114	 wd 0.0500	time 0.5843 (0.5400)	data time 0.0006 (0.0437)	model time 0.5837 (0.5008)	loss 0.6523 (0.6195)	grad_norm 1.6854 (1.4896)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:51:24 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][140/156]	eta 0:00:08 lr 0.000114	 wd 0.0500	time 0.4439 (0.5358)	data time 0.0010 (0.0418)	model time 0.4429 (0.4966)	loss 0.6090 (0.6203)	grad_norm 1.5967 (1.4803)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:51:29 vssm1_tiny_0230s](training.py 201): INFO Train: [74/300][150/156]	eta 0:00:03 lr 0.000114	 wd 0.0500	time 0.4226 (0.5322)	data time 0.0004 (0.0391)	model time 0.4222 (0.4951)	loss 0.6185 (0.6202)	grad_norm 0.9941 (1.4547)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:51:31 vssm1_tiny_0230s](training.py 212): INFO EPOCH 74 training takes 0:01:23
[2024-11-09 12:51:31 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_74.pth saving......
[2024-11-09 12:51:32 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_74.pth saved !!!
[2024-11-09 12:51:37 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.300 (4.300)	Loss 0.3145 (0.3145)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:51:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.148 (0.615)	Loss 0.3208 (0.3224)	Acc@1 92.969 (90.980)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:51:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.482)	Loss 0.3464 (0.3389)	Acc@1 85.938 (89.472)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:51:45 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.143 (0.394)	Loss 0.4192 (0.3594)	Acc@1 81.250 (87.374)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:51:47 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 86.360 Acc@5 100.000
[2024-11-09 12:51:47 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 86.4%
[2024-11-09 12:51:47 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 86.36%
[2024-11-09 12:51:51 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.395 (3.395)	Loss 0.3926 (0.3926)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:51:54 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.645 (0.568)	Loss 0.3999 (0.3966)	Acc@1 98.438 (98.864)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:51:56 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.403)	Loss 0.8521 (0.4309)	Acc@1 21.875 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:51:59 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.377)	Loss 0.9067 (0.5750)	Acc@1 18.750 (70.086)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:52:01 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 59.660 Acc@5 100.000
[2024-11-09 12:52:01 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 59.7%
[2024-11-09 12:52:01 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 59.66%
[2024-11-09 12:52:06 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][0/156]	eta 0:12:19 lr 0.000114	 wd 0.0500	time 4.7403 (4.7403)	data time 4.2457 (4.2457)	model time 0.0000 (0.0000)	loss 0.6694 (0.6694)	grad_norm 1.2992 (1.2992)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:52:11 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][10/156]	eta 0:02:12 lr 0.000114	 wd 0.0500	time 0.6244 (0.9084)	data time 0.0032 (0.3995)	model time 0.0000 (0.0000)	loss 0.6879 (0.6371)	grad_norm 1.5992 (1.2396)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:52:16 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][20/156]	eta 0:01:32 lr 0.000114	 wd 0.0500	time 0.4516 (0.6815)	data time 0.0199 (0.2157)	model time 0.0000 (0.0000)	loss 0.6139 (0.6170)	grad_norm 0.9496 (1.2842)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:52:20 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][30/156]	eta 0:01:17 lr 0.000114	 wd 0.0500	time 0.4771 (0.6129)	data time 0.0007 (0.1469)	model time 0.0000 (0.0000)	loss 0.6682 (0.6182)	grad_norm 3.1385 (1.4508)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:52:26 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][40/156]	eta 0:01:08 lr 0.000113	 wd 0.0500	time 0.7473 (0.5921)	data time 0.0089 (0.1128)	model time 0.0000 (0.0000)	loss 0.6271 (0.6167)	grad_norm 0.9754 (1.4214)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:52:31 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][50/156]	eta 0:01:02 lr 0.000113	 wd 0.0500	time 0.5029 (0.5850)	data time 0.0211 (0.0944)	model time 0.0000 (0.0000)	loss 0.6252 (0.6157)	grad_norm 1.2788 (1.4051)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:52:36 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][60/156]	eta 0:00:55 lr 0.000113	 wd 0.0500	time 0.4760 (0.5761)	data time 0.0362 (0.0815)	model time 0.4398 (0.5151)	loss 0.6673 (0.6176)	grad_norm 1.1814 (1.4049)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:52:41 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][70/156]	eta 0:00:48 lr 0.000113	 wd 0.0500	time 0.4577 (0.5657)	data time 0.0023 (0.0722)	model time 0.4554 (0.5008)	loss 0.5874 (0.6166)	grad_norm 1.5985 (1.3756)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:52:47 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][80/156]	eta 0:00:42 lr 0.000113	 wd 0.0500	time 0.4933 (0.5626)	data time 0.0006 (0.0657)	model time 0.4926 (0.5075)	loss 0.6322 (0.6185)	grad_norm 1.4607 (1.4286)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:52:52 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][90/156]	eta 0:00:36 lr 0.000113	 wd 0.0500	time 0.5400 (0.5578)	data time 0.0303 (0.0615)	model time 0.5097 (0.5036)	loss 0.6241 (0.6180)	grad_norm 2.3392 (1.4592)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:52:57 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][100/156]	eta 0:00:31 lr 0.000113	 wd 0.0500	time 0.4457 (0.5556)	data time 0.0145 (0.0570)	model time 0.4312 (0.5068)	loss 0.6301 (0.6169)	grad_norm 1.0904 (1.4567)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:53:03 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][110/156]	eta 0:00:25 lr 0.000113	 wd 0.0500	time 0.4346 (0.5514)	data time 0.0246 (0.0527)	model time 0.4100 (0.5054)	loss 0.6417 (0.6180)	grad_norm 1.6447 (1.4370)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:53:08 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][120/156]	eta 0:00:19 lr 0.000113	 wd 0.0500	time 0.5179 (0.5500)	data time 0.0233 (0.0497)	model time 0.4946 (0.5073)	loss 0.6316 (0.6182)	grad_norm 0.9996 (1.4348)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:53:13 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][130/156]	eta 0:00:14 lr 0.000113	 wd 0.0500	time 0.5499 (0.5490)	data time 0.0741 (0.0479)	model time 0.4758 (0.5079)	loss 0.6134 (0.6167)	grad_norm 1.1632 (1.4313)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:53:19 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][140/156]	eta 0:00:08 lr 0.000113	 wd 0.0500	time 0.5569 (0.5492)	data time 0.0008 (0.0455)	model time 0.5561 (0.5112)	loss 0.6345 (0.6165)	grad_norm 1.5944 (1.4383)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:53:24 vssm1_tiny_0230s](training.py 201): INFO Train: [75/300][150/156]	eta 0:00:03 lr 0.000113	 wd 0.0500	time 0.5685 (0.5455)	data time 0.0005 (0.0425)	model time 0.5679 (0.5093)	loss 0.6435 (0.6168)	grad_norm 1.7618 (1.4401)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:53:27 vssm1_tiny_0230s](training.py 212): INFO EPOCH 75 training takes 0:01:25
[2024-11-09 12:53:27 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_75.pth saving......
[2024-11-09 12:53:27 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_75.pth saved !!!
[2024-11-09 12:53:32 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.782 (4.782)	Loss 0.3232 (0.3232)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:53:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.163 (0.620)	Loss 0.3279 (0.3310)	Acc@1 89.844 (89.276)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:53:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.251 (0.417)	Loss 0.3411 (0.3522)	Acc@1 90.625 (87.500)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:53:38 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.241 (0.370)	Loss 0.4243 (0.3680)	Acc@1 81.250 (86.114)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:53:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 85.560 Acc@5 100.000
[2024-11-09 12:53:42 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 85.6%
[2024-11-09 12:53:42 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 86.36%
[2024-11-09 12:53:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.885 (2.885)	Loss 0.3894 (0.3894)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:53:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.986 (0.573)	Loss 0.3965 (0.3933)	Acc@1 98.438 (98.864)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:53:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.399)	Loss 0.8525 (0.4279)	Acc@1 22.656 (93.192)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:53:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.182 (0.371)	Loss 0.9082 (0.5733)	Acc@1 18.750 (70.186)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:53:56 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 59.800 Acc@5 100.000
[2024-11-09 12:53:56 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 59.8%
[2024-11-09 12:53:56 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 59.80%
[2024-11-09 12:54:00 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][0/156]	eta 0:11:54 lr 0.000113	 wd 0.0500	time 4.5826 (4.5826)	data time 4.1732 (4.1732)	model time 0.0000 (0.0000)	loss 0.5416 (0.5416)	grad_norm 1.1450 (1.1450)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:05 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][10/156]	eta 0:02:05 lr 0.000113	 wd 0.0500	time 0.6280 (0.8614)	data time 0.1016 (0.3936)	model time 0.0000 (0.0000)	loss 0.5965 (0.6071)	grad_norm 2.6031 (1.5730)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:10 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][20/156]	eta 0:01:33 lr 0.000113	 wd 0.0500	time 0.5052 (0.6897)	data time 0.0114 (0.2157)	model time 0.0000 (0.0000)	loss 0.6030 (0.6149)	grad_norm 1.2409 (1.6400)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:15 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][30/156]	eta 0:01:19 lr 0.000113	 wd 0.0500	time 0.4889 (0.6336)	data time 0.0214 (0.1517)	model time 0.0000 (0.0000)	loss 0.6108 (0.6117)	grad_norm 1.9242 (1.5666)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:21 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][40/156]	eta 0:01:10 lr 0.000113	 wd 0.0500	time 0.4882 (0.6095)	data time 0.0019 (0.1212)	model time 0.0000 (0.0000)	loss 0.6711 (0.6117)	grad_norm 1.4829 (1.5719)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:26 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][50/156]	eta 0:01:02 lr 0.000113	 wd 0.0500	time 0.4334 (0.5875)	data time 0.0007 (0.1000)	model time 0.0000 (0.0000)	loss 0.5871 (0.6149)	grad_norm 1.1522 (1.5435)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:31 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][60/156]	eta 0:00:55 lr 0.000113	 wd 0.0500	time 0.5625 (0.5753)	data time 0.0148 (0.0875)	model time 0.5477 (0.4887)	loss 0.6258 (0.6144)	grad_norm 1.7114 (1.5055)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:36 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][70/156]	eta 0:00:48 lr 0.000113	 wd 0.0500	time 0.4543 (0.5635)	data time 0.0008 (0.0770)	model time 0.4536 (0.4836)	loss 0.6557 (0.6161)	grad_norm 1.0265 (1.5397)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:41 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][80/156]	eta 0:00:42 lr 0.000113	 wd 0.0500	time 0.5125 (0.5539)	data time 0.0317 (0.0689)	model time 0.4808 (0.4808)	loss 0.5533 (0.6149)	grad_norm 1.9424 (1.5776)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:46 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][90/156]	eta 0:00:36 lr 0.000113	 wd 0.0500	time 0.4555 (0.5562)	data time 0.0058 (0.0632)	model time 0.4497 (0.4999)	loss 0.6699 (0.6163)	grad_norm 3.4564 (1.6461)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:51 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][100/156]	eta 0:00:30 lr 0.000113	 wd 0.0500	time 0.5531 (0.5485)	data time 0.0235 (0.0584)	model time 0.5296 (0.4927)	loss 0.5485 (0.6167)	grad_norm 1.0045 (1.6221)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:54:57 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][110/156]	eta 0:00:25 lr 0.000113	 wd 0.0500	time 0.4953 (0.5480)	data time 0.0192 (0.0552)	model time 0.4761 (0.4973)	loss 0.6381 (0.6183)	grad_norm 1.0123 (1.5953)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:55:01 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][120/156]	eta 0:00:19 lr 0.000113	 wd 0.0500	time 0.5025 (0.5426)	data time 0.0289 (0.0522)	model time 0.4736 (0.4925)	loss 0.6019 (0.6186)	grad_norm 2.3357 (1.5665)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:55:07 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][130/156]	eta 0:00:14 lr 0.000113	 wd 0.0500	time 0.4739 (0.5425)	data time 0.0059 (0.0503)	model time 0.4680 (0.4952)	loss 0.6092 (0.6177)	grad_norm 0.8033 (1.5514)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:55:12 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][140/156]	eta 0:00:08 lr 0.000113	 wd 0.0500	time 0.4338 (0.5405)	data time 0.0007 (0.0482)	model time 0.4331 (0.4949)	loss 0.6498 (0.6170)	grad_norm 1.0798 (1.5461)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:55:17 vssm1_tiny_0230s](training.py 201): INFO Train: [76/300][150/156]	eta 0:00:03 lr 0.000113	 wd 0.0500	time 0.5373 (0.5396)	data time 0.0005 (0.0453)	model time 0.5368 (0.4978)	loss 0.5881 (0.6185)	grad_norm 3.3774 (1.5694)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:55:20 vssm1_tiny_0230s](training.py 212): INFO EPOCH 76 training takes 0:01:24
[2024-11-09 12:55:20 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_76.pth saving......
[2024-11-09 12:55:21 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_76.pth saved !!!
[2024-11-09 12:55:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.449 (3.449)	Loss 0.5938 (0.5938)	Acc@1 65.625 (65.625)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:55:27 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.544)	Loss 0.5649 (0.5965)	Acc@1 68.750 (66.974)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:55:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.401)	Loss 0.2205 (0.5845)	Acc@1 98.438 (68.341)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:55:31 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.336)	Loss 0.2620 (0.4807)	Acc@1 94.531 (77.041)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:55:33 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 80.920 Acc@5 100.000
[2024-11-09 12:55:33 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 80.9%
[2024-11-09 12:55:33 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 86.36%
[2024-11-09 12:55:37 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.139 (4.139)	Loss 0.3862 (0.3862)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:55:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.564)	Loss 0.3933 (0.3902)	Acc@1 98.438 (98.864)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:55:42 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.225 (0.432)	Loss 0.8525 (0.4250)	Acc@1 22.656 (93.155)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:55:44 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.171 (0.362)	Loss 0.9092 (0.5716)	Acc@1 19.531 (70.186)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:55:47 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 59.860 Acc@5 100.000
[2024-11-09 12:55:47 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 59.9%
[2024-11-09 12:55:47 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 59.86%
[2024-11-09 12:55:50 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][0/156]	eta 0:10:00 lr 0.000113	 wd 0.0500	time 3.8494 (3.8494)	data time 3.3164 (3.3164)	model time 0.0000 (0.0000)	loss 0.5944 (0.5944)	grad_norm 1.5785 (1.5785)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:55:56 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][10/156]	eta 0:01:59 lr 0.000113	 wd 0.0500	time 0.4617 (0.8214)	data time 0.0399 (0.3313)	model time 0.0000 (0.0000)	loss 0.6378 (0.6155)	grad_norm 0.9995 (1.3455)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:01 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][20/156]	eta 0:01:33 lr 0.000113	 wd 0.0500	time 0.5216 (0.6851)	data time 0.0049 (0.1795)	model time 0.0000 (0.0000)	loss 0.6457 (0.6228)	grad_norm 1.4371 (1.3424)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:06 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][30/156]	eta 0:01:17 lr 0.000113	 wd 0.0500	time 0.4648 (0.6154)	data time 0.0254 (0.1260)	model time 0.0000 (0.0000)	loss 0.6053 (0.6278)	grad_norm 1.3552 (1.3470)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:11 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][40/156]	eta 0:01:08 lr 0.000113	 wd 0.0500	time 0.4909 (0.5885)	data time 0.0305 (0.0987)	model time 0.0000 (0.0000)	loss 0.6285 (0.6260)	grad_norm 1.5370 (1.2942)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:15 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][50/156]	eta 0:00:59 lr 0.000113	 wd 0.0500	time 0.4102 (0.5658)	data time 0.0023 (0.0833)	model time 0.0000 (0.0000)	loss 0.6205 (0.6245)	grad_norm 1.7852 (1.3086)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:20 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][60/156]	eta 0:00:52 lr 0.000113	 wd 0.0500	time 0.5288 (0.5508)	data time 0.0124 (0.0716)	model time 0.5164 (0.4627)	loss 0.6382 (0.6244)	grad_norm 1.2376 (1.3180)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:25 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][70/156]	eta 0:00:46 lr 0.000113	 wd 0.0500	time 0.4519 (0.5415)	data time 0.0316 (0.0635)	model time 0.4203 (0.4667)	loss 0.6264 (0.6200)	grad_norm 1.5378 (1.3442)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:30 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][80/156]	eta 0:00:40 lr 0.000113	 wd 0.0500	time 0.5028 (0.5350)	data time 0.0142 (0.0578)	model time 0.4887 (0.4682)	loss 0.5170 (0.6182)	grad_norm 1.0115 (1.3634)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:35 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][90/156]	eta 0:00:34 lr 0.000113	 wd 0.0500	time 0.5099 (0.5297)	data time 0.0325 (0.0533)	model time 0.4774 (0.4686)	loss 0.5640 (0.6152)	grad_norm 1.6172 (1.3848)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:40 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][100/156]	eta 0:00:29 lr 0.000113	 wd 0.0500	time 0.4666 (0.5241)	data time 0.0143 (0.0495)	model time 0.4523 (0.4666)	loss 0.5905 (0.6151)	grad_norm 1.8245 (1.4135)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:45 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][110/156]	eta 0:00:24 lr 0.000112	 wd 0.0500	time 0.4833 (0.5237)	data time 0.0142 (0.0471)	model time 0.4691 (0.4715)	loss 0.6523 (0.6147)	grad_norm 1.2210 (1.4401)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:50 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][120/156]	eta 0:00:18 lr 0.000112	 wd 0.0500	time 0.4254 (0.5208)	data time 0.0034 (0.0444)	model time 0.4220 (0.4719)	loss 0.6876 (0.6162)	grad_norm 2.1203 (1.4865)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:56:55 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][130/156]	eta 0:00:13 lr 0.000112	 wd 0.0500	time 0.4752 (0.5201)	data time 0.0200 (0.0422)	model time 0.4552 (0.4750)	loss 0.6255 (0.6167)	grad_norm 1.1544 (1.4950)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:57:00 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][140/156]	eta 0:00:08 lr 0.000112	 wd 0.0500	time 0.5043 (0.5190)	data time 0.0010 (0.0400)	model time 0.5033 (0.4771)	loss 0.6261 (0.6159)	grad_norm 1.6946 (1.4892)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:57:04 vssm1_tiny_0230s](training.py 201): INFO Train: [77/300][150/156]	eta 0:00:03 lr 0.000112	 wd 0.0500	time 0.4136 (0.5152)	data time 0.0007 (0.0376)	model time 0.4130 (0.4751)	loss 0.6518 (0.6157)	grad_norm 1.5349 (1.4858)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:57:07 vssm1_tiny_0230s](training.py 212): INFO EPOCH 77 training takes 0:01:20
[2024-11-09 12:57:07 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_77.pth saving......
[2024-11-09 12:57:08 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_77.pth saved !!!
[2024-11-09 12:57:12 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.165 (4.165)	Loss 0.3018 (0.3018)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:57:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.576)	Loss 0.3125 (0.3139)	Acc@1 91.406 (90.696)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:57:16 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.480 (0.409)	Loss 0.3191 (0.3285)	Acc@1 87.500 (89.286)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:57:19 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.347)	Loss 0.3894 (0.3435)	Acc@1 81.250 (87.576)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:57:21 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 86.620 Acc@5 100.000
[2024-11-09 12:57:21 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 86.6%
[2024-11-09 12:57:21 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 86.62%
[2024-11-09 12:57:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.882 (2.882)	Loss 0.3831 (0.3831)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:57:27 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.519)	Loss 0.3904 (0.3871)	Acc@1 98.438 (98.935)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:57:30 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.169 (0.415)	Loss 0.8525 (0.4222)	Acc@1 23.438 (93.266)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:57:32 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.150 (0.365)	Loss 0.9106 (0.5698)	Acc@1 20.312 (70.363)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:57:36 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 60.060 Acc@5 100.000
[2024-11-09 12:57:36 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 60.1%
[2024-11-09 12:57:36 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 60.06%
[2024-11-09 12:57:41 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][0/156]	eta 0:14:03 lr 0.000112	 wd 0.0500	time 5.4074 (5.4074)	data time 4.8876 (4.8876)	model time 0.0000 (0.0000)	loss 0.6751 (0.6751)	grad_norm 0.8907 (0.8907)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:57:46 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][10/156]	eta 0:02:15 lr 0.000112	 wd 0.0500	time 0.6209 (0.9280)	data time 0.0594 (0.4571)	model time 0.0000 (0.0000)	loss 0.6645 (0.6112)	grad_norm 1.6234 (1.2465)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:57:51 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][20/156]	eta 0:01:41 lr 0.000112	 wd 0.0500	time 0.4526 (0.7440)	data time 0.0297 (0.2503)	model time 0.0000 (0.0000)	loss 0.5289 (0.6077)	grad_norm 1.2844 (1.4736)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:57:56 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][30/156]	eta 0:01:22 lr 0.000112	 wd 0.0500	time 0.4181 (0.6513)	data time 0.0126 (0.1715)	model time 0.0000 (0.0000)	loss 0.5299 (0.6051)	grad_norm 1.4761 (1.6081)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:00 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][40/156]	eta 0:01:09 lr 0.000112	 wd 0.0500	time 0.4614 (0.6016)	data time 0.0011 (0.1314)	model time 0.0000 (0.0000)	loss 0.5789 (0.6034)	grad_norm 2.9085 (1.6657)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:05 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][50/156]	eta 0:01:01 lr 0.000112	 wd 0.0500	time 0.4587 (0.5831)	data time 0.0271 (0.1095)	model time 0.0000 (0.0000)	loss 0.6252 (0.6065)	grad_norm 2.0326 (1.6991)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:10 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][60/156]	eta 0:00:54 lr 0.000112	 wd 0.0500	time 0.5059 (0.5659)	data time 0.0118 (0.0922)	model time 0.4941 (0.4744)	loss 0.6738 (0.6087)	grad_norm 1.3876 (1.6907)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:16 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][70/156]	eta 0:00:48 lr 0.000112	 wd 0.0500	time 0.6448 (0.5629)	data time 0.0606 (0.0807)	model time 0.5842 (0.5042)	loss 0.5381 (0.6108)	grad_norm 1.2992 (1.6501)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:21 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][80/156]	eta 0:00:42 lr 0.000112	 wd 0.0500	time 0.5000 (0.5571)	data time 0.0130 (0.0726)	model time 0.4869 (0.5032)	loss 0.6614 (0.6124)	grad_norm 1.0682 (1.6478)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:26 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][90/156]	eta 0:00:36 lr 0.000112	 wd 0.0500	time 0.4113 (0.5495)	data time 0.0009 (0.0653)	model time 0.4104 (0.4977)	loss 0.5498 (0.6124)	grad_norm 1.1437 (1.6219)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:31 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][100/156]	eta 0:00:30 lr 0.000112	 wd 0.0500	time 0.5842 (0.5453)	data time 0.0294 (0.0603)	model time 0.5548 (0.4968)	loss 0.5711 (0.6127)	grad_norm 1.2446 (1.6136)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:36 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][110/156]	eta 0:00:24 lr 0.000112	 wd 0.0500	time 0.5142 (0.5414)	data time 0.0183 (0.0571)	model time 0.4958 (0.4933)	loss 0.6064 (0.6124)	grad_norm 1.0844 (1.6505)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:41 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][120/156]	eta 0:00:19 lr 0.000112	 wd 0.0500	time 0.5469 (0.5374)	data time 0.0008 (0.0534)	model time 0.5461 (0.4915)	loss 0.6154 (0.6130)	grad_norm 0.8465 (1.6134)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:45 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][130/156]	eta 0:00:13 lr 0.000112	 wd 0.0500	time 0.4326 (0.5338)	data time 0.0007 (0.0505)	model time 0.4319 (0.4896)	loss 0.6319 (0.6134)	grad_norm 1.4315 (1.5870)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:51 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][140/156]	eta 0:00:08 lr 0.000112	 wd 0.0500	time 0.4474 (0.5322)	data time 0.0007 (0.0485)	model time 0.4467 (0.4894)	loss 0.5910 (0.6136)	grad_norm 1.7340 (1.5800)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:55 vssm1_tiny_0230s](training.py 201): INFO Train: [78/300][150/156]	eta 0:00:03 lr 0.000112	 wd 0.0500	time 0.4852 (0.5283)	data time 0.0720 (0.0460)	model time 0.4131 (0.4868)	loss 0.6074 (0.6139)	grad_norm 1.1741 (1.5839)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:58:58 vssm1_tiny_0230s](training.py 212): INFO EPOCH 78 training takes 0:01:22
[2024-11-09 12:58:58 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_78.pth saving......
[2024-11-09 12:58:59 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_78.pth saved !!!
[2024-11-09 12:59:01 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.216 (2.216)	Loss 0.3274 (0.3274)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:59:04 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.140 (0.458)	Loss 0.3301 (0.3392)	Acc@1 91.406 (88.920)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:59:08 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.144 (0.411)	Loss 0.3340 (0.3520)	Acc@1 92.188 (88.058)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:59:11 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.367)	Loss 0.3965 (0.3617)	Acc@1 82.031 (87.097)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:59:14 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 86.800 Acc@5 100.000
[2024-11-09 12:59:14 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 86.8%
[2024-11-09 12:59:14 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 86.80%
[2024-11-09 12:59:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.687 (2.687)	Loss 0.3796 (0.3796)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:59:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.491 (0.528)	Loss 0.3870 (0.3837)	Acc@1 98.438 (98.935)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:59:23 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.408)	Loss 0.8530 (0.4192)	Acc@1 24.219 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:59:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.164 (0.358)	Loss 0.9121 (0.5681)	Acc@1 21.094 (70.464)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 12:59:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 60.300 Acc@5 100.000
[2024-11-09 12:59:27 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 60.3%
[2024-11-09 12:59:27 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 60.30%
[2024-11-09 12:59:30 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][0/156]	eta 0:08:32 lr 0.000112	 wd 0.0500	time 3.2878 (3.2878)	data time 2.8609 (2.8609)	model time 0.0000 (0.0000)	loss 0.6204 (0.6204)	grad_norm 1.0168 (1.0168)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:59:36 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][10/156]	eta 0:01:55 lr 0.000112	 wd 0.0500	time 0.5030 (0.7910)	data time 0.0227 (0.3050)	model time 0.0000 (0.0000)	loss 0.6346 (0.6090)	grad_norm 1.0937 (1.5801)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:59:41 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][20/156]	eta 0:01:29 lr 0.000112	 wd 0.0500	time 0.6407 (0.6586)	data time 0.0229 (0.1652)	model time 0.0000 (0.0000)	loss 0.5614 (0.6210)	grad_norm 1.2693 (1.3995)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:59:46 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][30/156]	eta 0:01:18 lr 0.000112	 wd 0.0500	time 0.6565 (0.6230)	data time 0.0163 (0.1165)	model time 0.0000 (0.0000)	loss 0.6070 (0.6110)	grad_norm 1.4375 (1.3812)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:59:52 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][40/156]	eta 0:01:09 lr 0.000112	 wd 0.0500	time 0.6632 (0.6013)	data time 0.0207 (0.0951)	model time 0.0000 (0.0000)	loss 0.5728 (0.6075)	grad_norm 2.1166 (1.4669)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 12:59:57 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][50/156]	eta 0:01:01 lr 0.000112	 wd 0.0500	time 0.4816 (0.5848)	data time 0.0303 (0.0818)	model time 0.0000 (0.0000)	loss 0.5963 (0.6063)	grad_norm 1.8342 (1.5943)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:02 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][60/156]	eta 0:00:55 lr 0.000112	 wd 0.0500	time 0.5092 (0.5737)	data time 0.0185 (0.0708)	model time 0.4907 (0.5017)	loss 0.6166 (0.6101)	grad_norm 2.0413 (1.6073)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:07 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][70/156]	eta 0:00:49 lr 0.000112	 wd 0.0500	time 0.4868 (0.5706)	data time 0.0057 (0.0641)	model time 0.4811 (0.5155)	loss 0.6198 (0.6118)	grad_norm 1.0182 (1.5898)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:12 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][80/156]	eta 0:00:42 lr 0.000112	 wd 0.0500	time 0.4512 (0.5597)	data time 0.0409 (0.0588)	model time 0.4103 (0.4974)	loss 0.6365 (0.6110)	grad_norm 0.8054 (1.5838)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:17 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][90/156]	eta 0:00:36 lr 0.000112	 wd 0.0500	time 0.5365 (0.5522)	data time 0.0022 (0.0549)	model time 0.5343 (0.4898)	loss 0.5705 (0.6117)	grad_norm 1.1627 (1.5664)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:22 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][100/156]	eta 0:00:30 lr 0.000112	 wd 0.0500	time 0.5012 (0.5442)	data time 0.0306 (0.0508)	model time 0.4705 (0.4836)	loss 0.6338 (0.6112)	grad_norm 2.3788 (1.5886)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:27 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][110/156]	eta 0:00:25 lr 0.000112	 wd 0.0500	time 0.5666 (0.5435)	data time 0.0461 (0.0483)	model time 0.5205 (0.4885)	loss 0.5095 (0.6098)	grad_norm 1.2689 (1.6112)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:33 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][120/156]	eta 0:00:19 lr 0.000112	 wd 0.0500	time 0.5079 (0.5435)	data time 0.0019 (0.0464)	model time 0.5060 (0.4927)	loss 0.5579 (0.6082)	grad_norm 1.7520 (1.6065)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:38 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][130/156]	eta 0:00:14 lr 0.000112	 wd 0.0500	time 0.4240 (0.5425)	data time 0.0150 (0.0444)	model time 0.4090 (0.4950)	loss 0.6156 (0.6077)	grad_norm 1.7328 (1.6052)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:43 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][140/156]	eta 0:00:08 lr 0.000112	 wd 0.0500	time 0.4145 (0.5373)	data time 0.0008 (0.0422)	model time 0.4138 (0.4906)	loss 0.6329 (0.6081)	grad_norm 1.9596 (1.5991)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:48 vssm1_tiny_0230s](training.py 201): INFO Train: [79/300][150/156]	eta 0:00:03 lr 0.000112	 wd 0.0500	time 0.4928 (0.5361)	data time 0.0005 (0.0396)	model time 0.4923 (0.4932)	loss 0.5464 (0.6082)	grad_norm 1.8254 (1.5861)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:00:51 vssm1_tiny_0230s](training.py 212): INFO EPOCH 79 training takes 0:01:23
[2024-11-09 13:00:51 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_79.pth saving......
[2024-11-09 13:00:51 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_79.pth saved !!!
[2024-11-09 13:00:54 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.078 (3.078)	Loss 0.3735 (0.3735)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:00:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.155 (0.567)	Loss 0.3892 (0.3892)	Acc@1 84.375 (84.020)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:01:00 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.441)	Loss 0.2448 (0.3962)	Acc@1 96.875 (83.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:01:04 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.294 (0.409)	Loss 0.2937 (0.3612)	Acc@1 88.281 (85.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:01:06 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 86.740 Acc@5 100.000
[2024-11-09 13:01:06 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 86.7%
[2024-11-09 13:01:06 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 86.80%
[2024-11-09 13:01:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.416 (4.416)	Loss 0.3770 (0.3770)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:01:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.703)	Loss 0.3843 (0.3810)	Acc@1 98.438 (98.935)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:01:16 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.186 (0.474)	Loss 0.8525 (0.4166)	Acc@1 25.000 (93.341)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:01:18 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.392)	Loss 0.9126 (0.5664)	Acc@1 21.094 (70.615)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:01:20 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 60.500 Acc@5 100.000
[2024-11-09 13:01:20 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 60.5%
[2024-11-09 13:01:20 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 60.50%
[2024-11-09 13:01:26 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][0/156]	eta 0:14:45 lr 0.000112	 wd 0.0500	time 5.6787 (5.6787)	data time 5.1991 (5.1991)	model time 0.0000 (0.0000)	loss 0.6479 (0.6479)	grad_norm 1.4440 (1.4440)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:01:31 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][10/156]	eta 0:02:22 lr 0.000111	 wd 0.0500	time 0.4581 (0.9781)	data time 0.0010 (0.4867)	model time 0.0000 (0.0000)	loss 0.5401 (0.6087)	grad_norm 1.3715 (1.7171)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:01:36 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][20/156]	eta 0:01:43 lr 0.000111	 wd 0.0500	time 0.4783 (0.7592)	data time 0.0074 (0.2664)	model time 0.0000 (0.0000)	loss 0.6154 (0.6116)	grad_norm 1.3923 (1.7584)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:01:41 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][30/156]	eta 0:01:24 lr 0.000111	 wd 0.0500	time 0.5224 (0.6689)	data time 0.0262 (0.1865)	model time 0.0000 (0.0000)	loss 0.6354 (0.6140)	grad_norm 1.0367 (1.6448)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:01:46 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][40/156]	eta 0:01:13 lr 0.000111	 wd 0.0500	time 0.5097 (0.6317)	data time 0.0197 (0.1454)	model time 0.0000 (0.0000)	loss 0.6534 (0.6161)	grad_norm 1.1526 (1.5537)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:01:51 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][50/156]	eta 0:01:04 lr 0.000111	 wd 0.0500	time 0.5943 (0.6096)	data time 0.0048 (0.1205)	model time 0.0000 (0.0000)	loss 0.5873 (0.6181)	grad_norm 1.3444 (1.4697)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:01:56 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][60/156]	eta 0:00:56 lr 0.000111	 wd 0.0500	time 0.4577 (0.5862)	data time 0.0033 (0.1021)	model time 0.4544 (0.4585)	loss 0.6348 (0.6157)	grad_norm 1.6672 (1.4627)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:02:01 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][70/156]	eta 0:00:49 lr 0.000111	 wd 0.0500	time 0.4521 (0.5727)	data time 0.0005 (0.0898)	model time 0.4516 (0.4671)	loss 0.6466 (0.6195)	grad_norm 1.0971 (1.5000)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:02:05 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][80/156]	eta 0:00:42 lr 0.000111	 wd 0.0500	time 0.4126 (0.5584)	data time 0.0033 (0.0804)	model time 0.4093 (0.4591)	loss 0.5655 (0.6198)	grad_norm 1.1597 (1.5134)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:02:11 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][90/156]	eta 0:00:36 lr 0.000111	 wd 0.0500	time 0.6562 (0.5540)	data time 0.0191 (0.0730)	model time 0.6371 (0.4707)	loss 0.6225 (0.6180)	grad_norm 0.8536 (1.4944)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:02:15 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][100/156]	eta 0:00:30 lr 0.000111	 wd 0.0500	time 0.5775 (0.5465)	data time 0.0473 (0.0685)	model time 0.5302 (0.4668)	loss 0.5876 (0.6196)	grad_norm 2.2868 (1.4902)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:02:21 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][110/156]	eta 0:00:25 lr 0.000111	 wd 0.0500	time 0.5806 (0.5454)	data time 0.0205 (0.0634)	model time 0.5601 (0.4758)	loss 0.6531 (0.6207)	grad_norm 1.8163 (1.5112)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:02:25 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][120/156]	eta 0:00:19 lr 0.000111	 wd 0.0500	time 0.4891 (0.5397)	data time 0.0368 (0.0598)	model time 0.4523 (0.4731)	loss 0.6298 (0.6190)	grad_norm 0.8469 (1.5083)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:02:30 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][130/156]	eta 0:00:13 lr 0.000111	 wd 0.0500	time 0.4145 (0.5364)	data time 0.0034 (0.0573)	model time 0.4111 (0.4728)	loss 0.5830 (0.6177)	grad_norm 0.7914 (1.4968)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:02:35 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][140/156]	eta 0:00:08 lr 0.000111	 wd 0.0500	time 0.4096 (0.5316)	data time 0.0009 (0.0541)	model time 0.4087 (0.4709)	loss 0.5682 (0.6173)	grad_norm 1.1367 (1.5000)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:02:40 vssm1_tiny_0230s](training.py 201): INFO Train: [80/300][150/156]	eta 0:00:03 lr 0.000111	 wd 0.0500	time 0.5512 (0.5313)	data time 0.0005 (0.0506)	model time 0.5507 (0.4763)	loss 0.6205 (0.6168)	grad_norm 1.1903 (1.5067)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:02:44 vssm1_tiny_0230s](training.py 212): INFO EPOCH 80 training takes 0:01:23
[2024-11-09 13:02:44 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_80.pth saving......
[2024-11-09 13:02:44 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_80.pth saved !!!
[2024-11-09 13:02:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.984 (2.984)	Loss 0.3003 (0.3003)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:02:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.229 (0.576)	Loss 0.3193 (0.3143)	Acc@1 90.625 (89.205)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:02:52 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.396)	Loss 0.3167 (0.3284)	Acc@1 90.625 (88.914)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:02:54 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.329 (0.334)	Loss 0.3794 (0.3376)	Acc@1 83.594 (88.155)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:02:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.860 Acc@5 100.000
[2024-11-09 13:02:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 87.9%
[2024-11-09 13:02:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 87.86%
[2024-11-09 13:03:02 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.990 (4.990)	Loss 0.3745 (0.3745)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:03:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.708)	Loss 0.3816 (0.3784)	Acc@1 98.438 (98.935)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:03:07 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.164 (0.481)	Loss 0.8521 (0.4142)	Acc@1 26.562 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:03:10 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.270 (0.403)	Loss 0.9131 (0.5649)	Acc@1 21.875 (70.842)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:03:12 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 60.740 Acc@5 100.000
[2024-11-09 13:03:12 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 60.7%
[2024-11-09 13:03:12 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 60.74%
[2024-11-09 13:03:17 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][0/156]	eta 0:11:00 lr 0.000111	 wd 0.0500	time 4.2368 (4.2368)	data time 3.8312 (3.8312)	model time 0.0000 (0.0000)	loss 0.5526 (0.5526)	grad_norm 2.1840 (2.1840)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:03:22 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][10/156]	eta 0:02:07 lr 0.000111	 wd 0.0500	time 0.4309 (0.8741)	data time 0.0024 (0.3851)	model time 0.0000 (0.0000)	loss 0.5301 (0.6181)	grad_norm 1.9090 (1.5214)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:03:26 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][20/156]	eta 0:01:31 lr 0.000111	 wd 0.0500	time 0.4756 (0.6752)	data time 0.0008 (0.2065)	model time 0.0000 (0.0000)	loss 0.5678 (0.6152)	grad_norm 1.4336 (1.4057)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:03:32 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][30/156]	eta 0:01:19 lr 0.000111	 wd 0.0500	time 0.4989 (0.6312)	data time 0.0177 (0.1451)	model time 0.0000 (0.0000)	loss 0.6415 (0.6174)	grad_norm 1.6833 (1.4478)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:03:37 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][40/156]	eta 0:01:09 lr 0.000111	 wd 0.0500	time 0.4466 (0.5954)	data time 0.0083 (0.1127)	model time 0.0000 (0.0000)	loss 0.5719 (0.6168)	grad_norm 1.9049 (1.4652)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:03:41 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][50/156]	eta 0:01:00 lr 0.000111	 wd 0.0500	time 0.4479 (0.5677)	data time 0.0009 (0.0915)	model time 0.0000 (0.0000)	loss 0.6385 (0.6166)	grad_norm 1.4748 (1.4709)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:03:46 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][60/156]	eta 0:00:53 lr 0.000111	 wd 0.0500	time 0.5305 (0.5584)	data time 0.0834 (0.0793)	model time 0.4471 (0.4936)	loss 0.5970 (0.6160)	grad_norm 1.7173 (1.4320)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:03:52 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][70/156]	eta 0:00:47 lr 0.000111	 wd 0.0500	time 0.4219 (0.5530)	data time 0.0019 (0.0692)	model time 0.4201 (0.5032)	loss 0.5462 (0.6163)	grad_norm 1.6286 (1.4227)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:03:56 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][80/156]	eta 0:00:41 lr 0.000111	 wd 0.0500	time 0.5265 (0.5455)	data time 0.0331 (0.0639)	model time 0.4935 (0.4910)	loss 0.5696 (0.6153)	grad_norm 1.6062 (1.4206)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:04:01 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][90/156]	eta 0:00:35 lr 0.000111	 wd 0.0500	time 0.5474 (0.5389)	data time 0.0238 (0.0587)	model time 0.5236 (0.4854)	loss 0.6846 (0.6169)	grad_norm 2.7213 (1.4574)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:04:06 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][100/156]	eta 0:00:30 lr 0.000111	 wd 0.0500	time 0.4241 (0.5366)	data time 0.0023 (0.0547)	model time 0.4218 (0.4877)	loss 0.5794 (0.6163)	grad_norm 1.7904 (1.4573)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:04:12 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][110/156]	eta 0:00:24 lr 0.000111	 wd 0.0500	time 0.7391 (0.5335)	data time 0.1390 (0.0519)	model time 0.6001 (0.4861)	loss 0.6660 (0.6154)	grad_norm 2.1030 (1.4613)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:04:17 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][120/156]	eta 0:00:19 lr 0.000111	 wd 0.0500	time 0.4137 (0.5333)	data time 0.0041 (0.0512)	model time 0.4096 (0.4864)	loss 0.5954 (0.6144)	grad_norm 2.1620 (1.4798)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:04:22 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][130/156]	eta 0:00:13 lr 0.000111	 wd 0.0500	time 0.6846 (0.5358)	data time 0.1012 (0.0491)	model time 0.5834 (0.4934)	loss 0.6633 (0.6147)	grad_norm 1.2001 (1.4756)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:04:28 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][140/156]	eta 0:00:08 lr 0.000111	 wd 0.0500	time 0.5802 (0.5356)	data time 0.0009 (0.0462)	model time 0.5792 (0.4968)	loss 0.6574 (0.6151)	grad_norm 0.9709 (1.4700)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:04:33 vssm1_tiny_0230s](training.py 201): INFO Train: [81/300][150/156]	eta 0:00:03 lr 0.000111	 wd 0.0500	time 0.4116 (0.5313)	data time 0.0005 (0.0432)	model time 0.4111 (0.4941)	loss 0.5597 (0.6143)	grad_norm 1.3062 (1.4655)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:04:35 vssm1_tiny_0230s](training.py 212): INFO EPOCH 81 training takes 0:01:22
[2024-11-09 13:04:35 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_81.pth saving......
[2024-11-09 13:04:36 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_81.pth saved !!!
[2024-11-09 13:04:39 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.673 (3.673)	Loss 0.3047 (0.3047)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:04:41 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.258 (0.511)	Loss 0.3147 (0.3183)	Acc@1 89.062 (90.199)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:04:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.210 (0.459)	Loss 0.3193 (0.3320)	Acc@1 87.500 (88.504)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:04:48 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.386)	Loss 0.3538 (0.3378)	Acc@1 84.375 (87.853)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:04:50 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.580 Acc@5 100.000
[2024-11-09 13:04:50 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 87.6%
[2024-11-09 13:04:50 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 87.86%
[2024-11-09 13:04:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.981 (2.981)	Loss 0.3721 (0.3721)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:04:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.211 (0.511)	Loss 0.3794 (0.3760)	Acc@1 98.438 (98.935)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:04:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.161 (0.374)	Loss 0.8511 (0.4120)	Acc@1 26.562 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:05:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.167 (0.325)	Loss 0.9131 (0.5632)	Acc@1 21.875 (70.968)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:05:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 61.000 Acc@5 100.000
[2024-11-09 13:05:03 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 61.0%
[2024-11-09 13:05:03 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 61.00%
[2024-11-09 13:05:08 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][0/156]	eta 0:11:07 lr 0.000111	 wd 0.0500	time 4.2767 (4.2767)	data time 3.8517 (3.8517)	model time 0.0000 (0.0000)	loss 0.5568 (0.5568)	grad_norm 1.6412 (1.6412)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:05:13 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][10/156]	eta 0:02:06 lr 0.000111	 wd 0.0500	time 0.5720 (0.8690)	data time 0.0351 (0.3676)	model time 0.0000 (0.0000)	loss 0.5946 (0.5954)	grad_norm 2.1846 (1.4543)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:05:18 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][20/156]	eta 0:01:34 lr 0.000111	 wd 0.0500	time 0.6080 (0.6968)	data time 0.0107 (0.1986)	model time 0.0000 (0.0000)	loss 0.6437 (0.6120)	grad_norm 1.5384 (1.6624)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:05:23 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][30/156]	eta 0:01:20 lr 0.000111	 wd 0.0500	time 0.4565 (0.6354)	data time 0.0179 (0.1392)	model time 0.0000 (0.0000)	loss 0.6350 (0.6102)	grad_norm 1.3216 (1.6134)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:05:28 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][40/156]	eta 0:01:09 lr 0.000111	 wd 0.0500	time 0.4642 (0.6023)	data time 0.0018 (0.1087)	model time 0.0000 (0.0000)	loss 0.6295 (0.6108)	grad_norm 0.9331 (1.5100)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:05:33 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][50/156]	eta 0:01:01 lr 0.000110	 wd 0.0500	time 0.5331 (0.5822)	data time 0.0239 (0.0908)	model time 0.0000 (0.0000)	loss 0.5953 (0.6082)	grad_norm 1.4993 (1.5345)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:05:38 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][60/156]	eta 0:00:54 lr 0.000110	 wd 0.0500	time 0.6034 (0.5628)	data time 0.0006 (0.0780)	model time 0.6028 (0.4510)	loss 0.6249 (0.6135)	grad_norm 1.3135 (1.5614)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:05:43 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][70/156]	eta 0:00:47 lr 0.000110	 wd 0.0500	time 0.5149 (0.5554)	data time 0.0056 (0.0677)	model time 0.5093 (0.4784)	loss 0.5855 (0.6100)	grad_norm 2.2836 (1.5780)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:05:48 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][80/156]	eta 0:00:41 lr 0.000110	 wd 0.0500	time 0.5726 (0.5500)	data time 0.0336 (0.0622)	model time 0.5390 (0.4816)	loss 0.6104 (0.6108)	grad_norm 1.7954 (1.5721)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:05:53 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][90/156]	eta 0:00:36 lr 0.000110	 wd 0.0500	time 0.5417 (0.5482)	data time 0.0671 (0.0572)	model time 0.4746 (0.4905)	loss 0.6557 (0.6124)	grad_norm 1.4632 (1.5748)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:05:58 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][100/156]	eta 0:00:30 lr 0.000110	 wd 0.0500	time 0.6844 (0.5464)	data time 0.0216 (0.0532)	model time 0.6628 (0.4951)	loss 0.6326 (0.6141)	grad_norm 0.9006 (1.5731)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:06:04 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][110/156]	eta 0:00:25 lr 0.000110	 wd 0.0500	time 0.5349 (0.5449)	data time 0.0330 (0.0499)	model time 0.5019 (0.4982)	loss 0.6458 (0.6153)	grad_norm 1.1273 (1.5481)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:06:09 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][120/156]	eta 0:00:19 lr 0.000110	 wd 0.0500	time 0.4344 (0.5433)	data time 0.0231 (0.0470)	model time 0.4113 (0.4999)	loss 0.6673 (0.6155)	grad_norm 1.0958 (1.5419)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:06:14 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][130/156]	eta 0:00:14 lr 0.000110	 wd 0.0500	time 0.4321 (0.5388)	data time 0.0176 (0.0446)	model time 0.4145 (0.4959)	loss 0.6129 (0.6164)	grad_norm 2.1909 (1.5225)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:06:19 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][140/156]	eta 0:00:08 lr 0.000110	 wd 0.0500	time 0.5721 (0.5354)	data time 0.0010 (0.0423)	model time 0.5712 (0.4940)	loss 0.5820 (0.6144)	grad_norm 0.8868 (1.5151)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:06:24 vssm1_tiny_0230s](training.py 201): INFO Train: [82/300][150/156]	eta 0:00:03 lr 0.000110	 wd 0.0500	time 0.5699 (0.5369)	data time 0.0005 (0.0397)	model time 0.5694 (0.5002)	loss 0.6783 (0.6146)	grad_norm 2.8040 (1.5282)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:06:27 vssm1_tiny_0230s](training.py 212): INFO EPOCH 82 training takes 0:01:23
[2024-11-09 13:06:27 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_82.pth saving......
[2024-11-09 13:06:28 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_82.pth saved !!!
[2024-11-09 13:06:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.285 (3.285)	Loss 0.2937 (0.2937)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:06:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.536)	Loss 0.3123 (0.3110)	Acc@1 89.062 (90.909)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:06:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.229 (0.405)	Loss 0.3125 (0.3263)	Acc@1 91.406 (89.658)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:06:39 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.163 (0.373)	Loss 0.3564 (0.3383)	Acc@1 87.500 (88.281)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:06:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.680 Acc@5 100.000
[2024-11-09 13:06:42 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 87.7%
[2024-11-09 13:06:42 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 87.86%
[2024-11-09 13:06:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.872 (2.872)	Loss 0.3699 (0.3699)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:06:47 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.696 (0.518)	Loss 0.3770 (0.3737)	Acc@1 98.438 (98.935)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:06:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.317 (0.397)	Loss 0.8496 (0.4098)	Acc@1 28.125 (93.564)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:06:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.228 (0.358)	Loss 0.9126 (0.5615)	Acc@1 21.875 (71.144)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:06:54 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 61.220 Acc@5 100.000
[2024-11-09 13:06:54 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 61.2%
[2024-11-09 13:06:54 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 61.22%
[2024-11-09 13:06:58 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][0/156]	eta 0:10:03 lr 0.000110	 wd 0.0500	time 3.8665 (3.8665)	data time 3.4567 (3.4567)	model time 0.0000 (0.0000)	loss 0.5478 (0.5478)	grad_norm 1.2598 (1.2598)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:03 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][10/156]	eta 0:01:56 lr 0.000110	 wd 0.0500	time 0.5705 (0.7972)	data time 0.0107 (0.3218)	model time 0.0000 (0.0000)	loss 0.6222 (0.6200)	grad_norm 1.6656 (1.3108)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:09 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][20/156]	eta 0:01:31 lr 0.000110	 wd 0.0500	time 0.6331 (0.6762)	data time 0.0181 (0.1811)	model time 0.0000 (0.0000)	loss 0.6314 (0.6261)	grad_norm 1.3184 (1.3529)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:14 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][30/156]	eta 0:01:18 lr 0.000110	 wd 0.0500	time 0.5446 (0.6230)	data time 0.0005 (0.1268)	model time 0.0000 (0.0000)	loss 0.6252 (0.6195)	grad_norm 1.8604 (1.3883)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:19 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][40/156]	eta 0:01:09 lr 0.000110	 wd 0.0500	time 0.4799 (0.5960)	data time 0.0181 (0.1043)	model time 0.0000 (0.0000)	loss 0.5143 (0.6122)	grad_norm 1.6905 (1.4016)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:24 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][50/156]	eta 0:01:01 lr 0.000110	 wd 0.0500	time 0.4705 (0.5829)	data time 0.0005 (0.0914)	model time 0.0000 (0.0000)	loss 0.6099 (0.6087)	grad_norm 1.6138 (1.5177)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:29 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][60/156]	eta 0:00:54 lr 0.000110	 wd 0.0500	time 0.4857 (0.5665)	data time 0.0029 (0.0778)	model time 0.4828 (0.4749)	loss 0.6419 (0.6101)	grad_norm 0.8313 (1.6407)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:34 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][70/156]	eta 0:00:48 lr 0.000110	 wd 0.0500	time 0.4692 (0.5585)	data time 0.0022 (0.0680)	model time 0.4669 (0.4881)	loss 0.6656 (0.6136)	grad_norm 0.9785 (1.6303)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:39 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][80/156]	eta 0:00:42 lr 0.000110	 wd 0.0500	time 0.4870 (0.5531)	data time 0.0171 (0.0615)	model time 0.4699 (0.4918)	loss 0.6214 (0.6159)	grad_norm 1.5943 (1.6225)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:45 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][90/156]	eta 0:00:36 lr 0.000110	 wd 0.0500	time 0.6586 (0.5519)	data time 0.0201 (0.0569)	model time 0.6385 (0.4995)	loss 0.6848 (0.6169)	grad_norm 4.0751 (1.6590)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:50 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][100/156]	eta 0:00:30 lr 0.000110	 wd 0.0500	time 0.6593 (0.5482)	data time 0.0058 (0.0524)	model time 0.6535 (0.5003)	loss 0.6212 (0.6172)	grad_norm 0.7496 (1.6301)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:07:55 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][110/156]	eta 0:00:25 lr 0.000110	 wd 0.0500	time 0.4092 (0.5474)	data time 0.0012 (0.0486)	model time 0.4080 (0.5050)	loss 0.5606 (0.6163)	grad_norm 1.6327 (1.5996)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:08:00 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][120/156]	eta 0:00:19 lr 0.000110	 wd 0.0500	time 0.5058 (0.5454)	data time 0.0061 (0.0464)	model time 0.4997 (0.5045)	loss 0.6557 (0.6148)	grad_norm 1.4449 (1.5956)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:08:06 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][130/156]	eta 0:00:14 lr 0.000110	 wd 0.0500	time 0.4569 (0.5437)	data time 0.0020 (0.0442)	model time 0.4550 (0.5046)	loss 0.5758 (0.6154)	grad_norm 1.2921 (1.6035)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:08:11 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][140/156]	eta 0:00:08 lr 0.000110	 wd 0.0500	time 0.4377 (0.5418)	data time 0.0009 (0.0419)	model time 0.4368 (0.5046)	loss 0.6138 (0.6158)	grad_norm 0.8115 (1.5901)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:08:16 vssm1_tiny_0230s](training.py 201): INFO Train: [83/300][150/156]	eta 0:00:03 lr 0.000110	 wd 0.0500	time 0.5389 (0.5386)	data time 0.0007 (0.0395)	model time 0.5383 (0.5030)	loss 0.6283 (0.6142)	grad_norm 1.9742 (1.5821)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:08:19 vssm1_tiny_0230s](training.py 212): INFO EPOCH 83 training takes 0:01:24
[2024-11-09 13:08:19 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_83.pth saving......
[2024-11-09 13:08:19 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_83.pth saved !!!
[2024-11-09 13:08:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.967 (3.967)	Loss 0.3005 (0.3005)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:08:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.549)	Loss 0.3096 (0.3106)	Acc@1 88.281 (89.915)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:08:28 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.399)	Loss 0.2983 (0.3263)	Acc@1 89.844 (88.058)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:08:30 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.147 (0.358)	Loss 0.3391 (0.3329)	Acc@1 87.500 (87.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:08:33 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.260 Acc@5 100.000
[2024-11-09 13:08:33 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 87.3%
[2024-11-09 13:08:33 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 87.86%
[2024-11-09 13:08:37 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.005 (4.005)	Loss 0.3679 (0.3679)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:08:40 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.150 (0.612)	Loss 0.3752 (0.3718)	Acc@1 98.438 (98.935)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:08:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.255 (0.478)	Loss 0.8481 (0.4080)	Acc@1 28.125 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:08:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.176 (0.403)	Loss 0.9121 (0.5600)	Acc@1 21.875 (71.169)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:08:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 61.280 Acc@5 100.000
[2024-11-09 13:08:48 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 61.3%
[2024-11-09 13:08:48 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 61.28%
[2024-11-09 13:08:53 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][0/156]	eta 0:12:38 lr 0.000110	 wd 0.0500	time 4.8620 (4.8620)	data time 4.4562 (4.4562)	model time 0.0000 (0.0000)	loss 0.6598 (0.6598)	grad_norm 1.1321 (1.1321)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:08:58 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][10/156]	eta 0:02:13 lr 0.000110	 wd 0.0500	time 0.4373 (0.9112)	data time 0.0326 (0.4218)	model time 0.0000 (0.0000)	loss 0.6349 (0.6048)	grad_norm 2.3288 (1.7581)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:03 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][20/156]	eta 0:01:36 lr 0.000110	 wd 0.0500	time 0.4760 (0.7128)	data time 0.0195 (0.2294)	model time 0.0000 (0.0000)	loss 0.6884 (0.6149)	grad_norm 2.5504 (1.7332)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:08 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][30/156]	eta 0:01:20 lr 0.000110	 wd 0.0500	time 0.5312 (0.6356)	data time 0.0219 (0.1598)	model time 0.0000 (0.0000)	loss 0.5654 (0.6057)	grad_norm 1.4660 (1.6260)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:13 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][40/156]	eta 0:01:09 lr 0.000110	 wd 0.0500	time 0.5062 (0.5970)	data time 0.0013 (0.1223)	model time 0.0000 (0.0000)	loss 0.5798 (0.6037)	grad_norm 1.0941 (1.5851)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:18 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][50/156]	eta 0:01:02 lr 0.000110	 wd 0.0500	time 0.4204 (0.5917)	data time 0.0167 (0.1023)	model time 0.0000 (0.0000)	loss 0.5919 (0.6085)	grad_norm 1.6229 (1.5630)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:23 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][60/156]	eta 0:00:55 lr 0.000110	 wd 0.0500	time 0.4616 (0.5763)	data time 0.0142 (0.0883)	model time 0.4474 (0.4811)	loss 0.6502 (0.6056)	grad_norm 1.1219 (1.6164)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:28 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][70/156]	eta 0:00:48 lr 0.000110	 wd 0.0500	time 0.4509 (0.5674)	data time 0.0195 (0.0782)	model time 0.4314 (0.4891)	loss 0.6332 (0.6038)	grad_norm 1.3536 (1.6089)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:33 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][80/156]	eta 0:00:42 lr 0.000109	 wd 0.0500	time 0.4476 (0.5582)	data time 0.0008 (0.0692)	model time 0.4468 (0.4886)	loss 0.6402 (0.6068)	grad_norm 1.5095 (1.6445)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:38 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][90/156]	eta 0:00:36 lr 0.000109	 wd 0.0500	time 0.4658 (0.5469)	data time 0.0028 (0.0627)	model time 0.4630 (0.4775)	loss 0.6134 (0.6050)	grad_norm 1.5719 (1.6161)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:43 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][100/156]	eta 0:00:30 lr 0.000109	 wd 0.0500	time 0.4896 (0.5412)	data time 0.0006 (0.0579)	model time 0.4890 (0.4772)	loss 0.6249 (0.6063)	grad_norm 1.0421 (1.5930)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:48 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][110/156]	eta 0:00:24 lr 0.000109	 wd 0.0500	time 0.5022 (0.5358)	data time 0.0009 (0.0535)	model time 0.5013 (0.4762)	loss 0.6061 (0.6104)	grad_norm 1.4186 (1.5769)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:53 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][120/156]	eta 0:00:19 lr 0.000109	 wd 0.0500	time 0.5100 (0.5367)	data time 0.0200 (0.0500)	model time 0.4900 (0.4848)	loss 0.5824 (0.6101)	grad_norm 0.7969 (1.5488)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:09:58 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][130/156]	eta 0:00:13 lr 0.000109	 wd 0.0500	time 0.5172 (0.5314)	data time 0.0794 (0.0479)	model time 0.4378 (0.4799)	loss 0.6186 (0.6102)	grad_norm 1.5466 (1.5339)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:10:03 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][140/156]	eta 0:00:08 lr 0.000109	 wd 0.0500	time 0.4196 (0.5291)	data time 0.0011 (0.0450)	model time 0.4185 (0.4811)	loss 0.6114 (0.6090)	grad_norm 1.6930 (1.5406)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:10:08 vssm1_tiny_0230s](training.py 201): INFO Train: [84/300][150/156]	eta 0:00:03 lr 0.000109	 wd 0.0500	time 0.4482 (0.5256)	data time 0.0043 (0.0422)	model time 0.4439 (0.4803)	loss 0.5977 (0.6095)	grad_norm 2.4634 (1.5491)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:10:11 vssm1_tiny_0230s](training.py 212): INFO EPOCH 84 training takes 0:01:22
[2024-11-09 13:10:11 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_84.pth saving......
[2024-11-09 13:10:12 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_84.pth saved !!!
[2024-11-09 13:10:15 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.776 (3.776)	Loss 0.3818 (0.3818)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:10:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.170 (0.538)	Loss 0.4072 (0.3935)	Acc@1 83.594 (84.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:10:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.227 (0.438)	Loss 0.2460 (0.3941)	Acc@1 94.531 (84.189)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:10:23 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.176 (0.356)	Loss 0.2959 (0.3580)	Acc@1 91.406 (87.046)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:10:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.200 Acc@5 100.000
[2024-11-09 13:10:25 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 88.2%
[2024-11-09 13:10:25 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 88.20%
[2024-11-09 13:10:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.791 (3.791)	Loss 0.3660 (0.3660)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:10:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.132 (0.564)	Loss 0.3730 (0.3698)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:10:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.445)	Loss 0.8467 (0.4060)	Acc@1 28.125 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:10:37 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.228 (0.391)	Loss 0.9116 (0.5583)	Acc@1 22.656 (71.220)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:10:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 61.400 Acc@5 100.000
[2024-11-09 13:10:40 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 61.4%
[2024-11-09 13:10:40 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 61.40%
[2024-11-09 13:10:45 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][0/156]	eta 0:12:19 lr 0.000109	 wd 0.0500	time 4.7388 (4.7388)	data time 4.2926 (4.2926)	model time 0.0000 (0.0000)	loss 0.5843 (0.5843)	grad_norm 1.3648 (1.3648)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:10:50 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][10/156]	eta 0:02:17 lr 0.000109	 wd 0.0500	time 0.6031 (0.9445)	data time 0.0008 (0.4277)	model time 0.0000 (0.0000)	loss 0.5297 (0.6036)	grad_norm 2.8321 (1.7579)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:10:55 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][20/156]	eta 0:01:38 lr 0.000109	 wd 0.0500	time 0.4816 (0.7247)	data time 0.0018 (0.2254)	model time 0.0000 (0.0000)	loss 0.6245 (0.6110)	grad_norm 1.7935 (1.8570)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:00 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][30/156]	eta 0:01:21 lr 0.000109	 wd 0.0500	time 0.4262 (0.6484)	data time 0.0191 (0.1585)	model time 0.0000 (0.0000)	loss 0.6491 (0.6067)	grad_norm 2.1990 (1.8380)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:06 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][40/156]	eta 0:01:12 lr 0.000109	 wd 0.0500	time 0.5127 (0.6279)	data time 0.0277 (0.1230)	model time 0.0000 (0.0000)	loss 0.5757 (0.6087)	grad_norm 1.0601 (1.7989)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:11 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][50/156]	eta 0:01:03 lr 0.000109	 wd 0.0500	time 0.5305 (0.6037)	data time 0.0081 (0.1015)	model time 0.0000 (0.0000)	loss 0.5057 (0.6015)	grad_norm 1.9599 (1.7886)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:16 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][60/156]	eta 0:00:56 lr 0.000109	 wd 0.0500	time 0.6629 (0.5861)	data time 0.0984 (0.0889)	model time 0.5645 (0.4711)	loss 0.6633 (0.6034)	grad_norm 2.3274 (1.7942)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:21 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][70/156]	eta 0:00:49 lr 0.000109	 wd 0.0500	time 0.4116 (0.5708)	data time 0.0020 (0.0778)	model time 0.4097 (0.4696)	loss 0.6532 (0.6043)	grad_norm 2.3902 (1.8338)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:25 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][80/156]	eta 0:00:42 lr 0.000109	 wd 0.0500	time 0.5074 (0.5611)	data time 0.0175 (0.0692)	model time 0.4898 (0.4744)	loss 0.6437 (0.6046)	grad_norm 1.9745 (1.8154)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:30 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][90/156]	eta 0:00:36 lr 0.000109	 wd 0.0500	time 0.5438 (0.5542)	data time 0.0024 (0.0626)	model time 0.5414 (0.4780)	loss 0.5912 (0.6062)	grad_norm 1.5105 (1.8105)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:35 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][100/156]	eta 0:00:30 lr 0.000109	 wd 0.0500	time 0.4473 (0.5478)	data time 0.0365 (0.0582)	model time 0.4107 (0.4768)	loss 0.5462 (0.6082)	grad_norm 1.8943 (1.8016)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:40 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][110/156]	eta 0:00:24 lr 0.000109	 wd 0.0500	time 0.4313 (0.5406)	data time 0.0009 (0.0536)	model time 0.4304 (0.4740)	loss 0.6279 (0.6092)	grad_norm 1.1431 (1.7705)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:45 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][120/156]	eta 0:00:19 lr 0.000109	 wd 0.0500	time 0.4698 (0.5382)	data time 0.0174 (0.0514)	model time 0.4524 (0.4756)	loss 0.6568 (0.6110)	grad_norm 0.8978 (1.7408)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:11:50 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][130/156]	eta 0:00:13 lr 0.000109	 wd 0.0500	time 0.4142 (0.5337)	data time 0.0008 (0.0478)	model time 0.4134 (0.4754)	loss 0.5767 (0.6099)	grad_norm 1.9102 (1.7463)	loss_scale 131072.0000 (67537.0992)	mem 13675MB
[2024-11-09 13:11:55 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][140/156]	eta 0:00:08 lr 0.000109	 wd 0.0500	time 0.4413 (0.5301)	data time 0.0007 (0.0450)	model time 0.4406 (0.4754)	loss 0.5639 (0.6077)	grad_norm 1.3122 (1.7604)	loss_scale 131072.0000 (72043.1206)	mem 13675MB
[2024-11-09 13:12:00 vssm1_tiny_0230s](training.py 201): INFO Train: [85/300][150/156]	eta 0:00:03 lr 0.000109	 wd 0.0500	time 0.4754 (0.5280)	data time 0.0006 (0.0421)	model time 0.4748 (0.4775)	loss 0.5946 (0.6064)	grad_norm 3.3063 (1.8085)	loss_scale 131072.0000 (75952.3179)	mem 13675MB
[2024-11-09 13:12:03 vssm1_tiny_0230s](training.py 212): INFO EPOCH 85 training takes 0:01:22
[2024-11-09 13:12:03 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_85.pth saving......
[2024-11-09 13:12:03 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_85.pth saved !!!
[2024-11-09 13:12:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.425 (3.425)	Loss 0.2191 (0.2191)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:12:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.149 (0.549)	Loss 0.2256 (0.2227)	Acc@1 93.750 (94.247)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:12:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.145 (0.441)	Loss 0.3555 (0.2489)	Acc@1 89.062 (92.336)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:12:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.346 (0.375)	Loss 0.4106 (0.3055)	Acc@1 84.375 (88.962)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:12:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.120 Acc@5 100.000
[2024-11-09 13:12:17 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 87.1%
[2024-11-09 13:12:17 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 88.20%
[2024-11-09 13:12:20 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.524 (3.524)	Loss 0.3638 (0.3638)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:12:23 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.132 (0.572)	Loss 0.3711 (0.3678)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:12:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.419)	Loss 0.8452 (0.4041)	Acc@1 28.906 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:12:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.161 (0.352)	Loss 0.9106 (0.5567)	Acc@1 22.656 (71.396)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:12:30 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 61.660 Acc@5 100.000
[2024-11-09 13:12:30 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 61.7%
[2024-11-09 13:12:30 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 61.66%
[2024-11-09 13:12:35 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][0/156]	eta 0:12:03 lr 0.000109	 wd 0.0500	time 4.6384 (4.6384)	data time 4.2334 (4.2334)	model time 0.0000 (0.0000)	loss 0.6025 (0.6025)	grad_norm 1.3488 (1.3488)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 13:12:40 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][10/156]	eta 0:02:14 lr 0.000109	 wd 0.0500	time 0.4732 (0.9182)	data time 0.0494 (0.4005)	model time 0.0000 (0.0000)	loss 0.6175 (0.5924)	grad_norm 1.0107 (1.5657)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 13:12:46 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][20/156]	eta 0:01:41 lr 0.000109	 wd 0.0500	time 0.5405 (0.7479)	data time 0.0850 (0.2317)	model time 0.0000 (0.0000)	loss 0.6279 (0.6114)	grad_norm 1.3766 (1.6401)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 13:12:51 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][30/156]	eta 0:01:22 lr 0.000109	 wd 0.0500	time 0.4291 (0.6546)	data time 0.0010 (0.1609)	model time 0.0000 (0.0000)	loss 0.6697 (0.6156)	grad_norm 0.9548 (1.5173)	loss_scale 131072.0000 (131072.0000)	mem 13675MB
[2024-11-09 13:12:55 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][40/156]	eta 0:01:11 lr 0.000109	 wd 0.0500	time 0.4811 (0.6145)	data time 0.0299 (0.1267)	model time 0.0000 (0.0000)	loss 0.6280 (0.6146)	grad_norm 1.0686 (inf)	loss_scale 65536.0000 (118284.4878)	mem 13675MB
[2024-11-09 13:13:00 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][50/156]	eta 0:01:02 lr 0.000109	 wd 0.0500	time 0.4207 (0.5923)	data time 0.0005 (0.1062)	model time 0.0000 (0.0000)	loss 0.5891 (0.6148)	grad_norm 1.7465 (inf)	loss_scale 65536.0000 (107941.6471)	mem 13675MB
[2024-11-09 13:13:06 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][60/156]	eta 0:00:56 lr 0.000109	 wd 0.0500	time 0.6319 (0.5841)	data time 0.0857 (0.0945)	model time 0.5462 (0.5075)	loss 0.5783 (0.6112)	grad_norm 2.5038 (inf)	loss_scale 65536.0000 (100989.9016)	mem 13675MB
[2024-11-09 13:13:12 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][70/156]	eta 0:00:49 lr 0.000109	 wd 0.0500	time 0.4553 (0.5814)	data time 0.0006 (0.0834)	model time 0.4546 (0.5282)	loss 0.6049 (0.6086)	grad_norm 1.8433 (inf)	loss_scale 65536.0000 (95996.3944)	mem 13675MB
[2024-11-09 13:13:16 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][80/156]	eta 0:00:43 lr 0.000109	 wd 0.0500	time 0.4251 (0.5674)	data time 0.0173 (0.0753)	model time 0.4078 (0.5023)	loss 0.5839 (0.6090)	grad_norm 1.1463 (inf)	loss_scale 65536.0000 (92235.8519)	mem 13675MB
[2024-11-09 13:13:21 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][90/156]	eta 0:00:36 lr 0.000109	 wd 0.0500	time 0.5179 (0.5581)	data time 0.0036 (0.0691)	model time 0.5143 (0.4926)	loss 0.6371 (0.6088)	grad_norm 1.1785 (inf)	loss_scale 65536.0000 (89301.8022)	mem 13675MB
[2024-11-09 13:13:26 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][100/156]	eta 0:00:31 lr 0.000108	 wd 0.0500	time 0.5042 (0.5549)	data time 0.0346 (0.0648)	model time 0.4696 (0.4942)	loss 0.6744 (0.6092)	grad_norm 1.0743 (inf)	loss_scale 65536.0000 (86948.7525)	mem 13675MB
[2024-11-09 13:13:32 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][110/156]	eta 0:00:25 lr 0.000108	 wd 0.0500	time 0.4199 (0.5532)	data time 0.0079 (0.0606)	model time 0.4120 (0.4981)	loss 0.6189 (0.6061)	grad_norm 2.5834 (inf)	loss_scale 65536.0000 (85019.6757)	mem 13675MB
[2024-11-09 13:13:37 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][120/156]	eta 0:00:19 lr 0.000108	 wd 0.0500	time 0.5653 (0.5518)	data time 0.0008 (0.0568)	model time 0.5646 (0.5014)	loss 0.6348 (0.6082)	grad_norm 1.5650 (inf)	loss_scale 65536.0000 (83409.4545)	mem 13675MB
[2024-11-09 13:13:42 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][130/156]	eta 0:00:14 lr 0.000108	 wd 0.0500	time 0.4540 (0.5495)	data time 0.0410 (0.0542)	model time 0.4129 (0.5012)	loss 0.6693 (0.6070)	grad_norm 1.1718 (inf)	loss_scale 65536.0000 (82045.0687)	mem 13675MB
[2024-11-09 13:13:47 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][140/156]	eta 0:00:08 lr 0.000108	 wd 0.0500	time 0.4228 (0.5468)	data time 0.0009 (0.0510)	model time 0.4219 (0.5014)	loss 0.5138 (0.6079)	grad_norm 1.5567 (inf)	loss_scale 65536.0000 (80874.2128)	mem 13675MB
[2024-11-09 13:13:52 vssm1_tiny_0230s](training.py 201): INFO Train: [86/300][150/156]	eta 0:00:03 lr 0.000108	 wd 0.0500	time 0.4583 (0.5421)	data time 0.0009 (0.0476)	model time 0.4574 (0.4987)	loss 0.6767 (0.6069)	grad_norm 1.6728 (inf)	loss_scale 65536.0000 (79858.4371)	mem 13675MB
[2024-11-09 13:13:56 vssm1_tiny_0230s](training.py 212): INFO EPOCH 86 training takes 0:01:25
[2024-11-09 13:13:56 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_86.pth saving......
[2024-11-09 13:13:56 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_86.pth saved !!!
[2024-11-09 13:14:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.098 (3.098)	Loss 0.3801 (0.3801)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:14:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.517)	Loss 0.3975 (0.3892)	Acc@1 83.594 (83.381)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:14:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.183 (0.414)	Loss 0.2196 (0.3915)	Acc@1 96.094 (83.185)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:14:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.159 (0.346)	Loss 0.2695 (0.3518)	Acc@1 89.062 (86.139)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:14:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.420 Acc@5 100.000
[2024-11-09 13:14:10 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 87.4%
[2024-11-09 13:14:10 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 88.20%
[2024-11-09 13:14:14 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.648 (3.648)	Loss 0.3618 (0.3618)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:14:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.146 (0.597)	Loss 0.3689 (0.3656)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:14:19 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.435)	Loss 0.8442 (0.4020)	Acc@1 28.906 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:14:22 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.143 (0.372)	Loss 0.9106 (0.5552)	Acc@1 22.656 (71.472)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:14:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 61.820 Acc@5 100.000
[2024-11-09 13:14:24 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 61.8%
[2024-11-09 13:14:24 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 61.82%
[2024-11-09 13:14:29 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][0/156]	eta 0:11:27 lr 0.000108	 wd 0.0500	time 4.4066 (4.4066)	data time 3.9040 (3.9040)	model time 0.0000 (0.0000)	loss 0.6429 (0.6429)	grad_norm 1.2344 (1.2344)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:14:34 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][10/156]	eta 0:02:01 lr 0.000108	 wd 0.0500	time 0.4108 (0.8294)	data time 0.0009 (0.3641)	model time 0.0000 (0.0000)	loss 0.5997 (0.6175)	grad_norm 2.0225 (1.4368)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:14:39 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][20/156]	eta 0:01:32 lr 0.000108	 wd 0.0500	time 0.4678 (0.6835)	data time 0.0208 (0.2004)	model time 0.0000 (0.0000)	loss 0.5505 (0.6044)	grad_norm 2.1501 (1.6260)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:14:44 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][30/156]	eta 0:01:18 lr 0.000108	 wd 0.0500	time 0.5236 (0.6268)	data time 0.0075 (0.1420)	model time 0.0000 (0.0000)	loss 0.6344 (0.5996)	grad_norm 1.8127 (1.6570)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:14:49 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][40/156]	eta 0:01:08 lr 0.000108	 wd 0.0500	time 0.4808 (0.5923)	data time 0.0025 (0.1117)	model time 0.0000 (0.0000)	loss 0.5460 (0.6019)	grad_norm 2.5495 (1.7623)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:14:54 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][50/156]	eta 0:01:01 lr 0.000108	 wd 0.0500	time 0.4936 (0.5795)	data time 0.0142 (0.0925)	model time 0.0000 (0.0000)	loss 0.6166 (0.6018)	grad_norm 1.4977 (1.7672)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:14:59 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][60/156]	eta 0:00:54 lr 0.000108	 wd 0.0500	time 0.4577 (0.5631)	data time 0.0137 (0.0795)	model time 0.4440 (0.4660)	loss 0.6077 (0.6044)	grad_norm 1.2768 (1.7755)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:15:03 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][70/156]	eta 0:00:46 lr 0.000108	 wd 0.0500	time 0.4109 (0.5444)	data time 0.0009 (0.0698)	model time 0.4100 (0.4427)	loss 0.6044 (0.6011)	grad_norm 1.4340 (1.7659)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:15:08 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][80/156]	eta 0:00:40 lr 0.000108	 wd 0.0500	time 0.5452 (0.5327)	data time 0.0138 (0.0615)	model time 0.5314 (0.4441)	loss 0.5891 (0.5992)	grad_norm 1.8249 (1.7555)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:15:13 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][90/156]	eta 0:00:34 lr 0.000108	 wd 0.0500	time 0.4172 (0.5298)	data time 0.0048 (0.0562)	model time 0.4124 (0.4565)	loss 0.6394 (0.6003)	grad_norm 1.1908 (1.7452)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:15:17 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][100/156]	eta 0:00:29 lr 0.000108	 wd 0.0500	time 0.5465 (0.5227)	data time 0.0008 (0.0520)	model time 0.5457 (0.4540)	loss 0.6289 (0.6019)	grad_norm 1.8428 (1.7590)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:15:22 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][110/156]	eta 0:00:23 lr 0.000108	 wd 0.0500	time 0.6263 (0.5203)	data time 0.0180 (0.0493)	model time 0.6084 (0.4572)	loss 0.6567 (0.6045)	grad_norm 1.4986 (1.7583)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:15:27 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][120/156]	eta 0:00:18 lr 0.000108	 wd 0.0500	time 0.4665 (0.5152)	data time 0.0605 (0.0465)	model time 0.4060 (0.4555)	loss 0.6410 (0.6045)	grad_norm 1.1046 (1.7450)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:15:31 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][130/156]	eta 0:00:13 lr 0.000108	 wd 0.0500	time 0.5102 (0.5109)	data time 0.0157 (0.0439)	model time 0.4946 (0.4541)	loss 0.5111 (0.6025)	grad_norm 1.9763 (1.7318)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:15:37 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][140/156]	eta 0:00:08 lr 0.000108	 wd 0.0500	time 0.4860 (0.5127)	data time 0.0008 (0.0427)	model time 0.4853 (0.4602)	loss 0.6052 (0.6038)	grad_norm 2.1834 (1.7348)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:15:41 vssm1_tiny_0230s](training.py 201): INFO Train: [87/300][150/156]	eta 0:00:03 lr 0.000108	 wd 0.0500	time 0.4312 (0.5100)	data time 0.0005 (0.0400)	model time 0.4307 (0.4614)	loss 0.6474 (0.6040)	grad_norm 1.6767 (1.7160)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:15:44 vssm1_tiny_0230s](training.py 212): INFO EPOCH 87 training takes 0:01:19
[2024-11-09 13:15:44 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_87.pth saving......
[2024-11-09 13:15:45 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_87.pth saved !!!
[2024-11-09 13:15:48 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.367 (3.367)	Loss 0.2383 (0.2383)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:15:51 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.145 (0.560)	Loss 0.2588 (0.2507)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:15:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.155 (0.382)	Loss 0.3411 (0.2689)	Acc@1 87.500 (92.932)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:15:56 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.447 (0.361)	Loss 0.4109 (0.3096)	Acc@1 84.375 (89.995)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:15:59 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.880 Acc@5 100.000
[2024-11-09 13:15:59 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 88.9%
[2024-11-09 13:15:59 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 88.88%
[2024-11-09 13:16:03 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.771 (3.771)	Loss 0.3591 (0.3591)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:16:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.642 (0.546)	Loss 0.3665 (0.3631)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:16:07 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.171 (0.396)	Loss 0.8438 (0.3998)	Acc@1 29.688 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:16:10 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.178 (0.355)	Loss 0.9106 (0.5536)	Acc@1 22.656 (71.497)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:16:12 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 61.860 Acc@5 100.000
[2024-11-09 13:16:12 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 61.9%
[2024-11-09 13:16:12 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 61.86%
[2024-11-09 13:16:16 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][0/156]	eta 0:09:47 lr 0.000108	 wd 0.0500	time 3.7634 (3.7634)	data time 3.2546 (3.2546)	model time 0.0000 (0.0000)	loss 0.6275 (0.6275)	grad_norm 1.1805 (1.1805)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:16:22 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][10/156]	eta 0:02:20 lr 0.000108	 wd 0.0500	time 0.4301 (0.9610)	data time 0.0240 (0.4397)	model time 0.0000 (0.0000)	loss 0.5647 (0.6180)	grad_norm 0.9980 (1.7269)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:16:27 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][20/156]	eta 0:01:40 lr 0.000108	 wd 0.0500	time 0.4815 (0.7381)	data time 0.0031 (0.2333)	model time 0.0000 (0.0000)	loss 0.5917 (0.6191)	grad_norm 1.4487 (1.7616)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:16:33 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][30/156]	eta 0:01:24 lr 0.000108	 wd 0.0500	time 0.5086 (0.6710)	data time 0.0035 (0.1621)	model time 0.0000 (0.0000)	loss 0.6317 (0.6227)	grad_norm 1.1251 (1.6602)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:16:38 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][40/156]	eta 0:01:13 lr 0.000108	 wd 0.0500	time 0.4334 (0.6299)	data time 0.0178 (0.1268)	model time 0.0000 (0.0000)	loss 0.6361 (0.6210)	grad_norm 1.1029 (1.6210)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:16:42 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][50/156]	eta 0:01:03 lr 0.000108	 wd 0.0500	time 0.4324 (0.5995)	data time 0.0007 (0.1046)	model time 0.0000 (0.0000)	loss 0.6244 (0.6214)	grad_norm 1.1416 (1.5599)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:16:47 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][60/156]	eta 0:00:55 lr 0.000108	 wd 0.0500	time 0.4334 (0.5809)	data time 0.0007 (0.0881)	model time 0.4327 (0.4817)	loss 0.6492 (0.6171)	grad_norm 1.4673 (1.5595)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:16:53 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][70/156]	eta 0:00:49 lr 0.000108	 wd 0.0500	time 0.8521 (0.5754)	data time 0.0533 (0.0795)	model time 0.7988 (0.4981)	loss 0.6521 (0.6157)	grad_norm 2.1139 (1.5865)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:16:58 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][80/156]	eta 0:00:42 lr 0.000108	 wd 0.0500	time 0.4135 (0.5649)	data time 0.0008 (0.0721)	model time 0.4127 (0.4890)	loss 0.5403 (0.6115)	grad_norm 2.5214 (1.6036)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:17:02 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][90/156]	eta 0:00:36 lr 0.000108	 wd 0.0500	time 0.4739 (0.5553)	data time 0.0005 (0.0650)	model time 0.4733 (0.4842)	loss 0.5628 (0.6094)	grad_norm 1.5815 (1.6483)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:17:08 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][100/156]	eta 0:00:30 lr 0.000108	 wd 0.0500	time 0.5740 (0.5525)	data time 0.0006 (0.0599)	model time 0.5735 (0.4902)	loss 0.5939 (0.6086)	grad_norm 1.6934 (1.7033)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:17:13 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][110/156]	eta 0:00:25 lr 0.000108	 wd 0.0500	time 0.4584 (0.5469)	data time 0.0006 (0.0558)	model time 0.4578 (0.4878)	loss 0.6215 (0.6083)	grad_norm 1.1393 (1.7366)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:17:18 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][120/156]	eta 0:00:19 lr 0.000107	 wd 0.0500	time 0.5423 (0.5457)	data time 0.0038 (0.0522)	model time 0.5385 (0.4924)	loss 0.5801 (0.6076)	grad_norm 1.7955 (1.7259)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:17:23 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][130/156]	eta 0:00:14 lr 0.000107	 wd 0.0500	time 0.4332 (0.5416)	data time 0.0037 (0.0495)	model time 0.4295 (0.4903)	loss 0.5854 (0.6082)	grad_norm 1.2049 (1.7142)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:17:28 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][140/156]	eta 0:00:08 lr 0.000107	 wd 0.0500	time 0.4449 (0.5371)	data time 0.0007 (0.0468)	model time 0.4442 (0.4878)	loss 0.6401 (0.6075)	grad_norm 1.0674 (1.7206)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:17:33 vssm1_tiny_0230s](training.py 201): INFO Train: [88/300][150/156]	eta 0:00:03 lr 0.000107	 wd 0.0500	time 0.4918 (0.5344)	data time 0.0006 (0.0439)	model time 0.4912 (0.4882)	loss 0.6752 (0.6092)	grad_norm 1.5469 (1.7184)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:17:36 vssm1_tiny_0230s](training.py 212): INFO EPOCH 88 training takes 0:01:23
[2024-11-09 13:17:36 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_88.pth saving......
[2024-11-09 13:17:36 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_88.pth saved !!!
[2024-11-09 13:17:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.250 (3.250)	Loss 0.2058 (0.2058)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:17:42 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.299 (0.513)	Loss 0.2299 (0.2238)	Acc@1 96.094 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:17:44 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.364)	Loss 0.4119 (0.2493)	Acc@1 81.250 (94.234)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:17:47 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.162 (0.343)	Loss 0.4675 (0.3190)	Acc@1 78.125 (89.088)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:17:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 86.900 Acc@5 100.000
[2024-11-09 13:17:49 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 86.9%
[2024-11-09 13:17:49 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 88.88%
[2024-11-09 13:17:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.082 (4.082)	Loss 0.3574 (0.3574)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:17:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.158 (0.591)	Loss 0.3645 (0.3612)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:17:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.445)	Loss 0.8418 (0.3979)	Acc@1 30.469 (93.564)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:18:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.177 (0.389)	Loss 0.9102 (0.5520)	Acc@1 22.656 (71.573)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:18:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 62.000 Acc@5 100.000
[2024-11-09 13:18:03 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 62.0%
[2024-11-09 13:18:03 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 62.00%
[2024-11-09 13:18:07 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][0/156]	eta 0:09:33 lr 0.000107	 wd 0.0500	time 3.6760 (3.6760)	data time 3.1540 (3.1540)	model time 0.0000 (0.0000)	loss 0.5752 (0.5752)	grad_norm 1.8093 (1.8093)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:18:13 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][10/156]	eta 0:02:05 lr 0.000107	 wd 0.0500	time 0.5937 (0.8588)	data time 0.0222 (0.3004)	model time 0.0000 (0.0000)	loss 0.5366 (0.6031)	grad_norm 1.1715 (1.3183)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:18:18 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][20/156]	eta 0:01:32 lr 0.000107	 wd 0.0500	time 0.4365 (0.6799)	data time 0.0081 (0.1612)	model time 0.0000 (0.0000)	loss 0.6428 (0.5993)	grad_norm 1.5204 (1.4059)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:18:23 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][30/156]	eta 0:01:18 lr 0.000107	 wd 0.0500	time 0.4492 (0.6230)	data time 0.0046 (0.1149)	model time 0.0000 (0.0000)	loss 0.6173 (0.6060)	grad_norm 1.1036 (1.5149)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:18:28 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][40/156]	eta 0:01:08 lr 0.000107	 wd 0.0500	time 0.4921 (0.5930)	data time 0.0430 (0.0916)	model time 0.0000 (0.0000)	loss 0.5645 (0.6043)	grad_norm 1.7792 (1.6310)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:18:33 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][50/156]	eta 0:01:01 lr 0.000107	 wd 0.0500	time 0.4106 (0.5816)	data time 0.0006 (0.0780)	model time 0.0000 (0.0000)	loss 0.5988 (0.6041)	grad_norm 1.4029 (1.6295)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:18:38 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][60/156]	eta 0:00:54 lr 0.000107	 wd 0.0500	time 0.4330 (0.5696)	data time 0.0140 (0.0688)	model time 0.4189 (0.4864)	loss 0.5481 (0.6053)	grad_norm 1.3944 (1.6394)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:18:44 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][70/156]	eta 0:00:48 lr 0.000107	 wd 0.0500	time 0.6089 (0.5654)	data time 0.0264 (0.0624)	model time 0.5825 (0.5014)	loss 0.5965 (0.6037)	grad_norm 1.1639 (1.6194)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:18:49 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][80/156]	eta 0:00:42 lr 0.000107	 wd 0.0500	time 0.5676 (0.5591)	data time 0.0036 (0.0559)	model time 0.5639 (0.5027)	loss 0.5025 (0.5997)	grad_norm 2.9369 (1.6773)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:18:53 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][90/156]	eta 0:00:36 lr 0.000107	 wd 0.0500	time 0.5174 (0.5497)	data time 0.0019 (0.0519)	model time 0.5155 (0.4903)	loss 0.5992 (0.6027)	grad_norm 0.8433 (1.7103)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:18:59 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][100/156]	eta 0:00:30 lr 0.000107	 wd 0.0500	time 0.5889 (0.5499)	data time 0.0464 (0.0487)	model time 0.5424 (0.4986)	loss 0.6739 (0.6039)	grad_norm 2.2482 (1.7196)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:19:04 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][110/156]	eta 0:00:25 lr 0.000107	 wd 0.0500	time 0.4589 (0.5491)	data time 0.0008 (0.0450)	model time 0.4581 (0.5045)	loss 0.5992 (0.6054)	grad_norm 1.0419 (1.7143)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:19:10 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][120/156]	eta 0:00:19 lr 0.000107	 wd 0.0500	time 0.5155 (0.5498)	data time 0.0325 (0.0429)	model time 0.4830 (0.5092)	loss 0.6253 (0.6076)	grad_norm 1.2907 (1.6985)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:19:15 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][130/156]	eta 0:00:14 lr 0.000107	 wd 0.0500	time 0.4339 (0.5437)	data time 0.0058 (0.0406)	model time 0.4281 (0.5027)	loss 0.6263 (0.6066)	grad_norm 1.0687 (1.6885)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:19:20 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][140/156]	eta 0:00:08 lr 0.000107	 wd 0.0500	time 0.4646 (0.5408)	data time 0.0010 (0.0393)	model time 0.4637 (0.5003)	loss 0.6445 (0.6067)	grad_norm 1.2405 (1.6870)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:19:25 vssm1_tiny_0230s](training.py 201): INFO Train: [89/300][150/156]	eta 0:00:03 lr 0.000107	 wd 0.0500	time 0.5793 (0.5391)	data time 0.0886 (0.0374)	model time 0.4907 (0.5008)	loss 0.5989 (0.6063)	grad_norm 1.3477 (1.7017)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:19:28 vssm1_tiny_0230s](training.py 212): INFO EPOCH 89 training takes 0:01:24
[2024-11-09 13:19:28 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_89.pth saving......
[2024-11-09 13:19:28 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_89.pth saved !!!
[2024-11-09 13:19:32 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.104 (3.104)	Loss 0.2778 (0.2778)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:19:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.549)	Loss 0.2910 (0.2885)	Acc@1 91.406 (91.619)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:19:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.366)	Loss 0.2979 (0.3057)	Acc@1 91.406 (90.141)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:19:38 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.297)	Loss 0.3674 (0.3229)	Acc@1 86.719 (88.936)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:19:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.280 Acc@5 100.000
[2024-11-09 13:19:40 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 88.3%
[2024-11-09 13:19:40 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 88.88%
[2024-11-09 13:19:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.972 (3.972)	Loss 0.3557 (0.3557)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:19:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.318 (0.575)	Loss 0.3628 (0.3595)	Acc@1 98.438 (98.864)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:19:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.396)	Loss 0.8398 (0.3962)	Acc@1 30.469 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:19:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.359)	Loss 0.9087 (0.5504)	Acc@1 23.438 (71.749)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:19:54 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 62.240 Acc@5 100.000
[2024-11-09 13:19:54 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 62.2%
[2024-11-09 13:19:54 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 62.24%
[2024-11-09 13:19:59 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][0/156]	eta 0:12:40 lr 0.000107	 wd 0.0500	time 4.8720 (4.8720)	data time 4.3909 (4.3909)	model time 0.0000 (0.0000)	loss 0.4828 (0.4828)	grad_norm 1.8078 (1.8078)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:04 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][10/156]	eta 0:02:12 lr 0.000107	 wd 0.0500	time 0.4311 (0.9105)	data time 0.0252 (0.4225)	model time 0.0000 (0.0000)	loss 0.6275 (0.5926)	grad_norm 1.4647 (1.5511)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:10 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][20/156]	eta 0:01:40 lr 0.000107	 wd 0.0500	time 0.6230 (0.7412)	data time 0.0793 (0.2331)	model time 0.0000 (0.0000)	loss 0.6395 (0.5938)	grad_norm 1.3263 (1.7322)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:15 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][30/156]	eta 0:01:24 lr 0.000107	 wd 0.0500	time 0.6674 (0.6693)	data time 0.0370 (0.1647)	model time 0.0000 (0.0000)	loss 0.6268 (0.6065)	grad_norm 1.3631 (1.7131)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:20 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][40/156]	eta 0:01:12 lr 0.000107	 wd 0.0500	time 0.4393 (0.6214)	data time 0.0243 (0.1281)	model time 0.0000 (0.0000)	loss 0.6204 (0.6081)	grad_norm 1.3958 (1.6261)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:25 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][50/156]	eta 0:01:03 lr 0.000107	 wd 0.0500	time 0.4910 (0.5975)	data time 0.0024 (0.1055)	model time 0.0000 (0.0000)	loss 0.5845 (0.6109)	grad_norm 1.5226 (1.5667)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:29 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][60/156]	eta 0:00:55 lr 0.000107	 wd 0.0500	time 0.4261 (0.5782)	data time 0.0011 (0.0897)	model time 0.4251 (0.4708)	loss 0.5564 (0.6092)	grad_norm 1.9326 (1.5516)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:35 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][70/156]	eta 0:00:49 lr 0.000107	 wd 0.0500	time 0.6615 (0.5716)	data time 0.0190 (0.0795)	model time 0.6425 (0.4922)	loss 0.6423 (0.6055)	grad_norm 2.1081 (1.5828)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:40 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][80/156]	eta 0:00:42 lr 0.000107	 wd 0.0500	time 0.4153 (0.5631)	data time 0.0054 (0.0722)	model time 0.4099 (0.4891)	loss 0.5386 (0.6044)	grad_norm 1.4769 (1.6254)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:45 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][90/156]	eta 0:00:36 lr 0.000107	 wd 0.0500	time 0.5124 (0.5595)	data time 0.0008 (0.0662)	model time 0.5116 (0.4949)	loss 0.5341 (0.6055)	grad_norm 1.4858 (1.6407)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:50 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][100/156]	eta 0:00:30 lr 0.000107	 wd 0.0500	time 0.4313 (0.5519)	data time 0.0234 (0.0612)	model time 0.4079 (0.4894)	loss 0.5976 (0.6050)	grad_norm 1.7427 (1.6492)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:20:55 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][110/156]	eta 0:00:25 lr 0.000107	 wd 0.0500	time 0.4633 (0.5475)	data time 0.0542 (0.0567)	model time 0.4091 (0.4898)	loss 0.5134 (0.6062)	grad_norm 2.5228 (1.6608)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:21:00 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][120/156]	eta 0:00:19 lr 0.000106	 wd 0.0500	time 0.4946 (0.5454)	data time 0.0334 (0.0539)	model time 0.4612 (0.4911)	loss 0.4920 (0.6054)	grad_norm 1.3609 (1.6468)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:21:05 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][130/156]	eta 0:00:14 lr 0.000106	 wd 0.0500	time 0.5249 (0.5413)	data time 0.0270 (0.0508)	model time 0.4980 (0.4896)	loss 0.5463 (0.6048)	grad_norm 1.3739 (1.6277)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:21:10 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][140/156]	eta 0:00:08 lr 0.000106	 wd 0.0500	time 0.4939 (0.5404)	data time 0.0007 (0.0484)	model time 0.4931 (0.4920)	loss 0.5049 (0.6036)	grad_norm 2.5002 (1.6587)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:21:15 vssm1_tiny_0230s](training.py 201): INFO Train: [90/300][150/156]	eta 0:00:03 lr 0.000106	 wd 0.0500	time 0.4954 (0.5378)	data time 0.0005 (0.0452)	model time 0.4949 (0.4929)	loss 0.6158 (0.6044)	grad_norm 2.7785 (1.6812)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:21:18 vssm1_tiny_0230s](training.py 212): INFO EPOCH 90 training takes 0:01:24
[2024-11-09 13:21:18 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_90.pth saving......
[2024-11-09 13:21:18 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_90.pth saved !!!
[2024-11-09 13:21:22 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.781 (3.781)	Loss 0.2502 (0.2502)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:21:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.145 (0.601)	Loss 0.2659 (0.2536)	Acc@1 92.188 (93.821)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:21:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.144 (0.401)	Loss 0.3347 (0.2712)	Acc@1 86.719 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:21:30 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.208 (0.357)	Loss 0.4126 (0.3081)	Acc@1 82.812 (89.592)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:21:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.860 Acc@5 100.000
[2024-11-09 13:21:32 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 88.9%
[2024-11-09 13:21:32 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 88.88%
[2024-11-09 13:21:35 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.947 (2.947)	Loss 0.3538 (0.3538)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:21:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.430)	Loss 0.3611 (0.3577)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:21:40 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.350)	Loss 0.8379 (0.3945)	Acc@1 30.469 (93.564)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:21:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.213 (0.287)	Loss 0.9077 (0.5488)	Acc@1 24.219 (71.799)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:21:44 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 62.400 Acc@5 100.000
[2024-11-09 13:21:44 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 62.4%
[2024-11-09 13:21:44 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 62.40%
[2024-11-09 13:21:48 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][0/156]	eta 0:11:40 lr 0.000106	 wd 0.0500	time 4.4922 (4.4922)	data time 4.0199 (4.0199)	model time 0.0000 (0.0000)	loss 0.6218 (0.6218)	grad_norm 1.5477 (1.5477)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:21:53 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][10/156]	eta 0:02:04 lr 0.000106	 wd 0.0500	time 0.4889 (0.8494)	data time 0.0007 (0.3726)	model time 0.0000 (0.0000)	loss 0.5440 (0.5891)	grad_norm 2.8911 (1.9218)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:21:58 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][20/156]	eta 0:01:34 lr 0.000106	 wd 0.0500	time 0.4219 (0.6974)	data time 0.0060 (0.2053)	model time 0.0000 (0.0000)	loss 0.5889 (0.5837)	grad_norm 1.9843 (1.9832)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:03 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][30/156]	eta 0:01:20 lr 0.000106	 wd 0.0500	time 0.4130 (0.6353)	data time 0.0047 (0.1407)	model time 0.0000 (0.0000)	loss 0.5152 (0.5849)	grad_norm 1.5561 (2.0239)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:09 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][40/156]	eta 0:01:10 lr 0.000106	 wd 0.0500	time 0.5017 (0.6049)	data time 0.0317 (0.1112)	model time 0.0000 (0.0000)	loss 0.6223 (0.5908)	grad_norm 2.5617 (1.9967)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:13 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][50/156]	eta 0:01:01 lr 0.000106	 wd 0.0500	time 0.4785 (0.5832)	data time 0.0066 (0.0931)	model time 0.0000 (0.0000)	loss 0.6085 (0.5912)	grad_norm 1.7085 (1.9233)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:18 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][60/156]	eta 0:00:54 lr 0.000106	 wd 0.0500	time 0.4323 (0.5696)	data time 0.0035 (0.0800)	model time 0.4288 (0.4872)	loss 0.5659 (0.5923)	grad_norm 1.4329 (1.8582)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:24 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][70/156]	eta 0:00:48 lr 0.000106	 wd 0.0500	time 0.6027 (0.5632)	data time 0.0166 (0.0710)	model time 0.5861 (0.4979)	loss 0.6507 (0.5956)	grad_norm 2.9224 (1.8620)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:29 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][80/156]	eta 0:00:42 lr 0.000106	 wd 0.0500	time 0.4916 (0.5533)	data time 0.0241 (0.0636)	model time 0.4675 (0.4891)	loss 0.5815 (0.5962)	grad_norm 1.0762 (1.8601)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:34 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][90/156]	eta 0:00:36 lr 0.000106	 wd 0.0500	time 0.5919 (0.5508)	data time 0.0137 (0.0590)	model time 0.5782 (0.4939)	loss 0.6808 (0.5972)	grad_norm 1.8696 (1.8762)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:39 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][100/156]	eta 0:00:30 lr 0.000106	 wd 0.0500	time 0.5592 (0.5455)	data time 0.0155 (0.0538)	model time 0.5436 (0.4934)	loss 0.6190 (0.5982)	grad_norm 0.9515 (1.8313)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:44 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][110/156]	eta 0:00:24 lr 0.000106	 wd 0.0500	time 0.5211 (0.5429)	data time 0.0190 (0.0500)	model time 0.5021 (0.4953)	loss 0.6061 (0.5984)	grad_norm 1.7371 (1.8024)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:49 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][120/156]	eta 0:00:19 lr 0.000106	 wd 0.0500	time 0.4595 (0.5374)	data time 0.0295 (0.0470)	model time 0.4300 (0.4906)	loss 0.6534 (0.5980)	grad_norm 1.8397 (1.8175)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:54 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][130/156]	eta 0:00:13 lr 0.000106	 wd 0.0500	time 0.4668 (0.5357)	data time 0.0074 (0.0446)	model time 0.4595 (0.4917)	loss 0.6072 (0.5990)	grad_norm 1.3232 (1.8097)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:22:59 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][140/156]	eta 0:00:08 lr 0.000106	 wd 0.0500	time 0.6052 (0.5343)	data time 0.0008 (0.0428)	model time 0.6043 (0.4922)	loss 0.5269 (0.5996)	grad_norm 1.8939 (1.7939)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:23:04 vssm1_tiny_0230s](training.py 201): INFO Train: [91/300][150/156]	eta 0:00:03 lr 0.000106	 wd 0.0500	time 0.6240 (0.5340)	data time 0.0005 (0.0402)	model time 0.6235 (0.4958)	loss 0.5820 (0.5998)	grad_norm 1.6265 (1.7780)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:23:07 vssm1_tiny_0230s](training.py 212): INFO EPOCH 91 training takes 0:01:23
[2024-11-09 13:23:07 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_91.pth saving......
[2024-11-09 13:23:07 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_91.pth saved !!!
[2024-11-09 13:23:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.768 (3.768)	Loss 0.3018 (0.3018)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:23:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.592)	Loss 0.3076 (0.3135)	Acc@1 89.062 (89.418)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:23:16 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.156 (0.422)	Loss 0.2693 (0.3290)	Acc@1 95.312 (88.542)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:23:18 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.359)	Loss 0.3162 (0.3252)	Acc@1 88.281 (88.810)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:23:21 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.960 Acc@5 100.000
[2024-11-09 13:23:21 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 89.0%
[2024-11-09 13:23:21 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 88.96%
[2024-11-09 13:23:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.050 (3.050)	Loss 0.3521 (0.3521)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:23:26 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.152 (0.479)	Loss 0.3591 (0.3559)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:23:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.154 (0.368)	Loss 0.8359 (0.3927)	Acc@1 30.469 (93.564)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:23:31 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.664 (0.313)	Loss 0.9067 (0.5471)	Acc@1 25.781 (71.976)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:23:33 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 62.600 Acc@5 100.000
[2024-11-09 13:23:33 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 62.6%
[2024-11-09 13:23:33 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 62.60%
[2024-11-09 13:23:38 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][0/156]	eta 0:11:32 lr 0.000106	 wd 0.0500	time 4.4405 (4.4405)	data time 3.9260 (3.9260)	model time 0.0000 (0.0000)	loss 0.5981 (0.5981)	grad_norm 2.5402 (2.5402)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:23:43 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][10/156]	eta 0:02:02 lr 0.000106	 wd 0.0500	time 0.4672 (0.8364)	data time 0.0212 (0.3688)	model time 0.0000 (0.0000)	loss 0.5995 (0.5979)	grad_norm 1.2459 (1.5770)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:23:48 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][20/156]	eta 0:01:32 lr 0.000106	 wd 0.0500	time 0.4731 (0.6804)	data time 0.0024 (0.2011)	model time 0.0000 (0.0000)	loss 0.5661 (0.6002)	grad_norm 0.9952 (1.6307)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:23:53 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][30/156]	eta 0:01:19 lr 0.000106	 wd 0.0500	time 0.5201 (0.6322)	data time 0.0271 (0.1415)	model time 0.0000 (0.0000)	loss 0.6855 (0.6019)	grad_norm 3.7980 (1.7370)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:23:58 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][40/156]	eta 0:01:10 lr 0.000106	 wd 0.0500	time 0.4505 (0.6080)	data time 0.0075 (0.1122)	model time 0.0000 (0.0000)	loss 0.6577 (0.6018)	grad_norm 3.5713 (1.8308)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:04 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][50/156]	eta 0:01:02 lr 0.000106	 wd 0.0500	time 0.5670 (0.5936)	data time 0.0506 (0.0954)	model time 0.0000 (0.0000)	loss 0.6377 (0.6063)	grad_norm 1.1961 (1.7928)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:09 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][60/156]	eta 0:00:56 lr 0.000106	 wd 0.0500	time 0.7412 (0.5849)	data time 0.0214 (0.0829)	model time 0.7198 (0.5217)	loss 0.6221 (0.6080)	grad_norm 2.1178 (1.7304)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:14 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][70/156]	eta 0:00:49 lr 0.000106	 wd 0.0500	time 0.4522 (0.5717)	data time 0.0179 (0.0724)	model time 0.4343 (0.5023)	loss 0.6467 (0.6072)	grad_norm 1.5975 (1.7442)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:19 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][80/156]	eta 0:00:42 lr 0.000106	 wd 0.0500	time 0.4959 (0.5625)	data time 0.0005 (0.0645)	model time 0.4953 (0.4975)	loss 0.5963 (0.6098)	grad_norm 1.8538 (1.7238)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:24 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][90/156]	eta 0:00:36 lr 0.000106	 wd 0.0500	time 0.5403 (0.5539)	data time 0.0061 (0.0586)	model time 0.5342 (0.4916)	loss 0.5874 (0.6097)	grad_norm 2.0062 (1.6895)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:29 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][100/156]	eta 0:00:30 lr 0.000106	 wd 0.0500	time 0.4439 (0.5484)	data time 0.0143 (0.0541)	model time 0.4296 (0.4902)	loss 0.5727 (0.6099)	grad_norm 1.0767 (1.6583)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:34 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][110/156]	eta 0:00:24 lr 0.000106	 wd 0.0500	time 0.4811 (0.5427)	data time 0.0256 (0.0507)	model time 0.4555 (0.4867)	loss 0.5915 (0.6094)	grad_norm 2.2289 (1.6445)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:38 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][120/156]	eta 0:00:19 lr 0.000105	 wd 0.0500	time 0.5923 (0.5384)	data time 0.1068 (0.0490)	model time 0.4855 (0.4830)	loss 0.6281 (0.6101)	grad_norm 1.2065 (1.6454)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:44 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][130/156]	eta 0:00:13 lr 0.000105	 wd 0.0500	time 0.4789 (0.5357)	data time 0.0063 (0.0460)	model time 0.4727 (0.4842)	loss 0.6313 (0.6092)	grad_norm 1.2937 (1.6459)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:49 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][140/156]	eta 0:00:08 lr 0.000105	 wd 0.0500	time 0.6174 (0.5361)	data time 0.0013 (0.0439)	model time 0.6161 (0.4888)	loss 0.5183 (0.6098)	grad_norm 1.7141 (1.6508)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:54 vssm1_tiny_0230s](training.py 201): INFO Train: [92/300][150/156]	eta 0:00:03 lr 0.000105	 wd 0.0500	time 0.5963 (0.5342)	data time 0.0006 (0.0410)	model time 0.5957 (0.4906)	loss 0.5395 (0.6090)	grad_norm 1.5024 (1.6396)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:24:57 vssm1_tiny_0230s](training.py 212): INFO EPOCH 92 training takes 0:01:23
[2024-11-09 13:24:57 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_92.pth saving......
[2024-11-09 13:24:58 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_92.pth saved !!!
[2024-11-09 13:25:01 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.141 (3.141)	Loss 0.2864 (0.2864)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:25:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.254 (0.489)	Loss 0.3047 (0.3042)	Acc@1 90.625 (90.980)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:25:06 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.207 (0.372)	Loss 0.2710 (0.3179)	Acc@1 92.188 (89.583)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:25:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.315)	Loss 0.3159 (0.3167)	Acc@1 89.844 (89.617)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:25:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.640 Acc@5 100.000
[2024-11-09 13:25:10 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 89.6%
[2024-11-09 13:25:10 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 89.64%
[2024-11-09 13:25:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.025 (3.025)	Loss 0.3503 (0.3503)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:25:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.474)	Loss 0.3577 (0.3544)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:25:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.231 (0.393)	Loss 0.8330 (0.3912)	Acc@1 31.250 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:25:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.202 (0.337)	Loss 0.9053 (0.5455)	Acc@1 26.562 (72.152)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:25:23 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 62.800 Acc@5 100.000
[2024-11-09 13:25:23 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 62.8%
[2024-11-09 13:25:23 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 62.80%
[2024-11-09 13:25:27 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][0/156]	eta 0:11:51 lr 0.000105	 wd 0.0500	time 4.5578 (4.5578)	data time 4.1020 (4.1020)	model time 0.0000 (0.0000)	loss 0.5563 (0.5563)	grad_norm 2.5791 (2.5791)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:25:33 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][10/156]	eta 0:02:08 lr 0.000105	 wd 0.0500	time 0.4832 (0.8827)	data time 0.0017 (0.3904)	model time 0.0000 (0.0000)	loss 0.6846 (0.6192)	grad_norm 2.0284 (1.8657)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:25:37 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][20/156]	eta 0:01:32 lr 0.000105	 wd 0.0500	time 0.4194 (0.6787)	data time 0.0006 (0.2078)	model time 0.0000 (0.0000)	loss 0.5275 (0.6129)	grad_norm 1.4087 (1.9269)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:25:42 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][30/156]	eta 0:01:16 lr 0.000105	 wd 0.0500	time 0.4142 (0.6105)	data time 0.0049 (0.1449)	model time 0.0000 (0.0000)	loss 0.6356 (0.6121)	grad_norm 1.7534 (1.7932)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:25:47 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][40/156]	eta 0:01:07 lr 0.000105	 wd 0.0500	time 0.5525 (0.5786)	data time 0.0514 (0.1124)	model time 0.0000 (0.0000)	loss 0.6660 (0.6067)	grad_norm 1.9745 (1.7730)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:25:52 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][50/156]	eta 0:00:59 lr 0.000105	 wd 0.0500	time 0.6014 (0.5634)	data time 0.0007 (0.0926)	model time 0.0000 (0.0000)	loss 0.5355 (0.6058)	grad_norm 1.9699 (1.7305)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:25:57 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][60/156]	eta 0:00:53 lr 0.000105	 wd 0.0500	time 0.5936 (0.5588)	data time 0.0059 (0.0796)	model time 0.5876 (0.5220)	loss 0.5556 (0.6049)	grad_norm 4.6238 (1.7604)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:26:03 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][70/156]	eta 0:00:47 lr 0.000105	 wd 0.0500	time 0.4741 (0.5581)	data time 0.0358 (0.0719)	model time 0.4383 (0.5255)	loss 0.5988 (0.6051)	grad_norm 1.5806 (1.8464)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:26:08 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][80/156]	eta 0:00:42 lr 0.000105	 wd 0.0500	time 0.6121 (0.5560)	data time 0.0163 (0.0648)	model time 0.5958 (0.5260)	loss 0.6646 (0.6065)	grad_norm 1.7263 (1.8420)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:26:13 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][90/156]	eta 0:00:36 lr 0.000105	 wd 0.0500	time 0.4139 (0.5512)	data time 0.0049 (0.0586)	model time 0.4089 (0.5203)	loss 0.6573 (0.6060)	grad_norm 1.2368 (1.8205)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:26:18 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][100/156]	eta 0:00:30 lr 0.000105	 wd 0.0500	time 0.4267 (0.5466)	data time 0.0075 (0.0542)	model time 0.4192 (0.5144)	loss 0.6751 (0.6075)	grad_norm 1.8198 (1.8106)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:26:23 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][110/156]	eta 0:00:25 lr 0.000105	 wd 0.0500	time 0.4212 (0.5449)	data time 0.0107 (0.0511)	model time 0.4105 (0.5134)	loss 0.6218 (0.6083)	grad_norm 0.8613 (1.8100)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:26:28 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][120/156]	eta 0:00:19 lr 0.000105	 wd 0.0500	time 0.4531 (0.5386)	data time 0.0277 (0.0488)	model time 0.4254 (0.5036)	loss 0.6153 (0.6084)	grad_norm 2.2741 (1.8344)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:26:33 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][130/156]	eta 0:00:13 lr 0.000105	 wd 0.0500	time 0.4302 (0.5329)	data time 0.0184 (0.0457)	model time 0.4118 (0.4976)	loss 0.5587 (0.6075)	grad_norm 1.6679 (1.8030)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:26:38 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][140/156]	eta 0:00:08 lr 0.000105	 wd 0.0500	time 0.4956 (0.5318)	data time 0.0311 (0.0433)	model time 0.4645 (0.4985)	loss 0.6381 (0.6056)	grad_norm 1.7983 (1.8009)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:26:43 vssm1_tiny_0230s](training.py 201): INFO Train: [93/300][150/156]	eta 0:00:03 lr 0.000105	 wd 0.0500	time 0.5148 (0.5315)	data time 0.0004 (0.0405)	model time 0.5144 (0.5013)	loss 0.6459 (0.6063)	grad_norm 1.3044 (1.8222)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:26:46 vssm1_tiny_0230s](training.py 212): INFO EPOCH 93 training takes 0:01:23
[2024-11-09 13:26:46 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_93.pth saving......
[2024-11-09 13:26:46 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_93.pth saved !!!
[2024-11-09 13:26:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.672 (2.672)	Loss 0.2649 (0.2649)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:26:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.511 (0.539)	Loss 0.2766 (0.2726)	Acc@1 92.969 (91.619)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:26:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.398)	Loss 0.2881 (0.2902)	Acc@1 92.188 (89.955)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:26:58 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.174 (0.359)	Loss 0.3357 (0.3051)	Acc@1 87.500 (89.189)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:27:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.820 Acc@5 100.000
[2024-11-09 13:27:00 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 88.8%
[2024-11-09 13:27:00 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 89.64%
[2024-11-09 13:27:03 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.606 (3.606)	Loss 0.3486 (0.3486)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:27:06 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.149 (0.602)	Loss 0.3557 (0.3526)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:27:09 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.427)	Loss 0.8311 (0.3894)	Acc@1 31.250 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:27:11 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.178 (0.351)	Loss 0.9038 (0.5438)	Acc@1 26.562 (72.303)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:27:13 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 63.020 Acc@5 100.000
[2024-11-09 13:27:13 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 63.0%
[2024-11-09 13:27:13 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 63.02%
[2024-11-09 13:27:18 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][0/156]	eta 0:10:59 lr 0.000105	 wd 0.0500	time 4.2257 (4.2257)	data time 3.7903 (3.7903)	model time 0.0000 (0.0000)	loss 0.6078 (0.6078)	grad_norm 1.7994 (1.7994)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:27:23 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][10/156]	eta 0:02:09 lr 0.000105	 wd 0.0500	time 0.4520 (0.8895)	data time 0.0009 (0.3517)	model time 0.0000 (0.0000)	loss 0.6335 (0.5944)	grad_norm 2.0020 (1.7135)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:27:28 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][20/156]	eta 0:01:35 lr 0.000105	 wd 0.0500	time 0.5428 (0.6990)	data time 0.1148 (0.1940)	model time 0.0000 (0.0000)	loss 0.6552 (0.5930)	grad_norm 1.6255 (1.8253)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:27:34 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][30/156]	eta 0:01:22 lr 0.000105	 wd 0.0500	time 0.5587 (0.6572)	data time 0.0374 (0.1361)	model time 0.0000 (0.0000)	loss 0.5293 (0.5849)	grad_norm 1.9342 (1.9352)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:27:39 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][40/156]	eta 0:01:13 lr 0.000105	 wd 0.0500	time 0.4775 (0.6352)	data time 0.0058 (0.1089)	model time 0.0000 (0.0000)	loss 0.6639 (0.5861)	grad_norm 2.2233 (1.9449)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:27:45 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][50/156]	eta 0:01:05 lr 0.000105	 wd 0.0500	time 0.4775 (0.6216)	data time 0.0286 (0.0927)	model time 0.0000 (0.0000)	loss 0.6083 (0.5850)	grad_norm 1.5467 (1.9849)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:27:50 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][60/156]	eta 0:00:57 lr 0.000105	 wd 0.0500	time 0.4988 (0.6021)	data time 0.0138 (0.0790)	model time 0.4851 (0.4941)	loss 0.6400 (0.5862)	grad_norm 1.4134 (1.9723)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:27:55 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][70/156]	eta 0:00:50 lr 0.000105	 wd 0.0500	time 0.5448 (0.5907)	data time 0.0176 (0.0721)	model time 0.5272 (0.4926)	loss 0.5543 (0.5865)	grad_norm 1.1003 (1.9303)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:28:00 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][80/156]	eta 0:00:43 lr 0.000105	 wd 0.0500	time 0.4884 (0.5775)	data time 0.0038 (0.0651)	model time 0.4846 (0.4844)	loss 0.6214 (0.5877)	grad_norm 1.3264 (1.9241)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:28:05 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][90/156]	eta 0:00:37 lr 0.000105	 wd 0.0500	time 0.4845 (0.5692)	data time 0.0093 (0.0600)	model time 0.4752 (0.4842)	loss 0.6506 (0.5894)	grad_norm 2.2833 (1.9546)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:28:11 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][100/156]	eta 0:00:31 lr 0.000105	 wd 0.0500	time 0.4631 (0.5664)	data time 0.0050 (0.0553)	model time 0.4581 (0.4929)	loss 0.7100 (0.5896)	grad_norm 1.8324 (1.9591)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:28:15 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][110/156]	eta 0:00:25 lr 0.000105	 wd 0.0500	time 0.4890 (0.5604)	data time 0.0011 (0.0512)	model time 0.4879 (0.4925)	loss 0.5639 (0.5880)	grad_norm 1.7982 (1.9429)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:28:21 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][120/156]	eta 0:00:20 lr 0.000104	 wd 0.0500	time 0.4783 (0.5577)	data time 0.0265 (0.0484)	model time 0.4519 (0.4950)	loss 0.6221 (0.5881)	grad_norm 1.5113 (1.9297)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:28:26 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][130/156]	eta 0:00:14 lr 0.000104	 wd 0.0500	time 0.4665 (0.5576)	data time 0.0232 (0.0468)	model time 0.4433 (0.4993)	loss 0.6193 (0.5899)	grad_norm 1.1256 (1.9015)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:28:31 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][140/156]	eta 0:00:08 lr 0.000104	 wd 0.0500	time 0.5277 (0.5533)	data time 0.0009 (0.0445)	model time 0.5268 (0.4974)	loss 0.5842 (0.5914)	grad_norm 1.3302 (1.8690)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:28:36 vssm1_tiny_0230s](training.py 201): INFO Train: [94/300][150/156]	eta 0:00:03 lr 0.000104	 wd 0.0500	time 0.5305 (0.5487)	data time 0.0006 (0.0416)	model time 0.5299 (0.4960)	loss 0.6183 (0.5921)	grad_norm 1.3256 (1.8576)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:28:39 vssm1_tiny_0230s](training.py 212): INFO EPOCH 94 training takes 0:01:25
[2024-11-09 13:28:39 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_94.pth saving......
[2024-11-09 13:28:39 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_94.pth saved !!!
[2024-11-09 13:28:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.091 (3.091)	Loss 0.2803 (0.2803)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:28:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.247 (0.601)	Loss 0.3101 (0.2952)	Acc@1 89.844 (90.909)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:28:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.418)	Loss 0.2656 (0.3065)	Acc@1 91.406 (89.955)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:28:50 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.155 (0.358)	Loss 0.3215 (0.3072)	Acc@1 86.719 (89.516)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:28:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.520 Acc@5 100.000
[2024-11-09 13:28:53 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 89.5%
[2024-11-09 13:28:53 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 89.64%
[2024-11-09 13:28:57 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.666 (4.666)	Loss 0.3467 (0.3467)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:29:00 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.637)	Loss 0.3540 (0.3508)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:29:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.423)	Loss 0.8286 (0.3877)	Acc@1 32.031 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:29:04 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.376)	Loss 0.9023 (0.5421)	Acc@1 27.344 (72.505)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:29:07 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 63.260 Acc@5 100.000
[2024-11-09 13:29:07 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 63.3%
[2024-11-09 13:29:07 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 63.26%
[2024-11-09 13:29:12 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][0/156]	eta 0:12:15 lr 0.000104	 wd 0.0500	time 4.7165 (4.7165)	data time 4.1518 (4.1518)	model time 0.0000 (0.0000)	loss 0.5385 (0.5385)	grad_norm 1.6843 (1.6843)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:29:17 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][10/156]	eta 0:02:10 lr 0.000104	 wd 0.0500	time 0.4898 (0.8959)	data time 0.0010 (0.3840)	model time 0.0000 (0.0000)	loss 0.5655 (0.5885)	grad_norm 2.6358 (2.0168)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:29:22 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][20/156]	eta 0:01:34 lr 0.000104	 wd 0.0500	time 0.4323 (0.6950)	data time 0.0009 (0.2083)	model time 0.0000 (0.0000)	loss 0.5793 (0.5999)	grad_norm 1.2612 (1.7870)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:29:27 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][30/156]	eta 0:01:21 lr 0.000104	 wd 0.0500	time 0.5051 (0.6463)	data time 0.0031 (0.1469)	model time 0.0000 (0.0000)	loss 0.5509 (0.6072)	grad_norm 2.0010 (1.7188)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:29:33 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][40/156]	eta 0:01:11 lr 0.000104	 wd 0.0500	time 0.5244 (0.6191)	data time 0.0063 (0.1144)	model time 0.0000 (0.0000)	loss 0.6286 (0.6038)	grad_norm 1.0751 (1.7195)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:29:38 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][50/156]	eta 0:01:03 lr 0.000104	 wd 0.0500	time 0.4241 (0.5947)	data time 0.0036 (0.0953)	model time 0.0000 (0.0000)	loss 0.6220 (0.6030)	grad_norm 1.9477 (1.7424)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:29:42 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][60/156]	eta 0:00:55 lr 0.000104	 wd 0.0500	time 0.5843 (0.5759)	data time 0.0581 (0.0838)	model time 0.5262 (0.4552)	loss 0.5920 (0.6031)	grad_norm 1.8925 (1.7660)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:29:48 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][70/156]	eta 0:00:48 lr 0.000104	 wd 0.0500	time 0.5714 (0.5674)	data time 0.0088 (0.0729)	model time 0.5626 (0.4817)	loss 0.5010 (0.6018)	grad_norm 2.2647 (1.7568)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:29:52 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][80/156]	eta 0:00:42 lr 0.000104	 wd 0.0500	time 0.4812 (0.5576)	data time 0.0135 (0.0656)	model time 0.4677 (0.4792)	loss 0.6487 (0.6029)	grad_norm 1.9983 (1.7487)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:29:58 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][90/156]	eta 0:00:36 lr 0.000104	 wd 0.0500	time 0.4317 (0.5564)	data time 0.0006 (0.0592)	model time 0.4310 (0.4945)	loss 0.6406 (0.6030)	grad_norm 1.7395 (1.7564)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:30:03 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][100/156]	eta 0:00:30 lr 0.000104	 wd 0.0500	time 0.5832 (0.5534)	data time 0.0307 (0.0548)	model time 0.5525 (0.4978)	loss 0.6306 (0.6030)	grad_norm 1.6130 (1.7509)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:30:08 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][110/156]	eta 0:00:25 lr 0.000104	 wd 0.0500	time 0.5102 (0.5488)	data time 0.0005 (0.0514)	model time 0.5096 (0.4957)	loss 0.5107 (0.6013)	grad_norm 1.7145 (1.7309)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:30:13 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][120/156]	eta 0:00:19 lr 0.000104	 wd 0.0500	time 0.4468 (0.5456)	data time 0.0041 (0.0486)	model time 0.4427 (0.4953)	loss 0.6579 (0.6024)	grad_norm 1.4631 (1.7425)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:30:18 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][130/156]	eta 0:00:14 lr 0.000104	 wd 0.0500	time 0.5859 (0.5430)	data time 0.0309 (0.0465)	model time 0.5549 (0.4947)	loss 0.6581 (0.6022)	grad_norm 1.2260 (1.7570)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:30:24 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][140/156]	eta 0:00:08 lr 0.000104	 wd 0.0500	time 0.4687 (0.5450)	data time 0.0009 (0.0458)	model time 0.4679 (0.4991)	loss 0.6248 (0.6020)	grad_norm 1.3221 (1.7651)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:30:29 vssm1_tiny_0230s](training.py 201): INFO Train: [95/300][150/156]	eta 0:00:03 lr 0.000104	 wd 0.0500	time 0.5603 (0.5411)	data time 0.0005 (0.0428)	model time 0.5598 (0.4978)	loss 0.5802 (0.6015)	grad_norm 0.7691 (1.7506)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:30:32 vssm1_tiny_0230s](training.py 212): INFO EPOCH 95 training takes 0:01:24
[2024-11-09 13:30:32 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_95.pth saving......
[2024-11-09 13:30:32 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_95.pth saved !!!
[2024-11-09 13:30:35 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.813 (2.813)	Loss 0.2451 (0.2451)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:30:38 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.499)	Loss 0.2761 (0.2666)	Acc@1 91.406 (92.472)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:30:40 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.385)	Loss 0.2688 (0.2796)	Acc@1 90.625 (91.146)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:30:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.340)	Loss 0.3315 (0.2924)	Acc@1 86.719 (90.222)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:30:45 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.900 Acc@5 100.000
[2024-11-09 13:30:45 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 89.9%
[2024-11-09 13:30:45 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 89.90%
[2024-11-09 13:30:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.331 (3.331)	Loss 0.3450 (0.3450)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:30:51 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.201 (0.509)	Loss 0.3523 (0.3490)	Acc@1 98.438 (98.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:30:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.367)	Loss 0.8262 (0.3859)	Acc@1 32.031 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:30:56 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.355)	Loss 0.9009 (0.5404)	Acc@1 27.344 (72.681)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:30:58 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 63.440 Acc@5 100.000
[2024-11-09 13:30:58 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 63.4%
[2024-11-09 13:30:58 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 63.44%
[2024-11-09 13:31:03 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][0/156]	eta 0:11:23 lr 0.000104	 wd 0.0500	time 4.3844 (4.3844)	data time 3.8588 (3.8588)	model time 0.0000 (0.0000)	loss 0.5842 (0.5842)	grad_norm 1.5714 (1.5714)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:08 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][10/156]	eta 0:02:10 lr 0.000104	 wd 0.0500	time 0.5440 (0.8970)	data time 0.0220 (0.3704)	model time 0.0000 (0.0000)	loss 0.5059 (0.6013)	grad_norm 1.3504 (1.7355)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:13 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][20/156]	eta 0:01:35 lr 0.000104	 wd 0.0500	time 0.4258 (0.7023)	data time 0.0029 (0.1979)	model time 0.0000 (0.0000)	loss 0.6241 (0.6065)	grad_norm 0.9087 (1.6452)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:18 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][30/156]	eta 0:01:19 lr 0.000104	 wd 0.0500	time 0.4117 (0.6323)	data time 0.0007 (0.1393)	model time 0.0000 (0.0000)	loss 0.6343 (0.6083)	grad_norm 1.1408 (1.5799)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:23 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][40/156]	eta 0:01:08 lr 0.000104	 wd 0.0500	time 0.4586 (0.5925)	data time 0.0103 (0.1083)	model time 0.0000 (0.0000)	loss 0.6906 (0.6062)	grad_norm 1.7993 (1.6640)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:28 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][50/156]	eta 0:01:01 lr 0.000104	 wd 0.0500	time 0.5040 (0.5763)	data time 0.0259 (0.0895)	model time 0.0000 (0.0000)	loss 0.5133 (0.6009)	grad_norm 3.3352 (1.7756)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:33 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][60/156]	eta 0:00:54 lr 0.000104	 wd 0.0500	time 0.4700 (0.5642)	data time 0.0023 (0.0813)	model time 0.4678 (0.4628)	loss 0.6231 (0.6035)	grad_norm 2.7651 (1.8176)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:38 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][70/156]	eta 0:00:47 lr 0.000104	 wd 0.0500	time 0.4727 (0.5531)	data time 0.0183 (0.0718)	model time 0.4544 (0.4672)	loss 0.5557 (0.6009)	grad_norm 2.0541 (1.8272)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:43 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][80/156]	eta 0:00:41 lr 0.000104	 wd 0.0500	time 0.5675 (0.5460)	data time 0.0007 (0.0643)	model time 0.5668 (0.4729)	loss 0.5338 (0.5993)	grad_norm 2.0521 (1.8410)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:47 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][90/156]	eta 0:00:35 lr 0.000104	 wd 0.0500	time 0.4661 (0.5396)	data time 0.0060 (0.0590)	model time 0.4601 (0.4727)	loss 0.6605 (0.5965)	grad_norm 1.5886 (1.8742)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:53 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][100/156]	eta 0:00:30 lr 0.000103	 wd 0.0500	time 0.4470 (0.5381)	data time 0.0026 (0.0544)	model time 0.4444 (0.4805)	loss 0.6461 (0.5990)	grad_norm 2.0685 (1.8966)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:31:58 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][110/156]	eta 0:00:24 lr 0.000103	 wd 0.0500	time 0.5207 (0.5344)	data time 0.0062 (0.0504)	model time 0.5146 (0.4816)	loss 0.5383 (0.5982)	grad_norm 1.6689 (1.8737)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:32:03 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][120/156]	eta 0:00:19 lr 0.000103	 wd 0.0500	time 0.4471 (0.5349)	data time 0.0221 (0.0472)	model time 0.4250 (0.4884)	loss 0.6228 (0.5993)	grad_norm 1.2601 (1.8368)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:32:08 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][130/156]	eta 0:00:13 lr 0.000103	 wd 0.0500	time 0.4367 (0.5307)	data time 0.0044 (0.0446)	model time 0.4324 (0.4858)	loss 0.6246 (0.5966)	grad_norm 1.7609 (1.8384)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:32:13 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][140/156]	eta 0:00:08 lr 0.000103	 wd 0.0500	time 0.5283 (0.5327)	data time 0.0009 (0.0426)	model time 0.5274 (0.4919)	loss 0.6137 (0.5988)	grad_norm 1.9726 (1.8731)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:32:19 vssm1_tiny_0230s](training.py 201): INFO Train: [96/300][150/156]	eta 0:00:03 lr 0.000103	 wd 0.0500	time 0.4998 (0.5326)	data time 0.0004 (0.0402)	model time 0.4994 (0.4952)	loss 0.6371 (0.5989)	grad_norm 1.6703 (1.8735)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:32:22 vssm1_tiny_0230s](training.py 212): INFO EPOCH 96 training takes 0:01:23
[2024-11-09 13:32:22 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_96.pth saving......
[2024-11-09 13:32:22 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_96.pth saved !!!
[2024-11-09 13:32:25 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.631 (2.631)	Loss 0.2264 (0.2264)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:32:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.248 (0.526)	Loss 0.2534 (0.2444)	Acc@1 93.750 (94.389)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:32:30 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.203 (0.391)	Loss 0.3115 (0.2609)	Acc@1 90.625 (93.006)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:32:33 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.344)	Loss 0.3740 (0.2923)	Acc@1 83.594 (90.902)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:32:36 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.960 Acc@5 100.000
[2024-11-09 13:32:36 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 90.0%
[2024-11-09 13:32:36 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 89.96%
[2024-11-09 13:32:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.248 (4.248)	Loss 0.3433 (0.3433)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:32:42 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.562)	Loss 0.3506 (0.3474)	Acc@1 98.438 (98.722)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:32:44 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.184 (0.416)	Loss 0.8237 (0.3843)	Acc@1 32.812 (93.527)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:32:47 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.196 (0.354)	Loss 0.8994 (0.5387)	Acc@1 28.125 (72.782)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:32:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 63.540 Acc@5 100.000
[2024-11-09 13:32:49 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 63.5%
[2024-11-09 13:32:49 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 63.54%
[2024-11-09 13:32:53 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][0/156]	eta 0:11:27 lr 0.000103	 wd 0.0500	time 4.4080 (4.4080)	data time 3.8415 (3.8415)	model time 0.0000 (0.0000)	loss 0.5792 (0.5792)	grad_norm 1.6288 (1.6288)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:32:59 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][10/156]	eta 0:02:09 lr 0.000103	 wd 0.0500	time 0.5154 (0.8857)	data time 0.0255 (0.3656)	model time 0.0000 (0.0000)	loss 0.5929 (0.6035)	grad_norm 4.3329 (1.9864)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:04 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][20/156]	eta 0:01:34 lr 0.000103	 wd 0.0500	time 0.4112 (0.6962)	data time 0.0021 (0.1984)	model time 0.0000 (0.0000)	loss 0.6223 (0.6152)	grad_norm 1.7778 (1.9453)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:09 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][30/156]	eta 0:01:21 lr 0.000103	 wd 0.0500	time 0.4711 (0.6498)	data time 0.0235 (0.1435)	model time 0.0000 (0.0000)	loss 0.6420 (0.6078)	grad_norm 1.8660 (1.9400)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:14 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][40/156]	eta 0:01:10 lr 0.000103	 wd 0.0500	time 0.5098 (0.6104)	data time 0.0009 (0.1101)	model time 0.0000 (0.0000)	loss 0.6358 (0.6075)	grad_norm 1.4171 (1.9531)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:19 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][50/156]	eta 0:01:02 lr 0.000103	 wd 0.0500	time 0.4470 (0.5855)	data time 0.0246 (0.0912)	model time 0.0000 (0.0000)	loss 0.6198 (0.6103)	grad_norm 1.4963 (1.8518)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:24 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][60/156]	eta 0:00:54 lr 0.000103	 wd 0.0500	time 0.5156 (0.5725)	data time 0.0006 (0.0787)	model time 0.5149 (0.4914)	loss 0.5401 (0.6078)	grad_norm 1.9710 (1.8135)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:29 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][70/156]	eta 0:00:48 lr 0.000103	 wd 0.0500	time 0.4570 (0.5625)	data time 0.0058 (0.0694)	model time 0.4512 (0.4903)	loss 0.4765 (0.6044)	grad_norm 1.2661 (1.7628)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:34 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][80/156]	eta 0:00:42 lr 0.000103	 wd 0.0500	time 0.8056 (0.5588)	data time 0.0327 (0.0630)	model time 0.7728 (0.4984)	loss 0.6366 (0.6054)	grad_norm 2.1648 (1.7866)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:39 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][90/156]	eta 0:00:36 lr 0.000103	 wd 0.0500	time 0.6138 (0.5543)	data time 0.0272 (0.0582)	model time 0.5866 (0.4985)	loss 0.6184 (0.6055)	grad_norm 1.5308 (1.7887)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:45 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][100/156]	eta 0:00:30 lr 0.000103	 wd 0.0500	time 0.4677 (0.5527)	data time 0.0006 (0.0547)	model time 0.4671 (0.5018)	loss 0.6611 (0.6057)	grad_norm 1.8359 (1.7999)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:50 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][110/156]	eta 0:00:25 lr 0.000103	 wd 0.0500	time 0.4706 (0.5483)	data time 0.0238 (0.0515)	model time 0.4468 (0.4989)	loss 0.5143 (0.6029)	grad_norm 2.5591 (1.7832)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:33:55 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][120/156]	eta 0:00:19 lr 0.000103	 wd 0.0500	time 0.4372 (0.5443)	data time 0.0288 (0.0493)	model time 0.4084 (0.4955)	loss 0.5221 (0.6044)	grad_norm 2.5846 (1.7643)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:34:00 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][130/156]	eta 0:00:14 lr 0.000103	 wd 0.0500	time 0.5759 (0.5447)	data time 0.0046 (0.0465)	model time 0.5714 (0.5006)	loss 0.6342 (0.6036)	grad_norm 1.2927 (1.7451)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:34:05 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][140/156]	eta 0:00:08 lr 0.000103	 wd 0.0500	time 0.4253 (0.5418)	data time 0.0008 (0.0442)	model time 0.4245 (0.4995)	loss 0.6469 (0.6035)	grad_norm 1.3562 (1.7278)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:34:10 vssm1_tiny_0230s](training.py 201): INFO Train: [97/300][150/156]	eta 0:00:03 lr 0.000103	 wd 0.0500	time 0.4968 (0.5374)	data time 0.0006 (0.0415)	model time 0.4962 (0.4967)	loss 0.6150 (0.6050)	grad_norm 1.8696 (1.7537)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:34:13 vssm1_tiny_0230s](training.py 212): INFO EPOCH 97 training takes 0:01:24
[2024-11-09 13:34:13 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_97.pth saving......
[2024-11-09 13:34:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_97.pth saved !!!
[2024-11-09 13:34:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.464 (3.464)	Loss 0.3867 (0.3867)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:34:21 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.628)	Loss 0.4084 (0.4014)	Acc@1 84.375 (83.736)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:34:23 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.438)	Loss 0.2135 (0.4008)	Acc@1 97.656 (83.854)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:34:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.366)	Loss 0.2578 (0.3513)	Acc@1 95.312 (87.626)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:34:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.320 Acc@5 100.000
[2024-11-09 13:34:27 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 89.3%
[2024-11-09 13:34:27 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 89.96%
[2024-11-09 13:34:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.014 (4.014)	Loss 0.3418 (0.3418)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:34:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.142 (0.568)	Loss 0.3489 (0.3457)	Acc@1 98.438 (98.651)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:34:35 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.380)	Loss 0.8213 (0.3827)	Acc@1 33.594 (93.527)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:34:37 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.315)	Loss 0.8979 (0.5371)	Acc@1 29.688 (72.933)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:34:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 63.800 Acc@5 100.000
[2024-11-09 13:34:40 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 63.8%
[2024-11-09 13:34:40 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 63.80%
[2024-11-09 13:34:44 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][0/156]	eta 0:11:59 lr 0.000103	 wd 0.0500	time 4.6151 (4.6151)	data time 3.8523 (3.8523)	model time 0.0000 (0.0000)	loss 0.6901 (0.6901)	grad_norm 1.8351 (1.8351)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:34:49 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][10/156]	eta 0:02:08 lr 0.000103	 wd 0.0500	time 0.5017 (0.8833)	data time 0.0304 (0.3677)	model time 0.0000 (0.0000)	loss 0.5469 (0.6211)	grad_norm 1.5419 (1.6866)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:34:55 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][20/156]	eta 0:01:36 lr 0.000103	 wd 0.0500	time 0.5591 (0.7126)	data time 0.0226 (0.1966)	model time 0.0000 (0.0000)	loss 0.5479 (0.6030)	grad_norm 3.7050 (1.7469)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:00 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][30/156]	eta 0:01:21 lr 0.000103	 wd 0.0500	time 0.4701 (0.6500)	data time 0.0127 (0.1394)	model time 0.0000 (0.0000)	loss 0.5099 (0.6043)	grad_norm 1.9796 (1.7327)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:05 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][40/156]	eta 0:01:11 lr 0.000103	 wd 0.0500	time 0.5186 (0.6185)	data time 0.0059 (0.1131)	model time 0.0000 (0.0000)	loss 0.6126 (0.5984)	grad_norm 1.0312 (1.6679)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:10 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][50/156]	eta 0:01:03 lr 0.000103	 wd 0.0500	time 0.4202 (0.6010)	data time 0.0009 (0.0942)	model time 0.0000 (0.0000)	loss 0.6079 (0.5983)	grad_norm 1.5564 (1.7106)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:15 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][60/156]	eta 0:00:56 lr 0.000103	 wd 0.0500	time 0.5445 (0.5882)	data time 0.0031 (0.0815)	model time 0.5414 (0.5068)	loss 0.5473 (0.5987)	grad_norm 2.4435 (1.7687)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:21 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][70/156]	eta 0:00:49 lr 0.000103	 wd 0.0500	time 0.4276 (0.5767)	data time 0.0092 (0.0718)	model time 0.4185 (0.5004)	loss 0.6275 (0.6003)	grad_norm 1.5615 (1.7275)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:26 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][80/156]	eta 0:00:43 lr 0.000103	 wd 0.0500	time 0.5164 (0.5698)	data time 0.0230 (0.0666)	model time 0.4933 (0.4973)	loss 0.5730 (0.5994)	grad_norm 0.9880 (1.7748)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:32 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][90/156]	eta 0:00:37 lr 0.000102	 wd 0.0500	time 0.4329 (0.5707)	data time 0.0236 (0.0622)	model time 0.4093 (0.5107)	loss 0.5344 (0.6007)	grad_norm 1.8441 (1.7469)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:37 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][100/156]	eta 0:00:31 lr 0.000102	 wd 0.0500	time 0.6139 (0.5665)	data time 0.0015 (0.0576)	model time 0.6125 (0.5112)	loss 0.5571 (0.5996)	grad_norm 1.3195 (1.7052)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:42 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][110/156]	eta 0:00:25 lr 0.000102	 wd 0.0500	time 0.5678 (0.5635)	data time 0.0099 (0.0535)	model time 0.5579 (0.5128)	loss 0.5693 (0.5967)	grad_norm 1.2770 (1.7337)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:47 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][120/156]	eta 0:00:20 lr 0.000102	 wd 0.0500	time 0.4571 (0.5581)	data time 0.0012 (0.0502)	model time 0.4559 (0.5087)	loss 0.5802 (0.5955)	grad_norm 1.6106 (1.8140)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:52 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][130/156]	eta 0:00:14 lr 0.000102	 wd 0.0500	time 0.4891 (0.5545)	data time 0.0368 (0.0475)	model time 0.4523 (0.5071)	loss 0.5848 (0.5959)	grad_norm 1.2436 (1.8810)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:35:57 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][140/156]	eta 0:00:08 lr 0.000102	 wd 0.0500	time 0.5207 (0.5501)	data time 0.0012 (0.0455)	model time 0.5195 (0.5035)	loss 0.6143 (0.5955)	grad_norm 1.3689 (1.8983)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:36:02 vssm1_tiny_0230s](training.py 201): INFO Train: [98/300][150/156]	eta 0:00:03 lr 0.000102	 wd 0.0500	time 0.6256 (0.5471)	data time 0.0005 (0.0425)	model time 0.6252 (0.5034)	loss 0.5838 (0.5949)	grad_norm 1.8274 (1.9080)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:36:05 vssm1_tiny_0230s](training.py 212): INFO EPOCH 98 training takes 0:01:25
[2024-11-09 13:36:05 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_98.pth saving......
[2024-11-09 13:36:05 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_98.pth saved !!!
[2024-11-09 13:36:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.978 (2.978)	Loss 0.3525 (0.3525)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:36:11 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.506)	Loss 0.3728 (0.3685)	Acc@1 85.938 (84.162)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:36:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.350)	Loss 0.2218 (0.3687)	Acc@1 96.875 (84.747)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:36:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.323)	Loss 0.2783 (0.3320)	Acc@1 91.406 (87.777)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:36:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.220 Acc@5 100.000
[2024-11-09 13:36:17 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 89.2%
[2024-11-09 13:36:17 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 89.96%
[2024-11-09 13:36:20 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.797 (2.797)	Loss 0.3406 (0.3406)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:36:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.425 (0.447)	Loss 0.3479 (0.3446)	Acc@1 98.438 (98.651)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:36:25 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.386 (0.374)	Loss 0.8174 (0.3815)	Acc@1 33.594 (93.527)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:36:27 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.167 (0.323)	Loss 0.8950 (0.5353)	Acc@1 29.688 (73.110)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:36:30 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 64.020 Acc@5 100.000
[2024-11-09 13:36:30 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 64.0%
[2024-11-09 13:36:30 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 64.02%
[2024-11-09 13:36:34 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][0/156]	eta 0:10:22 lr 0.000102	 wd 0.0500	time 3.9877 (3.9877)	data time 3.4360 (3.4360)	model time 0.0000 (0.0000)	loss 0.5855 (0.5855)	grad_norm 1.7006 (1.7006)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:36:39 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][10/156]	eta 0:02:00 lr 0.000102	 wd 0.0500	time 0.4472 (0.8265)	data time 0.0005 (0.3411)	model time 0.0000 (0.0000)	loss 0.6223 (0.5826)	grad_norm 1.5718 (1.7543)	loss_scale 131072.0000 (101282.9091)	mem 13675MB
[2024-11-09 13:36:44 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][20/156]	eta 0:01:28 lr 0.000102	 wd 0.0500	time 0.4499 (0.6504)	data time 0.0007 (0.1834)	model time 0.0000 (0.0000)	loss 0.5905 (0.5846)	grad_norm 1.2135 (1.8056)	loss_scale 131072.0000 (115468.1905)	mem 13675MB
[2024-11-09 13:36:49 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][30/156]	eta 0:01:17 lr 0.000102	 wd 0.0500	time 0.5816 (0.6184)	data time 0.0460 (0.1329)	model time 0.0000 (0.0000)	loss 0.5638 (0.5819)	grad_norm 3.6652 (inf)	loss_scale 65536.0000 (112045.4194)	mem 13675MB
[2024-11-09 13:36:55 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][40/156]	eta 0:01:09 lr 0.000102	 wd 0.0500	time 0.4882 (0.5963)	data time 0.0008 (0.1032)	model time 0.0000 (0.0000)	loss 0.6272 (0.5902)	grad_norm 1.4252 (inf)	loss_scale 65536.0000 (100701.6585)	mem 13675MB
[2024-11-09 13:36:59 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][50/156]	eta 0:01:00 lr 0.000102	 wd 0.0500	time 0.4342 (0.5741)	data time 0.0120 (0.0869)	model time 0.0000 (0.0000)	loss 0.6308 (0.5945)	grad_norm 0.8826 (inf)	loss_scale 65536.0000 (93806.4314)	mem 13675MB
[2024-11-09 13:37:05 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][60/156]	eta 0:00:54 lr 0.000102	 wd 0.0500	time 0.5277 (0.5669)	data time 0.0220 (0.0752)	model time 0.5057 (0.5142)	loss 0.6379 (0.5967)	grad_norm 1.7983 (inf)	loss_scale 65536.0000 (89171.9344)	mem 13675MB
[2024-11-09 13:37:10 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][70/156]	eta 0:00:48 lr 0.000102	 wd 0.0500	time 0.5778 (0.5669)	data time 0.0216 (0.0678)	model time 0.5562 (0.5294)	loss 0.5972 (0.5977)	grad_norm 1.6245 (inf)	loss_scale 65536.0000 (85842.9296)	mem 13675MB
[2024-11-09 13:37:15 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][80/156]	eta 0:00:42 lr 0.000102	 wd 0.0500	time 0.4759 (0.5593)	data time 0.0044 (0.0612)	model time 0.4716 (0.5167)	loss 0.6431 (0.5994)	grad_norm 2.3826 (inf)	loss_scale 65536.0000 (83335.9012)	mem 13675MB
[2024-11-09 13:37:21 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][90/156]	eta 0:00:36 lr 0.000102	 wd 0.0500	time 0.5538 (0.5600)	data time 0.0366 (0.0573)	model time 0.5172 (0.5224)	loss 0.6408 (0.5980)	grad_norm 1.0464 (inf)	loss_scale 65536.0000 (81379.8681)	mem 13675MB
[2024-11-09 13:37:26 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][100/156]	eta 0:00:31 lr 0.000102	 wd 0.0500	time 0.4143 (0.5539)	data time 0.0008 (0.0538)	model time 0.4135 (0.5132)	loss 0.6024 (0.5967)	grad_norm 2.3797 (inf)	loss_scale 65536.0000 (79811.1683)	mem 13675MB
[2024-11-09 13:37:31 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][110/156]	eta 0:00:25 lr 0.000102	 wd 0.0500	time 0.4155 (0.5493)	data time 0.0046 (0.0499)	model time 0.4109 (0.5097)	loss 0.6120 (0.5965)	grad_norm 1.7857 (inf)	loss_scale 65536.0000 (78525.1171)	mem 13675MB
[2024-11-09 13:37:36 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][120/156]	eta 0:00:19 lr 0.000102	 wd 0.0500	time 0.4589 (0.5463)	data time 0.0009 (0.0475)	model time 0.4580 (0.5073)	loss 0.5593 (0.5957)	grad_norm 3.1950 (inf)	loss_scale 65536.0000 (77451.6364)	mem 13675MB
[2024-11-09 13:37:41 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][130/156]	eta 0:00:14 lr 0.000102	 wd 0.0500	time 0.4948 (0.5445)	data time 0.0143 (0.0467)	model time 0.4805 (0.5047)	loss 0.6683 (0.5969)	grad_norm 1.2833 (inf)	loss_scale 65536.0000 (76542.0458)	mem 13675MB
[2024-11-09 13:37:46 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][140/156]	eta 0:00:08 lr 0.000102	 wd 0.0500	time 0.4525 (0.5398)	data time 0.0114 (0.0442)	model time 0.4412 (0.5005)	loss 0.6612 (0.5965)	grad_norm 1.9929 (inf)	loss_scale 65536.0000 (75761.4752)	mem 13675MB
[2024-11-09 13:37:51 vssm1_tiny_0230s](training.py 201): INFO Train: [99/300][150/156]	eta 0:00:03 lr 0.000102	 wd 0.0500	time 0.5182 (0.5362)	data time 0.0007 (0.0413)	model time 0.5175 (0.4989)	loss 0.5036 (0.5949)	grad_norm 3.0598 (inf)	loss_scale 65536.0000 (75084.2914)	mem 13675MB
[2024-11-09 13:37:54 vssm1_tiny_0230s](training.py 212): INFO EPOCH 99 training takes 0:01:23
[2024-11-09 13:37:54 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_99.pth saving......
[2024-11-09 13:37:54 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_99.pth saved !!!
[2024-11-09 13:37:58 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.967 (3.967)	Loss 0.2935 (0.2935)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:38:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.168 (0.622)	Loss 0.3291 (0.3125)	Acc@1 87.500 (87.784)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:38:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.214 (0.434)	Loss 0.2019 (0.3209)	Acc@1 96.875 (87.165)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:38:06 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.156 (0.375)	Loss 0.2639 (0.2963)	Acc@1 91.406 (89.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:38:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.380 Acc@5 100.000
[2024-11-09 13:38:08 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 90.4%
[2024-11-09 13:38:08 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 90.38%
[2024-11-09 13:38:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.888 (2.888)	Loss 0.3394 (0.3394)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:38:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.782 (0.483)	Loss 0.3464 (0.3434)	Acc@1 98.438 (98.580)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:38:16 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.355)	Loss 0.8140 (0.3801)	Acc@1 33.594 (93.527)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:38:19 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.161 (0.340)	Loss 0.8926 (0.5335)	Acc@1 29.688 (73.160)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:38:21 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 64.080 Acc@5 100.000
[2024-11-09 13:38:21 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 64.1%
[2024-11-09 13:38:21 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 64.08%
[2024-11-09 13:38:25 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][0/156]	eta 0:10:04 lr 0.000102	 wd 0.0500	time 3.8724 (3.8724)	data time 3.4151 (3.4151)	model time 0.0000 (0.0000)	loss 0.6084 (0.6084)	grad_norm 2.1053 (2.1053)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:38:29 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][10/156]	eta 0:01:57 lr 0.000102	 wd 0.0500	time 0.5156 (0.8023)	data time 0.0058 (0.3299)	model time 0.0000 (0.0000)	loss 0.5353 (0.5884)	grad_norm 3.1108 (2.0972)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:38:35 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][20/156]	eta 0:01:30 lr 0.000102	 wd 0.0500	time 0.4620 (0.6666)	data time 0.0058 (0.1807)	model time 0.0000 (0.0000)	loss 0.6840 (0.5943)	grad_norm 1.2264 (1.8999)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:38:40 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][30/156]	eta 0:01:16 lr 0.000102	 wd 0.0500	time 0.7183 (0.6106)	data time 0.0579 (0.1311)	model time 0.0000 (0.0000)	loss 0.5871 (0.5995)	grad_norm 0.9164 (1.7979)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:38:45 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][40/156]	eta 0:01:08 lr 0.000102	 wd 0.0500	time 0.6207 (0.5873)	data time 0.0419 (0.1018)	model time 0.0000 (0.0000)	loss 0.6644 (0.6018)	grad_norm 1.7752 (1.7489)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:38:50 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][50/156]	eta 0:01:01 lr 0.000102	 wd 0.0500	time 0.4818 (0.5815)	data time 0.0126 (0.0850)	model time 0.0000 (0.0000)	loss 0.5884 (0.5962)	grad_norm 2.9437 (1.8430)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:38:55 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][60/156]	eta 0:00:54 lr 0.000101	 wd 0.0500	time 0.5625 (0.5699)	data time 0.0537 (0.0733)	model time 0.5088 (0.4968)	loss 0.6561 (0.5972)	grad_norm 2.4637 (1.8815)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:39:00 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][70/156]	eta 0:00:48 lr 0.000101	 wd 0.0500	time 0.6204 (0.5591)	data time 0.0139 (0.0647)	model time 0.6066 (0.4892)	loss 0.6631 (0.5978)	grad_norm 2.0081 (1.9257)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:39:05 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][80/156]	eta 0:00:41 lr 0.000101	 wd 0.0500	time 0.4341 (0.5519)	data time 0.0008 (0.0606)	model time 0.4333 (0.4826)	loss 0.5673 (0.5975)	grad_norm 1.8292 (1.9100)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:39:10 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][90/156]	eta 0:00:35 lr 0.000101	 wd 0.0500	time 0.4503 (0.5426)	data time 0.0223 (0.0560)	model time 0.4281 (0.4739)	loss 0.5813 (0.5951)	grad_norm 1.9287 (1.8988)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:39:15 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][100/156]	eta 0:00:30 lr 0.000101	 wd 0.0500	time 0.7839 (0.5420)	data time 0.0008 (0.0516)	model time 0.7831 (0.4843)	loss 0.6368 (0.5959)	grad_norm 2.4973 (1.9184)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:39:20 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][110/156]	eta 0:00:24 lr 0.000101	 wd 0.0500	time 0.4198 (0.5377)	data time 0.0012 (0.0478)	model time 0.4186 (0.4842)	loss 0.6306 (0.5959)	grad_norm 1.7237 (1.9165)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:39:26 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][120/156]	eta 0:00:19 lr 0.000101	 wd 0.0500	time 0.4594 (0.5370)	data time 0.0492 (0.0449)	model time 0.4102 (0.4889)	loss 0.5854 (0.5977)	grad_norm 1.7734 (1.9044)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:39:30 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][130/156]	eta 0:00:13 lr 0.000101	 wd 0.0500	time 0.5140 (0.5332)	data time 0.0586 (0.0432)	model time 0.4554 (0.4858)	loss 0.5050 (0.5956)	grad_norm 1.0880 (1.8861)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:39:36 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][140/156]	eta 0:00:08 lr 0.000101	 wd 0.0500	time 0.4631 (0.5322)	data time 0.0078 (0.0409)	model time 0.4552 (0.4884)	loss 0.5179 (0.5951)	grad_norm 1.4753 (1.8633)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:39:40 vssm1_tiny_0230s](training.py 201): INFO Train: [100/300][150/156]	eta 0:00:03 lr 0.000101	 wd 0.0500	time 0.4681 (0.5277)	data time 0.0041 (0.0383)	model time 0.4640 (0.4858)	loss 0.5846 (0.5955)	grad_norm 1.0736 (1.8756)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:39:43 vssm1_tiny_0230s](training.py 212): INFO EPOCH 100 training takes 0:01:22
[2024-11-09 13:39:43 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_100.pth saving......
[2024-11-09 13:39:43 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_100.pth saved !!!
[2024-11-09 13:39:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.203 (2.203)	Loss 0.2411 (0.2411)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:39:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.427)	Loss 0.2598 (0.2565)	Acc@1 92.188 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:39:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.324)	Loss 0.2500 (0.2719)	Acc@1 95.312 (91.555)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:39:52 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.171 (0.288)	Loss 0.3044 (0.2799)	Acc@1 89.844 (91.053)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:39:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.160 Acc@5 100.000
[2024-11-09 13:39:55 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.2%
[2024-11-09 13:39:55 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.16%
[2024-11-09 13:39:58 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.404 (2.404)	Loss 0.3376 (0.3376)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:40:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.927 (0.564)	Loss 0.3447 (0.3416)	Acc@1 98.438 (98.580)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:40:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.213 (0.405)	Loss 0.8115 (0.3784)	Acc@1 33.594 (93.527)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:40:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.235 (0.366)	Loss 0.8911 (0.5318)	Acc@1 29.688 (73.211)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:40:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 64.140 Acc@5 100.000
[2024-11-09 13:40:08 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 64.1%
[2024-11-09 13:40:08 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 64.14%
[2024-11-09 13:40:13 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][0/156]	eta 0:12:09 lr 0.000101	 wd 0.0500	time 4.6738 (4.6738)	data time 4.2224 (4.2224)	model time 0.0000 (0.0000)	loss 0.5833 (0.5833)	grad_norm 1.6591 (1.6591)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:40:18 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][10/156]	eta 0:02:03 lr 0.000101	 wd 0.0500	time 0.4143 (0.8425)	data time 0.0007 (0.3921)	model time 0.0000 (0.0000)	loss 0.5791 (0.5870)	grad_norm 2.2194 (1.9310)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:40:23 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][20/156]	eta 0:01:31 lr 0.000101	 wd 0.0500	time 0.4889 (0.6725)	data time 0.0007 (0.2124)	model time 0.0000 (0.0000)	loss 0.5992 (0.5965)	grad_norm 1.3980 (1.9309)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:40:28 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][30/156]	eta 0:01:18 lr 0.000101	 wd 0.0500	time 0.5329 (0.6246)	data time 0.0007 (0.1558)	model time 0.0000 (0.0000)	loss 0.6575 (0.5923)	grad_norm 1.4594 (1.9770)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:40:33 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][40/156]	eta 0:01:08 lr 0.000101	 wd 0.0500	time 0.4593 (0.5944)	data time 0.0011 (0.1196)	model time 0.0000 (0.0000)	loss 0.6328 (0.5907)	grad_norm 2.7340 (2.0413)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:40:38 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][50/156]	eta 0:01:01 lr 0.000101	 wd 0.0500	time 0.4275 (0.5801)	data time 0.0015 (0.0986)	model time 0.0000 (0.0000)	loss 0.5340 (0.5913)	grad_norm 2.8187 (2.1094)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:40:43 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][60/156]	eta 0:00:54 lr 0.000101	 wd 0.0500	time 0.5576 (0.5674)	data time 0.0268 (0.0845)	model time 0.5308 (0.4896)	loss 0.5959 (0.5915)	grad_norm 1.6451 (2.0680)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:40:48 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][70/156]	eta 0:00:48 lr 0.000101	 wd 0.0500	time 0.6350 (0.5619)	data time 0.0254 (0.0752)	model time 0.6096 (0.4997)	loss 0.5621 (0.5940)	grad_norm 2.3000 (2.0873)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:40:54 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][80/156]	eta 0:00:42 lr 0.000101	 wd 0.0500	time 0.7079 (0.5601)	data time 0.0271 (0.0690)	model time 0.6808 (0.5075)	loss 0.6069 (0.5950)	grad_norm 2.8566 (2.0705)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:40:59 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][90/156]	eta 0:00:36 lr 0.000101	 wd 0.0500	time 0.4933 (0.5585)	data time 0.0019 (0.0637)	model time 0.4914 (0.5119)	loss 0.6181 (0.5975)	grad_norm 1.5070 (2.0352)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:41:04 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][100/156]	eta 0:00:31 lr 0.000101	 wd 0.0500	time 0.4906 (0.5547)	data time 0.0007 (0.0589)	model time 0.4899 (0.5104)	loss 0.5691 (0.5950)	grad_norm 1.3893 (1.9956)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:41:10 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][110/156]	eta 0:00:25 lr 0.000101	 wd 0.0500	time 0.5121 (0.5516)	data time 0.0356 (0.0548)	model time 0.4765 (0.5097)	loss 0.6452 (0.5958)	grad_norm 2.0305 (1.9910)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:41:14 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][120/156]	eta 0:00:19 lr 0.000101	 wd 0.0500	time 0.5521 (0.5461)	data time 0.0273 (0.0514)	model time 0.5249 (0.5043)	loss 0.6222 (0.5974)	grad_norm 1.1409 (1.9670)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:41:20 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][130/156]	eta 0:00:14 lr 0.000101	 wd 0.0500	time 0.4883 (0.5455)	data time 0.0342 (0.0501)	model time 0.4541 (0.5042)	loss 0.5099 (0.5975)	grad_norm 1.6982 (1.9616)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:41:25 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][140/156]	eta 0:00:08 lr 0.000101	 wd 0.0500	time 0.4563 (0.5411)	data time 0.0009 (0.0476)	model time 0.4554 (0.5003)	loss 0.5835 (0.5976)	grad_norm 3.2206 (1.9542)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:41:29 vssm1_tiny_0230s](training.py 201): INFO Train: [101/300][150/156]	eta 0:00:03 lr 0.000101	 wd 0.0500	time 0.4632 (0.5356)	data time 0.0005 (0.0446)	model time 0.4628 (0.4959)	loss 0.6105 (0.5988)	grad_norm 1.2887 (1.9341)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:41:32 vssm1_tiny_0230s](training.py 212): INFO EPOCH 101 training takes 0:01:23
[2024-11-09 13:41:32 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_101.pth saving......
[2024-11-09 13:41:32 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_101.pth saved !!!
[2024-11-09 13:41:37 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.415 (4.415)	Loss 0.2793 (0.2793)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:41:38 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.153 (0.548)	Loss 0.3049 (0.2959)	Acc@1 89.844 (90.412)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:41:40 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.383)	Loss 0.2546 (0.3060)	Acc@1 93.750 (89.509)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:41:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.315 (0.327)	Loss 0.3127 (0.3028)	Acc@1 90.625 (90.222)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:41:45 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.760 Acc@5 100.000
[2024-11-09 13:41:45 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 90.8%
[2024-11-09 13:41:45 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.16%
[2024-11-09 13:41:48 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.115 (3.115)	Loss 0.3359 (0.3359)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:41:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.269 (0.604)	Loss 0.3430 (0.3398)	Acc@1 98.438 (98.580)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:41:54 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.422)	Loss 0.8091 (0.3766)	Acc@1 33.594 (93.564)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:41:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.364)	Loss 0.8896 (0.5299)	Acc@1 29.688 (73.412)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:41:59 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 64.380 Acc@5 100.000
[2024-11-09 13:41:59 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 64.4%
[2024-11-09 13:41:59 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 64.38%
[2024-11-09 13:42:03 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][0/156]	eta 0:09:42 lr 0.000101	 wd 0.0500	time 3.7345 (3.7345)	data time 3.1444 (3.1444)	model time 0.0000 (0.0000)	loss 0.6199 (0.6199)	grad_norm 1.4926 (1.4926)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:08 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][10/156]	eta 0:02:02 lr 0.000101	 wd 0.0500	time 0.5210 (0.8397)	data time 0.0006 (0.3062)	model time 0.0000 (0.0000)	loss 0.6541 (0.5967)	grad_norm 2.1137 (2.0441)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:13 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][20/156]	eta 0:01:32 lr 0.000101	 wd 0.0500	time 0.4551 (0.6817)	data time 0.0006 (0.1666)	model time 0.0000 (0.0000)	loss 0.5647 (0.5687)	grad_norm 3.1658 (2.1896)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:18 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][30/156]	eta 0:01:18 lr 0.000101	 wd 0.0500	time 0.5411 (0.6250)	data time 0.0029 (0.1183)	model time 0.0000 (0.0000)	loss 0.6372 (0.5768)	grad_norm 1.5882 (2.2337)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:23 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][40/156]	eta 0:01:08 lr 0.000100	 wd 0.0500	time 0.4587 (0.5894)	data time 0.0052 (0.0921)	model time 0.0000 (0.0000)	loss 0.6000 (0.5772)	grad_norm 1.5485 (2.1686)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:29 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][50/156]	eta 0:01:01 lr 0.000100	 wd 0.0500	time 0.5126 (0.5768)	data time 0.0211 (0.0792)	model time 0.0000 (0.0000)	loss 0.6546 (0.5807)	grad_norm 1.4254 (2.1387)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:34 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][60/156]	eta 0:00:54 lr 0.000100	 wd 0.0500	time 0.5571 (0.5668)	data time 0.0078 (0.0688)	model time 0.5494 (0.4996)	loss 0.6440 (0.5839)	grad_norm 1.5704 (2.1182)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:39 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][70/156]	eta 0:00:48 lr 0.000100	 wd 0.0500	time 0.4997 (0.5627)	data time 0.0189 (0.0638)	model time 0.4807 (0.5020)	loss 0.4923 (0.5836)	grad_norm 1.5955 (2.0702)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:44 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][80/156]	eta 0:00:41 lr 0.000100	 wd 0.0500	time 0.4135 (0.5524)	data time 0.0008 (0.0574)	model time 0.4126 (0.4903)	loss 0.5869 (0.5822)	grad_norm 1.2441 (2.0828)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:49 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][90/156]	eta 0:00:36 lr 0.000100	 wd 0.0500	time 0.4608 (0.5467)	data time 0.0128 (0.0523)	model time 0.4480 (0.4902)	loss 0.6392 (0.5861)	grad_norm 1.3784 (2.0692)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:54 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][100/156]	eta 0:00:30 lr 0.000100	 wd 0.0500	time 0.4975 (0.5426)	data time 0.0028 (0.0488)	model time 0.4947 (0.4899)	loss 0.6099 (0.5851)	grad_norm 1.4793 (2.0503)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:42:59 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][110/156]	eta 0:00:24 lr 0.000100	 wd 0.0500	time 0.4815 (0.5404)	data time 0.0042 (0.0454)	model time 0.4773 (0.4927)	loss 0.5246 (0.5866)	grad_norm 2.0013 (2.0355)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:43:04 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][120/156]	eta 0:00:19 lr 0.000100	 wd 0.0500	time 0.5845 (0.5374)	data time 0.0370 (0.0430)	model time 0.5475 (0.4921)	loss 0.5679 (0.5861)	grad_norm 2.1979 (2.0224)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:43:09 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][130/156]	eta 0:00:13 lr 0.000100	 wd 0.0500	time 0.4333 (0.5344)	data time 0.0203 (0.0410)	model time 0.4131 (0.4907)	loss 0.5482 (0.5871)	grad_norm 1.7691 (1.9969)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:43:14 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][140/156]	eta 0:00:08 lr 0.000100	 wd 0.0500	time 0.5195 (0.5326)	data time 0.0009 (0.0390)	model time 0.5186 (0.4914)	loss 0.5108 (0.5868)	grad_norm 2.7352 (2.0248)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:43:19 vssm1_tiny_0230s](training.py 201): INFO Train: [102/300][150/156]	eta 0:00:03 lr 0.000100	 wd 0.0500	time 0.4116 (0.5287)	data time 0.0004 (0.0364)	model time 0.4112 (0.4895)	loss 0.6314 (0.5867)	grad_norm 3.2319 (2.0640)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:43:22 vssm1_tiny_0230s](training.py 212): INFO EPOCH 102 training takes 0:01:22
[2024-11-09 13:43:22 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_102.pth saving......
[2024-11-09 13:43:22 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_102.pth saved !!!
[2024-11-09 13:43:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.876 (3.876)	Loss 0.2286 (0.2286)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:43:29 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.578)	Loss 0.2500 (0.2473)	Acc@1 93.750 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:43:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.165 (0.455)	Loss 0.2595 (0.2628)	Acc@1 93.750 (91.592)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:43:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.428)	Loss 0.3281 (0.2823)	Acc@1 88.281 (90.575)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:43:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.360 Acc@5 100.000
[2024-11-09 13:43:38 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 90.4%
[2024-11-09 13:43:38 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.16%
[2024-11-09 13:43:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.795 (2.795)	Loss 0.3345 (0.3345)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:43:44 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.801 (0.524)	Loss 0.3416 (0.3384)	Acc@1 98.438 (98.580)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:43:46 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.375)	Loss 0.8057 (0.3751)	Acc@1 35.156 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:43:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.199 (0.364)	Loss 0.8867 (0.5281)	Acc@1 29.688 (73.614)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:43:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 64.700 Acc@5 100.000
[2024-11-09 13:43:51 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 64.7%
[2024-11-09 13:43:51 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 64.70%
[2024-11-09 13:43:55 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][0/156]	eta 0:09:23 lr 0.000100	 wd 0.0500	time 3.6133 (3.6133)	data time 3.0390 (3.0390)	model time 0.0000 (0.0000)	loss 0.5584 (0.5584)	grad_norm 3.1215 (3.1215)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:00 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][10/156]	eta 0:01:53 lr 0.000100	 wd 0.0500	time 0.4655 (0.7758)	data time 0.0594 (0.3079)	model time 0.0000 (0.0000)	loss 0.6069 (0.6066)	grad_norm 1.4056 (2.0936)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:05 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][20/156]	eta 0:01:29 lr 0.000100	 wd 0.0500	time 0.4811 (0.6614)	data time 0.0036 (0.1646)	model time 0.0000 (0.0000)	loss 0.5542 (0.5990)	grad_norm 1.2913 (1.9057)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:10 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][30/156]	eta 0:01:18 lr 0.000100	 wd 0.0500	time 0.4395 (0.6243)	data time 0.0198 (0.1164)	model time 0.0000 (0.0000)	loss 0.6303 (0.5923)	grad_norm 2.6589 (1.9841)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:15 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][40/156]	eta 0:01:08 lr 0.000100	 wd 0.0500	time 0.4090 (0.5911)	data time 0.0009 (0.0899)	model time 0.0000 (0.0000)	loss 0.6142 (0.5875)	grad_norm 2.0339 (2.0180)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:20 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][50/156]	eta 0:01:00 lr 0.000100	 wd 0.0500	time 0.4692 (0.5690)	data time 0.0006 (0.0743)	model time 0.0000 (0.0000)	loss 0.6394 (0.5903)	grad_norm 1.9378 (2.1014)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:25 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][60/156]	eta 0:00:53 lr 0.000100	 wd 0.0500	time 0.5150 (0.5564)	data time 0.0093 (0.0641)	model time 0.5057 (0.4798)	loss 0.6315 (0.5929)	grad_norm 1.2857 (2.0419)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:30 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][70/156]	eta 0:00:47 lr 0.000100	 wd 0.0500	time 0.5367 (0.5511)	data time 0.0007 (0.0579)	model time 0.5360 (0.4892)	loss 0.6414 (0.5968)	grad_norm 1.2878 (1.9989)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:35 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][80/156]	eta 0:00:41 lr 0.000100	 wd 0.0500	time 0.4307 (0.5468)	data time 0.0026 (0.0528)	model time 0.4281 (0.4928)	loss 0.6628 (0.5987)	grad_norm 1.9799 (1.9342)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:40 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][90/156]	eta 0:00:35 lr 0.000100	 wd 0.0500	time 0.4597 (0.5417)	data time 0.0110 (0.0479)	model time 0.4486 (0.4925)	loss 0.6471 (0.5980)	grad_norm 1.0508 (1.8754)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:46 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][100/156]	eta 0:00:30 lr 0.000100	 wd 0.0500	time 0.4826 (0.5405)	data time 0.0015 (0.0452)	model time 0.4811 (0.4958)	loss 0.6440 (0.5966)	grad_norm 1.2340 (1.8488)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:50 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][110/156]	eta 0:00:24 lr 0.000100	 wd 0.0500	time 0.4450 (0.5350)	data time 0.0311 (0.0424)	model time 0.4139 (0.4908)	loss 0.6080 (0.5944)	grad_norm 1.7224 (1.8794)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:44:55 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][120/156]	eta 0:00:19 lr 0.000100	 wd 0.0500	time 0.6415 (0.5316)	data time 0.0087 (0.0407)	model time 0.6328 (0.4881)	loss 0.5629 (0.5934)	grad_norm 0.9610 (1.9301)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:45:00 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][130/156]	eta 0:00:13 lr 0.000100	 wd 0.0500	time 0.4738 (0.5282)	data time 0.0007 (0.0386)	model time 0.4730 (0.4863)	loss 0.5741 (0.5927)	grad_norm 1.8886 (1.9163)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:45:06 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][140/156]	eta 0:00:08 lr 0.000100	 wd 0.0500	time 0.4603 (0.5283)	data time 0.0008 (0.0367)	model time 0.4595 (0.4898)	loss 0.6253 (0.5943)	grad_norm 2.0919 (1.9101)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:45:10 vssm1_tiny_0230s](training.py 201): INFO Train: [103/300][150/156]	eta 0:00:03 lr 0.000100	 wd 0.0500	time 0.4130 (0.5247)	data time 0.0006 (0.0344)	model time 0.4124 (0.4880)	loss 0.4867 (0.5931)	grad_norm 2.0385 (1.9195)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:45:13 vssm1_tiny_0230s](training.py 212): INFO EPOCH 103 training takes 0:01:22
[2024-11-09 13:45:13 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_103.pth saving......
[2024-11-09 13:45:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_103.pth saved !!!
[2024-11-09 13:45:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.718 (2.718)	Loss 0.2883 (0.2883)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:45:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.140 (0.579)	Loss 0.3142 (0.3088)	Acc@1 88.281 (89.205)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:45:23 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.429)	Loss 0.2169 (0.3182)	Acc@1 96.875 (88.095)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:45:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.155 (0.351)	Loss 0.2834 (0.3010)	Acc@1 91.406 (89.793)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:45:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.620 Acc@5 100.000
[2024-11-09 13:45:27 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 90.6%
[2024-11-09 13:45:27 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.16%
[2024-11-09 13:45:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.872 (3.872)	Loss 0.3333 (0.3333)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:45:33 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.562)	Loss 0.3403 (0.3372)	Acc@1 98.438 (98.509)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:45:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.428)	Loss 0.8013 (0.3738)	Acc@1 35.156 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:45:38 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.156 (0.348)	Loss 0.8838 (0.5261)	Acc@1 30.469 (73.790)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:45:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 65.040 Acc@5 100.000
[2024-11-09 13:45:40 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 65.0%
[2024-11-09 13:45:40 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 65.04%
[2024-11-09 13:45:44 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][0/156]	eta 0:10:07 lr 0.000099	 wd 0.0500	time 3.8931 (3.8931)	data time 3.2809 (3.2809)	model time 0.0000 (0.0000)	loss 0.5975 (0.5975)	grad_norm 1.2363 (1.2363)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:45:49 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][10/156]	eta 0:02:01 lr 0.000099	 wd 0.0500	time 0.4403 (0.8324)	data time 0.0163 (0.3082)	model time 0.0000 (0.0000)	loss 0.4945 (0.5860)	grad_norm 1.9344 (1.6259)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:45:54 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][20/156]	eta 0:01:31 lr 0.000099	 wd 0.0500	time 0.4397 (0.6707)	data time 0.0147 (0.1693)	model time 0.0000 (0.0000)	loss 0.6492 (0.5861)	grad_norm 1.9739 (1.8159)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:00 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][30/156]	eta 0:01:18 lr 0.000099	 wd 0.0500	time 0.6141 (0.6232)	data time 0.0060 (0.1198)	model time 0.0000 (0.0000)	loss 0.5286 (0.5817)	grad_norm 2.2332 (1.9802)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:04 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][40/156]	eta 0:01:08 lr 0.000099	 wd 0.0500	time 0.4516 (0.5876)	data time 0.0042 (0.0929)	model time 0.0000 (0.0000)	loss 0.6257 (0.5870)	grad_norm 2.1730 (2.0754)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:09 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][50/156]	eta 0:01:00 lr 0.000099	 wd 0.0500	time 0.5521 (0.5679)	data time 0.0222 (0.0785)	model time 0.0000 (0.0000)	loss 0.5623 (0.5819)	grad_norm 1.4048 (2.1738)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:15 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][60/156]	eta 0:00:54 lr 0.000099	 wd 0.0500	time 0.5014 (0.5628)	data time 0.0213 (0.0682)	model time 0.4801 (0.5213)	loss 0.5676 (0.5841)	grad_norm 2.0969 (2.1699)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:20 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][70/156]	eta 0:00:47 lr 0.000099	 wd 0.0500	time 0.5184 (0.5534)	data time 0.0119 (0.0612)	model time 0.5065 (0.4995)	loss 0.6070 (0.5841)	grad_norm 1.3450 (2.1689)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:24 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][80/156]	eta 0:00:41 lr 0.000099	 wd 0.0500	time 0.4810 (0.5440)	data time 0.0161 (0.0559)	model time 0.4649 (0.4860)	loss 0.5801 (0.5831)	grad_norm 1.7703 (2.1419)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:29 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][90/156]	eta 0:00:35 lr 0.000099	 wd 0.0500	time 0.5236 (0.5387)	data time 0.0006 (0.0518)	model time 0.5230 (0.4837)	loss 0.6522 (0.5874)	grad_norm 1.5623 (2.0957)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:34 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][100/156]	eta 0:00:29 lr 0.000099	 wd 0.0500	time 0.4390 (0.5338)	data time 0.0064 (0.0493)	model time 0.4326 (0.4796)	loss 0.5678 (0.5887)	grad_norm 1.4469 (2.0461)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:39 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][110/156]	eta 0:00:24 lr 0.000099	 wd 0.0500	time 0.4323 (0.5290)	data time 0.0170 (0.0459)	model time 0.4153 (0.4777)	loss 0.6346 (0.5901)	grad_norm 1.3865 (2.0125)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:44 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][120/156]	eta 0:00:18 lr 0.000099	 wd 0.0500	time 0.5942 (0.5272)	data time 0.0290 (0.0435)	model time 0.5652 (0.4797)	loss 0.5131 (0.5885)	grad_norm 1.9884 (1.9959)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:49 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][130/156]	eta 0:00:13 lr 0.000099	 wd 0.0500	time 0.4696 (0.5281)	data time 0.0077 (0.0423)	model time 0.4619 (0.4837)	loss 0.4789 (0.5863)	grad_norm 2.8158 (2.0056)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:46:54 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][140/156]	eta 0:00:08 lr 0.000099	 wd 0.0500	time 0.4303 (0.5249)	data time 0.0009 (0.0404)	model time 0.4293 (0.4818)	loss 0.6473 (0.5873)	grad_norm 1.4998 (2.0096)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:47:00 vssm1_tiny_0230s](training.py 201): INFO Train: [104/300][150/156]	eta 0:00:03 lr 0.000099	 wd 0.0500	time 0.5745 (0.5268)	data time 0.0006 (0.0380)	model time 0.5739 (0.4886)	loss 0.5678 (0.5883)	grad_norm 2.1097 (2.0368)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:47:03 vssm1_tiny_0230s](training.py 212): INFO EPOCH 104 training takes 0:01:22
[2024-11-09 13:47:03 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_104.pth saving......
[2024-11-09 13:47:03 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_104.pth saved !!!
[2024-11-09 13:47:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.768 (3.768)	Loss 0.2308 (0.2308)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:47:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 1.212 (0.646)	Loss 0.2445 (0.2472)	Acc@1 95.312 (94.034)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:47:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.152 (0.435)	Loss 0.2866 (0.2642)	Acc@1 94.531 (92.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:47:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.351)	Loss 0.3352 (0.2870)	Acc@1 89.844 (91.457)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:47:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.320 Acc@5 100.000
[2024-11-09 13:47:17 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.3%
[2024-11-09 13:47:17 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.32%
[2024-11-09 13:47:20 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.709 (3.709)	Loss 0.3318 (0.3318)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:47:23 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.417 (0.568)	Loss 0.3389 (0.3357)	Acc@1 98.438 (98.509)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:47:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 1.015 (0.444)	Loss 0.7983 (0.3723)	Acc@1 35.938 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:47:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.154 (0.383)	Loss 0.8813 (0.5242)	Acc@1 30.469 (74.017)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:47:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 65.300 Acc@5 100.000
[2024-11-09 13:47:32 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 65.3%
[2024-11-09 13:47:32 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 65.30%
[2024-11-09 13:47:36 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][0/156]	eta 0:10:54 lr 0.000099	 wd 0.0500	time 4.1932 (4.1932)	data time 3.6311 (3.6311)	model time 0.0000 (0.0000)	loss 0.5483 (0.5483)	grad_norm 2.6363 (2.6363)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:47:41 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][10/156]	eta 0:02:01 lr 0.000099	 wd 0.0500	time 0.4200 (0.8341)	data time 0.0137 (0.3414)	model time 0.0000 (0.0000)	loss 0.6454 (0.5864)	grad_norm 6.4111 (2.5193)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:47:46 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][20/156]	eta 0:01:30 lr 0.000099	 wd 0.0500	time 0.4886 (0.6645)	data time 0.0227 (0.1890)	model time 0.0000 (0.0000)	loss 0.5526 (0.5863)	grad_norm 1.3970 (2.2858)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:47:51 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][30/156]	eta 0:01:16 lr 0.000099	 wd 0.0500	time 0.4625 (0.6106)	data time 0.0271 (0.1329)	model time 0.0000 (0.0000)	loss 0.6195 (0.5934)	grad_norm 1.2926 (2.1654)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:47:56 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][40/156]	eta 0:01:07 lr 0.000099	 wd 0.0500	time 0.5837 (0.5802)	data time 0.0029 (0.1035)	model time 0.0000 (0.0000)	loss 0.5798 (0.5934)	grad_norm 1.7479 (2.0917)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:01 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][50/156]	eta 0:01:00 lr 0.000099	 wd 0.0500	time 0.4459 (0.5671)	data time 0.0044 (0.0878)	model time 0.0000 (0.0000)	loss 0.6169 (0.5916)	grad_norm 1.6903 (2.0046)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:06 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][60/156]	eta 0:00:53 lr 0.000099	 wd 0.0500	time 0.4987 (0.5547)	data time 0.0009 (0.0756)	model time 0.4978 (0.4784)	loss 0.6972 (0.5916)	grad_norm 2.3143 (2.0172)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:11 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][70/156]	eta 0:00:47 lr 0.000099	 wd 0.0500	time 0.5315 (0.5480)	data time 0.0073 (0.0679)	model time 0.5242 (0.4822)	loss 0.6029 (0.5916)	grad_norm 1.2082 (1.9984)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:17 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][80/156]	eta 0:00:41 lr 0.000099	 wd 0.0500	time 0.4781 (0.5494)	data time 0.0064 (0.0612)	model time 0.4716 (0.5032)	loss 0.6156 (0.5902)	grad_norm 1.4330 (1.9773)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:22 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][90/156]	eta 0:00:36 lr 0.000099	 wd 0.0500	time 0.6071 (0.5486)	data time 0.0166 (0.0554)	model time 0.5906 (0.5109)	loss 0.5615 (0.5901)	grad_norm 1.1585 (1.9740)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:27 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][100/156]	eta 0:00:30 lr 0.000099	 wd 0.0500	time 0.5480 (0.5469)	data time 0.0143 (0.0512)	model time 0.5337 (0.5124)	loss 0.5786 (0.5910)	grad_norm 1.1872 (1.9787)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:32 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][110/156]	eta 0:00:24 lr 0.000099	 wd 0.0500	time 0.4978 (0.5427)	data time 0.0192 (0.0484)	model time 0.4787 (0.5072)	loss 0.6431 (0.5917)	grad_norm 1.4269 (1.9537)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:38 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][120/156]	eta 0:00:19 lr 0.000098	 wd 0.0500	time 0.4799 (0.5397)	data time 0.0199 (0.0454)	model time 0.4600 (0.5053)	loss 0.6586 (0.5925)	grad_norm 1.3538 (1.9597)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:43 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][130/156]	eta 0:00:13 lr 0.000098	 wd 0.0500	time 0.4631 (0.5369)	data time 0.0174 (0.0430)	model time 0.4458 (0.5033)	loss 0.6014 (0.5931)	grad_norm 1.7060 (1.9525)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:48 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][140/156]	eta 0:00:08 lr 0.000098	 wd 0.0500	time 0.5346 (0.5370)	data time 0.0009 (0.0411)	model time 0.5337 (0.5053)	loss 0.5949 (0.5930)	grad_norm 0.9936 (1.9532)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:53 vssm1_tiny_0230s](training.py 201): INFO Train: [105/300][150/156]	eta 0:00:03 lr 0.000098	 wd 0.0500	time 0.4252 (0.5352)	data time 0.0033 (0.0385)	model time 0.4218 (0.5057)	loss 0.5892 (0.5929)	grad_norm 1.1985 (1.9557)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:48:56 vssm1_tiny_0230s](training.py 212): INFO EPOCH 105 training takes 0:01:23
[2024-11-09 13:48:56 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_105.pth saving......
[2024-11-09 13:48:56 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_105.pth saved !!!
[2024-11-09 13:49:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.696 (3.696)	Loss 0.2693 (0.2693)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:49:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.143 (0.525)	Loss 0.2920 (0.2800)	Acc@1 90.625 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:49:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.175 (0.391)	Loss 0.2450 (0.2885)	Acc@1 93.750 (90.662)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:49:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.146 (0.369)	Loss 0.2798 (0.2857)	Acc@1 92.188 (90.978)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:49:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.440 Acc@5 100.000
[2024-11-09 13:49:10 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.4%
[2024-11-09 13:49:10 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.44%
[2024-11-09 13:49:12 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.389 (2.389)	Loss 0.3306 (0.3306)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:49:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.188 (0.425)	Loss 0.3376 (0.3347)	Acc@1 98.438 (98.509)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:49:17 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.176 (0.326)	Loss 0.7939 (0.3710)	Acc@1 36.719 (93.713)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:49:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.467 (0.331)	Loss 0.8784 (0.5224)	Acc@1 32.031 (74.294)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:49:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 65.700 Acc@5 100.000
[2024-11-09 13:49:24 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 65.7%
[2024-11-09 13:49:24 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 65.70%
[2024-11-09 13:49:32 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][0/156]	eta 0:20:29 lr 0.000098	 wd 0.0500	time 7.8815 (7.8815)	data time 7.1990 (7.1990)	model time 0.0000 (0.0000)	loss 0.6222 (0.6222)	grad_norm 1.3760 (1.3760)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:49:37 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][10/156]	eta 0:02:54 lr 0.000098	 wd 0.0500	time 0.4835 (1.1931)	data time 0.0005 (0.6632)	model time 0.0000 (0.0000)	loss 0.5253 (0.5752)	grad_norm 2.1776 (2.1091)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:49:43 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][20/156]	eta 0:01:58 lr 0.000098	 wd 0.0500	time 0.4719 (0.8740)	data time 0.0097 (0.3510)	model time 0.0000 (0.0000)	loss 0.5564 (0.5664)	grad_norm 1.9697 (2.3509)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:49:49 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][30/156]	eta 0:01:41 lr 0.000098	 wd 0.0500	time 0.5196 (0.8038)	data time 0.0019 (0.2566)	model time 0.0000 (0.0000)	loss 0.6397 (0.5765)	grad_norm 2.5997 (2.4013)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:49:56 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][40/156]	eta 0:01:29 lr 0.000098	 wd 0.0500	time 0.4579 (0.7745)	data time 0.0006 (0.2425)	model time 0.0000 (0.0000)	loss 0.6157 (0.5830)	grad_norm 1.7497 (2.3667)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:01 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][50/156]	eta 0:01:16 lr 0.000098	 wd 0.0500	time 0.4614 (0.7208)	data time 0.0127 (0.1970)	model time 0.0000 (0.0000)	loss 0.6287 (0.5894)	grad_norm 1.1946 (2.1899)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:06 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][60/156]	eta 0:01:05 lr 0.000098	 wd 0.0500	time 0.5014 (0.6791)	data time 0.0005 (0.1676)	model time 0.5008 (0.4487)	loss 0.5276 (0.5849)	grad_norm 2.1374 (2.1113)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:11 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][70/156]	eta 0:00:56 lr 0.000098	 wd 0.0500	time 0.5916 (0.6560)	data time 0.0204 (0.1468)	model time 0.5712 (0.4722)	loss 0.6425 (0.5870)	grad_norm 2.0026 (2.1167)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:16 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][80/156]	eta 0:00:48 lr 0.000098	 wd 0.0500	time 0.5709 (0.6437)	data time 0.0179 (0.1304)	model time 0.5530 (0.4955)	loss 0.5828 (0.5879)	grad_norm 2.1652 (2.1273)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:22 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][90/156]	eta 0:00:41 lr 0.000098	 wd 0.0500	time 0.6017 (0.6346)	data time 0.0152 (0.1169)	model time 0.5865 (0.5101)	loss 0.6066 (0.5881)	grad_norm 1.3363 (2.1096)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:27 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][100/156]	eta 0:00:34 lr 0.000098	 wd 0.0500	time 0.4670 (0.6240)	data time 0.0121 (0.1071)	model time 0.4549 (0.5098)	loss 0.5499 (0.5895)	grad_norm 1.9755 (2.0911)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:32 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][110/156]	eta 0:00:28 lr 0.000098	 wd 0.0500	time 0.5170 (0.6132)	data time 0.0147 (0.0988)	model time 0.5023 (0.5065)	loss 0.6150 (0.5893)	grad_norm 1.5686 (2.0624)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:38 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][120/156]	eta 0:00:21 lr 0.000098	 wd 0.0500	time 0.5796 (0.6089)	data time 0.0058 (0.0914)	model time 0.5738 (0.5131)	loss 0.5309 (0.5894)	grad_norm 1.7385 (2.0456)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:43 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][130/156]	eta 0:00:15 lr 0.000098	 wd 0.0500	time 0.6032 (0.5996)	data time 0.0926 (0.0864)	model time 0.5106 (0.5065)	loss 0.6809 (0.5898)	grad_norm 2.0351 (2.0793)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:48 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][140/156]	eta 0:00:09 lr 0.000098	 wd 0.0500	time 0.5289 (0.5923)	data time 0.0186 (0.0812)	model time 0.5104 (0.5039)	loss 0.6205 (0.5887)	grad_norm 1.3483 (2.0800)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:53 vssm1_tiny_0230s](training.py 201): INFO Train: [106/300][150/156]	eta 0:00:03 lr 0.000098	 wd 0.0500	time 0.5175 (0.5903)	data time 0.0007 (0.0759)	model time 0.5167 (0.5097)	loss 0.6421 (0.5891)	grad_norm 3.5089 (2.0911)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:50:56 vssm1_tiny_0230s](training.py 212): INFO EPOCH 106 training takes 0:01:32
[2024-11-09 13:50:56 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_106.pth saving......
[2024-11-09 13:50:57 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_106.pth saved !!!
[2024-11-09 13:51:01 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.819 (3.819)	Loss 0.3059 (0.3059)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:51:04 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.828 (0.656)	Loss 0.3357 (0.3176)	Acc@1 85.156 (87.287)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:51:07 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.476)	Loss 0.2170 (0.3241)	Acc@1 96.875 (86.979)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:51:09 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.407)	Loss 0.2539 (0.3000)	Acc@1 94.531 (89.642)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:51:12 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.840 Acc@5 100.000
[2024-11-09 13:51:12 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 90.8%
[2024-11-09 13:51:12 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.44%
[2024-11-09 13:51:15 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.857 (2.857)	Loss 0.3291 (0.3291)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:51:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.251 (0.450)	Loss 0.3364 (0.3334)	Acc@1 98.438 (98.509)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:51:19 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.163 (0.341)	Loss 0.7905 (0.3697)	Acc@1 36.719 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:51:21 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.279)	Loss 0.8760 (0.5206)	Acc@1 32.031 (74.294)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:51:23 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 65.820 Acc@5 100.000
[2024-11-09 13:51:23 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 65.8%
[2024-11-09 13:51:23 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 65.82%
[2024-11-09 13:51:27 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][0/156]	eta 0:11:16 lr 0.000098	 wd 0.0500	time 4.3373 (4.3373)	data time 3.8811 (3.8811)	model time 0.0000 (0.0000)	loss 0.6198 (0.6198)	grad_norm 1.6125 (1.6125)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:51:33 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][10/156]	eta 0:02:13 lr 0.000098	 wd 0.0500	time 0.4175 (0.9158)	data time 0.0006 (0.3586)	model time 0.0000 (0.0000)	loss 0.5654 (0.6023)	grad_norm 1.6801 (1.5604)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:51:38 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][20/156]	eta 0:01:40 lr 0.000098	 wd 0.0500	time 0.7133 (0.7363)	data time 0.0051 (0.1947)	model time 0.0000 (0.0000)	loss 0.6350 (0.5993)	grad_norm 1.2895 (1.6476)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:51:43 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][30/156]	eta 0:01:22 lr 0.000098	 wd 0.0500	time 0.5411 (0.6570)	data time 0.0216 (0.1369)	model time 0.0000 (0.0000)	loss 0.5734 (0.5863)	grad_norm 1.8258 (1.7944)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:51:49 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][40/156]	eta 0:01:13 lr 0.000098	 wd 0.0500	time 0.5939 (0.6299)	data time 0.0299 (0.1076)	model time 0.0000 (0.0000)	loss 0.5101 (0.5828)	grad_norm 2.0288 (1.8616)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:51:54 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][50/156]	eta 0:01:04 lr 0.000098	 wd 0.0500	time 0.6580 (0.6090)	data time 0.0945 (0.0903)	model time 0.0000 (0.0000)	loss 0.6347 (0.5851)	grad_norm 2.4883 (1.9714)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:51:59 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][60/156]	eta 0:00:56 lr 0.000098	 wd 0.0500	time 0.5611 (0.5900)	data time 0.0157 (0.0767)	model time 0.5454 (0.4851)	loss 0.6120 (0.5883)	grad_norm 1.8828 (1.9158)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:52:04 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][70/156]	eta 0:00:50 lr 0.000098	 wd 0.0500	time 0.4291 (0.5869)	data time 0.0056 (0.0728)	model time 0.4234 (0.5022)	loss 0.5910 (0.5909)	grad_norm 1.6041 (1.8558)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:52:09 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][80/156]	eta 0:00:43 lr 0.000097	 wd 0.0500	time 0.4842 (0.5730)	data time 0.0177 (0.0656)	model time 0.4665 (0.4882)	loss 0.6461 (0.5924)	grad_norm 1.1555 (1.8312)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:52:14 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][90/156]	eta 0:00:37 lr 0.000097	 wd 0.0500	time 0.4388 (0.5616)	data time 0.0110 (0.0602)	model time 0.4277 (0.4794)	loss 0.5242 (0.5925)	grad_norm 2.0323 (1.8056)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:52:19 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][100/156]	eta 0:00:31 lr 0.000097	 wd 0.0500	time 0.6003 (0.5599)	data time 0.0230 (0.0568)	model time 0.5773 (0.4872)	loss 0.4756 (0.5881)	grad_norm 2.0433 (1.7973)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:52:24 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][110/156]	eta 0:00:25 lr 0.000097	 wd 0.0500	time 0.4558 (0.5547)	data time 0.0006 (0.0528)	model time 0.4551 (0.4875)	loss 0.6159 (0.5877)	grad_norm 1.5120 (1.8194)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:52:30 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][120/156]	eta 0:00:19 lr 0.000097	 wd 0.0500	time 0.6451 (0.5534)	data time 0.0111 (0.0492)	model time 0.6340 (0.4936)	loss 0.5124 (0.5854)	grad_norm 2.6965 (1.8559)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:52:35 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][130/156]	eta 0:00:14 lr 0.000097	 wd 0.0500	time 0.5221 (0.5483)	data time 0.0029 (0.0468)	model time 0.5193 (0.4905)	loss 0.6564 (0.5849)	grad_norm 2.2267 (1.9092)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:52:40 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][140/156]	eta 0:00:08 lr 0.000097	 wd 0.0500	time 0.4881 (0.5469)	data time 0.0011 (0.0446)	model time 0.4870 (0.4929)	loss 0.6244 (0.5868)	grad_norm 2.5683 (1.9752)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:52:45 vssm1_tiny_0230s](training.py 201): INFO Train: [107/300][150/156]	eta 0:00:03 lr 0.000097	 wd 0.0500	time 0.4189 (0.5432)	data time 0.0006 (0.0417)	model time 0.4183 (0.4926)	loss 0.6324 (0.5881)	grad_norm 1.6309 (1.9920)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:52:47 vssm1_tiny_0230s](training.py 212): INFO EPOCH 107 training takes 0:01:24
[2024-11-09 13:52:47 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_107.pth saving......
[2024-11-09 13:52:48 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_107.pth saved !!!
[2024-11-09 13:52:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.776 (3.776)	Loss 0.2451 (0.2451)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:52:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.181 (0.627)	Loss 0.2610 (0.2548)	Acc@1 95.312 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:52:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.487)	Loss 0.3206 (0.2706)	Acc@1 91.406 (94.271)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:53:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.202 (0.414)	Loss 0.3738 (0.3059)	Acc@1 85.938 (91.230)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:53:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.200 Acc@5 100.000
[2024-11-09 13:53:03 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 90.2%
[2024-11-09 13:53:03 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.44%
[2024-11-09 13:53:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.187 (3.187)	Loss 0.3281 (0.3281)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:53:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.164 (0.546)	Loss 0.3352 (0.3323)	Acc@1 98.438 (98.509)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:53:11 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.369)	Loss 0.7866 (0.3685)	Acc@1 38.281 (93.676)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:53:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.143 (0.335)	Loss 0.8726 (0.5187)	Acc@1 33.594 (74.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:53:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 66.120 Acc@5 100.000
[2024-11-09 13:53:16 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 66.1%
[2024-11-09 13:53:16 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 66.12%
[2024-11-09 13:53:20 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][0/156]	eta 0:10:28 lr 0.000097	 wd 0.0500	time 4.0291 (4.0291)	data time 3.5218 (3.5218)	model time 0.0000 (0.0000)	loss 0.5968 (0.5968)	grad_norm 1.7005 (1.7005)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:53:26 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][10/156]	eta 0:02:03 lr 0.000097	 wd 0.0500	time 0.5086 (0.8440)	data time 0.0174 (0.3474)	model time 0.0000 (0.0000)	loss 0.5427 (0.5826)	grad_norm 1.4503 (2.0473)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:53:31 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][20/156]	eta 0:01:34 lr 0.000097	 wd 0.0500	time 0.4591 (0.6971)	data time 0.0012 (0.1902)	model time 0.0000 (0.0000)	loss 0.6015 (0.5930)	grad_norm 2.0729 (1.9861)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:53:36 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][30/156]	eta 0:01:21 lr 0.000097	 wd 0.0500	time 0.4566 (0.6452)	data time 0.0494 (0.1339)	model time 0.0000 (0.0000)	loss 0.5897 (0.5905)	grad_norm 1.4762 (1.8636)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:53:41 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][40/156]	eta 0:01:11 lr 0.000097	 wd 0.0500	time 0.6275 (0.6151)	data time 0.0861 (0.1072)	model time 0.0000 (0.0000)	loss 0.5563 (0.5904)	grad_norm 1.8418 (1.8881)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:53:46 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][50/156]	eta 0:01:02 lr 0.000097	 wd 0.0500	time 0.5647 (0.5897)	data time 0.0058 (0.0877)	model time 0.0000 (0.0000)	loss 0.6032 (0.5874)	grad_norm 1.9281 (1.9381)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:53:52 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][60/156]	eta 0:00:55 lr 0.000097	 wd 0.0500	time 0.4355 (0.5809)	data time 0.0009 (0.0764)	model time 0.4346 (0.5173)	loss 0.5549 (0.5844)	grad_norm 3.6597 (2.0281)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:53:57 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][70/156]	eta 0:00:49 lr 0.000097	 wd 0.0500	time 0.5905 (0.5754)	data time 0.0024 (0.0678)	model time 0.5881 (0.5216)	loss 0.6659 (0.5890)	grad_norm 2.0707 (2.0647)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:54:02 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][80/156]	eta 0:00:43 lr 0.000097	 wd 0.0500	time 0.5149 (0.5699)	data time 0.0007 (0.0610)	model time 0.5142 (0.5205)	loss 0.5646 (0.5880)	grad_norm 1.4739 (2.0364)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:54:08 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][90/156]	eta 0:00:37 lr 0.000097	 wd 0.0500	time 0.4489 (0.5701)	data time 0.0239 (0.0586)	model time 0.4250 (0.5236)	loss 0.6420 (0.5867)	grad_norm 2.1912 (2.0419)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:54:13 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][100/156]	eta 0:00:31 lr 0.000097	 wd 0.0500	time 0.5105 (0.5644)	data time 0.0167 (0.0544)	model time 0.4938 (0.5181)	loss 0.6529 (0.5900)	grad_norm 2.1633 (2.0235)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:54:19 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][110/156]	eta 0:00:25 lr 0.000097	 wd 0.0500	time 0.5268 (0.5610)	data time 0.0469 (0.0518)	model time 0.4799 (0.5153)	loss 0.5212 (0.5915)	grad_norm 1.8072 (1.9932)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:54:23 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][120/156]	eta 0:00:19 lr 0.000097	 wd 0.0500	time 0.4504 (0.5550)	data time 0.0072 (0.0481)	model time 0.4432 (0.5105)	loss 0.5695 (0.5899)	grad_norm 1.7737 (1.9712)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:54:28 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][130/156]	eta 0:00:14 lr 0.000097	 wd 0.0500	time 0.5280 (0.5495)	data time 0.0753 (0.0459)	model time 0.4528 (0.5046)	loss 0.5312 (0.5911)	grad_norm 2.0655 (1.9567)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:54:34 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][140/156]	eta 0:00:08 lr 0.000097	 wd 0.0500	time 0.4973 (0.5484)	data time 0.0009 (0.0431)	model time 0.4963 (0.5072)	loss 0.5141 (0.5892)	grad_norm 4.3207 (1.9813)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:54:39 vssm1_tiny_0230s](training.py 201): INFO Train: [108/300][150/156]	eta 0:00:03 lr 0.000097	 wd 0.0500	time 0.4468 (0.5450)	data time 0.0009 (0.0403)	model time 0.4459 (0.5061)	loss 0.5909 (0.5898)	grad_norm 1.9446 (1.9949)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:54:42 vssm1_tiny_0230s](training.py 212): INFO EPOCH 108 training takes 0:01:25
[2024-11-09 13:54:42 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_108.pth saving......
[2024-11-09 13:54:42 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_108.pth saved !!!
[2024-11-09 13:54:46 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.932 (3.932)	Loss 0.2047 (0.2047)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:54:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.139 (0.508)	Loss 0.2233 (0.2186)	Acc@1 95.312 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:54:49 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.335)	Loss 0.3105 (0.2400)	Acc@1 91.406 (94.568)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:54:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.599 (0.337)	Loss 0.3474 (0.2785)	Acc@1 88.281 (91.885)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:54:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.780 Acc@5 100.000
[2024-11-09 13:54:55 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 90.8%
[2024-11-09 13:54:55 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.44%
[2024-11-09 13:54:59 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.489 (3.489)	Loss 0.3267 (0.3267)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:55:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.542)	Loss 0.3340 (0.3311)	Acc@1 98.438 (98.509)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:55:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.166 (0.452)	Loss 0.7827 (0.3672)	Acc@1 38.281 (93.676)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:55:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.380)	Loss 0.8696 (0.5169)	Acc@1 34.375 (74.748)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:55:09 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 66.300 Acc@5 100.000
[2024-11-09 13:55:09 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 66.3%
[2024-11-09 13:55:09 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 66.30%
[2024-11-09 13:55:13 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][0/156]	eta 0:09:49 lr 0.000097	 wd 0.0500	time 3.7800 (3.7800)	data time 3.3462 (3.3462)	model time 0.0000 (0.0000)	loss 0.5963 (0.5963)	grad_norm 1.8510 (1.8510)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:55:18 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][10/156]	eta 0:01:58 lr 0.000097	 wd 0.0500	time 0.4281 (0.8140)	data time 0.0161 (0.3308)	model time 0.0000 (0.0000)	loss 0.5478 (0.5598)	grad_norm 2.0644 (2.0272)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:55:23 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][20/156]	eta 0:01:28 lr 0.000097	 wd 0.0500	time 0.4080 (0.6524)	data time 0.0010 (0.1814)	model time 0.0000 (0.0000)	loss 0.6547 (0.5636)	grad_norm 4.2318 (2.2751)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:55:28 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][30/156]	eta 0:01:15 lr 0.000097	 wd 0.0500	time 0.4289 (0.6016)	data time 0.0047 (0.1285)	model time 0.0000 (0.0000)	loss 0.5569 (0.5562)	grad_norm 1.4398 (2.2607)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:55:33 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][40/156]	eta 0:01:06 lr 0.000096	 wd 0.0500	time 0.6405 (0.5763)	data time 0.0280 (0.0997)	model time 0.0000 (0.0000)	loss 0.6073 (0.5648)	grad_norm 2.3346 (2.2692)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:55:38 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][50/156]	eta 0:01:00 lr 0.000096	 wd 0.0500	time 0.5506 (0.5708)	data time 0.0289 (0.0878)	model time 0.0000 (0.0000)	loss 0.6383 (0.5692)	grad_norm 1.7835 (2.1953)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:55:43 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][60/156]	eta 0:00:53 lr 0.000096	 wd 0.0500	time 0.6532 (0.5580)	data time 0.0102 (0.0760)	model time 0.6430 (0.4770)	loss 0.4584 (0.5708)	grad_norm 1.7351 (2.1694)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:55:48 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][70/156]	eta 0:00:47 lr 0.000096	 wd 0.0500	time 0.4239 (0.5493)	data time 0.0147 (0.0669)	model time 0.4092 (0.4808)	loss 0.5831 (0.5752)	grad_norm 1.8037 (2.1977)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:55:54 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][80/156]	eta 0:00:41 lr 0.000096	 wd 0.0500	time 0.4882 (0.5486)	data time 0.0206 (0.0601)	model time 0.4676 (0.4978)	loss 0.6257 (0.5783)	grad_norm 2.5736 (2.1890)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:55:59 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][90/156]	eta 0:00:36 lr 0.000096	 wd 0.0500	time 0.4470 (0.5474)	data time 0.0070 (0.0567)	model time 0.4400 (0.5003)	loss 0.6311 (0.5787)	grad_norm 2.5643 (2.1727)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:56:04 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][100/156]	eta 0:00:30 lr 0.000096	 wd 0.0500	time 0.5325 (0.5420)	data time 0.0010 (0.0531)	model time 0.5315 (0.4949)	loss 0.5184 (0.5818)	grad_norm 2.7947 (2.1920)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:56:09 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][110/156]	eta 0:00:24 lr 0.000096	 wd 0.0500	time 0.5708 (0.5414)	data time 0.0007 (0.0518)	model time 0.5702 (0.4952)	loss 0.6159 (0.5821)	grad_norm 1.0415 (2.1717)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:56:15 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][120/156]	eta 0:00:19 lr 0.000096	 wd 0.0500	time 0.5317 (0.5405)	data time 0.0217 (0.0492)	model time 0.5100 (0.4974)	loss 0.5397 (0.5842)	grad_norm 2.6706 (2.1653)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:56:20 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][130/156]	eta 0:00:14 lr 0.000096	 wd 0.0500	time 0.4337 (0.5390)	data time 0.0035 (0.0469)	model time 0.4302 (0.4978)	loss 0.5996 (0.5850)	grad_norm 1.3440 (2.1456)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:56:25 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][140/156]	eta 0:00:08 lr 0.000096	 wd 0.0500	time 0.5963 (0.5347)	data time 0.0009 (0.0445)	model time 0.5955 (0.4943)	loss 0.6376 (0.5839)	grad_norm 2.0874 (2.1457)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:56:30 vssm1_tiny_0230s](training.py 201): INFO Train: [109/300][150/156]	eta 0:00:03 lr 0.000096	 wd 0.0500	time 0.6247 (0.5331)	data time 0.0005 (0.0418)	model time 0.6242 (0.4955)	loss 0.6610 (0.5854)	grad_norm 1.7773 (2.1367)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:56:33 vssm1_tiny_0230s](training.py 212): INFO EPOCH 109 training takes 0:01:23
[2024-11-09 13:56:33 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_109.pth saving......
[2024-11-09 13:56:33 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_109.pth saved !!!
[2024-11-09 13:56:36 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.690 (2.690)	Loss 0.2415 (0.2415)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:56:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.372 (0.491)	Loss 0.2620 (0.2567)	Acc@1 95.312 (94.886)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:56:42 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.164 (0.413)	Loss 0.3074 (0.2713)	Acc@1 91.406 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:56:44 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.150 (0.334)	Loss 0.3525 (0.2953)	Acc@1 89.844 (91.835)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:56:46 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.320 Acc@5 100.000
[2024-11-09 13:56:46 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.3%
[2024-11-09 13:56:46 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.44%
[2024-11-09 13:56:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.865 (2.865)	Loss 0.3259 (0.3259)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:56:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.394 (0.543)	Loss 0.3330 (0.3304)	Acc@1 98.438 (98.509)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:56:54 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.155 (0.410)	Loss 0.7778 (0.3662)	Acc@1 38.281 (93.676)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:56:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.190 (0.364)	Loss 0.8657 (0.5150)	Acc@1 35.156 (74.924)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:57:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 66.580 Acc@5 100.000
[2024-11-09 13:57:00 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 66.6%
[2024-11-09 13:57:00 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 66.58%
[2024-11-09 13:57:05 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][0/156]	eta 0:12:02 lr 0.000096	 wd 0.0500	time 4.6331 (4.6331)	data time 4.2249 (4.2249)	model time 0.0000 (0.0000)	loss 0.6125 (0.6125)	grad_norm 1.8408 (1.8408)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:57:09 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][10/156]	eta 0:02:06 lr 0.000096	 wd 0.0500	time 0.4069 (0.8644)	data time 0.0011 (0.4000)	model time 0.0000 (0.0000)	loss 0.5878 (0.5864)	grad_norm 2.4559 (1.6560)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:57:14 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][20/156]	eta 0:01:32 lr 0.000096	 wd 0.0500	time 0.4334 (0.6835)	data time 0.0047 (0.2170)	model time 0.0000 (0.0000)	loss 0.4964 (0.5803)	grad_norm 2.6123 (1.7158)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:57:19 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][30/156]	eta 0:01:17 lr 0.000096	 wd 0.0500	time 0.5402 (0.6187)	data time 0.0082 (0.1516)	model time 0.0000 (0.0000)	loss 0.6327 (0.5770)	grad_norm 2.3384 (1.9248)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:57:24 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][40/156]	eta 0:01:09 lr 0.000096	 wd 0.0500	time 0.4678 (0.5961)	data time 0.0123 (0.1183)	model time 0.0000 (0.0000)	loss 0.5696 (0.5773)	grad_norm 2.1114 (1.9538)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:57:30 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][50/156]	eta 0:01:01 lr 0.000096	 wd 0.0500	time 0.5016 (0.5844)	data time 0.0008 (0.0972)	model time 0.0000 (0.0000)	loss 0.5879 (0.5774)	grad_norm 2.5217 (2.0315)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:57:35 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][60/156]	eta 0:00:54 lr 0.000096	 wd 0.0500	time 0.4391 (0.5684)	data time 0.0012 (0.0845)	model time 0.4379 (0.4671)	loss 0.6107 (0.5785)	grad_norm 1.8130 (2.0396)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:57:39 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][70/156]	eta 0:00:47 lr 0.000096	 wd 0.0500	time 0.4893 (0.5563)	data time 0.0045 (0.0743)	model time 0.4848 (0.4685)	loss 0.5700 (0.5777)	grad_norm 2.1549 (2.0717)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:57:45 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][80/156]	eta 0:00:42 lr 0.000096	 wd 0.0500	time 0.4931 (0.5534)	data time 0.0008 (0.0683)	model time 0.4924 (0.4815)	loss 0.5548 (0.5797)	grad_norm 2.1396 (2.1441)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:57:50 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][90/156]	eta 0:00:35 lr 0.000096	 wd 0.0500	time 0.4666 (0.5453)	data time 0.0223 (0.0624)	model time 0.4443 (0.4773)	loss 0.5730 (0.5816)	grad_norm 1.7826 (2.1375)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:57:55 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][100/156]	eta 0:00:30 lr 0.000096	 wd 0.0500	time 0.4877 (0.5411)	data time 0.0007 (0.0574)	model time 0.4870 (0.4799)	loss 0.6840 (0.5826)	grad_norm 2.2965 (2.1375)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:58:00 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][110/156]	eta 0:00:24 lr 0.000096	 wd 0.0500	time 0.5828 (0.5372)	data time 0.0266 (0.0534)	model time 0.5562 (0.4809)	loss 0.4899 (0.5823)	grad_norm 2.7837 (2.1484)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:58:05 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][120/156]	eta 0:00:19 lr 0.000096	 wd 0.0500	time 0.4885 (0.5351)	data time 0.0257 (0.0504)	model time 0.4628 (0.4828)	loss 0.6427 (0.5818)	grad_norm 2.0738 (2.1628)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:58:10 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][130/156]	eta 0:00:13 lr 0.000096	 wd 0.0500	time 0.4113 (0.5341)	data time 0.0006 (0.0481)	model time 0.4107 (0.4852)	loss 0.5950 (0.5825)	grad_norm 2.2384 (2.1473)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:58:15 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][140/156]	eta 0:00:08 lr 0.000096	 wd 0.0500	time 0.4568 (0.5306)	data time 0.0010 (0.0452)	model time 0.4558 (0.4844)	loss 0.5898 (0.5832)	grad_norm 1.1053 (2.1321)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:58:20 vssm1_tiny_0230s](training.py 201): INFO Train: [110/300][150/156]	eta 0:00:03 lr 0.000095	 wd 0.0500	time 0.4598 (0.5282)	data time 0.0007 (0.0424)	model time 0.4591 (0.4850)	loss 0.6119 (0.5846)	grad_norm 1.6842 (2.1222)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:58:23 vssm1_tiny_0230s](training.py 212): INFO EPOCH 110 training takes 0:01:23
[2024-11-09 13:58:23 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_110.pth saving......
[2024-11-09 13:58:24 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_110.pth saved !!!
[2024-11-09 13:58:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.874 (3.874)	Loss 0.2399 (0.2399)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:58:30 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.191 (0.585)	Loss 0.2607 (0.2524)	Acc@1 94.531 (94.602)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:58:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.405)	Loss 0.2637 (0.2690)	Acc@1 95.312 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:58:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.232 (0.356)	Loss 0.3372 (0.2878)	Acc@1 87.500 (91.835)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:58:37 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.360 Acc@5 100.000
[2024-11-09 13:58:37 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.4%
[2024-11-09 13:58:37 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.44%
[2024-11-09 13:58:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.977 (3.977)	Loss 0.3245 (0.3245)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:58:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.149 (0.541)	Loss 0.3318 (0.3290)	Acc@1 98.438 (98.509)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:58:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.378)	Loss 0.7744 (0.3648)	Acc@1 39.062 (93.713)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:58:48 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.338)	Loss 0.8628 (0.5130)	Acc@1 35.156 (75.076)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 13:58:50 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 66.820 Acc@5 100.000
[2024-11-09 13:58:50 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 66.8%
[2024-11-09 13:58:50 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 66.82%
[2024-11-09 13:58:53 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][0/156]	eta 0:08:52 lr 0.000095	 wd 0.0500	time 3.4159 (3.4159)	data time 2.9875 (2.9875)	model time 0.0000 (0.0000)	loss 0.6265 (0.6265)	grad_norm 3.3635 (3.3635)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 13:58:59 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][10/156]	eta 0:01:57 lr 0.000095	 wd 0.0500	time 0.5536 (0.8081)	data time 0.0107 (0.3173)	model time 0.0000 (0.0000)	loss 0.6325 (0.6066)	grad_norm 1.9839 (inf)	loss_scale 32768.0000 (41704.7273)	mem 13675MB
[2024-11-09 13:59:04 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][20/156]	eta 0:01:31 lr 0.000095	 wd 0.0500	time 0.5200 (0.6706)	data time 0.0008 (0.1766)	model time 0.0000 (0.0000)	loss 0.5791 (0.6008)	grad_norm 2.3030 (inf)	loss_scale 32768.0000 (37449.1429)	mem 13675MB
[2024-11-09 13:59:10 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][30/156]	eta 0:01:19 lr 0.000095	 wd 0.0500	time 0.5214 (0.6310)	data time 0.0205 (0.1218)	model time 0.0000 (0.0000)	loss 0.6333 (0.5925)	grad_norm 1.1071 (inf)	loss_scale 32768.0000 (35939.0968)	mem 13675MB
[2024-11-09 13:59:15 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][40/156]	eta 0:01:10 lr 0.000095	 wd 0.0500	time 0.6165 (0.6080)	data time 0.0073 (0.0994)	model time 0.0000 (0.0000)	loss 0.6639 (0.5960)	grad_norm 2.9817 (inf)	loss_scale 32768.0000 (35165.6585)	mem 13675MB
[2024-11-09 13:59:20 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][50/156]	eta 0:01:02 lr 0.000095	 wd 0.0500	time 0.5804 (0.5856)	data time 0.0525 (0.0834)	model time 0.0000 (0.0000)	loss 0.5273 (0.5932)	grad_norm 3.1219 (inf)	loss_scale 32768.0000 (34695.5294)	mem 13675MB
[2024-11-09 13:59:25 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][60/156]	eta 0:00:55 lr 0.000095	 wd 0.0500	time 0.6948 (0.5808)	data time 0.0779 (0.0748)	model time 0.6169 (0.5252)	loss 0.6057 (0.5930)	grad_norm 1.5803 (inf)	loss_scale 32768.0000 (34379.5410)	mem 13675MB
[2024-11-09 13:59:31 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][70/156]	eta 0:00:49 lr 0.000095	 wd 0.0500	time 0.4919 (0.5778)	data time 0.0290 (0.0686)	model time 0.4629 (0.5271)	loss 0.6280 (0.5883)	grad_norm 1.3051 (inf)	loss_scale 32768.0000 (34152.5634)	mem 13675MB
[2024-11-09 13:59:36 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][80/156]	eta 0:00:43 lr 0.000095	 wd 0.0500	time 0.5764 (0.5675)	data time 0.0275 (0.0621)	model time 0.5489 (0.5109)	loss 0.6162 (0.5892)	grad_norm 1.5251 (inf)	loss_scale 32768.0000 (33981.6296)	mem 13675MB
[2024-11-09 13:59:41 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][90/156]	eta 0:00:37 lr 0.000095	 wd 0.0500	time 0.5524 (0.5623)	data time 0.0343 (0.0572)	model time 0.5181 (0.5087)	loss 0.5356 (0.5906)	grad_norm 1.9523 (inf)	loss_scale 32768.0000 (33848.2637)	mem 13675MB
[2024-11-09 13:59:46 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][100/156]	eta 0:00:31 lr 0.000095	 wd 0.0500	time 0.4335 (0.5565)	data time 0.0245 (0.0531)	model time 0.4090 (0.5048)	loss 0.6119 (0.5921)	grad_norm 1.1898 (inf)	loss_scale 32768.0000 (33741.3069)	mem 13675MB
[2024-11-09 13:59:51 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][110/156]	eta 0:00:25 lr 0.000095	 wd 0.0500	time 0.4577 (0.5488)	data time 0.0400 (0.0500)	model time 0.4178 (0.4958)	loss 0.5385 (0.5930)	grad_norm 2.2658 (inf)	loss_scale 32768.0000 (33653.6216)	mem 13675MB
[2024-11-09 13:59:56 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][120/156]	eta 0:00:19 lr 0.000095	 wd 0.0500	time 0.6001 (0.5472)	data time 0.0625 (0.0476)	model time 0.5375 (0.4977)	loss 0.5666 (0.5918)	grad_norm 1.9779 (inf)	loss_scale 32768.0000 (33580.4298)	mem 13675MB
[2024-11-09 14:00:01 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][130/156]	eta 0:00:14 lr 0.000095	 wd 0.0500	time 0.4661 (0.5422)	data time 0.0007 (0.0447)	model time 0.4655 (0.4944)	loss 0.5128 (0.5908)	grad_norm 2.4292 (inf)	loss_scale 32768.0000 (33518.4122)	mem 13675MB
[2024-11-09 14:00:06 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][140/156]	eta 0:00:08 lr 0.000095	 wd 0.0500	time 0.4258 (0.5371)	data time 0.0008 (0.0424)	model time 0.4249 (0.4903)	loss 0.4766 (0.5872)	grad_norm 2.8033 (inf)	loss_scale 32768.0000 (33465.1915)	mem 13675MB
[2024-11-09 14:00:10 vssm1_tiny_0230s](training.py 201): INFO Train: [111/300][150/156]	eta 0:00:03 lr 0.000095	 wd 0.0500	time 0.4284 (0.5312)	data time 0.0007 (0.0397)	model time 0.4277 (0.4860)	loss 0.6756 (0.5895)	grad_norm 1.7750 (inf)	loss_scale 32768.0000 (33419.0199)	mem 13675MB
[2024-11-09 14:00:13 vssm1_tiny_0230s](training.py 212): INFO EPOCH 111 training takes 0:01:23
[2024-11-09 14:00:13 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_111.pth saving......
[2024-11-09 14:00:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_111.pth saved !!!
[2024-11-09 14:00:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.693 (3.693)	Loss 0.2463 (0.2463)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:00:21 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.594)	Loss 0.2585 (0.2500)	Acc@1 94.531 (93.963)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:00:23 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.441 (0.424)	Loss 0.2678 (0.2635)	Acc@1 92.969 (92.820)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:00:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.371)	Loss 0.3203 (0.2785)	Acc@1 91.406 (92.137)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:00:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.700 Acc@5 100.000
[2024-11-09 14:00:27 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.7%
[2024-11-09 14:00:27 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.70%
[2024-11-09 14:00:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.860 (3.860)	Loss 0.3230 (0.3230)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:00:35 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.132 (0.674)	Loss 0.3303 (0.3277)	Acc@1 98.438 (98.366)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:00:37 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.450)	Loss 0.7710 (0.3635)	Acc@1 39.062 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:00:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.306 (0.427)	Loss 0.8599 (0.5112)	Acc@1 35.938 (75.176)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:00:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 66.980 Acc@5 100.000
[2024-11-09 14:00:43 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 67.0%
[2024-11-09 14:00:43 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 66.98%
[2024-11-09 14:00:46 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][0/156]	eta 0:09:41 lr 0.000095	 wd 0.0500	time 3.7279 (3.7279)	data time 3.2466 (3.2466)	model time 0.0000 (0.0000)	loss 0.5620 (0.5620)	grad_norm 2.3657 (2.3657)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:00:51 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][10/156]	eta 0:01:50 lr 0.000095	 wd 0.0500	time 0.4070 (0.7571)	data time 0.0007 (0.3023)	model time 0.0000 (0.0000)	loss 0.6108 (0.5860)	grad_norm 2.0012 (1.9877)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:00:56 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][20/156]	eta 0:01:24 lr 0.000095	 wd 0.0500	time 0.4472 (0.6209)	data time 0.0101 (0.1625)	model time 0.0000 (0.0000)	loss 0.5166 (0.5925)	grad_norm 1.6673 (2.0015)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:01 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][30/156]	eta 0:01:13 lr 0.000095	 wd 0.0500	time 0.4513 (0.5843)	data time 0.0156 (0.1129)	model time 0.0000 (0.0000)	loss 0.4575 (0.5798)	grad_norm 2.7229 (1.9981)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:06 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][40/156]	eta 0:01:04 lr 0.000095	 wd 0.0500	time 0.5346 (0.5555)	data time 0.0038 (0.0879)	model time 0.0000 (0.0000)	loss 0.4761 (0.5813)	grad_norm 4.0558 (2.1293)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:10 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][50/156]	eta 0:00:56 lr 0.000095	 wd 0.0500	time 0.4647 (0.5302)	data time 0.0007 (0.0717)	model time 0.0000 (0.0000)	loss 0.6893 (0.5904)	grad_norm 1.4723 (2.1832)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:15 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][60/156]	eta 0:00:50 lr 0.000095	 wd 0.0500	time 0.4833 (0.5227)	data time 0.0056 (0.0614)	model time 0.4777 (0.4757)	loss 0.5039 (0.5870)	grad_norm 1.4387 (2.1429)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:19 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][70/156]	eta 0:00:44 lr 0.000095	 wd 0.0500	time 0.4568 (0.5162)	data time 0.0216 (0.0550)	model time 0.4352 (0.4681)	loss 0.6066 (0.5892)	grad_norm 1.5050 (2.0411)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:24 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][80/156]	eta 0:00:38 lr 0.000095	 wd 0.0500	time 0.5602 (0.5090)	data time 0.0007 (0.0489)	model time 0.5595 (0.4628)	loss 0.6605 (0.5867)	grad_norm 2.8252 (2.0514)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:28 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][90/156]	eta 0:00:32 lr 0.000095	 wd 0.0500	time 0.4106 (0.4994)	data time 0.0006 (0.0443)	model time 0.4100 (0.4509)	loss 0.5239 (0.5861)	grad_norm 1.7182 (2.1486)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:33 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][100/156]	eta 0:00:27 lr 0.000094	 wd 0.0500	time 0.4371 (0.4957)	data time 0.0024 (0.0405)	model time 0.4346 (0.4517)	loss 0.6042 (0.5891)	grad_norm 1.2135 (2.1605)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:38 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][110/156]	eta 0:00:22 lr 0.000094	 wd 0.0500	time 0.4452 (0.4956)	data time 0.0021 (0.0377)	model time 0.4431 (0.4574)	loss 0.6342 (0.5884)	grad_norm 1.3188 (2.1330)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:42 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][120/156]	eta 0:00:17 lr 0.000094	 wd 0.0500	time 0.4439 (0.4937)	data time 0.0173 (0.0352)	model time 0.4266 (0.4586)	loss 0.5814 (0.5891)	grad_norm 1.2623 (2.0978)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:47 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][130/156]	eta 0:00:12 lr 0.000094	 wd 0.0500	time 0.4318 (0.4936)	data time 0.0028 (0.0333)	model time 0.4289 (0.4613)	loss 0.6102 (0.5904)	grad_norm 1.6640 (2.0685)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:52 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][140/156]	eta 0:00:07 lr 0.000094	 wd 0.0500	time 0.5044 (0.4930)	data time 0.0008 (0.0323)	model time 0.5036 (0.4620)	loss 0.5897 (0.5904)	grad_norm 1.1198 (2.0379)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:01:57 vssm1_tiny_0230s](training.py 201): INFO Train: [112/300][150/156]	eta 0:00:02 lr 0.000094	 wd 0.0500	time 0.5013 (0.4949)	data time 0.0005 (0.0306)	model time 0.5008 (0.4673)	loss 0.6198 (0.5910)	grad_norm 1.7584 (2.0356)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:02:00 vssm1_tiny_0230s](training.py 212): INFO EPOCH 112 training takes 0:01:17
[2024-11-09 14:02:00 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_112.pth saving......
[2024-11-09 14:02:01 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_112.pth saved !!!
[2024-11-09 14:02:03 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.662 (2.662)	Loss 0.2913 (0.2913)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:02:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.146 (0.424)	Loss 0.2942 (0.2974)	Acc@1 92.188 (89.773)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:02:09 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 1.308 (0.412)	Loss 0.2098 (0.3081)	Acc@1 96.875 (89.025)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:02:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.375)	Loss 0.2634 (0.2909)	Acc@1 93.750 (90.625)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:02:15 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.440 Acc@5 100.000
[2024-11-09 14:02:15 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.4%
[2024-11-09 14:02:15 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.70%
[2024-11-09 14:02:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.788 (3.788)	Loss 0.3223 (0.3223)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:02:21 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.157 (0.556)	Loss 0.3296 (0.3271)	Acc@1 97.656 (98.295)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:02:23 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.169 (0.392)	Loss 0.7661 (0.3626)	Acc@1 39.844 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:02:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.331)	Loss 0.8555 (0.5093)	Acc@1 37.500 (75.554)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:02:28 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 67.380 Acc@5 100.000
[2024-11-09 14:02:28 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 67.4%
[2024-11-09 14:02:28 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 67.38%
[2024-11-09 14:02:33 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][0/156]	eta 0:13:18 lr 0.000094	 wd 0.0500	time 5.1180 (5.1180)	data time 4.6259 (4.6259)	model time 0.0000 (0.0000)	loss 0.4515 (0.4515)	grad_norm 1.6984 (1.6984)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:02:38 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][10/156]	eta 0:02:10 lr 0.000094	 wd 0.0500	time 0.4291 (0.8929)	data time 0.0065 (0.4289)	model time 0.0000 (0.0000)	loss 0.6116 (0.5778)	grad_norm 1.5209 (1.8508)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:02:42 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][20/156]	eta 0:01:34 lr 0.000094	 wd 0.0500	time 0.4573 (0.6935)	data time 0.0183 (0.2306)	model time 0.0000 (0.0000)	loss 0.6410 (0.5762)	grad_norm 1.8829 (2.4300)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:02:47 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][30/156]	eta 0:01:18 lr 0.000094	 wd 0.0500	time 0.4526 (0.6236)	data time 0.0007 (0.1616)	model time 0.0000 (0.0000)	loss 0.6529 (0.5835)	grad_norm 2.0295 (2.3673)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:02:52 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][40/156]	eta 0:01:07 lr 0.000094	 wd 0.0500	time 0.4477 (0.5860)	data time 0.0275 (0.1252)	model time 0.0000 (0.0000)	loss 0.4824 (0.5782)	grad_norm 2.3392 (2.3740)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:02:56 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][50/156]	eta 0:00:59 lr 0.000094	 wd 0.0500	time 0.4350 (0.5625)	data time 0.0034 (0.1017)	model time 0.0000 (0.0000)	loss 0.6265 (0.5821)	grad_norm 1.9632 (2.3315)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:02 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][60/156]	eta 0:00:53 lr 0.000094	 wd 0.0500	time 0.4994 (0.5588)	data time 0.0084 (0.0881)	model time 0.4910 (0.5214)	loss 0.6350 (0.5779)	grad_norm 1.5073 (2.3045)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:07 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][70/156]	eta 0:00:47 lr 0.000094	 wd 0.0500	time 0.4745 (0.5494)	data time 0.0412 (0.0787)	model time 0.4333 (0.4959)	loss 0.5366 (0.5742)	grad_norm 2.2007 (2.3061)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:12 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][80/156]	eta 0:00:41 lr 0.000094	 wd 0.0500	time 0.6010 (0.5434)	data time 0.0221 (0.0715)	model time 0.5790 (0.4910)	loss 0.5383 (0.5770)	grad_norm 2.4021 (2.2914)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:17 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][90/156]	eta 0:00:35 lr 0.000094	 wd 0.0500	time 0.4686 (0.5363)	data time 0.0061 (0.0655)	model time 0.4626 (0.4835)	loss 0.5976 (0.5775)	grad_norm 1.8807 (2.3320)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:21 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][100/156]	eta 0:00:29 lr 0.000094	 wd 0.0500	time 0.4200 (0.5306)	data time 0.0007 (0.0606)	model time 0.4193 (0.4794)	loss 0.6505 (0.5765)	grad_norm 2.7978 (2.3697)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:26 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][110/156]	eta 0:00:24 lr 0.000094	 wd 0.0500	time 0.6159 (0.5260)	data time 0.0231 (0.0571)	model time 0.5929 (0.4757)	loss 0.6388 (0.5797)	grad_norm 0.9701 (2.3185)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:31 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][120/156]	eta 0:00:18 lr 0.000094	 wd 0.0500	time 0.5153 (0.5234)	data time 0.0014 (0.0543)	model time 0.5139 (0.4753)	loss 0.6756 (0.5806)	grad_norm 1.6797 (2.2862)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:36 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][130/156]	eta 0:00:13 lr 0.000094	 wd 0.0500	time 0.5081 (0.5224)	data time 0.0037 (0.0514)	model time 0.5044 (0.4774)	loss 0.6104 (0.5825)	grad_norm 1.7483 (2.2528)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:41 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][140/156]	eta 0:00:08 lr 0.000094	 wd 0.0500	time 0.4898 (0.5203)	data time 0.0260 (0.0488)	model time 0.4639 (0.4776)	loss 0.5647 (0.5828)	grad_norm 1.9894 (2.2138)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:46 vssm1_tiny_0230s](training.py 201): INFO Train: [113/300][150/156]	eta 0:00:03 lr 0.000094	 wd 0.0500	time 0.4541 (0.5190)	data time 0.0007 (0.0457)	model time 0.4535 (0.4797)	loss 0.6101 (0.5827)	grad_norm 1.7314 (2.2017)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:03:49 vssm1_tiny_0230s](training.py 212): INFO EPOCH 113 training takes 0:01:21
[2024-11-09 14:03:49 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_113.pth saving......
[2024-11-09 14:03:49 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_113.pth saved !!!
[2024-11-09 14:03:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.763 (2.763)	Loss 0.2539 (0.2539)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:03:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.552)	Loss 0.2629 (0.2543)	Acc@1 93.750 (92.685)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:03:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.231 (0.432)	Loss 0.2147 (0.2681)	Acc@1 94.531 (91.183)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:04:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.367)	Loss 0.2693 (0.2660)	Acc@1 91.406 (91.532)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:04:04 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.840 Acc@5 100.000
[2024-11-09 14:04:04 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.8%
[2024-11-09 14:04:04 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.84%
[2024-11-09 14:04:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.477 (3.477)	Loss 0.3210 (0.3210)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:04:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.413 (0.610)	Loss 0.3284 (0.3259)	Acc@1 97.656 (98.295)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:04:14 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.472)	Loss 0.7617 (0.3613)	Acc@1 40.625 (93.676)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:04:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.148 (0.369)	Loss 0.8525 (0.5074)	Acc@1 37.500 (75.706)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:04:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 67.520 Acc@5 100.000
[2024-11-09 14:04:17 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 67.5%
[2024-11-09 14:04:17 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 67.52%
[2024-11-09 14:04:21 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][0/156]	eta 0:10:11 lr 0.000094	 wd 0.0500	time 3.9197 (3.9197)	data time 3.4689 (3.4689)	model time 0.0000 (0.0000)	loss 0.4718 (0.4718)	grad_norm 2.1265 (2.1265)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:04:27 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][10/156]	eta 0:02:01 lr 0.000094	 wd 0.0500	time 0.4452 (0.8315)	data time 0.0209 (0.3560)	model time 0.0000 (0.0000)	loss 0.5651 (0.5781)	grad_norm 2.6806 (2.3997)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:04:31 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][20/156]	eta 0:01:29 lr 0.000094	 wd 0.0500	time 0.5646 (0.6609)	data time 0.0200 (0.1917)	model time 0.0000 (0.0000)	loss 0.6666 (0.5835)	grad_norm 2.2631 (2.3358)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:04:36 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][30/156]	eta 0:01:15 lr 0.000094	 wd 0.0500	time 0.4544 (0.6016)	data time 0.0154 (0.1331)	model time 0.0000 (0.0000)	loss 0.6020 (0.5827)	grad_norm 2.0575 (2.1640)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:04:40 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][40/156]	eta 0:01:05 lr 0.000094	 wd 0.0500	time 0.4240 (0.5627)	data time 0.0005 (0.1029)	model time 0.0000 (0.0000)	loss 0.5344 (0.5807)	grad_norm 2.2500 (2.2085)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:04:45 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][50/156]	eta 0:00:57 lr 0.000093	 wd 0.0500	time 0.4901 (0.5470)	data time 0.0172 (0.0851)	model time 0.0000 (0.0000)	loss 0.6172 (0.5795)	grad_norm 1.6778 (2.1987)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:04:50 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][60/156]	eta 0:00:51 lr 0.000093	 wd 0.0500	time 0.4389 (0.5363)	data time 0.0228 (0.0740)	model time 0.4162 (0.4642)	loss 0.5902 (0.5836)	grad_norm 1.3433 (2.2335)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:04:55 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][70/156]	eta 0:00:45 lr 0.000093	 wd 0.0500	time 0.6454 (0.5253)	data time 0.0214 (0.0651)	model time 0.6240 (0.4559)	loss 0.5816 (0.5813)	grad_norm 1.8630 (2.2379)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:05:00 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][80/156]	eta 0:00:39 lr 0.000093	 wd 0.0500	time 0.4717 (0.5262)	data time 0.0193 (0.0586)	model time 0.4525 (0.4772)	loss 0.5505 (0.5810)	grad_norm 2.4878 (2.1917)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:05:05 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][90/156]	eta 0:00:34 lr 0.000093	 wd 0.0500	time 0.4256 (0.5244)	data time 0.0007 (0.0547)	model time 0.4249 (0.4797)	loss 0.6548 (0.5837)	grad_norm 1.4086 (2.2255)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:05:10 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][100/156]	eta 0:00:29 lr 0.000093	 wd 0.0500	time 0.4689 (0.5253)	data time 0.0141 (0.0513)	model time 0.4548 (0.4864)	loss 0.6191 (0.5820)	grad_norm 2.7107 (2.2337)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:05:15 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][110/156]	eta 0:00:23 lr 0.000093	 wd 0.0500	time 0.4534 (0.5189)	data time 0.0007 (0.0475)	model time 0.4527 (0.4794)	loss 0.5443 (0.5837)	grad_norm 1.6748 (2.2352)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:05:21 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][120/156]	eta 0:00:18 lr 0.000093	 wd 0.0500	time 0.6217 (0.5242)	data time 0.0066 (0.0466)	model time 0.6151 (0.4890)	loss 0.6455 (0.5842)	grad_norm 1.1600 (2.2088)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:05:26 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][130/156]	eta 0:00:13 lr 0.000093	 wd 0.0500	time 0.4623 (0.5260)	data time 0.0130 (0.0446)	model time 0.4492 (0.4939)	loss 0.5941 (0.5868)	grad_norm 1.6632 (2.1959)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:05:31 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][140/156]	eta 0:00:08 lr 0.000093	 wd 0.0500	time 0.4340 (0.5220)	data time 0.0008 (0.0427)	model time 0.4332 (0.4891)	loss 0.6313 (0.5866)	grad_norm 1.4582 (2.1960)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:05:36 vssm1_tiny_0230s](training.py 201): INFO Train: [114/300][150/156]	eta 0:00:03 lr 0.000093	 wd 0.0500	time 0.5652 (0.5202)	data time 0.0008 (0.0400)	model time 0.5644 (0.4896)	loss 0.5334 (0.5848)	grad_norm 3.1831 (2.2048)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:05:39 vssm1_tiny_0230s](training.py 212): INFO EPOCH 114 training takes 0:01:21
[2024-11-09 14:05:39 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_114.pth saving......
[2024-11-09 14:05:39 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_114.pth saved !!!
[2024-11-09 14:05:43 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.037 (4.037)	Loss 0.2006 (0.2006)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:05:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.167 (0.617)	Loss 0.2134 (0.2153)	Acc@1 96.094 (94.886)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:05:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.144 (0.428)	Loss 0.2415 (0.2332)	Acc@1 94.531 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:05:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.148 (0.365)	Loss 0.3040 (0.2540)	Acc@1 90.625 (92.061)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:05:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.800 Acc@5 100.000
[2024-11-09 14:05:53 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.8%
[2024-11-09 14:05:53 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.84%
[2024-11-09 14:05:57 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.953 (3.953)	Loss 0.3206 (0.3206)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:06:00 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.623)	Loss 0.3276 (0.3253)	Acc@1 97.656 (98.295)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:06:03 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.462)	Loss 0.7563 (0.3605)	Acc@1 40.625 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:06:05 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.389)	Loss 0.8477 (0.5053)	Acc@1 37.500 (76.008)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:06:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 67.920 Acc@5 100.000
[2024-11-09 14:06:08 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 67.9%
[2024-11-09 14:06:08 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 67.92%
[2024-11-09 14:06:11 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][0/156]	eta 0:07:16 lr 0.000093	 wd 0.0500	time 2.7978 (2.7978)	data time 2.1173 (2.1173)	model time 0.0000 (0.0000)	loss 0.6022 (0.6022)	grad_norm 2.2188 (2.2188)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:06:17 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][10/156]	eta 0:02:02 lr 0.000093	 wd 0.0500	time 0.4290 (0.8404)	data time 0.0006 (0.3065)	model time 0.0000 (0.0000)	loss 0.6079 (0.5931)	grad_norm 2.4748 (2.4821)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:06:22 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][20/156]	eta 0:01:31 lr 0.000093	 wd 0.0500	time 0.4690 (0.6710)	data time 0.0006 (0.1634)	model time 0.0000 (0.0000)	loss 0.6673 (0.5864)	grad_norm 2.2597 (2.4238)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:06:27 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][30/156]	eta 0:01:17 lr 0.000093	 wd 0.0500	time 0.5669 (0.6136)	data time 0.0341 (0.1177)	model time 0.0000 (0.0000)	loss 0.6676 (0.5858)	grad_norm 1.6258 (2.2711)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:06:32 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][40/156]	eta 0:01:08 lr 0.000093	 wd 0.0500	time 0.5742 (0.5896)	data time 0.0306 (0.0910)	model time 0.0000 (0.0000)	loss 0.4843 (0.5823)	grad_norm 1.5305 (2.2299)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:06:37 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][50/156]	eta 0:00:59 lr 0.000093	 wd 0.0500	time 0.4483 (0.5653)	data time 0.0068 (0.0761)	model time 0.0000 (0.0000)	loss 0.5972 (0.5782)	grad_norm 1.4191 (2.2204)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:06:42 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][60/156]	eta 0:00:53 lr 0.000093	 wd 0.0500	time 0.5769 (0.5588)	data time 0.0237 (0.0666)	model time 0.5532 (0.5074)	loss 0.6220 (0.5782)	grad_norm 2.5608 (2.1831)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:06:47 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][70/156]	eta 0:00:46 lr 0.000093	 wd 0.0500	time 0.5243 (0.5465)	data time 0.0008 (0.0583)	model time 0.5234 (0.4854)	loss 0.5884 (0.5789)	grad_norm 2.2632 (2.2347)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:06:52 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][80/156]	eta 0:00:41 lr 0.000093	 wd 0.0500	time 0.5706 (0.5489)	data time 0.0099 (0.0534)	model time 0.5607 (0.5062)	loss 0.6005 (0.5794)	grad_norm 1.8567 (2.2517)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:06:57 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][90/156]	eta 0:00:35 lr 0.000093	 wd 0.0500	time 0.4568 (0.5413)	data time 0.0005 (0.0499)	model time 0.4563 (0.4941)	loss 0.5657 (0.5795)	grad_norm 3.3886 (2.2318)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:07:02 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][100/156]	eta 0:00:29 lr 0.000093	 wd 0.0500	time 0.4192 (0.5336)	data time 0.0013 (0.0468)	model time 0.4179 (0.4845)	loss 0.6107 (0.5797)	grad_norm 1.8337 (2.1882)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:07:07 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][110/156]	eta 0:00:24 lr 0.000093	 wd 0.0500	time 0.7486 (0.5304)	data time 0.0496 (0.0439)	model time 0.6990 (0.4841)	loss 0.6046 (0.5799)	grad_norm 2.3904 (2.1950)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:07:11 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][120/156]	eta 0:00:18 lr 0.000093	 wd 0.0500	time 0.4544 (0.5246)	data time 0.0107 (0.0413)	model time 0.4438 (0.4789)	loss 0.5833 (0.5794)	grad_norm 1.4129 (2.2006)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:07:16 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][130/156]	eta 0:00:13 lr 0.000093	 wd 0.0500	time 0.7000 (0.5242)	data time 0.0218 (0.0395)	model time 0.6782 (0.4819)	loss 0.5337 (0.5791)	grad_norm 1.5494 (2.2080)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:07:21 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][140/156]	eta 0:00:08 lr 0.000093	 wd 0.0500	time 0.4493 (0.5213)	data time 0.0009 (0.0373)	model time 0.4484 (0.4811)	loss 0.5314 (0.5813)	grad_norm 2.8067 (2.1915)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:07:27 vssm1_tiny_0230s](training.py 201): INFO Train: [115/300][150/156]	eta 0:00:03 lr 0.000092	 wd 0.0500	time 0.4875 (0.5253)	data time 0.0005 (0.0349)	model time 0.4870 (0.4909)	loss 0.6338 (0.5822)	grad_norm 1.3842 (2.1662)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:07:30 vssm1_tiny_0230s](training.py 212): INFO EPOCH 115 training takes 0:01:21
[2024-11-09 14:07:30 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_115.pth saving......
[2024-11-09 14:07:30 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_115.pth saved !!!
[2024-11-09 14:07:35 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.619 (4.619)	Loss 0.2590 (0.2590)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:07:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.170 (0.629)	Loss 0.2695 (0.2659)	Acc@1 94.531 (94.957)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:07:40 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.152 (0.487)	Loss 0.2661 (0.2783)	Acc@1 93.750 (93.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:07:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.410)	Loss 0.3235 (0.2926)	Acc@1 90.625 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:07:46 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.900 Acc@5 100.000
[2024-11-09 14:07:46 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.9%
[2024-11-09 14:07:46 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.90%
[2024-11-09 14:07:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.426 (3.426)	Loss 0.3198 (0.3198)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:07:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.294 (0.508)	Loss 0.3269 (0.3248)	Acc@1 97.656 (98.224)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:07:54 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.151 (0.379)	Loss 0.7510 (0.3597)	Acc@1 41.406 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:07:56 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.200 (0.330)	Loss 0.8428 (0.5032)	Acc@1 38.281 (76.109)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:07:59 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 68.080 Acc@5 100.000
[2024-11-09 14:07:59 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 68.1%
[2024-11-09 14:07:59 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 68.08%
[2024-11-09 14:08:04 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][0/156]	eta 0:12:35 lr 0.000092	 wd 0.0500	time 4.8418 (4.8418)	data time 4.3290 (4.3290)	model time 0.0000 (0.0000)	loss 0.6616 (0.6616)	grad_norm 1.3196 (1.3196)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:08:09 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][10/156]	eta 0:02:11 lr 0.000092	 wd 0.0500	time 0.4893 (0.8981)	data time 0.0061 (0.4149)	model time 0.0000 (0.0000)	loss 0.5265 (0.6120)	grad_norm 1.6719 (1.8996)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:08:14 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][20/156]	eta 0:01:38 lr 0.000092	 wd 0.0500	time 0.5687 (0.7241)	data time 0.0087 (0.2284)	model time 0.0000 (0.0000)	loss 0.4896 (0.5968)	grad_norm 2.8721 (1.8207)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:08:19 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][30/156]	eta 0:01:22 lr 0.000092	 wd 0.0500	time 0.6020 (0.6555)	data time 0.0135 (0.1606)	model time 0.0000 (0.0000)	loss 0.5860 (0.5954)	grad_norm 2.0319 (1.9894)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:08:25 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][40/156]	eta 0:01:13 lr 0.000092	 wd 0.0500	time 0.5702 (0.6315)	data time 0.0012 (0.1291)	model time 0.0000 (0.0000)	loss 0.6373 (0.5933)	grad_norm 2.5395 (2.0863)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:08:30 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][50/156]	eta 0:01:04 lr 0.000092	 wd 0.0500	time 0.4339 (0.6118)	data time 0.0011 (0.1079)	model time 0.0000 (0.0000)	loss 0.5834 (0.5929)	grad_norm 2.3204 (2.1194)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:08:35 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][60/156]	eta 0:00:57 lr 0.000092	 wd 0.0500	time 0.4332 (0.5960)	data time 0.0132 (0.0939)	model time 0.4200 (0.4929)	loss 0.6069 (0.5930)	grad_norm 2.7325 (2.1216)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:08:40 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][70/156]	eta 0:00:50 lr 0.000092	 wd 0.0500	time 0.4156 (0.5818)	data time 0.0007 (0.0841)	model time 0.4149 (0.4819)	loss 0.6565 (0.5906)	grad_norm 2.4838 (2.1296)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:08:45 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][80/156]	eta 0:00:43 lr 0.000092	 wd 0.0500	time 0.4409 (0.5739)	data time 0.0246 (0.0753)	model time 0.4163 (0.4898)	loss 0.5156 (0.5904)	grad_norm 2.4639 (2.1047)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:08:50 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][90/156]	eta 0:00:37 lr 0.000092	 wd 0.0500	time 0.4353 (0.5635)	data time 0.0005 (0.0678)	model time 0.4348 (0.4853)	loss 0.5823 (0.5901)	grad_norm 2.9235 (2.1547)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:08:55 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][100/156]	eta 0:00:31 lr 0.000092	 wd 0.0500	time 0.4764 (0.5560)	data time 0.0283 (0.0624)	model time 0.4481 (0.4833)	loss 0.5826 (0.5892)	grad_norm 1.7779 (2.1651)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:09:00 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][110/156]	eta 0:00:25 lr 0.000092	 wd 0.0500	time 0.4837 (0.5512)	data time 0.0297 (0.0582)	model time 0.4540 (0.4838)	loss 0.5707 (0.5893)	grad_norm 1.9182 (2.1531)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:09:05 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][120/156]	eta 0:00:19 lr 0.000092	 wd 0.0500	time 0.5073 (0.5493)	data time 0.0031 (0.0544)	model time 0.5043 (0.4885)	loss 0.6229 (0.5906)	grad_norm 1.8402 (2.1671)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:09:10 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][130/156]	eta 0:00:14 lr 0.000092	 wd 0.0500	time 0.4705 (0.5447)	data time 0.0255 (0.0515)	model time 0.4450 (0.4864)	loss 0.6285 (0.5914)	grad_norm 1.6745 (2.1876)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:09:15 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][140/156]	eta 0:00:08 lr 0.000092	 wd 0.0500	time 0.4259 (0.5406)	data time 0.0010 (0.0485)	model time 0.4249 (0.4853)	loss 0.5933 (0.5919)	grad_norm 1.3328 (2.2030)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:09:20 vssm1_tiny_0230s](training.py 201): INFO Train: [116/300][150/156]	eta 0:00:03 lr 0.000092	 wd 0.0500	time 0.4277 (0.5376)	data time 0.0007 (0.0455)	model time 0.4270 (0.4860)	loss 0.5902 (0.5918)	grad_norm 2.2842 (2.1660)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:09:23 vssm1_tiny_0230s](training.py 212): INFO EPOCH 116 training takes 0:01:23
[2024-11-09 14:09:23 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_116.pth saving......
[2024-11-09 14:09:23 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_116.pth saved !!!
[2024-11-09 14:09:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.978 (2.978)	Loss 0.3296 (0.3296)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:09:30 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 1.363 (0.636)	Loss 0.3455 (0.3470)	Acc@1 86.719 (86.293)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:09:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.439)	Loss 0.1774 (0.3522)	Acc@1 97.656 (85.677)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:09:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.380)	Loss 0.2257 (0.3074)	Acc@1 93.750 (89.163)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:09:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.640 Acc@5 100.000
[2024-11-09 14:09:38 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 90.6%
[2024-11-09 14:09:38 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 91.90%
[2024-11-09 14:09:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.786 (3.786)	Loss 0.3191 (0.3191)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:09:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.173 (0.589)	Loss 0.3262 (0.3241)	Acc@1 97.656 (98.224)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:09:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.215 (0.470)	Loss 0.7456 (0.3587)	Acc@1 41.406 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:09:50 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.373)	Loss 0.8379 (0.5011)	Acc@1 38.281 (76.285)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:09:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 68.320 Acc@5 100.000
[2024-11-09 14:09:51 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 68.3%
[2024-11-09 14:09:51 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 68.32%
[2024-11-09 14:09:56 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][0/156]	eta 0:10:56 lr 0.000092	 wd 0.0500	time 4.2099 (4.2099)	data time 3.6880 (3.6880)	model time 0.0000 (0.0000)	loss 0.6147 (0.6147)	grad_norm 1.5881 (1.5881)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:00 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][10/156]	eta 0:01:57 lr 0.000092	 wd 0.0500	time 0.4319 (0.8057)	data time 0.0045 (0.3463)	model time 0.0000 (0.0000)	loss 0.5647 (0.6038)	grad_norm 1.8453 (1.8853)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:05 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][20/156]	eta 0:01:28 lr 0.000092	 wd 0.0500	time 0.5041 (0.6503)	data time 0.0009 (0.1866)	model time 0.0000 (0.0000)	loss 0.6305 (0.6072)	grad_norm 1.4630 (1.8465)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:10 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][30/156]	eta 0:01:14 lr 0.000092	 wd 0.0500	time 0.4391 (0.5948)	data time 0.0317 (0.1313)	model time 0.0000 (0.0000)	loss 0.5613 (0.6032)	grad_norm 2.3790 (1.9412)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:15 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][40/156]	eta 0:01:06 lr 0.000092	 wd 0.0500	time 0.4924 (0.5759)	data time 0.0106 (0.1021)	model time 0.0000 (0.0000)	loss 0.5180 (0.5974)	grad_norm 2.1745 (1.9316)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:20 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][50/156]	eta 0:00:59 lr 0.000092	 wd 0.0500	time 0.5504 (0.5647)	data time 0.0009 (0.0837)	model time 0.0000 (0.0000)	loss 0.5649 (0.5953)	grad_norm 2.8741 (1.9242)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:26 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][60/156]	eta 0:00:53 lr 0.000092	 wd 0.0500	time 0.6198 (0.5603)	data time 0.0182 (0.0715)	model time 0.6016 (0.5284)	loss 0.5381 (0.5933)	grad_norm 1.4685 (1.9703)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:31 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][70/156]	eta 0:00:48 lr 0.000092	 wd 0.0500	time 0.5198 (0.5633)	data time 0.0063 (0.0637)	model time 0.5135 (0.5471)	loss 0.6004 (0.5912)	grad_norm 1.9026 (2.0031)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:37 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][80/156]	eta 0:00:42 lr 0.000092	 wd 0.0500	time 0.6095 (0.5587)	data time 0.0050 (0.0576)	model time 0.6046 (0.5353)	loss 0.5386 (0.5909)	grad_norm 1.6110 (2.0087)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:42 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][90/156]	eta 0:00:36 lr 0.000091	 wd 0.0500	time 0.5349 (0.5569)	data time 0.0736 (0.0524)	model time 0.4613 (0.5345)	loss 0.6214 (0.5898)	grad_norm 1.9007 (2.0052)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:47 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][100/156]	eta 0:00:30 lr 0.000091	 wd 0.0500	time 0.5536 (0.5511)	data time 0.0470 (0.0485)	model time 0.5067 (0.5246)	loss 0.4775 (0.5871)	grad_norm 1.8554 (2.0489)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:52 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][110/156]	eta 0:00:25 lr 0.000091	 wd 0.0500	time 0.4868 (0.5478)	data time 0.0009 (0.0451)	model time 0.4859 (0.5212)	loss 0.5654 (0.5856)	grad_norm 4.4689 (2.0894)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:10:57 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][120/156]	eta 0:00:19 lr 0.000091	 wd 0.0500	time 0.5151 (0.5439)	data time 0.0197 (0.0424)	model time 0.4954 (0.5164)	loss 0.6260 (0.5845)	grad_norm 1.3704 (2.1496)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:11:02 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][130/156]	eta 0:00:14 lr 0.000091	 wd 0.0500	time 0.5550 (0.5409)	data time 0.0218 (0.0405)	model time 0.5331 (0.5127)	loss 0.5085 (0.5854)	grad_norm 3.2076 (2.1803)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:11:08 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][140/156]	eta 0:00:08 lr 0.000091	 wd 0.0500	time 0.5206 (0.5436)	data time 0.0008 (0.0386)	model time 0.5198 (0.5186)	loss 0.6130 (0.5865)	grad_norm 1.6344 (2.1845)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:11:13 vssm1_tiny_0230s](training.py 201): INFO Train: [117/300][150/156]	eta 0:00:03 lr 0.000091	 wd 0.0500	time 0.5403 (0.5404)	data time 0.0006 (0.0361)	model time 0.5397 (0.5162)	loss 0.6714 (0.5873)	grad_norm 1.1321 (2.1668)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:11:16 vssm1_tiny_0230s](training.py 212): INFO EPOCH 117 training takes 0:01:24
[2024-11-09 14:11:16 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_117.pth saving......
[2024-11-09 14:11:16 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_117.pth saved !!!
[2024-11-09 14:11:19 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.255 (2.255)	Loss 0.2634 (0.2634)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:11:21 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.642 (0.460)	Loss 0.2764 (0.2746)	Acc@1 92.969 (94.389)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:11:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.352)	Loss 0.2404 (0.2864)	Acc@1 94.531 (93.006)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:11:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.165 (0.296)	Loss 0.2903 (0.2869)	Acc@1 92.188 (92.742)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:11:28 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.700 Acc@5 100.000
[2024-11-09 14:11:28 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.7%
[2024-11-09 14:11:28 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.70%
[2024-11-09 14:11:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.045 (3.045)	Loss 0.3184 (0.3184)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:11:33 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.156 (0.477)	Loss 0.3254 (0.3235)	Acc@1 97.656 (98.153)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:11:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.175 (0.384)	Loss 0.7402 (0.3580)	Acc@1 42.188 (93.564)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:11:39 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.332)	Loss 0.8335 (0.4991)	Acc@1 39.062 (76.436)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:11:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 68.500 Acc@5 100.000
[2024-11-09 14:11:42 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 68.5%
[2024-11-09 14:11:42 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 68.50%
[2024-11-09 14:11:46 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][0/156]	eta 0:11:01 lr 0.000091	 wd 0.0500	time 4.2391 (4.2391)	data time 3.6581 (3.6581)	model time 0.0000 (0.0000)	loss 0.6018 (0.6018)	grad_norm 1.5692 (1.5692)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:11:51 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][10/156]	eta 0:02:04 lr 0.000091	 wd 0.0500	time 0.5297 (0.8498)	data time 0.0253 (0.3515)	model time 0.0000 (0.0000)	loss 0.5523 (0.5813)	grad_norm 2.3011 (1.9547)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:11:57 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][20/156]	eta 0:01:37 lr 0.000091	 wd 0.0500	time 0.5460 (0.7141)	data time 0.0486 (0.2041)	model time 0.0000 (0.0000)	loss 0.4672 (0.5686)	grad_norm 3.1513 (2.0522)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:02 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][30/156]	eta 0:01:22 lr 0.000091	 wd 0.0500	time 0.4510 (0.6560)	data time 0.0056 (0.1432)	model time 0.0000 (0.0000)	loss 0.5192 (0.5710)	grad_norm 3.4136 (2.1690)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:07 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][40/156]	eta 0:01:12 lr 0.000091	 wd 0.0500	time 0.8085 (0.6252)	data time 0.0250 (0.1117)	model time 0.0000 (0.0000)	loss 0.4737 (0.5714)	grad_norm 2.4032 (2.3891)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:12 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][50/156]	eta 0:01:03 lr 0.000091	 wd 0.0500	time 0.5010 (0.5954)	data time 0.0238 (0.0926)	model time 0.0000 (0.0000)	loss 0.5947 (0.5673)	grad_norm 2.0445 (2.4866)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:17 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][60/156]	eta 0:00:55 lr 0.000091	 wd 0.0500	time 0.5319 (0.5754)	data time 0.0215 (0.0795)	model time 0.5105 (0.4603)	loss 0.6064 (0.5687)	grad_norm 2.5937 (2.5248)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:22 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][70/156]	eta 0:00:49 lr 0.000091	 wd 0.0500	time 0.4859 (0.5720)	data time 0.0052 (0.0700)	model time 0.4807 (0.5001)	loss 0.6252 (0.5773)	grad_norm 2.6591 (2.4805)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:27 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][80/156]	eta 0:00:42 lr 0.000091	 wd 0.0500	time 0.4390 (0.5603)	data time 0.0014 (0.0631)	model time 0.4376 (0.4875)	loss 0.5244 (0.5772)	grad_norm 3.7308 (2.4926)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:32 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][90/156]	eta 0:00:36 lr 0.000091	 wd 0.0500	time 0.6264 (0.5564)	data time 0.1216 (0.0594)	model time 0.5048 (0.4898)	loss 0.6318 (0.5796)	grad_norm 4.0993 (2.4866)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:37 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][100/156]	eta 0:00:30 lr 0.000091	 wd 0.0500	time 0.5457 (0.5502)	data time 0.0417 (0.0563)	model time 0.5041 (0.4848)	loss 0.4981 (0.5797)	grad_norm 1.7896 (2.4436)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:43 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][110/156]	eta 0:00:25 lr 0.000091	 wd 0.0500	time 0.5788 (0.5499)	data time 0.0272 (0.0542)	model time 0.5516 (0.4896)	loss 0.6732 (0.5833)	grad_norm 2.2795 (2.4372)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:48 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][120/156]	eta 0:00:19 lr 0.000091	 wd 0.0500	time 0.5508 (0.5479)	data time 0.0781 (0.0516)	model time 0.4727 (0.4916)	loss 0.5779 (0.5838)	grad_norm 1.7866 (2.4212)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:53 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][130/156]	eta 0:00:14 lr 0.000091	 wd 0.0500	time 0.5275 (0.5425)	data time 0.0182 (0.0487)	model time 0.5093 (0.4881)	loss 0.5572 (0.5813)	grad_norm 2.5769 (2.4193)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:12:57 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][140/156]	eta 0:00:08 lr 0.000091	 wd 0.0500	time 0.5023 (0.5365)	data time 0.0014 (0.0457)	model time 0.5009 (0.4840)	loss 0.5903 (0.5784)	grad_norm 2.1694 (2.4393)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:13:02 vssm1_tiny_0230s](training.py 201): INFO Train: [118/300][150/156]	eta 0:00:03 lr 0.000091	 wd 0.0500	time 0.4433 (0.5326)	data time 0.0005 (0.0427)	model time 0.4427 (0.4833)	loss 0.5574 (0.5803)	grad_norm 2.7435 (2.4632)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:13:05 vssm1_tiny_0230s](training.py 212): INFO EPOCH 118 training takes 0:01:23
[2024-11-09 14:13:05 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_118.pth saving......
[2024-11-09 14:13:05 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_118.pth saved !!!
[2024-11-09 14:13:09 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.930 (3.930)	Loss 0.2284 (0.2284)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:13:12 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.206 (0.632)	Loss 0.2350 (0.2340)	Acc@1 93.750 (94.460)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:13:15 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.162 (0.464)	Loss 0.2456 (0.2482)	Acc@1 94.531 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:13:17 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.385)	Loss 0.3035 (0.2644)	Acc@1 91.406 (92.641)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:13:19 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.520 Acc@5 100.000
[2024-11-09 14:13:19 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.5%
[2024-11-09 14:13:19 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.70%
[2024-11-09 14:13:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.115 (4.115)	Loss 0.3176 (0.3176)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:13:26 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.196 (0.633)	Loss 0.3247 (0.3229)	Acc@1 97.656 (98.153)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:13:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.460)	Loss 0.7349 (0.3571)	Acc@1 42.969 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:13:31 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.394)	Loss 0.8281 (0.4970)	Acc@1 40.625 (76.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:13:34 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 68.800 Acc@5 100.000
[2024-11-09 14:13:34 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 68.8%
[2024-11-09 14:13:34 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 68.80%
[2024-11-09 14:13:39 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][0/156]	eta 0:11:25 lr 0.000091	 wd 0.0500	time 4.3953 (4.3953)	data time 3.9888 (3.9888)	model time 0.0000 (0.0000)	loss 0.5287 (0.5287)	grad_norm 3.6446 (3.6446)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:13:44 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][10/156]	eta 0:02:07 lr 0.000091	 wd 0.0500	time 0.4647 (0.8740)	data time 0.0024 (0.3741)	model time 0.0000 (0.0000)	loss 0.4819 (0.5751)	grad_norm 2.1737 (2.2166)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:13:49 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][20/156]	eta 0:01:34 lr 0.000091	 wd 0.0500	time 0.4615 (0.6968)	data time 0.0242 (0.1997)	model time 0.0000 (0.0000)	loss 0.5994 (0.5801)	grad_norm 2.9257 (2.2240)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:13:55 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][30/156]	eta 0:01:22 lr 0.000090	 wd 0.0500	time 0.5166 (0.6520)	data time 0.0105 (0.1416)	model time 0.0000 (0.0000)	loss 0.5045 (0.5799)	grad_norm 2.1892 (2.2517)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:00 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][40/156]	eta 0:01:12 lr 0.000090	 wd 0.0500	time 0.4885 (0.6282)	data time 0.0034 (0.1127)	model time 0.0000 (0.0000)	loss 0.5855 (0.5812)	grad_norm 2.2357 (2.1656)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:05 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][50/156]	eta 0:01:04 lr 0.000090	 wd 0.0500	time 0.4870 (0.6048)	data time 0.0009 (0.0930)	model time 0.0000 (0.0000)	loss 0.5797 (0.5784)	grad_norm 2.2897 (2.1063)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:10 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][60/156]	eta 0:00:56 lr 0.000090	 wd 0.0500	time 0.5176 (0.5862)	data time 0.0128 (0.0814)	model time 0.5048 (0.4689)	loss 0.5352 (0.5772)	grad_norm 4.2372 (2.1279)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:15 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][70/156]	eta 0:00:49 lr 0.000090	 wd 0.0500	time 0.5387 (0.5785)	data time 0.0115 (0.0719)	model time 0.5272 (0.4934)	loss 0.6091 (0.5733)	grad_norm 2.1500 (2.2120)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:21 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][80/156]	eta 0:00:43 lr 0.000090	 wd 0.0500	time 0.4599 (0.5747)	data time 0.0007 (0.0663)	model time 0.4592 (0.5027)	loss 0.5873 (0.5770)	grad_norm 1.7377 (2.2095)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:26 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][90/156]	eta 0:00:37 lr 0.000090	 wd 0.0500	time 0.4217 (0.5679)	data time 0.0047 (0.0611)	model time 0.4170 (0.5006)	loss 0.5702 (0.5773)	grad_norm 1.4760 (2.2108)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:32 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][100/156]	eta 0:00:31 lr 0.000090	 wd 0.0500	time 0.4914 (0.5655)	data time 0.0281 (0.0570)	model time 0.4633 (0.5051)	loss 0.6316 (0.5764)	grad_norm 1.3909 (2.1857)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:37 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][110/156]	eta 0:00:25 lr 0.000090	 wd 0.0500	time 0.5135 (0.5594)	data time 0.0029 (0.0529)	model time 0.5106 (0.5020)	loss 0.4530 (0.5745)	grad_norm 3.7516 (2.1972)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:42 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][120/156]	eta 0:00:19 lr 0.000090	 wd 0.0500	time 0.5067 (0.5545)	data time 0.0054 (0.0497)	model time 0.5013 (0.4998)	loss 0.4881 (0.5738)	grad_norm 3.6299 (2.2067)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:47 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][130/156]	eta 0:00:14 lr 0.000090	 wd 0.0500	time 0.4235 (0.5524)	data time 0.0042 (0.0486)	model time 0.4193 (0.4986)	loss 0.6363 (0.5774)	grad_norm 1.9638 (2.1864)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:52 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][140/156]	eta 0:00:08 lr 0.000090	 wd 0.0500	time 0.5363 (0.5478)	data time 0.0015 (0.0463)	model time 0.5348 (0.4957)	loss 0.5143 (0.5769)	grad_norm 1.8379 (2.1640)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:14:57 vssm1_tiny_0230s](training.py 201): INFO Train: [119/300][150/156]	eta 0:00:03 lr 0.000090	 wd 0.0500	time 0.4749 (0.5482)	data time 0.0005 (0.0433)	model time 0.4744 (0.5014)	loss 0.5472 (0.5747)	grad_norm 1.4743 (2.1598)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:15:00 vssm1_tiny_0230s](training.py 212): INFO EPOCH 119 training takes 0:01:25
[2024-11-09 14:15:00 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_119.pth saving......
[2024-11-09 14:15:00 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_119.pth saved !!!
[2024-11-09 14:15:04 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.213 (3.213)	Loss 0.1730 (0.1730)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:15:07 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.180 (0.604)	Loss 0.1896 (0.1795)	Acc@1 94.531 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:15:09 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.402)	Loss 0.2520 (0.1988)	Acc@1 94.531 (94.866)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:15:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.190 (0.384)	Loss 0.3201 (0.2367)	Acc@1 90.625 (92.792)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:15:14 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.960 Acc@5 100.000
[2024-11-09 14:15:14 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.0%
[2024-11-09 14:15:14 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.70%
[2024-11-09 14:15:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.321 (2.321)	Loss 0.3167 (0.3167)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:15:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.145 (0.578)	Loss 0.3237 (0.3220)	Acc@1 97.656 (98.153)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:15:22 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.308 (0.388)	Loss 0.7295 (0.3561)	Acc@1 44.531 (93.527)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:15:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.368)	Loss 0.8232 (0.4948)	Acc@1 40.625 (76.890)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:15:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 69.160 Acc@5 100.000
[2024-11-09 14:15:27 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 69.2%
[2024-11-09 14:15:27 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 69.16%
[2024-11-09 14:15:30 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][0/156]	eta 0:07:59 lr 0.000090	 wd 0.0500	time 3.0726 (3.0726)	data time 2.6008 (2.6008)	model time 0.0000 (0.0000)	loss 0.5539 (0.5539)	grad_norm 3.1115 (3.1115)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:15:36 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][10/156]	eta 0:01:49 lr 0.000090	 wd 0.0500	time 0.4883 (0.7478)	data time 0.0007 (0.2478)	model time 0.0000 (0.0000)	loss 0.5346 (0.5717)	grad_norm 3.4264 (2.2407)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:15:40 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][20/156]	eta 0:01:22 lr 0.000090	 wd 0.0500	time 0.4539 (0.6086)	data time 0.0006 (0.1372)	model time 0.0000 (0.0000)	loss 0.5797 (0.5719)	grad_norm 1.4796 (2.3180)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:15:45 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][30/156]	eta 0:01:12 lr 0.000090	 wd 0.0500	time 0.4426 (0.5726)	data time 0.0065 (0.1025)	model time 0.0000 (0.0000)	loss 0.4807 (0.5721)	grad_norm 2.4863 (2.2522)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:15:50 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][40/156]	eta 0:01:02 lr 0.000090	 wd 0.0500	time 0.4359 (0.5421)	data time 0.0028 (0.0798)	model time 0.0000 (0.0000)	loss 0.5569 (0.5739)	grad_norm 2.4088 (2.2232)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:15:54 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][50/156]	eta 0:00:55 lr 0.000090	 wd 0.0500	time 0.5074 (0.5256)	data time 0.0225 (0.0666)	model time 0.0000 (0.0000)	loss 0.6141 (0.5809)	grad_norm 1.3567 (2.1507)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:15:59 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][60/156]	eta 0:00:49 lr 0.000090	 wd 0.0500	time 0.4105 (0.5166)	data time 0.0019 (0.0574)	model time 0.4086 (0.4602)	loss 0.5940 (0.5801)	grad_norm 1.1633 (2.0968)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:16:04 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][70/156]	eta 0:00:44 lr 0.000090	 wd 0.0500	time 0.4690 (0.5139)	data time 0.0006 (0.0508)	model time 0.4684 (0.4734)	loss 0.5068 (0.5802)	grad_norm 1.7286 (2.0453)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:16:09 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][80/156]	eta 0:00:38 lr 0.000090	 wd 0.0500	time 0.4483 (0.5124)	data time 0.0153 (0.0460)	model time 0.4330 (0.4790)	loss 0.6165 (0.5822)	grad_norm 4.9641 (2.0902)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:16:13 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][90/156]	eta 0:00:33 lr 0.000090	 wd 0.0500	time 0.4329 (0.5062)	data time 0.0079 (0.0421)	model time 0.4251 (0.4706)	loss 0.6149 (0.5821)	grad_norm 2.3946 (2.1097)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:16:18 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][100/156]	eta 0:00:28 lr 0.000090	 wd 0.0500	time 0.4842 (0.5032)	data time 0.0474 (0.0396)	model time 0.4368 (0.4682)	loss 0.5414 (0.5825)	grad_norm 2.8812 (2.1378)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:16:23 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][110/156]	eta 0:00:22 lr 0.000090	 wd 0.0500	time 0.4140 (0.4990)	data time 0.0011 (0.0364)	model time 0.4129 (0.4657)	loss 0.5570 (0.5829)	grad_norm 1.5624 (2.1460)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:16:28 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][120/156]	eta 0:00:17 lr 0.000089	 wd 0.0500	time 0.4551 (0.4997)	data time 0.0009 (0.0346)	model time 0.4542 (0.4695)	loss 0.4612 (0.5805)	grad_norm 3.0312 (2.1577)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:16:33 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][130/156]	eta 0:00:13 lr 0.000089	 wd 0.0500	time 0.4472 (0.5030)	data time 0.0008 (0.0333)	model time 0.4464 (0.4764)	loss 0.6352 (0.5787)	grad_norm 1.9018 (2.1951)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:16:38 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][140/156]	eta 0:00:08 lr 0.000089	 wd 0.0500	time 0.4704 (0.5002)	data time 0.0010 (0.0319)	model time 0.4694 (0.4735)	loss 0.6116 (0.5792)	grad_norm 2.8080 (2.2249)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:16:43 vssm1_tiny_0230s](training.py 201): INFO Train: [120/300][150/156]	eta 0:00:03 lr 0.000089	 wd 0.0500	time 0.5340 (0.5038)	data time 0.0007 (0.0300)	model time 0.5333 (0.4814)	loss 0.6173 (0.5804)	grad_norm 1.5606 (2.2171)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:16:46 vssm1_tiny_0230s](training.py 212): INFO EPOCH 120 training takes 0:01:18
[2024-11-09 14:16:46 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_120.pth saving......
[2024-11-09 14:16:47 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_120.pth saved !!!
[2024-11-09 14:16:50 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.604 (3.604)	Loss 0.2981 (0.2981)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:16:53 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.227 (0.582)	Loss 0.3088 (0.3029)	Acc@1 92.969 (91.690)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:16:56 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.448)	Loss 0.2174 (0.3093)	Acc@1 98.438 (90.699)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:16:59 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.411)	Loss 0.2666 (0.2922)	Acc@1 93.750 (91.885)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:17:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.620 Acc@5 100.000
[2024-11-09 14:17:03 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.6%
[2024-11-09 14:17:03 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.70%
[2024-11-09 14:17:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.267 (4.267)	Loss 0.3157 (0.3157)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:17:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.168 (0.616)	Loss 0.3230 (0.3214)	Acc@1 97.656 (98.153)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:17:14 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.158 (0.510)	Loss 0.7241 (0.3552)	Acc@1 46.094 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:17:17 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.204 (0.445)	Loss 0.8184 (0.4926)	Acc@1 41.406 (77.319)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:17:20 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 69.720 Acc@5 100.000
[2024-11-09 14:17:20 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 69.7%
[2024-11-09 14:17:20 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 69.72%
[2024-11-09 14:17:24 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][0/156]	eta 0:11:39 lr 0.000089	 wd 0.0500	time 4.4830 (4.4830)	data time 3.9469 (3.9469)	model time 0.0000 (0.0000)	loss 0.6692 (0.6692)	grad_norm 1.9484 (1.9484)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:17:30 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][10/156]	eta 0:02:13 lr 0.000089	 wd 0.0500	time 0.6591 (0.9146)	data time 0.0486 (0.3756)	model time 0.0000 (0.0000)	loss 0.5894 (0.5950)	grad_norm 1.8756 (1.9584)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:17:35 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][20/156]	eta 0:01:37 lr 0.000089	 wd 0.0500	time 0.5155 (0.7171)	data time 0.0905 (0.2104)	model time 0.0000 (0.0000)	loss 0.6796 (0.6118)	grad_norm 2.2513 (2.0604)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:17:40 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][30/156]	eta 0:01:20 lr 0.000089	 wd 0.0500	time 0.4301 (0.6417)	data time 0.0146 (0.1473)	model time 0.0000 (0.0000)	loss 0.4919 (0.6038)	grad_norm 2.3750 (2.0715)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:17:44 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][40/156]	eta 0:01:09 lr 0.000089	 wd 0.0500	time 0.4918 (0.5980)	data time 0.0096 (0.1138)	model time 0.0000 (0.0000)	loss 0.5178 (0.5959)	grad_norm 2.2296 (2.1198)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:17:50 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][50/156]	eta 0:01:01 lr 0.000089	 wd 0.0500	time 0.4343 (0.5838)	data time 0.0179 (0.0997)	model time 0.0000 (0.0000)	loss 0.6090 (0.5998)	grad_norm 1.0725 (2.1368)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:17:54 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][60/156]	eta 0:00:54 lr 0.000089	 wd 0.0500	time 0.4333 (0.5674)	data time 0.0045 (0.0875)	model time 0.4287 (0.4587)	loss 0.6151 (0.5962)	grad_norm 2.3660 (2.1656)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:17:59 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][70/156]	eta 0:00:48 lr 0.000089	 wd 0.0500	time 0.4282 (0.5589)	data time 0.0152 (0.0776)	model time 0.4131 (0.4744)	loss 0.5895 (0.5905)	grad_norm 3.7249 (2.2425)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:18:04 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][80/156]	eta 0:00:41 lr 0.000089	 wd 0.0500	time 0.4342 (0.5450)	data time 0.0105 (0.0696)	model time 0.4237 (0.4607)	loss 0.6721 (0.5867)	grad_norm 3.5409 (2.2519)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:18:09 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][90/156]	eta 0:00:35 lr 0.000089	 wd 0.0500	time 0.4750 (0.5414)	data time 0.0061 (0.0645)	model time 0.4690 (0.4675)	loss 0.6170 (0.5868)	grad_norm 2.0057 (2.2548)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:18:14 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][100/156]	eta 0:00:29 lr 0.000089	 wd 0.0500	time 0.4691 (0.5329)	data time 0.0335 (0.0590)	model time 0.4356 (0.4634)	loss 0.5077 (0.5903)	grad_norm 1.7282 (2.2175)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:18:19 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][110/156]	eta 0:00:24 lr 0.000089	 wd 0.0500	time 0.5641 (0.5299)	data time 0.0163 (0.0546)	model time 0.5478 (0.4678)	loss 0.5166 (0.5883)	grad_norm 1.9285 (2.1734)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:18:24 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][120/156]	eta 0:00:19 lr 0.000089	 wd 0.0500	time 0.4547 (0.5310)	data time 0.0178 (0.0510)	model time 0.4369 (0.4770)	loss 0.5696 (0.5879)	grad_norm 1.5950 (2.1624)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:18:29 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][130/156]	eta 0:00:13 lr 0.000089	 wd 0.0500	time 0.4660 (0.5288)	data time 0.0106 (0.0484)	model time 0.4553 (0.4780)	loss 0.6335 (0.5869)	grad_norm 2.0477 (2.1785)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:18:34 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][140/156]	eta 0:00:08 lr 0.000089	 wd 0.0500	time 0.4863 (0.5271)	data time 0.0010 (0.0458)	model time 0.4853 (0.4797)	loss 0.6259 (0.5866)	grad_norm 1.4010 (2.1694)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:18:39 vssm1_tiny_0230s](training.py 201): INFO Train: [121/300][150/156]	eta 0:00:03 lr 0.000089	 wd 0.0500	time 0.5471 (0.5263)	data time 0.0008 (0.0432)	model time 0.5463 (0.4827)	loss 0.6119 (0.5860)	grad_norm 1.3577 (2.1903)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:18:42 vssm1_tiny_0230s](training.py 212): INFO EPOCH 121 training takes 0:01:22
[2024-11-09 14:18:42 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_121.pth saving......
[2024-11-09 14:18:43 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_121.pth saved !!!
[2024-11-09 14:18:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.606 (3.606)	Loss 0.2100 (0.2100)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:18:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.139 (0.644)	Loss 0.2166 (0.2175)	Acc@1 96.094 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:18:52 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.282 (0.411)	Loss 0.2668 (0.2347)	Acc@1 94.531 (94.606)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:18:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.377)	Loss 0.3230 (0.2647)	Acc@1 90.625 (92.692)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:18:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.880 Acc@5 100.000
[2024-11-09 14:18:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 91.9%
[2024-11-09 14:18:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.70%
[2024-11-09 14:19:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.719 (2.719)	Loss 0.3149 (0.3149)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:19:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.217 (0.580)	Loss 0.3220 (0.3208)	Acc@1 97.656 (98.011)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:19:07 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.199 (0.504)	Loss 0.7188 (0.3543)	Acc@1 46.875 (93.564)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:19:10 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.421)	Loss 0.8135 (0.4905)	Acc@1 42.188 (77.545)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:19:12 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 70.000 Acc@5 100.000
[2024-11-09 14:19:12 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 70.0%
[2024-11-09 14:19:12 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 70.00%
[2024-11-09 14:19:18 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][0/156]	eta 0:14:45 lr 0.000089	 wd 0.0500	time 5.6790 (5.6790)	data time 5.2256 (5.2256)	model time 0.0000 (0.0000)	loss 0.6497 (0.6497)	grad_norm 1.5589 (1.5589)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:19:23 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][10/156]	eta 0:02:33 lr 0.000089	 wd 0.0500	time 0.5969 (1.0506)	data time 0.0025 (0.4864)	model time 0.0000 (0.0000)	loss 0.5163 (0.5550)	grad_norm 2.7075 (1.9337)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:19:29 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][20/156]	eta 0:01:52 lr 0.000089	 wd 0.0500	time 0.6628 (0.8291)	data time 0.0719 (0.2663)	model time 0.0000 (0.0000)	loss 0.6606 (0.5678)	grad_norm 2.2958 (2.2236)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:19:35 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][30/156]	eta 0:01:32 lr 0.000089	 wd 0.0500	time 0.5928 (0.7379)	data time 0.0218 (0.1847)	model time 0.0000 (0.0000)	loss 0.5504 (0.5735)	grad_norm 2.5640 (2.2773)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:19:40 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][40/156]	eta 0:01:19 lr 0.000089	 wd 0.0500	time 0.6674 (0.6833)	data time 0.0329 (0.1454)	model time 0.0000 (0.0000)	loss 0.5438 (0.5782)	grad_norm 1.5235 (2.1884)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:19:45 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][50/156]	eta 0:01:08 lr 0.000089	 wd 0.0500	time 0.5211 (0.6417)	data time 0.0367 (0.1213)	model time 0.0000 (0.0000)	loss 0.6142 (0.5803)	grad_norm 1.8088 (2.1716)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:19:50 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][60/156]	eta 0:00:59 lr 0.000088	 wd 0.0500	time 0.5654 (0.6179)	data time 0.0022 (0.1041)	model time 0.5632 (0.4797)	loss 0.6068 (0.5766)	grad_norm 2.3755 (2.2114)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:19:54 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][70/156]	eta 0:00:51 lr 0.000088	 wd 0.0500	time 0.4121 (0.5984)	data time 0.0047 (0.0911)	model time 0.4074 (0.4739)	loss 0.6018 (0.5783)	grad_norm 1.7427 (2.1792)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:20:00 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][80/156]	eta 0:00:44 lr 0.000088	 wd 0.0500	time 0.5378 (0.5889)	data time 0.0200 (0.0828)	model time 0.5177 (0.4816)	loss 0.5153 (0.5822)	grad_norm 2.5583 (2.1592)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:20:05 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][90/156]	eta 0:00:38 lr 0.000088	 wd 0.0500	time 0.4986 (0.5785)	data time 0.0009 (0.0751)	model time 0.4977 (0.4818)	loss 0.5215 (0.5810)	grad_norm 1.8263 (2.1221)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:20:10 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][100/156]	eta 0:00:32 lr 0.000088	 wd 0.0500	time 0.6761 (0.5734)	data time 0.0796 (0.0701)	model time 0.5965 (0.4859)	loss 0.5090 (0.5777)	grad_norm 2.7419 (2.1151)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:20:15 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][110/156]	eta 0:00:26 lr 0.000088	 wd 0.0500	time 0.4859 (0.5669)	data time 0.0006 (0.0665)	model time 0.4853 (0.4835)	loss 0.6289 (0.5771)	grad_norm 3.1024 (2.1682)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:20:19 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][120/156]	eta 0:00:20 lr 0.000088	 wd 0.0500	time 0.4480 (0.5567)	data time 0.0156 (0.0617)	model time 0.4324 (0.4765)	loss 0.5778 (0.5768)	grad_norm 1.9551 (2.2103)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:20:24 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][130/156]	eta 0:00:14 lr 0.000088	 wd 0.0500	time 0.4531 (0.5496)	data time 0.0279 (0.0577)	model time 0.4252 (0.4738)	loss 0.5802 (0.5776)	grad_norm 1.7918 (2.2607)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:20:28 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][140/156]	eta 0:00:08 lr 0.000088	 wd 0.0500	time 0.4340 (0.5423)	data time 0.0008 (0.0539)	model time 0.4331 (0.4703)	loss 0.5294 (0.5782)	grad_norm 3.1202 (2.2413)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:20:33 vssm1_tiny_0230s](training.py 201): INFO Train: [122/300][150/156]	eta 0:00:03 lr 0.000088	 wd 0.0500	time 0.4343 (0.5378)	data time 0.0006 (0.0505)	model time 0.4337 (0.4704)	loss 0.6004 (0.5796)	grad_norm 2.6599 (2.2195)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:20:36 vssm1_tiny_0230s](training.py 212): INFO EPOCH 122 training takes 0:01:23
[2024-11-09 14:20:36 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_122.pth saving......
[2024-11-09 14:20:36 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_122.pth saved !!!
[2024-11-09 14:20:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 5.259 (5.259)	Loss 0.2754 (0.2754)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:20:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 1.202 (0.761)	Loss 0.2815 (0.2772)	Acc@1 92.188 (93.537)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:20:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.516)	Loss 0.2422 (0.2895)	Acc@1 93.750 (92.113)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:20:52 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.503)	Loss 0.2913 (0.2861)	Acc@1 92.969 (92.061)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:20:56 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.300 Acc@5 100.000
[2024-11-09 14:20:56 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.3%
[2024-11-09 14:20:56 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.70%
[2024-11-09 14:21:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.383 (4.383)	Loss 0.3142 (0.3142)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:21:04 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.346 (0.753)	Loss 0.3213 (0.3201)	Acc@1 97.656 (98.011)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:21:08 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.205 (0.565)	Loss 0.7134 (0.3534)	Acc@1 47.656 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:21:11 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.487)	Loss 0.8081 (0.4884)	Acc@1 42.969 (77.848)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:21:14 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 70.520 Acc@5 100.000
[2024-11-09 14:21:14 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 70.5%
[2024-11-09 14:21:14 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 70.52%
[2024-11-09 14:21:18 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][0/156]	eta 0:09:55 lr 0.000088	 wd 0.0500	time 3.8189 (3.8189)	data time 3.3253 (3.3253)	model time 0.0000 (0.0000)	loss 0.6327 (0.6327)	grad_norm 2.5578 (2.5578)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:21:23 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][10/156]	eta 0:01:55 lr 0.000088	 wd 0.0500	time 0.6199 (0.7937)	data time 0.0048 (0.3092)	model time 0.0000 (0.0000)	loss 0.5209 (0.5692)	grad_norm 2.1971 (2.1688)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:21:28 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][20/156]	eta 0:01:30 lr 0.000088	 wd 0.0500	time 0.6316 (0.6635)	data time 0.0153 (0.1706)	model time 0.0000 (0.0000)	loss 0.6215 (0.5775)	grad_norm 1.5919 (2.0368)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:21:33 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][30/156]	eta 0:01:17 lr 0.000088	 wd 0.0500	time 0.5071 (0.6142)	data time 0.0164 (0.1202)	model time 0.0000 (0.0000)	loss 0.5638 (0.5877)	grad_norm 1.6801 (2.0393)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:21:39 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][40/156]	eta 0:01:09 lr 0.000088	 wd 0.0500	time 0.6777 (0.5997)	data time 0.0035 (0.0930)	model time 0.0000 (0.0000)	loss 0.6166 (0.5942)	grad_norm 1.7803 (1.9525)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:21:44 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][50/156]	eta 0:01:02 lr 0.000088	 wd 0.0500	time 0.5202 (0.5893)	data time 0.0009 (0.0804)	model time 0.0000 (0.0000)	loss 0.6100 (0.5947)	grad_norm 1.8669 (1.9727)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:21:50 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][60/156]	eta 0:00:56 lr 0.000088	 wd 0.0500	time 0.5660 (0.5896)	data time 0.0687 (0.0735)	model time 0.4973 (0.5532)	loss 0.6414 (0.5925)	grad_norm 1.9797 (2.0157)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:21:55 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][70/156]	eta 0:00:49 lr 0.000088	 wd 0.0500	time 0.5678 (0.5763)	data time 0.0300 (0.0650)	model time 0.5378 (0.5175)	loss 0.6479 (0.5851)	grad_norm 2.1410 (2.1243)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:22:00 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][80/156]	eta 0:00:43 lr 0.000088	 wd 0.0500	time 0.5876 (0.5717)	data time 0.0185 (0.0594)	model time 0.5690 (0.5182)	loss 0.6292 (0.5834)	grad_norm 2.4523 (2.1739)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:22:05 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][90/156]	eta 0:00:37 lr 0.000088	 wd 0.0500	time 0.5109 (0.5642)	data time 0.0008 (0.0539)	model time 0.5101 (0.5121)	loss 0.5833 (0.5843)	grad_norm 2.4356 (2.1837)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:22:10 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][100/156]	eta 0:00:31 lr 0.000088	 wd 0.0500	time 0.5130 (0.5587)	data time 0.0155 (0.0513)	model time 0.4975 (0.5060)	loss 0.5555 (0.5827)	grad_norm 2.1642 (2.1907)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:22:15 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][110/156]	eta 0:00:25 lr 0.000088	 wd 0.0500	time 0.5281 (0.5494)	data time 0.0180 (0.0478)	model time 0.5101 (0.4955)	loss 0.5568 (0.5819)	grad_norm 2.0474 (2.1977)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:22:20 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][120/156]	eta 0:00:19 lr 0.000088	 wd 0.0500	time 0.4278 (0.5418)	data time 0.0009 (0.0447)	model time 0.4269 (0.4885)	loss 0.6322 (0.5820)	grad_norm 2.1184 (2.2008)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:22:24 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][130/156]	eta 0:00:13 lr 0.000088	 wd 0.0500	time 0.4463 (0.5364)	data time 0.0149 (0.0425)	model time 0.4314 (0.4843)	loss 0.5556 (0.5803)	grad_norm 2.6812 (2.2032)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:22:29 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][140/156]	eta 0:00:08 lr 0.000088	 wd 0.0500	time 0.4910 (0.5337)	data time 0.0387 (0.0410)	model time 0.4522 (0.4835)	loss 0.5869 (0.5793)	grad_norm 2.6295 (2.2355)	loss_scale 65536.0000 (35091.9716)	mem 13675MB
[2024-11-09 14:22:34 vssm1_tiny_0230s](training.py 201): INFO Train: [123/300][150/156]	eta 0:00:03 lr 0.000087	 wd 0.0500	time 0.4211 (0.5299)	data time 0.0005 (0.0383)	model time 0.4206 (0.4827)	loss 0.5613 (0.5789)	grad_norm 2.2043 (2.2417)	loss_scale 65536.0000 (37108.1325)	mem 13675MB
[2024-11-09 14:22:37 vssm1_tiny_0230s](training.py 212): INFO EPOCH 123 training takes 0:01:23
[2024-11-09 14:22:37 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_123.pth saving......
[2024-11-09 14:22:37 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_123.pth saved !!!
[2024-11-09 14:22:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.425 (4.425)	Loss 0.2585 (0.2585)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:22:44 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.211 (0.648)	Loss 0.2815 (0.2741)	Acc@1 92.969 (93.324)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:22:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.197 (0.466)	Loss 0.2217 (0.2868)	Acc@1 95.312 (91.704)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:22:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.381)	Loss 0.2737 (0.2790)	Acc@1 92.188 (92.213)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:22:52 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.480 Acc@5 100.000
[2024-11-09 14:22:52 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.5%
[2024-11-09 14:22:52 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.70%
[2024-11-09 14:22:54 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.603 (2.603)	Loss 0.3135 (0.3135)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:22:58 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.943 (0.530)	Loss 0.3206 (0.3195)	Acc@1 97.656 (98.011)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:23:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.152 (0.456)	Loss 0.7075 (0.3526)	Acc@1 47.656 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:23:04 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.402)	Loss 0.8027 (0.4861)	Acc@1 45.312 (78.125)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:23:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 70.860 Acc@5 100.000
[2024-11-09 14:23:08 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 70.9%
[2024-11-09 14:23:08 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 70.86%
[2024-11-09 14:23:12 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][0/156]	eta 0:10:10 lr 0.000087	 wd 0.0500	time 3.9157 (3.9157)	data time 3.4233 (3.4233)	model time 0.0000 (0.0000)	loss 0.6526 (0.6526)	grad_norm 1.9427 (1.9427)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:23:20 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][10/156]	eta 0:02:29 lr 0.000087	 wd 0.0500	time 0.5059 (1.0273)	data time 0.0308 (0.5233)	model time 0.0000 (0.0000)	loss 0.6631 (0.5921)	grad_norm 2.0774 (2.1132)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:23:25 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][20/156]	eta 0:01:46 lr 0.000087	 wd 0.0500	time 0.4797 (0.7825)	data time 0.0014 (0.2781)	model time 0.0000 (0.0000)	loss 0.6167 (0.5939)	grad_norm 1.5810 (2.1674)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:23:30 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][30/156]	eta 0:01:26 lr 0.000087	 wd 0.0500	time 0.4635 (0.6841)	data time 0.0251 (0.1942)	model time 0.0000 (0.0000)	loss 0.6114 (0.5826)	grad_norm 2.5585 (2.4090)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:23:35 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][40/156]	eta 0:01:14 lr 0.000087	 wd 0.0500	time 0.5021 (0.6429)	data time 0.0205 (0.1509)	model time 0.0000 (0.0000)	loss 0.6009 (0.5782)	grad_norm 1.6388 (2.5000)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:23:40 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][50/156]	eta 0:01:05 lr 0.000087	 wd 0.0500	time 0.5179 (0.6160)	data time 0.0008 (0.1239)	model time 0.0000 (0.0000)	loss 0.4472 (0.5706)	grad_norm 2.0964 (2.5188)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:23:44 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][60/156]	eta 0:00:56 lr 0.000087	 wd 0.0500	time 0.4344 (0.5900)	data time 0.0006 (0.1054)	model time 0.4338 (0.4460)	loss 0.6037 (0.5752)	grad_norm 2.2031 (2.4971)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:23:50 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][70/156]	eta 0:00:50 lr 0.000087	 wd 0.0500	time 0.5956 (0.5856)	data time 0.0127 (0.0955)	model time 0.5829 (0.4850)	loss 0.5922 (0.5782)	grad_norm 1.7010 (2.3959)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:23:55 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][80/156]	eta 0:00:43 lr 0.000087	 wd 0.0500	time 0.6556 (0.5771)	data time 0.0173 (0.0854)	model time 0.6383 (0.4911)	loss 0.5821 (0.5810)	grad_norm 1.6120 (2.3216)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:24:00 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][90/156]	eta 0:00:37 lr 0.000087	 wd 0.0500	time 0.4364 (0.5681)	data time 0.0136 (0.0779)	model time 0.4227 (0.4879)	loss 0.6025 (0.5801)	grad_norm 2.7719 (2.3483)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:24:06 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][100/156]	eta 0:00:32 lr 0.000087	 wd 0.0500	time 0.4882 (0.5745)	data time 0.0038 (0.0731)	model time 0.4844 (0.5109)	loss 0.4631 (0.5815)	grad_norm 3.3233 (2.3230)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:24:11 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][110/156]	eta 0:00:26 lr 0.000087	 wd 0.0500	time 0.5131 (0.5681)	data time 0.0800 (0.0679)	model time 0.4332 (0.5069)	loss 0.6522 (0.5836)	grad_norm 2.1383 (2.2994)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:24:16 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][120/156]	eta 0:00:20 lr 0.000087	 wd 0.0500	time 0.5078 (0.5632)	data time 0.0223 (0.0637)	model time 0.4855 (0.5048)	loss 0.5249 (0.5832)	grad_norm 1.6525 (2.2706)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:24:21 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][130/156]	eta 0:00:14 lr 0.000087	 wd 0.0500	time 0.4713 (0.5574)	data time 0.0412 (0.0607)	model time 0.4301 (0.4996)	loss 0.5737 (0.5840)	grad_norm 2.9460 (2.2796)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:24:26 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][140/156]	eta 0:00:08 lr 0.000087	 wd 0.0500	time 0.5346 (0.5535)	data time 0.0009 (0.0572)	model time 0.5337 (0.4987)	loss 0.5556 (0.5849)	grad_norm 2.1401 (2.2397)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:24:31 vssm1_tiny_0230s](training.py 201): INFO Train: [124/300][150/156]	eta 0:00:03 lr 0.000087	 wd 0.0500	time 0.4133 (0.5485)	data time 0.0008 (0.0542)	model time 0.4126 (0.4954)	loss 0.6350 (0.5853)	grad_norm 1.6747 (2.2244)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:24:34 vssm1_tiny_0230s](training.py 212): INFO EPOCH 124 training takes 0:01:26
[2024-11-09 14:24:34 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_124.pth saving......
[2024-11-09 14:24:35 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_124.pth saved !!!
[2024-11-09 14:24:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.127 (3.127)	Loss 0.3154 (0.3154)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:24:41 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.156 (0.569)	Loss 0.3311 (0.3246)	Acc@1 87.500 (88.991)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:24:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.144 (0.410)	Loss 0.2151 (0.3309)	Acc@1 98.438 (88.542)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:24:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.158 (0.350)	Loss 0.2644 (0.3037)	Acc@1 93.750 (90.978)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:24:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.100 Acc@5 100.000
[2024-11-09 14:24:48 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.1%
[2024-11-09 14:24:48 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.70%
[2024-11-09 14:24:50 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.758 (2.758)	Loss 0.3132 (0.3132)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:24:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.426)	Loss 0.3203 (0.3195)	Acc@1 97.656 (98.011)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:24:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.286 (0.362)	Loss 0.7007 (0.3521)	Acc@1 49.219 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:24:58 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.353)	Loss 0.7959 (0.4838)	Acc@1 46.094 (78.276)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:25:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 71.140 Acc@5 100.000
[2024-11-09 14:25:00 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 71.1%
[2024-11-09 14:25:00 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 71.14%
[2024-11-09 14:25:04 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][0/156]	eta 0:09:10 lr 0.000087	 wd 0.0500	time 3.5280 (3.5280)	data time 3.0969 (3.0969)	model time 0.0000 (0.0000)	loss 0.5254 (0.5254)	grad_norm 2.2724 (2.2724)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:09 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][10/156]	eta 0:01:49 lr 0.000087	 wd 0.0500	time 0.5033 (0.7485)	data time 0.0008 (0.2907)	model time 0.0000 (0.0000)	loss 0.6050 (0.5638)	grad_norm 2.8953 (2.2708)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:13 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][20/156]	eta 0:01:23 lr 0.000087	 wd 0.0500	time 0.5102 (0.6160)	data time 0.0007 (0.1556)	model time 0.0000 (0.0000)	loss 0.6203 (0.5700)	grad_norm 1.9206 (2.2911)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:19 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][30/156]	eta 0:01:15 lr 0.000087	 wd 0.0500	time 0.7489 (0.6001)	data time 0.0474 (0.1132)	model time 0.0000 (0.0000)	loss 0.5138 (0.5725)	grad_norm 1.9282 (2.2961)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:24 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][40/156]	eta 0:01:06 lr 0.000087	 wd 0.0500	time 0.5223 (0.5732)	data time 0.0006 (0.0889)	model time 0.0000 (0.0000)	loss 0.4711 (0.5770)	grad_norm 2.8750 (2.3702)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:29 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][50/156]	eta 0:00:59 lr 0.000087	 wd 0.0500	time 0.6705 (0.5652)	data time 0.0008 (0.0749)	model time 0.0000 (0.0000)	loss 0.5814 (0.5793)	grad_norm 2.7058 (2.3216)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:34 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][60/156]	eta 0:00:53 lr 0.000087	 wd 0.0500	time 0.4473 (0.5526)	data time 0.0188 (0.0648)	model time 0.4285 (0.4748)	loss 0.5794 (0.5793)	grad_norm 2.3976 (2.3766)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:39 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][70/156]	eta 0:00:46 lr 0.000087	 wd 0.0500	time 0.5655 (0.5439)	data time 0.0260 (0.0578)	model time 0.5395 (0.4755)	loss 0.6560 (0.5852)	grad_norm 1.8401 (2.3207)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:43 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][80/156]	eta 0:00:40 lr 0.000086	 wd 0.0500	time 0.4311 (0.5325)	data time 0.0006 (0.0525)	model time 0.4305 (0.4627)	loss 0.6214 (0.5858)	grad_norm 1.6605 (2.2790)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:48 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][90/156]	eta 0:00:34 lr 0.000086	 wd 0.0500	time 0.4623 (0.5244)	data time 0.0306 (0.0484)	model time 0.4317 (0.4577)	loss 0.5222 (0.5831)	grad_norm 1.3295 (2.2730)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:53 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][100/156]	eta 0:00:29 lr 0.000086	 wd 0.0500	time 0.6038 (0.5188)	data time 0.0006 (0.0447)	model time 0.6031 (0.4576)	loss 0.5034 (0.5806)	grad_norm 1.9882 (2.2578)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:25:58 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][110/156]	eta 0:00:23 lr 0.000086	 wd 0.0500	time 0.6230 (0.5182)	data time 0.0008 (0.0431)	model time 0.6222 (0.4621)	loss 0.6025 (0.5808)	grad_norm 2.0539 (2.2214)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:26:03 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][120/156]	eta 0:00:18 lr 0.000086	 wd 0.0500	time 0.4303 (0.5216)	data time 0.0076 (0.0407)	model time 0.4227 (0.4741)	loss 0.5239 (0.5805)	grad_norm 2.2751 (2.2123)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:26:08 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][130/156]	eta 0:00:13 lr 0.000086	 wd 0.0500	time 0.4778 (0.5184)	data time 0.0179 (0.0388)	model time 0.4600 (0.4728)	loss 0.5762 (0.5804)	grad_norm 2.2265 (2.2088)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:26:13 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][140/156]	eta 0:00:08 lr 0.000086	 wd 0.0500	time 0.4138 (0.5139)	data time 0.0008 (0.0364)	model time 0.4130 (0.4702)	loss 0.5332 (0.5803)	grad_norm 3.8692 (2.2267)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:26:18 vssm1_tiny_0230s](training.py 201): INFO Train: [125/300][150/156]	eta 0:00:03 lr 0.000086	 wd 0.0500	time 0.4997 (0.5113)	data time 0.0009 (0.0340)	model time 0.4988 (0.4705)	loss 0.6285 (0.5783)	grad_norm 1.6723 (2.2720)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:26:20 vssm1_tiny_0230s](training.py 212): INFO EPOCH 125 training takes 0:01:19
[2024-11-09 14:26:20 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_125.pth saving......
[2024-11-09 14:26:20 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_125.pth saved !!!
[2024-11-09 14:26:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.113 (3.113)	Loss 0.2502 (0.2502)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:26:26 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.363 (0.545)	Loss 0.2686 (0.2557)	Acc@1 92.188 (92.543)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:26:30 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.454)	Loss 0.1958 (0.2678)	Acc@1 97.656 (91.704)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:26:32 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.152 (0.374)	Loss 0.2502 (0.2585)	Acc@1 93.750 (92.389)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:26:34 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.900 Acc@5 100.000
[2024-11-09 14:26:34 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.9%
[2024-11-09 14:26:34 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.90%
[2024-11-09 14:26:37 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.551 (3.551)	Loss 0.3127 (0.3127)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:26:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.156 (0.495)	Loss 0.3198 (0.3191)	Acc@1 97.656 (97.940)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:26:42 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.373)	Loss 0.6948 (0.3514)	Acc@1 51.562 (93.713)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:26:45 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 1.713 (0.373)	Loss 0.7900 (0.4816)	Acc@1 46.875 (78.705)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:26:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 71.620 Acc@5 100.000
[2024-11-09 14:26:48 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 71.6%
[2024-11-09 14:26:48 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 71.62%
[2024-11-09 14:26:52 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][0/156]	eta 0:10:44 lr 0.000086	 wd 0.0500	time 4.1311 (4.1311)	data time 3.7236 (3.7236)	model time 0.0000 (0.0000)	loss 0.4715 (0.4715)	grad_norm 2.3206 (2.3206)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:26:57 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][10/156]	eta 0:02:03 lr 0.000086	 wd 0.0500	time 0.4431 (0.8456)	data time 0.0007 (0.3635)	model time 0.0000 (0.0000)	loss 0.6086 (0.5627)	grad_norm 2.0480 (2.2606)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:02 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][20/156]	eta 0:01:33 lr 0.000086	 wd 0.0500	time 0.4988 (0.6858)	data time 0.0170 (0.1979)	model time 0.0000 (0.0000)	loss 0.5102 (0.5660)	grad_norm 2.3270 (2.3043)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:07 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][30/156]	eta 0:01:19 lr 0.000086	 wd 0.0500	time 0.6986 (0.6287)	data time 0.0942 (0.1395)	model time 0.0000 (0.0000)	loss 0.4459 (0.5720)	grad_norm 3.7462 (2.3898)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:13 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][40/156]	eta 0:01:09 lr 0.000086	 wd 0.0500	time 0.5717 (0.6010)	data time 0.0381 (0.1095)	model time 0.0000 (0.0000)	loss 0.6188 (0.5764)	grad_norm 1.7961 (2.3572)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:18 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][50/156]	eta 0:01:02 lr 0.000086	 wd 0.0500	time 0.4445 (0.5864)	data time 0.0044 (0.0927)	model time 0.0000 (0.0000)	loss 0.5671 (0.5801)	grad_norm 1.8863 (2.2892)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:23 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][60/156]	eta 0:00:55 lr 0.000086	 wd 0.0500	time 0.5937 (0.5743)	data time 0.0665 (0.0811)	model time 0.5272 (0.4903)	loss 0.5824 (0.5737)	grad_norm 2.4498 (2.2793)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:28 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][70/156]	eta 0:00:49 lr 0.000086	 wd 0.0500	time 0.4151 (0.5716)	data time 0.0006 (0.0742)	model time 0.4145 (0.5067)	loss 0.5913 (0.5774)	grad_norm 2.5042 (2.2848)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:34 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][80/156]	eta 0:00:43 lr 0.000086	 wd 0.0500	time 0.5392 (0.5671)	data time 0.0170 (0.0678)	model time 0.5222 (0.5088)	loss 0.5061 (0.5781)	grad_norm 3.5259 (2.2958)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:39 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][90/156]	eta 0:00:37 lr 0.000086	 wd 0.0500	time 0.4458 (0.5633)	data time 0.0302 (0.0624)	model time 0.4156 (0.5099)	loss 0.6379 (0.5781)	grad_norm 2.3414 (2.2814)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:44 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][100/156]	eta 0:00:31 lr 0.000086	 wd 0.0500	time 0.5162 (0.5594)	data time 0.0014 (0.0576)	model time 0.5148 (0.5101)	loss 0.4466 (0.5761)	grad_norm 3.3680 (2.3058)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:50 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][110/156]	eta 0:00:25 lr 0.000086	 wd 0.0500	time 0.6524 (0.5555)	data time 0.0094 (0.0538)	model time 0.6431 (0.5084)	loss 0.6301 (0.5791)	grad_norm 2.2132 (2.3070)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:27:55 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][120/156]	eta 0:00:19 lr 0.000086	 wd 0.0500	time 0.4253 (0.5511)	data time 0.0025 (0.0505)	model time 0.4228 (0.5057)	loss 0.5547 (0.5762)	grad_norm 1.6443 (2.2841)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:28:00 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][130/156]	eta 0:00:14 lr 0.000086	 wd 0.0500	time 0.4543 (0.5476)	data time 0.0022 (0.0482)	model time 0.4521 (0.5030)	loss 0.5956 (0.5750)	grad_norm 2.0732 (2.2723)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:28:04 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][140/156]	eta 0:00:08 lr 0.000086	 wd 0.0500	time 0.4124 (0.5415)	data time 0.0008 (0.0454)	model time 0.4116 (0.4975)	loss 0.4633 (0.5728)	grad_norm 4.2065 (2.3065)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:28:09 vssm1_tiny_0230s](training.py 201): INFO Train: [126/300][150/156]	eta 0:00:03 lr 0.000086	 wd 0.0500	time 0.4679 (0.5371)	data time 0.0062 (0.0425)	model time 0.4617 (0.4951)	loss 0.5438 (0.5724)	grad_norm 1.8634 (2.2925)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:28:12 vssm1_tiny_0230s](training.py 212): INFO EPOCH 126 training takes 0:01:24
[2024-11-09 14:28:12 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_126.pth saving......
[2024-11-09 14:28:13 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_126.pth saved !!!
[2024-11-09 14:28:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.618 (3.618)	Loss 0.1918 (0.1918)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:28:19 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.143 (0.569)	Loss 0.2101 (0.2014)	Acc@1 95.312 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:28:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.242 (0.388)	Loss 0.2373 (0.2216)	Acc@1 92.188 (94.085)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:28:24 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.226 (0.349)	Loss 0.3069 (0.2444)	Acc@1 91.406 (92.843)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:28:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.300 Acc@5 100.000
[2024-11-09 14:28:27 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.3%
[2024-11-09 14:28:27 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.90%
[2024-11-09 14:28:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.273 (4.273)	Loss 0.3120 (0.3120)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:28:35 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.976 (0.671)	Loss 0.3191 (0.3184)	Acc@1 97.656 (97.940)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:28:37 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.468)	Loss 0.6890 (0.3505)	Acc@1 52.344 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:28:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.154 (0.411)	Loss 0.7842 (0.4793)	Acc@1 46.875 (79.007)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:28:44 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 72.080 Acc@5 100.000
[2024-11-09 14:28:44 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 72.1%
[2024-11-09 14:28:44 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 72.08%
[2024-11-09 14:28:48 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][0/156]	eta 0:10:27 lr 0.000086	 wd 0.0500	time 4.0205 (4.0205)	data time 3.5829 (3.5829)	model time 0.0000 (0.0000)	loss 0.5969 (0.5969)	grad_norm 1.8461 (1.8461)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:28:53 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][10/156]	eta 0:02:04 lr 0.000085	 wd 0.0500	time 0.5198 (0.8531)	data time 0.0117 (0.3761)	model time 0.0000 (0.0000)	loss 0.5763 (0.5747)	grad_norm 1.6971 (2.2636)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:28:59 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][20/156]	eta 0:01:35 lr 0.000085	 wd 0.0500	time 0.5285 (0.7003)	data time 0.0455 (0.2109)	model time 0.0000 (0.0000)	loss 0.6251 (0.5713)	grad_norm 1.6738 (2.4300)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:04 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][30/156]	eta 0:01:20 lr 0.000085	 wd 0.0500	time 0.4554 (0.6386)	data time 0.0075 (0.1465)	model time 0.0000 (0.0000)	loss 0.6087 (0.5738)	grad_norm 2.1391 (2.3650)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:09 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][40/156]	eta 0:01:10 lr 0.000085	 wd 0.0500	time 0.4876 (0.6043)	data time 0.0226 (0.1140)	model time 0.0000 (0.0000)	loss 0.5594 (0.5661)	grad_norm 1.8272 (2.3546)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:14 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][50/156]	eta 0:01:01 lr 0.000085	 wd 0.0500	time 0.4269 (0.5842)	data time 0.0067 (0.0934)	model time 0.0000 (0.0000)	loss 0.5718 (0.5708)	grad_norm 2.5287 (2.3674)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:19 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][60/156]	eta 0:00:54 lr 0.000085	 wd 0.0500	time 0.4211 (0.5689)	data time 0.0021 (0.0808)	model time 0.4190 (0.4741)	loss 0.6230 (0.5712)	grad_norm 2.5174 (2.3876)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:24 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][70/156]	eta 0:00:48 lr 0.000085	 wd 0.0500	time 0.5015 (0.5620)	data time 0.0007 (0.0718)	model time 0.5008 (0.4886)	loss 0.5984 (0.5724)	grad_norm 2.2357 (2.3833)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:29 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][80/156]	eta 0:00:42 lr 0.000085	 wd 0.0500	time 0.4343 (0.5559)	data time 0.0055 (0.0652)	model time 0.4289 (0.4903)	loss 0.5802 (0.5742)	grad_norm 1.8195 (2.3164)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:33 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][90/156]	eta 0:00:35 lr 0.000085	 wd 0.0500	time 0.4573 (0.5444)	data time 0.0197 (0.0589)	model time 0.4376 (0.4787)	loss 0.6435 (0.5752)	grad_norm 3.9502 (2.3045)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:38 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][100/156]	eta 0:00:30 lr 0.000085	 wd 0.0500	time 0.4983 (0.5404)	data time 0.0013 (0.0546)	model time 0.4970 (0.4807)	loss 0.6161 (0.5734)	grad_norm 1.1608 (2.3645)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:43 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][110/156]	eta 0:00:24 lr 0.000085	 wd 0.0500	time 0.5223 (0.5365)	data time 0.0007 (0.0511)	model time 0.5216 (0.4808)	loss 0.5768 (0.5742)	grad_norm 2.2305 (2.3822)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:48 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][120/156]	eta 0:00:19 lr 0.000085	 wd 0.0500	time 0.4832 (0.5324)	data time 0.0097 (0.0477)	model time 0.4734 (0.4802)	loss 0.6451 (0.5752)	grad_norm 1.4625 (2.3634)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:53 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][130/156]	eta 0:00:13 lr 0.000085	 wd 0.0500	time 0.5397 (0.5296)	data time 0.0007 (0.0467)	model time 0.5390 (0.4779)	loss 0.5333 (0.5764)	grad_norm 2.4561 (2.3432)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:29:58 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][140/156]	eta 0:00:08 lr 0.000085	 wd 0.0500	time 0.5042 (0.5283)	data time 0.0010 (0.0444)	model time 0.5032 (0.4799)	loss 0.6393 (0.5772)	grad_norm 1.4117 (2.3283)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:30:03 vssm1_tiny_0230s](training.py 201): INFO Train: [127/300][150/156]	eta 0:00:03 lr 0.000085	 wd 0.0500	time 0.5169 (0.5252)	data time 0.0005 (0.0415)	model time 0.5164 (0.4801)	loss 0.5926 (0.5768)	grad_norm 2.0198 (2.3155)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:30:06 vssm1_tiny_0230s](training.py 212): INFO EPOCH 127 training takes 0:01:22
[2024-11-09 14:30:06 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_127.pth saving......
[2024-11-09 14:30:07 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_127.pth saved !!!
[2024-11-09 14:30:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.500 (3.500)	Loss 0.2690 (0.2690)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:30:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.339 (0.656)	Loss 0.2793 (0.2716)	Acc@1 93.750 (93.253)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:30:16 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.192 (0.433)	Loss 0.2332 (0.2836)	Acc@1 95.312 (91.890)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:30:19 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.379)	Loss 0.2822 (0.2787)	Acc@1 92.188 (92.540)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:30:22 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.940 Acc@5 100.000
[2024-11-09 14:30:22 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.9%
[2024-11-09 14:30:22 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.94%
[2024-11-09 14:30:25 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.529 (3.529)	Loss 0.3115 (0.3115)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:30:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.233 (0.581)	Loss 0.3184 (0.3178)	Acc@1 97.656 (97.798)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:30:31 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.178 (0.420)	Loss 0.6836 (0.3496)	Acc@1 52.344 (93.564)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:30:33 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.362)	Loss 0.7788 (0.4771)	Acc@1 46.875 (79.032)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:30:37 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 72.140 Acc@5 100.000
[2024-11-09 14:30:37 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 72.1%
[2024-11-09 14:30:37 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 72.14%
[2024-11-09 14:30:42 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][0/156]	eta 0:12:15 lr 0.000085	 wd 0.0500	time 4.7125 (4.7125)	data time 4.1291 (4.1291)	model time 0.0000 (0.0000)	loss 0.5817 (0.5817)	grad_norm 2.1931 (2.1931)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:30:47 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][10/156]	eta 0:02:09 lr 0.000085	 wd 0.0500	time 0.4861 (0.8872)	data time 0.0187 (0.3893)	model time 0.0000 (0.0000)	loss 0.6479 (0.5684)	grad_norm 2.5080 (2.8401)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:30:52 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][20/156]	eta 0:01:37 lr 0.000085	 wd 0.0500	time 0.4497 (0.7136)	data time 0.0202 (0.2089)	model time 0.0000 (0.0000)	loss 0.5679 (0.5653)	grad_norm 2.1196 (2.8384)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:30:57 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][30/156]	eta 0:01:22 lr 0.000085	 wd 0.0500	time 0.5722 (0.6579)	data time 0.0164 (0.1470)	model time 0.0000 (0.0000)	loss 0.6137 (0.5681)	grad_norm 3.1353 (2.6615)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:02 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][40/156]	eta 0:01:11 lr 0.000085	 wd 0.0500	time 0.5195 (0.6178)	data time 0.0181 (0.1135)	model time 0.0000 (0.0000)	loss 0.4297 (0.5687)	grad_norm 2.1860 (2.5192)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:08 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][50/156]	eta 0:01:03 lr 0.000085	 wd 0.0500	time 0.4144 (0.5981)	data time 0.0044 (0.0961)	model time 0.0000 (0.0000)	loss 0.5811 (0.5687)	grad_norm 1.5845 (2.4088)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:13 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][60/156]	eta 0:00:55 lr 0.000085	 wd 0.0500	time 0.5198 (0.5825)	data time 0.0249 (0.0853)	model time 0.4949 (0.4725)	loss 0.6616 (0.5708)	grad_norm 2.1744 (2.4983)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:18 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][70/156]	eta 0:00:49 lr 0.000085	 wd 0.0500	time 0.4644 (0.5709)	data time 0.0457 (0.0790)	model time 0.4187 (0.4662)	loss 0.6770 (0.5756)	grad_norm 2.1009 (2.4611)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:22 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][80/156]	eta 0:00:42 lr 0.000085	 wd 0.0500	time 0.5394 (0.5603)	data time 0.0130 (0.0716)	model time 0.5264 (0.4659)	loss 0.6302 (0.5775)	grad_norm 2.3279 (2.4029)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:27 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][90/156]	eta 0:00:36 lr 0.000084	 wd 0.0500	time 0.5063 (0.5514)	data time 0.0026 (0.0652)	model time 0.5038 (0.4662)	loss 0.6470 (0.5779)	grad_norm 2.2709 (2.3739)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:32 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][100/156]	eta 0:00:30 lr 0.000084	 wd 0.0500	time 0.4795 (0.5435)	data time 0.0187 (0.0598)	model time 0.4608 (0.4651)	loss 0.6545 (0.5787)	grad_norm 3.0776 (2.4069)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:37 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][110/156]	eta 0:00:24 lr 0.000084	 wd 0.0500	time 0.4634 (0.5434)	data time 0.0009 (0.0557)	model time 0.4625 (0.4755)	loss 0.6342 (0.5801)	grad_norm 2.6717 (2.4396)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:43 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][120/156]	eta 0:00:19 lr 0.000084	 wd 0.0500	time 0.7190 (0.5444)	data time 0.0100 (0.0528)	model time 0.7090 (0.4840)	loss 0.4645 (0.5786)	grad_norm 1.9675 (2.4020)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:48 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][130/156]	eta 0:00:14 lr 0.000084	 wd 0.0500	time 0.5614 (0.5432)	data time 0.0288 (0.0513)	model time 0.5326 (0.4854)	loss 0.6290 (0.5805)	grad_norm 1.9392 (2.3438)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:54 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][140/156]	eta 0:00:08 lr 0.000084	 wd 0.0500	time 0.4805 (0.5442)	data time 0.0008 (0.0488)	model time 0.4797 (0.4917)	loss 0.5406 (0.5799)	grad_norm 1.7867 (2.3220)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:31:59 vssm1_tiny_0230s](training.py 201): INFO Train: [128/300][150/156]	eta 0:00:03 lr 0.000084	 wd 0.0500	time 0.4744 (0.5402)	data time 0.0006 (0.0456)	model time 0.4738 (0.4908)	loss 0.4837 (0.5775)	grad_norm 4.1756 (2.3156)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:32:02 vssm1_tiny_0230s](training.py 212): INFO EPOCH 128 training takes 0:01:24
[2024-11-09 14:32:02 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_128.pth saving......
[2024-11-09 14:32:02 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_128.pth saved !!!
[2024-11-09 14:32:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.820 (3.820)	Loss 0.2411 (0.2411)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:32:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.287 (0.596)	Loss 0.2666 (0.2644)	Acc@1 91.406 (91.264)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:32:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.162 (0.437)	Loss 0.1613 (0.2749)	Acc@1 97.656 (90.216)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:32:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.367)	Loss 0.2156 (0.2502)	Acc@1 95.312 (92.061)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:32:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.940 Acc@5 100.000
[2024-11-09 14:32:16 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.9%
[2024-11-09 14:32:16 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.94%
[2024-11-09 14:32:19 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.192 (3.192)	Loss 0.3108 (0.3108)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:32:21 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.508)	Loss 0.3176 (0.3172)	Acc@1 97.656 (97.798)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:32:25 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.270 (0.442)	Loss 0.6777 (0.3488)	Acc@1 53.906 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:32:27 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.363)	Loss 0.7729 (0.4748)	Acc@1 47.656 (79.183)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:32:30 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 72.440 Acc@5 100.000
[2024-11-09 14:32:30 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 72.4%
[2024-11-09 14:32:30 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 72.44%
[2024-11-09 14:32:36 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][0/156]	eta 0:16:02 lr 0.000084	 wd 0.0500	time 6.1710 (6.1710)	data time 5.5835 (5.5835)	model time 0.0000 (0.0000)	loss 0.6755 (0.6755)	grad_norm 2.6971 (2.6971)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:32:41 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][10/156]	eta 0:02:27 lr 0.000084	 wd 0.0500	time 0.4443 (1.0101)	data time 0.0072 (0.5241)	model time 0.0000 (0.0000)	loss 0.5280 (0.5942)	grad_norm 2.1495 (2.8567)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:32:46 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][20/156]	eta 0:01:43 lr 0.000084	 wd 0.0500	time 0.4955 (0.7610)	data time 0.0194 (0.2876)	model time 0.0000 (0.0000)	loss 0.5392 (0.5825)	grad_norm 4.9331 (2.7709)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:32:52 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][30/156]	eta 0:01:26 lr 0.000084	 wd 0.0500	time 0.4575 (0.6881)	data time 0.0007 (0.1994)	model time 0.0000 (0.0000)	loss 0.6102 (0.5932)	grad_norm 2.1221 (2.6938)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:32:56 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][40/156]	eta 0:01:14 lr 0.000084	 wd 0.0500	time 0.4777 (0.6383)	data time 0.0242 (0.1539)	model time 0.0000 (0.0000)	loss 0.4966 (0.5875)	grad_norm 1.8268 (2.6152)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:01 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][50/156]	eta 0:01:04 lr 0.000084	 wd 0.0500	time 0.4409 (0.6130)	data time 0.0038 (0.1271)	model time 0.0000 (0.0000)	loss 0.5544 (0.5860)	grad_norm 1.7181 (2.4847)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:08 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][60/156]	eta 0:00:58 lr 0.000084	 wd 0.0500	time 0.6791 (0.6126)	data time 0.0164 (0.1126)	model time 0.6627 (0.5718)	loss 0.6269 (0.5758)	grad_norm 4.8285 (2.5813)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:13 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][70/156]	eta 0:00:52 lr 0.000084	 wd 0.0500	time 0.5368 (0.6067)	data time 0.0082 (0.0995)	model time 0.5285 (0.5615)	loss 0.5110 (0.5738)	grad_norm 3.8182 (2.6691)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:19 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][80/156]	eta 0:00:45 lr 0.000084	 wd 0.0500	time 0.4639 (0.6042)	data time 0.0139 (0.0895)	model time 0.4500 (0.5637)	loss 0.5941 (0.5743)	grad_norm 1.7473 (2.6739)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:24 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][90/156]	eta 0:00:39 lr 0.000084	 wd 0.0500	time 0.5190 (0.5910)	data time 0.0483 (0.0813)	model time 0.4707 (0.5400)	loss 0.6050 (0.5735)	grad_norm 3.3759 (2.6698)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:29 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][100/156]	eta 0:00:32 lr 0.000084	 wd 0.0500	time 0.4726 (0.5835)	data time 0.0255 (0.0756)	model time 0.4470 (0.5304)	loss 0.5555 (0.5730)	grad_norm 2.1124 (2.6391)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:34 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][110/156]	eta 0:00:26 lr 0.000084	 wd 0.0500	time 0.5736 (0.5752)	data time 0.0023 (0.0701)	model time 0.5713 (0.5213)	loss 0.6071 (0.5726)	grad_norm 5.1761 (2.6520)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:40 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][120/156]	eta 0:00:20 lr 0.000084	 wd 0.0500	time 0.5841 (0.5734)	data time 0.0139 (0.0664)	model time 0.5702 (0.5223)	loss 0.5876 (0.5747)	grad_norm 1.8465 (2.6407)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:45 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][130/156]	eta 0:00:14 lr 0.000084	 wd 0.0500	time 0.5592 (0.5713)	data time 0.0006 (0.0628)	model time 0.5586 (0.5229)	loss 0.4971 (0.5731)	grad_norm 2.7851 (2.6565)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:50 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][140/156]	eta 0:00:09 lr 0.000084	 wd 0.0500	time 0.5482 (0.5672)	data time 0.0009 (0.0595)	model time 0.5473 (0.5200)	loss 0.5276 (0.5731)	grad_norm 2.5818 (2.6466)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:55 vssm1_tiny_0230s](training.py 201): INFO Train: [129/300][150/156]	eta 0:00:03 lr 0.000084	 wd 0.0500	time 0.6331 (0.5632)	data time 0.0005 (0.0556)	model time 0.6326 (0.5187)	loss 0.4985 (0.5728)	grad_norm 1.8496 (2.6343)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:33:59 vssm1_tiny_0230s](training.py 212): INFO EPOCH 129 training takes 0:01:28
[2024-11-09 14:33:59 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_129.pth saving......
[2024-11-09 14:33:59 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_129.pth saved !!!
[2024-11-09 14:34:04 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.841 (4.841)	Loss 0.2300 (0.2300)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:34:08 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.140 (0.752)	Loss 0.2312 (0.2330)	Acc@1 95.312 (95.099)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:34:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 1.072 (0.515)	Loss 0.2333 (0.2483)	Acc@1 94.531 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:34:13 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.150 (0.448)	Loss 0.3040 (0.2588)	Acc@1 90.625 (93.070)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:34:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.860 Acc@5 100.000
[2024-11-09 14:34:16 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.9%
[2024-11-09 14:34:16 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.94%
[2024-11-09 14:34:19 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.997 (2.997)	Loss 0.3098 (0.3098)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:34:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.302 (0.540)	Loss 0.3167 (0.3165)	Acc@1 97.656 (97.869)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:34:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.172 (0.392)	Loss 0.6729 (0.3479)	Acc@1 54.688 (93.713)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:34:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.287 (0.346)	Loss 0.7676 (0.4726)	Acc@1 47.656 (79.410)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:34:29 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 72.720 Acc@5 100.000
[2024-11-09 14:34:29 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 72.7%
[2024-11-09 14:34:29 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 72.72%
[2024-11-09 14:34:33 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][0/156]	eta 0:11:15 lr 0.000084	 wd 0.0500	time 4.3316 (4.3316)	data time 3.8516 (3.8516)	model time 0.0000 (0.0000)	loss 0.6152 (0.6152)	grad_norm 1.7369 (1.7369)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:34:38 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][10/156]	eta 0:02:05 lr 0.000084	 wd 0.0500	time 0.4897 (0.8629)	data time 0.0010 (0.3764)	model time 0.0000 (0.0000)	loss 0.5773 (0.6064)	grad_norm 3.0268 (2.3343)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:34:43 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][20/156]	eta 0:01:31 lr 0.000083	 wd 0.0500	time 0.4762 (0.6711)	data time 0.0155 (0.2046)	model time 0.0000 (0.0000)	loss 0.5086 (0.6050)	grad_norm 1.8926 (2.1645)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:34:48 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][30/156]	eta 0:01:17 lr 0.000083	 wd 0.0500	time 0.4659 (0.6133)	data time 0.0228 (0.1414)	model time 0.0000 (0.0000)	loss 0.6594 (0.5917)	grad_norm 1.8700 (2.1765)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:34:53 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][40/156]	eta 0:01:07 lr 0.000083	 wd 0.0500	time 0.4830 (0.5786)	data time 0.0367 (0.1104)	model time 0.0000 (0.0000)	loss 0.6118 (0.5821)	grad_norm 5.1447 (2.3310)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:34:57 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][50/156]	eta 0:00:58 lr 0.000083	 wd 0.0500	time 0.4188 (0.5554)	data time 0.0122 (0.0918)	model time 0.0000 (0.0000)	loss 0.5681 (0.5798)	grad_norm 4.3736 (2.4264)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:02 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][60/156]	eta 0:00:52 lr 0.000083	 wd 0.0500	time 0.4642 (0.5436)	data time 0.0215 (0.0812)	model time 0.4427 (0.4564)	loss 0.6577 (0.5838)	grad_norm 2.1812 (2.4210)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:07 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][70/156]	eta 0:00:45 lr 0.000083	 wd 0.0500	time 0.4682 (0.5329)	data time 0.0276 (0.0720)	model time 0.4406 (0.4542)	loss 0.5299 (0.5804)	grad_norm 1.7052 (2.4259)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:12 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][80/156]	eta 0:00:40 lr 0.000083	 wd 0.0500	time 0.4169 (0.5273)	data time 0.0060 (0.0645)	model time 0.4109 (0.4617)	loss 0.5003 (0.5734)	grad_norm 3.2510 (2.4757)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:16 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][90/156]	eta 0:00:34 lr 0.000083	 wd 0.0500	time 0.4326 (0.5216)	data time 0.0007 (0.0580)	model time 0.4318 (0.4635)	loss 0.6302 (0.5775)	grad_norm 1.8251 (2.5102)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:21 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][100/156]	eta 0:00:29 lr 0.000083	 wd 0.0500	time 0.5039 (0.5187)	data time 0.0482 (0.0550)	model time 0.4556 (0.4636)	loss 0.6270 (0.5778)	grad_norm 2.2464 (2.4972)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:26 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][110/156]	eta 0:00:23 lr 0.000083	 wd 0.0500	time 0.4304 (0.5154)	data time 0.0011 (0.0517)	model time 0.4293 (0.4639)	loss 0.6050 (0.5791)	grad_norm 0.9781 (2.4470)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:31 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][120/156]	eta 0:00:18 lr 0.000083	 wd 0.0500	time 0.6394 (0.5162)	data time 0.0027 (0.0487)	model time 0.6368 (0.4704)	loss 0.5404 (0.5795)	grad_norm 2.0694 (2.4147)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:36 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][130/156]	eta 0:00:13 lr 0.000083	 wd 0.0500	time 0.4425 (0.5144)	data time 0.0066 (0.0459)	model time 0.4359 (0.4716)	loss 0.6774 (0.5786)	grad_norm 2.2647 (2.4162)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:42 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][140/156]	eta 0:00:08 lr 0.000083	 wd 0.0500	time 0.5399 (0.5158)	data time 0.0010 (0.0437)	model time 0.5389 (0.4770)	loss 0.6132 (0.5799)	grad_norm 2.2024 (2.3837)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:47 vssm1_tiny_0230s](training.py 201): INFO Train: [130/300][150/156]	eta 0:00:03 lr 0.000083	 wd 0.0500	time 0.5943 (0.5151)	data time 0.0589 (0.0414)	model time 0.5355 (0.4788)	loss 0.5840 (0.5811)	grad_norm 2.0535 (2.3467)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:35:50 vssm1_tiny_0230s](training.py 212): INFO EPOCH 130 training takes 0:01:20
[2024-11-09 14:35:50 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_130.pth saving......
[2024-11-09 14:35:50 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_130.pth saved !!!
[2024-11-09 14:35:54 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.625 (3.625)	Loss 0.2959 (0.2959)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:35:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.174 (0.576)	Loss 0.3040 (0.3021)	Acc@1 94.531 (91.903)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:35:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.403)	Loss 0.1925 (0.3117)	Acc@1 97.656 (90.439)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:36:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.142 (0.348)	Loss 0.2366 (0.2849)	Acc@1 93.750 (92.087)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:36:04 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.880 Acc@5 100.000
[2024-11-09 14:36:04 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.9%
[2024-11-09 14:36:04 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.94%
[2024-11-09 14:36:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.538 (3.538)	Loss 0.3093 (0.3093)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:36:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.594)	Loss 0.3162 (0.3161)	Acc@1 97.656 (97.798)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:36:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.151 (0.384)	Loss 0.6670 (0.3471)	Acc@1 56.250 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:36:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.344)	Loss 0.7617 (0.4705)	Acc@1 48.438 (79.587)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:36:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 72.920 Acc@5 100.000
[2024-11-09 14:36:16 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 72.9%
[2024-11-09 14:36:16 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 72.92%
[2024-11-09 14:36:21 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][0/156]	eta 0:12:50 lr 0.000083	 wd 0.0500	time 4.9404 (4.9404)	data time 4.4050 (4.4050)	model time 0.0000 (0.0000)	loss 0.5882 (0.5882)	grad_norm 2.2214 (2.2214)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:36:27 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][10/156]	eta 0:02:17 lr 0.000083	 wd 0.0500	time 0.6713 (0.9393)	data time 0.0171 (0.4120)	model time 0.0000 (0.0000)	loss 0.5696 (0.5560)	grad_norm 2.3005 (2.2697)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:36:32 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][20/156]	eta 0:01:40 lr 0.000083	 wd 0.0500	time 0.4449 (0.7425)	data time 0.0242 (0.2246)	model time 0.0000 (0.0000)	loss 0.6722 (0.5700)	grad_norm 2.3555 (2.4147)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:36:37 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][30/156]	eta 0:01:24 lr 0.000083	 wd 0.0500	time 0.5184 (0.6687)	data time 0.0007 (0.1565)	model time 0.0000 (0.0000)	loss 0.5096 (0.5694)	grad_norm 1.8544 (2.4320)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:36:42 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][40/156]	eta 0:01:13 lr 0.000083	 wd 0.0500	time 0.4222 (0.6348)	data time 0.0152 (0.1212)	model time 0.0000 (0.0000)	loss 0.6199 (0.5716)	grad_norm 0.9799 (2.4273)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:36:47 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][50/156]	eta 0:01:04 lr 0.000083	 wd 0.0500	time 0.4569 (0.6121)	data time 0.0009 (0.0998)	model time 0.0000 (0.0000)	loss 0.5980 (0.5741)	grad_norm 1.7891 (2.3222)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:36:52 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][60/156]	eta 0:00:57 lr 0.000083	 wd 0.0500	time 0.4253 (0.5942)	data time 0.0063 (0.0849)	model time 0.4190 (0.4937)	loss 0.6051 (0.5726)	grad_norm 2.2183 (2.2835)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:36:57 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][70/156]	eta 0:00:49 lr 0.000083	 wd 0.0500	time 0.4645 (0.5789)	data time 0.0037 (0.0741)	model time 0.4608 (0.4858)	loss 0.6054 (0.5723)	grad_norm 2.5589 (2.2985)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:37:02 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][80/156]	eta 0:00:43 lr 0.000083	 wd 0.0500	time 0.4380 (0.5681)	data time 0.0008 (0.0667)	model time 0.4372 (0.4828)	loss 0.6207 (0.5750)	grad_norm 1.9543 (2.3138)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:37:07 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][90/156]	eta 0:00:36 lr 0.000083	 wd 0.0500	time 0.4367 (0.5571)	data time 0.0156 (0.0610)	model time 0.4211 (0.4754)	loss 0.5838 (0.5755)	grad_norm 2.1555 (2.3103)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:37:12 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][100/156]	eta 0:00:30 lr 0.000082	 wd 0.0500	time 0.5042 (0.5478)	data time 0.0184 (0.0558)	model time 0.4858 (0.4713)	loss 0.6102 (0.5752)	grad_norm 1.7568 (2.2602)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:37:17 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][110/156]	eta 0:00:25 lr 0.000082	 wd 0.0500	time 0.5447 (0.5498)	data time 0.0014 (0.0537)	model time 0.5433 (0.4823)	loss 0.6115 (0.5797)	grad_norm 1.9617 (2.2524)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:37:23 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][120/156]	eta 0:00:19 lr 0.000082	 wd 0.0500	time 0.5968 (0.5494)	data time 0.0202 (0.0508)	model time 0.5766 (0.4885)	loss 0.5085 (0.5781)	grad_norm 2.5032 (2.2211)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:37:28 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][130/156]	eta 0:00:14 lr 0.000082	 wd 0.0500	time 0.5832 (0.5485)	data time 0.0219 (0.0488)	model time 0.5613 (0.4916)	loss 0.6301 (0.5800)	grad_norm 2.0175 (2.2336)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:37:33 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][140/156]	eta 0:00:08 lr 0.000082	 wd 0.0500	time 0.4941 (0.5435)	data time 0.0008 (0.0461)	model time 0.4933 (0.4890)	loss 0.6130 (0.5797)	grad_norm 3.5497 (2.2426)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:37:38 vssm1_tiny_0230s](training.py 201): INFO Train: [131/300][150/156]	eta 0:00:03 lr 0.000082	 wd 0.0500	time 0.4719 (0.5419)	data time 0.0006 (0.0431)	model time 0.4713 (0.4920)	loss 0.6085 (0.5811)	grad_norm 1.0290 (2.2884)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:37:41 vssm1_tiny_0230s](training.py 212): INFO EPOCH 131 training takes 0:01:24
[2024-11-09 14:37:41 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_131.pth saving......
[2024-11-09 14:37:42 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_131.pth saved !!!
[2024-11-09 14:37:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.796 (3.796)	Loss 0.2368 (0.2368)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:37:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.142 (0.607)	Loss 0.2439 (0.2380)	Acc@1 97.656 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:37:51 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.431)	Loss 0.2629 (0.2514)	Acc@1 95.312 (94.308)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:37:54 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.219 (0.397)	Loss 0.3225 (0.2688)	Acc@1 89.844 (93.095)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:37:56 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.680 Acc@5 100.000
[2024-11-09 14:37:56 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.7%
[2024-11-09 14:37:56 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.94%
[2024-11-09 14:38:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.541 (3.541)	Loss 0.3088 (0.3088)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:38:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.533)	Loss 0.3157 (0.3156)	Acc@1 97.656 (97.798)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:38:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.415)	Loss 0.6611 (0.3463)	Acc@1 56.250 (93.713)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:38:06 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.329)	Loss 0.7559 (0.4683)	Acc@1 49.219 (79.688)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:38:09 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 73.180 Acc@5 100.000
[2024-11-09 14:38:09 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 73.2%
[2024-11-09 14:38:09 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 73.18%
[2024-11-09 14:38:15 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][0/156]	eta 0:13:39 lr 0.000082	 wd 0.0500	time 5.2527 (5.2527)	data time 4.6999 (4.6999)	model time 0.0000 (0.0000)	loss 0.6171 (0.6171)	grad_norm 2.0054 (2.0054)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:38:20 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][10/156]	eta 0:02:17 lr 0.000082	 wd 0.0500	time 0.6205 (0.9408)	data time 0.0110 (0.4465)	model time 0.0000 (0.0000)	loss 0.5913 (0.5866)	grad_norm 1.4517 (2.2769)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:38:25 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][20/156]	eta 0:01:43 lr 0.000082	 wd 0.0500	time 0.5397 (0.7575)	data time 0.0121 (0.2413)	model time 0.0000 (0.0000)	loss 0.6227 (0.5812)	grad_norm 2.3184 (2.2193)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:38:30 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][30/156]	eta 0:01:24 lr 0.000082	 wd 0.0500	time 0.5686 (0.6667)	data time 0.0008 (0.1680)	model time 0.0000 (0.0000)	loss 0.6365 (0.5847)	grad_norm 1.4570 (2.0913)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:38:35 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][40/156]	eta 0:01:13 lr 0.000082	 wd 0.0500	time 0.5676 (0.6301)	data time 0.0201 (0.1312)	model time 0.0000 (0.0000)	loss 0.6042 (0.5848)	grad_norm 3.2046 (2.0879)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:38:40 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][50/156]	eta 0:01:04 lr 0.000082	 wd 0.0500	time 0.4544 (0.6072)	data time 0.0344 (0.1078)	model time 0.0000 (0.0000)	loss 0.6447 (0.5818)	grad_norm 2.6579 (2.1310)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:38:46 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][60/156]	eta 0:00:56 lr 0.000082	 wd 0.0500	time 0.5861 (0.5935)	data time 0.0161 (0.0930)	model time 0.5700 (0.5060)	loss 0.6294 (0.5847)	grad_norm 1.7057 (2.1367)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:38:50 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][70/156]	eta 0:00:49 lr 0.000082	 wd 0.0500	time 0.4333 (0.5742)	data time 0.0259 (0.0812)	model time 0.4074 (0.4767)	loss 0.6046 (0.5842)	grad_norm 1.5182 (2.1093)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:38:55 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][80/156]	eta 0:00:43 lr 0.000082	 wd 0.0500	time 0.5107 (0.5682)	data time 0.0057 (0.0737)	model time 0.5050 (0.4860)	loss 0.4684 (0.5822)	grad_norm 2.1788 (2.1239)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:39:01 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][90/156]	eta 0:00:37 lr 0.000082	 wd 0.0500	time 0.5166 (0.5634)	data time 0.0031 (0.0680)	model time 0.5135 (0.4903)	loss 0.5822 (0.5826)	grad_norm 2.3612 (2.1072)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:39:05 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][100/156]	eta 0:00:31 lr 0.000082	 wd 0.0500	time 0.4124 (0.5549)	data time 0.0006 (0.0630)	model time 0.4118 (0.4843)	loss 0.6253 (0.5814)	grad_norm 2.1819 (2.1049)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:39:10 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][110/156]	eta 0:00:25 lr 0.000082	 wd 0.0500	time 0.4698 (0.5493)	data time 0.0245 (0.0588)	model time 0.4453 (0.4830)	loss 0.6302 (0.5819)	grad_norm 1.6596 (2.1127)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:39:15 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][120/156]	eta 0:00:19 lr 0.000082	 wd 0.0500	time 0.4863 (0.5448)	data time 0.0008 (0.0552)	model time 0.4854 (0.4824)	loss 0.4935 (0.5799)	grad_norm 1.8912 (2.0950)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:39:20 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][130/156]	eta 0:00:14 lr 0.000082	 wd 0.0500	time 0.4397 (0.5423)	data time 0.0012 (0.0519)	model time 0.4385 (0.4846)	loss 0.5827 (0.5798)	grad_norm 2.4283 (2.0925)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:39:25 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][140/156]	eta 0:00:08 lr 0.000082	 wd 0.0500	time 0.4698 (0.5402)	data time 0.0009 (0.0491)	model time 0.4688 (0.4863)	loss 0.5282 (0.5783)	grad_norm 1.8974 (2.0915)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:39:31 vssm1_tiny_0230s](training.py 201): INFO Train: [132/300][150/156]	eta 0:00:03 lr 0.000082	 wd 0.0500	time 0.5734 (0.5389)	data time 0.0005 (0.0459)	model time 0.5729 (0.4897)	loss 0.6090 (0.5766)	grad_norm 1.9327 (2.1169)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:39:34 vssm1_tiny_0230s](training.py 212): INFO EPOCH 132 training takes 0:01:24
[2024-11-09 14:39:34 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_132.pth saving......
[2024-11-09 14:39:35 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_132.pth saved !!!
[2024-11-09 14:39:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.572 (3.572)	Loss 0.2269 (0.2269)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:39:42 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.208 (0.643)	Loss 0.2390 (0.2432)	Acc@1 95.312 (94.318)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:39:44 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.174 (0.442)	Loss 0.2070 (0.2548)	Acc@1 96.875 (93.043)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:39:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.362)	Loss 0.2690 (0.2575)	Acc@1 93.750 (92.566)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:39:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.420 Acc@5 100.000
[2024-11-09 14:39:49 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.4%
[2024-11-09 14:39:49 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 92.94%
[2024-11-09 14:39:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.602 (3.602)	Loss 0.3083 (0.3083)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:39:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.617)	Loss 0.3149 (0.3151)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:39:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.131 (0.448)	Loss 0.6553 (0.3456)	Acc@1 56.250 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:40:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.375)	Loss 0.7495 (0.4659)	Acc@1 49.219 (79.814)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:40:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 73.540 Acc@5 100.000
[2024-11-09 14:40:02 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 73.5%
[2024-11-09 14:40:02 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 73.54%
[2024-11-09 14:40:06 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][0/156]	eta 0:08:51 lr 0.000082	 wd 0.0500	time 3.4049 (3.4049)	data time 2.9964 (2.9964)	model time 0.0000 (0.0000)	loss 0.6529 (0.6529)	grad_norm 1.7142 (1.7142)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:40:11 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][10/156]	eta 0:01:51 lr 0.000082	 wd 0.0500	time 0.4775 (0.7654)	data time 0.0682 (0.2907)	model time 0.0000 (0.0000)	loss 0.5086 (0.5817)	grad_norm 1.8476 (2.0396)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:40:16 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][20/156]	eta 0:01:27 lr 0.000081	 wd 0.0500	time 0.4811 (0.6421)	data time 0.0006 (0.1594)	model time 0.0000 (0.0000)	loss 0.5646 (0.5867)	grad_norm 2.0186 (2.1078)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:40:21 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][30/156]	eta 0:01:16 lr 0.000081	 wd 0.0500	time 0.6211 (0.6098)	data time 0.0224 (0.1134)	model time 0.0000 (0.0000)	loss 0.5284 (0.5774)	grad_norm 3.5212 (2.1403)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:40:26 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][40/156]	eta 0:01:08 lr 0.000081	 wd 0.0500	time 0.5763 (0.5893)	data time 0.0393 (0.0921)	model time 0.0000 (0.0000)	loss 0.5616 (0.5861)	grad_norm 1.5903 (2.1057)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:40:32 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][50/156]	eta 0:01:01 lr 0.000081	 wd 0.0500	time 0.4874 (0.5781)	data time 0.0199 (0.0761)	model time 0.0000 (0.0000)	loss 0.6351 (0.5802)	grad_norm 2.4473 (2.1952)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:40:37 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][60/156]	eta 0:00:54 lr 0.000081	 wd 0.0500	time 0.4917 (0.5678)	data time 0.0264 (0.0650)	model time 0.4653 (0.5070)	loss 0.6189 (0.5774)	grad_norm 3.2525 (2.2411)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:40:42 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][70/156]	eta 0:00:48 lr 0.000081	 wd 0.0500	time 0.4295 (0.5609)	data time 0.0140 (0.0594)	model time 0.4154 (0.5002)	loss 0.6095 (0.5793)	grad_norm 1.1310 (2.2648)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:40:47 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][80/156]	eta 0:00:42 lr 0.000081	 wd 0.0500	time 0.4920 (0.5531)	data time 0.0336 (0.0542)	model time 0.4584 (0.4935)	loss 0.6560 (0.5784)	grad_norm 2.7971 (2.2701)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:40:52 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][90/156]	eta 0:00:36 lr 0.000081	 wd 0.0500	time 0.5837 (0.5505)	data time 0.0380 (0.0500)	model time 0.5457 (0.4986)	loss 0.6384 (0.5823)	grad_norm 3.0831 (2.2758)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:40:57 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][100/156]	eta 0:00:30 lr 0.000081	 wd 0.0500	time 0.4735 (0.5404)	data time 0.0006 (0.0458)	model time 0.4729 (0.4869)	loss 0.5026 (0.5822)	grad_norm 2.2267 (2.2709)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:41:02 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][110/156]	eta 0:00:24 lr 0.000081	 wd 0.0500	time 0.4909 (0.5356)	data time 0.0007 (0.0431)	model time 0.4902 (0.4844)	loss 0.4730 (0.5802)	grad_norm 2.8708 (2.2767)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:41:06 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][120/156]	eta 0:00:19 lr 0.000081	 wd 0.0500	time 0.4858 (0.5299)	data time 0.0006 (0.0403)	model time 0.4853 (0.4807)	loss 0.4690 (0.5773)	grad_norm 2.1452 (2.2533)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:41:11 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][130/156]	eta 0:00:13 lr 0.000081	 wd 0.0500	time 0.4364 (0.5245)	data time 0.0075 (0.0376)	model time 0.4289 (0.4772)	loss 0.5212 (0.5785)	grad_norm 2.2793 (2.2707)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:41:16 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][140/156]	eta 0:00:08 lr 0.000081	 wd 0.0500	time 0.5174 (0.5226)	data time 0.0143 (0.0360)	model time 0.5031 (0.4779)	loss 0.6672 (0.5780)	grad_norm 1.8604 (2.3541)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:41:21 vssm1_tiny_0230s](training.py 201): INFO Train: [133/300][150/156]	eta 0:00:03 lr 0.000081	 wd 0.0500	time 0.4644 (0.5216)	data time 0.0007 (0.0337)	model time 0.4637 (0.4806)	loss 0.5805 (0.5787)	grad_norm 1.9236 (2.3793)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:41:24 vssm1_tiny_0230s](training.py 212): INFO EPOCH 133 training takes 0:01:21
[2024-11-09 14:41:24 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_133.pth saving......
[2024-11-09 14:41:24 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_133.pth saved !!!
[2024-11-09 14:41:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.285 (3.285)	Loss 0.2238 (0.2238)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:41:30 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.342 (0.531)	Loss 0.2366 (0.2374)	Acc@1 93.750 (94.247)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:41:33 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.163 (0.421)	Loss 0.2427 (0.2510)	Acc@1 95.312 (93.229)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:41:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.142 (0.349)	Loss 0.3027 (0.2625)	Acc@1 92.188 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:41:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.040 Acc@5 100.000
[2024-11-09 14:41:38 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.0%
[2024-11-09 14:41:38 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.04%
[2024-11-09 14:41:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.388 (4.388)	Loss 0.3074 (0.3074)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:41:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 1.111 (0.682)	Loss 0.3142 (0.3144)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:41:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.186 (0.466)	Loss 0.6494 (0.3446)	Acc@1 56.250 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:41:50 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.409)	Loss 0.7437 (0.4635)	Acc@1 50.781 (80.040)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:41:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 73.860 Acc@5 100.000
[2024-11-09 14:41:53 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 73.9%
[2024-11-09 14:41:53 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 73.86%
[2024-11-09 14:41:58 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][0/156]	eta 0:12:21 lr 0.000081	 wd 0.0500	time 4.7545 (4.7545)	data time 4.2280 (4.2280)	model time 0.0000 (0.0000)	loss 0.5255 (0.5255)	grad_norm 2.4246 (2.4246)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:04 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][10/156]	eta 0:02:26 lr 0.000081	 wd 0.0500	time 0.5478 (1.0038)	data time 0.0599 (0.4979)	model time 0.0000 (0.0000)	loss 0.5876 (0.5628)	grad_norm 1.7487 (2.0618)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:10 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][20/156]	eta 0:01:47 lr 0.000081	 wd 0.0500	time 0.6165 (0.7937)	data time 0.0424 (0.2698)	model time 0.0000 (0.0000)	loss 0.5632 (0.5825)	grad_norm 1.7870 (2.1379)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:15 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][30/156]	eta 0:01:27 lr 0.000081	 wd 0.0500	time 0.5175 (0.6955)	data time 0.0125 (0.1882)	model time 0.0000 (0.0000)	loss 0.5913 (0.5683)	grad_norm 3.3938 (2.1226)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:20 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][40/156]	eta 0:01:16 lr 0.000081	 wd 0.0500	time 0.5952 (0.6616)	data time 0.0049 (0.1487)	model time 0.0000 (0.0000)	loss 0.4944 (0.5599)	grad_norm 1.8218 (2.0914)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:25 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][50/156]	eta 0:01:05 lr 0.000081	 wd 0.0500	time 0.4665 (0.6221)	data time 0.0203 (0.1224)	model time 0.0000 (0.0000)	loss 0.6216 (0.5637)	grad_norm 1.4775 (2.1348)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:30 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][60/156]	eta 0:00:57 lr 0.000081	 wd 0.0500	time 0.5166 (0.5971)	data time 0.0825 (0.1053)	model time 0.4341 (0.4514)	loss 0.4692 (0.5633)	grad_norm 1.8389 (2.2080)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:34 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][70/156]	eta 0:00:49 lr 0.000081	 wd 0.0500	time 0.5993 (0.5800)	data time 0.0158 (0.0923)	model time 0.5835 (0.4573)	loss 0.6057 (0.5637)	grad_norm 1.9762 (2.2501)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:39 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][80/156]	eta 0:00:43 lr 0.000081	 wd 0.0500	time 0.5774 (0.5701)	data time 0.0190 (0.0840)	model time 0.5584 (0.4632)	loss 0.6632 (0.5659)	grad_norm 1.9684 (2.2870)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:45 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][90/156]	eta 0:00:37 lr 0.000081	 wd 0.0500	time 0.4799 (0.5664)	data time 0.0235 (0.0772)	model time 0.4563 (0.4760)	loss 0.6536 (0.5694)	grad_norm 2.3154 (2.3432)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:50 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][100/156]	eta 0:00:31 lr 0.000080	 wd 0.0500	time 0.5202 (0.5622)	data time 0.0008 (0.0714)	model time 0.5194 (0.4818)	loss 0.6338 (0.5719)	grad_norm 1.5280 (2.3304)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:42:55 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][110/156]	eta 0:00:25 lr 0.000080	 wd 0.0500	time 0.5215 (0.5574)	data time 0.0313 (0.0663)	model time 0.4902 (0.4838)	loss 0.5181 (0.5720)	grad_norm 2.2710 (2.3372)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:43:00 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][120/156]	eta 0:00:19 lr 0.000080	 wd 0.0500	time 0.4147 (0.5508)	data time 0.0043 (0.0631)	model time 0.4104 (0.4790)	loss 0.5911 (0.5711)	grad_norm 2.1106 (2.3877)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:43:05 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][130/156]	eta 0:00:14 lr 0.000080	 wd 0.0500	time 0.7073 (0.5476)	data time 0.0285 (0.0588)	model time 0.6788 (0.4819)	loss 0.4690 (0.5711)	grad_norm 3.2455 (2.3734)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:43:10 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][140/156]	eta 0:00:08 lr 0.000080	 wd 0.0500	time 0.4843 (0.5425)	data time 0.0008 (0.0553)	model time 0.4835 (0.4802)	loss 0.5301 (0.5708)	grad_norm 2.0082 (2.3564)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:43:15 vssm1_tiny_0230s](training.py 201): INFO Train: [134/300][150/156]	eta 0:00:03 lr 0.000080	 wd 0.0500	time 0.6430 (0.5401)	data time 0.0005 (0.0517)	model time 0.6425 (0.4827)	loss 0.6150 (0.5703)	grad_norm 2.6679 (2.3740)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:43:18 vssm1_tiny_0230s](training.py 212): INFO EPOCH 134 training takes 0:01:24
[2024-11-09 14:43:18 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_134.pth saving......
[2024-11-09 14:43:18 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_134.pth saved !!!
[2024-11-09 14:43:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 5.232 (5.232)	Loss 0.1461 (0.1461)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:43:26 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.352 (0.677)	Loss 0.1669 (0.1560)	Acc@1 96.094 (97.940)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:43:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.478)	Loss 0.3245 (0.1806)	Acc@1 89.062 (96.615)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:43:31 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.172 (0.390)	Loss 0.3950 (0.2514)	Acc@1 85.938 (92.414)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:43:33 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.400 Acc@5 100.000
[2024-11-09 14:43:33 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 90.4%
[2024-11-09 14:43:33 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.04%
[2024-11-09 14:43:37 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.446 (3.446)	Loss 0.3064 (0.3064)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:43:40 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.132 (0.600)	Loss 0.3130 (0.3135)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:43:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.565 (0.450)	Loss 0.6440 (0.3435)	Acc@1 56.250 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:43:45 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.378)	Loss 0.7378 (0.4611)	Acc@1 50.781 (80.141)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:43:47 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 74.040 Acc@5 100.000
[2024-11-09 14:43:47 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 74.0%
[2024-11-09 14:43:47 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 74.04%
[2024-11-09 14:43:52 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][0/156]	eta 0:12:24 lr 0.000080	 wd 0.0500	time 4.7697 (4.7697)	data time 4.3646 (4.3646)	model time 0.0000 (0.0000)	loss 0.6695 (0.6695)	grad_norm 6.5844 (6.5844)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:43:57 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][10/156]	eta 0:02:18 lr 0.000080	 wd 0.0500	time 0.4966 (0.9494)	data time 0.0672 (0.4320)	model time 0.0000 (0.0000)	loss 0.6000 (0.5738)	grad_norm 1.7237 (3.2173)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:44:02 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][20/156]	eta 0:01:39 lr 0.000080	 wd 0.0500	time 0.4579 (0.7330)	data time 0.0005 (0.2335)	model time 0.0000 (0.0000)	loss 0.4775 (0.5614)	grad_norm 2.4420 (2.9836)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 14:44:07 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][30/156]	eta 0:01:21 lr 0.000080	 wd 0.0500	time 0.4644 (0.6473)	data time 0.0361 (0.1628)	model time 0.0000 (0.0000)	loss 0.6449 (0.5710)	grad_norm 2.0382 (inf)	loss_scale 32768.0000 (62364.9032)	mem 13675MB
[2024-11-09 14:44:12 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][40/156]	eta 0:01:10 lr 0.000080	 wd 0.0500	time 0.4325 (0.6103)	data time 0.0016 (0.1267)	model time 0.0000 (0.0000)	loss 0.5662 (0.5684)	grad_norm 1.6941 (inf)	loss_scale 32768.0000 (55146.1463)	mem 13675MB
[2024-11-09 14:44:17 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][50/156]	eta 0:01:03 lr 0.000080	 wd 0.0500	time 0.6383 (0.5955)	data time 0.0161 (0.1048)	model time 0.0000 (0.0000)	loss 0.5539 (0.5658)	grad_norm 1.5496 (inf)	loss_scale 32768.0000 (50758.2745)	mem 13675MB
[2024-11-09 14:44:23 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][60/156]	eta 0:00:56 lr 0.000080	 wd 0.0500	time 0.7318 (0.5858)	data time 0.0180 (0.0901)	model time 0.7138 (0.5207)	loss 0.5507 (0.5627)	grad_norm 1.5985 (inf)	loss_scale 32768.0000 (47809.0492)	mem 13675MB
[2024-11-09 14:44:27 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][70/156]	eta 0:00:49 lr 0.000080	 wd 0.0500	time 0.5224 (0.5723)	data time 0.0082 (0.0789)	model time 0.5142 (0.5003)	loss 0.6370 (0.5632)	grad_norm 1.8814 (inf)	loss_scale 32768.0000 (45690.5915)	mem 13675MB
[2024-11-09 14:44:32 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][80/156]	eta 0:00:42 lr 0.000080	 wd 0.0500	time 0.5030 (0.5598)	data time 0.0007 (0.0698)	model time 0.5023 (0.4887)	loss 0.6237 (0.5638)	grad_norm 1.9584 (inf)	loss_scale 32768.0000 (44095.2099)	mem 13675MB
[2024-11-09 14:44:37 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][90/156]	eta 0:00:36 lr 0.000080	 wd 0.0500	time 0.4218 (0.5535)	data time 0.0054 (0.0641)	model time 0.4165 (0.4877)	loss 0.5943 (0.5672)	grad_norm 2.7087 (inf)	loss_scale 32768.0000 (42850.4615)	mem 13675MB
[2024-11-09 14:44:42 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][100/156]	eta 0:00:30 lr 0.000080	 wd 0.0500	time 0.5093 (0.5469)	data time 0.0249 (0.0593)	model time 0.4844 (0.4844)	loss 0.5716 (0.5684)	grad_norm 2.2405 (inf)	loss_scale 32768.0000 (41852.1980)	mem 13675MB
[2024-11-09 14:44:47 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][110/156]	eta 0:00:24 lr 0.000080	 wd 0.0500	time 0.4482 (0.5384)	data time 0.0006 (0.0546)	model time 0.4476 (0.4779)	loss 0.6245 (0.5678)	grad_norm 2.1595 (inf)	loss_scale 32768.0000 (41033.8018)	mem 13675MB
[2024-11-09 14:44:51 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][120/156]	eta 0:00:19 lr 0.000080	 wd 0.0500	time 0.6472 (0.5342)	data time 0.0221 (0.0510)	model time 0.6251 (0.4776)	loss 0.6044 (0.5684)	grad_norm 1.7679 (inf)	loss_scale 32768.0000 (40350.6777)	mem 13675MB
[2024-11-09 14:44:57 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][130/156]	eta 0:00:13 lr 0.000080	 wd 0.0500	time 0.4645 (0.5328)	data time 0.0056 (0.0480)	model time 0.4589 (0.4810)	loss 0.6214 (0.5701)	grad_norm 1.3796 (inf)	loss_scale 32768.0000 (39771.8473)	mem 13675MB
[2024-11-09 14:45:02 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][140/156]	eta 0:00:08 lr 0.000080	 wd 0.0500	time 0.4387 (0.5311)	data time 0.0020 (0.0458)	model time 0.4367 (0.4823)	loss 0.6289 (0.5713)	grad_norm 2.1309 (inf)	loss_scale 32768.0000 (39275.1206)	mem 13675MB
[2024-11-09 14:45:07 vssm1_tiny_0230s](training.py 201): INFO Train: [135/300][150/156]	eta 0:00:03 lr 0.000080	 wd 0.0500	time 0.5397 (0.5278)	data time 0.0006 (0.0428)	model time 0.5391 (0.4822)	loss 0.6275 (0.5724)	grad_norm 2.2758 (inf)	loss_scale 32768.0000 (38844.1854)	mem 13675MB
[2024-11-09 14:45:09 vssm1_tiny_0230s](training.py 212): INFO EPOCH 135 training takes 0:01:22
[2024-11-09 14:45:09 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_135.pth saving......
[2024-11-09 14:45:10 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_135.pth saved !!!
[2024-11-09 14:45:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.520 (3.520)	Loss 0.2034 (0.2034)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:45:16 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.573)	Loss 0.2205 (0.2164)	Acc@1 96.094 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:45:19 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.438)	Loss 0.2605 (0.2311)	Acc@1 93.750 (94.717)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:45:21 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.366)	Loss 0.3186 (0.2554)	Acc@1 91.406 (93.397)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:45:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.100 Acc@5 100.000
[2024-11-09 14:45:24 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.1%
[2024-11-09 14:45:24 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.10%
[2024-11-09 14:45:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.943 (4.943)	Loss 0.3064 (0.3064)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:45:30 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.257 (0.611)	Loss 0.3130 (0.3134)	Acc@1 96.875 (97.372)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:45:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.414)	Loss 0.6377 (0.3431)	Acc@1 57.031 (93.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:45:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.361)	Loss 0.7305 (0.4587)	Acc@1 52.344 (80.242)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:45:37 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 74.300 Acc@5 100.000
[2024-11-09 14:45:37 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 74.3%
[2024-11-09 14:45:37 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 74.30%
[2024-11-09 14:45:42 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][0/156]	eta 0:13:02 lr 0.000080	 wd 0.0500	time 5.0180 (5.0180)	data time 4.4606 (4.4606)	model time 0.0000 (0.0000)	loss 0.6048 (0.6048)	grad_norm 2.4727 (2.4727)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:45:47 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][10/156]	eta 0:02:10 lr 0.000080	 wd 0.0500	time 0.4868 (0.8904)	data time 0.0226 (0.4208)	model time 0.0000 (0.0000)	loss 0.6216 (0.5743)	grad_norm 1.3593 (2.3306)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:45:52 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][20/156]	eta 0:01:35 lr 0.000080	 wd 0.0500	time 0.4028 (0.7047)	data time 0.0006 (0.2337)	model time 0.0000 (0.0000)	loss 0.5694 (0.5775)	grad_norm 2.8959 (2.4627)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:45:57 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][30/156]	eta 0:01:20 lr 0.000079	 wd 0.0500	time 0.5094 (0.6394)	data time 0.0161 (0.1639)	model time 0.0000 (0.0000)	loss 0.5799 (0.5760)	grad_norm 1.9814 (2.3790)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:02 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][40/156]	eta 0:01:09 lr 0.000079	 wd 0.0500	time 0.5356 (0.5993)	data time 0.0157 (0.1261)	model time 0.0000 (0.0000)	loss 0.6139 (0.5756)	grad_norm 3.7261 (2.4191)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:06 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][50/156]	eta 0:01:00 lr 0.000079	 wd 0.0500	time 0.4090 (0.5726)	data time 0.0007 (0.1068)	model time 0.0000 (0.0000)	loss 0.6138 (0.5784)	grad_norm 2.0044 (2.3301)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:11 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][60/156]	eta 0:00:53 lr 0.000079	 wd 0.0500	time 0.5023 (0.5555)	data time 0.0033 (0.0917)	model time 0.4990 (0.4535)	loss 0.5079 (0.5799)	grad_norm 1.9539 (2.2423)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:16 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][70/156]	eta 0:00:47 lr 0.000079	 wd 0.0500	time 0.4746 (0.5479)	data time 0.0277 (0.0817)	model time 0.4469 (0.4669)	loss 0.5664 (0.5808)	grad_norm 1.9011 (2.1684)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:21 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][80/156]	eta 0:00:41 lr 0.000079	 wd 0.0500	time 0.4758 (0.5449)	data time 0.0104 (0.0736)	model time 0.4654 (0.4807)	loss 0.5547 (0.5767)	grad_norm 2.1012 (2.1759)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:26 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][90/156]	eta 0:00:35 lr 0.000079	 wd 0.0500	time 0.8242 (0.5404)	data time 0.0195 (0.0669)	model time 0.8048 (0.4832)	loss 0.4877 (0.5720)	grad_norm 2.5828 (2.2275)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:32 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][100/156]	eta 0:00:30 lr 0.000079	 wd 0.0500	time 0.4655 (0.5378)	data time 0.0132 (0.0629)	model time 0.4523 (0.4840)	loss 0.4624 (0.5656)	grad_norm 2.1351 (2.2414)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:37 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][110/156]	eta 0:00:24 lr 0.000079	 wd 0.0500	time 0.6168 (0.5368)	data time 0.0075 (0.0593)	model time 0.6093 (0.4875)	loss 0.6626 (0.5676)	grad_norm 1.4770 (2.2561)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:42 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][120/156]	eta 0:00:19 lr 0.000079	 wd 0.0500	time 0.4431 (0.5354)	data time 0.0130 (0.0560)	model time 0.4301 (0.4891)	loss 0.6425 (0.5705)	grad_norm 1.2582 (2.2482)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:47 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][130/156]	eta 0:00:13 lr 0.000079	 wd 0.0500	time 0.5091 (0.5330)	data time 0.0074 (0.0529)	model time 0.5017 (0.4892)	loss 0.5317 (0.5715)	grad_norm 1.9999 (2.2203)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:52 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][140/156]	eta 0:00:08 lr 0.000079	 wd 0.0500	time 0.4091 (0.5307)	data time 0.0010 (0.0507)	model time 0.4081 (0.4880)	loss 0.5244 (0.5725)	grad_norm 3.8290 (2.2042)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:46:57 vssm1_tiny_0230s](training.py 201): INFO Train: [136/300][150/156]	eta 0:00:03 lr 0.000079	 wd 0.0500	time 0.6524 (0.5294)	data time 0.0005 (0.0474)	model time 0.6519 (0.4903)	loss 0.4840 (0.5734)	grad_norm 2.8237 (2.2058)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:47:00 vssm1_tiny_0230s](training.py 212): INFO EPOCH 136 training takes 0:01:23
[2024-11-09 14:47:00 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_136.pth saving......
[2024-11-09 14:47:00 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_136.pth saved !!!
[2024-11-09 14:47:04 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.761 (3.761)	Loss 0.2688 (0.2688)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:47:07 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.190 (0.627)	Loss 0.2751 (0.2830)	Acc@1 92.969 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:47:09 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.318 (0.430)	Loss 0.1962 (0.2946)	Acc@1 97.656 (90.885)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:47:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.166 (0.366)	Loss 0.2389 (0.2764)	Acc@1 95.312 (92.137)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:47:15 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.760 Acc@5 100.000
[2024-11-09 14:47:15 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.8%
[2024-11-09 14:47:15 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.10%
[2024-11-09 14:47:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.603 (2.603)	Loss 0.3062 (0.3062)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:47:21 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.248 (0.568)	Loss 0.3125 (0.3132)	Acc@1 96.875 (97.372)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:47:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.436)	Loss 0.6309 (0.3425)	Acc@1 59.375 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:47:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.146 (0.358)	Loss 0.7231 (0.4562)	Acc@1 53.125 (80.519)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:47:29 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 74.700 Acc@5 100.000
[2024-11-09 14:47:29 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 74.7%
[2024-11-09 14:47:29 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 74.70%
[2024-11-09 14:47:34 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][0/156]	eta 0:12:13 lr 0.000079	 wd 0.0500	time 4.7051 (4.7051)	data time 4.2582 (4.2582)	model time 0.0000 (0.0000)	loss 0.6336 (0.6336)	grad_norm 2.6903 (2.6903)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:47:39 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][10/156]	eta 0:02:06 lr 0.000079	 wd 0.0500	time 0.4643 (0.8645)	data time 0.0009 (0.4012)	model time 0.0000 (0.0000)	loss 0.5143 (0.5626)	grad_norm 2.1450 (2.2191)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:47:44 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][20/156]	eta 0:01:35 lr 0.000079	 wd 0.0500	time 0.4322 (0.7038)	data time 0.0178 (0.2205)	model time 0.0000 (0.0000)	loss 0.5959 (0.5647)	grad_norm 1.9446 (2.6896)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:47:49 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][30/156]	eta 0:01:20 lr 0.000079	 wd 0.0500	time 0.4529 (0.6417)	data time 0.0007 (0.1519)	model time 0.0000 (0.0000)	loss 0.5748 (0.5726)	grad_norm 1.8667 (2.6111)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:47:54 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][40/156]	eta 0:01:11 lr 0.000079	 wd 0.0500	time 0.4930 (0.6124)	data time 0.0100 (0.1219)	model time 0.0000 (0.0000)	loss 0.6167 (0.5647)	grad_norm 1.4368 (2.5896)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:47:59 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][50/156]	eta 0:01:02 lr 0.000079	 wd 0.0500	time 0.4563 (0.5920)	data time 0.0034 (0.1012)	model time 0.0000 (0.0000)	loss 0.5667 (0.5656)	grad_norm 1.8985 (2.4990)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:04 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][60/156]	eta 0:00:55 lr 0.000079	 wd 0.0500	time 0.4213 (0.5780)	data time 0.0033 (0.0863)	model time 0.4179 (0.4958)	loss 0.6064 (0.5655)	grad_norm 2.9106 (2.4583)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:09 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][70/156]	eta 0:00:48 lr 0.000079	 wd 0.0500	time 0.5299 (0.5669)	data time 0.0018 (0.0762)	model time 0.5280 (0.4905)	loss 0.5525 (0.5639)	grad_norm 3.3804 (2.4970)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:15 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][80/156]	eta 0:00:42 lr 0.000079	 wd 0.0500	time 0.5001 (0.5632)	data time 0.0164 (0.0691)	model time 0.4836 (0.4996)	loss 0.5704 (0.5655)	grad_norm 1.3540 (2.4894)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:20 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][90/156]	eta 0:00:36 lr 0.000079	 wd 0.0500	time 0.4978 (0.5554)	data time 0.0008 (0.0630)	model time 0.4969 (0.4945)	loss 0.5895 (0.5620)	grad_norm 4.5602 (2.5386)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:25 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][100/156]	eta 0:00:30 lr 0.000078	 wd 0.0500	time 0.4205 (0.5500)	data time 0.0007 (0.0584)	model time 0.4198 (0.4923)	loss 0.6142 (0.5627)	grad_norm 1.9738 (2.5078)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:30 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][110/156]	eta 0:00:25 lr 0.000078	 wd 0.0500	time 0.5232 (0.5463)	data time 0.0214 (0.0545)	model time 0.5018 (0.4925)	loss 0.5761 (0.5638)	grad_norm 2.0348 (2.5079)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:34 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][120/156]	eta 0:00:19 lr 0.000078	 wd 0.0500	time 0.5902 (0.5405)	data time 0.0009 (0.0513)	model time 0.5893 (0.4881)	loss 0.4808 (0.5625)	grad_norm 3.0768 (2.5216)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:40 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][130/156]	eta 0:00:13 lr 0.000078	 wd 0.0500	time 0.5535 (0.5384)	data time 0.0044 (0.0482)	model time 0.5490 (0.4899)	loss 0.5093 (0.5612)	grad_norm 1.7792 (2.5623)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:45 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][140/156]	eta 0:00:08 lr 0.000078	 wd 0.0500	time 0.4303 (0.5364)	data time 0.0009 (0.0457)	model time 0.4294 (0.4907)	loss 0.5805 (0.5607)	grad_norm 2.4684 (2.6092)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:50 vssm1_tiny_0230s](training.py 201): INFO Train: [137/300][150/156]	eta 0:00:03 lr 0.000078	 wd 0.0500	time 0.4062 (0.5334)	data time 0.0005 (0.0427)	model time 0.4057 (0.4907)	loss 0.5584 (0.5617)	grad_norm 2.1911 (2.6343)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:48:52 vssm1_tiny_0230s](training.py 212): INFO EPOCH 137 training takes 0:01:23
[2024-11-09 14:48:52 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_137.pth saving......
[2024-11-09 14:48:53 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_137.pth saved !!!
[2024-11-09 14:48:56 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.332 (3.332)	Loss 0.2443 (0.2443)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:48:58 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.164 (0.469)	Loss 0.2585 (0.2531)	Acc@1 93.750 (93.679)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:49:00 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.317)	Loss 0.2004 (0.2627)	Acc@1 96.094 (92.820)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:49:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.270)	Loss 0.2554 (0.2561)	Acc@1 91.406 (93.019)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:49:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.380 Acc@5 100.000
[2024-11-09 14:49:03 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.4%
[2024-11-09 14:49:03 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.38%
[2024-11-09 14:49:05 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.930 (1.930)	Loss 0.3054 (0.3054)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:49:06 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.308)	Loss 0.3123 (0.3129)	Acc@1 96.875 (97.372)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:49:08 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.229)	Loss 0.6245 (0.3418)	Acc@1 60.156 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:49:09 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.204)	Loss 0.7163 (0.4538)	Acc@1 53.125 (80.746)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:49:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 75.080 Acc@5 100.000
[2024-11-09 14:49:10 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 75.1%
[2024-11-09 14:49:10 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 75.08%
[2024-11-09 14:49:15 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][0/156]	eta 0:11:25 lr 0.000078	 wd 0.0500	time 4.3969 (4.3969)	data time 3.8849 (3.8849)	model time 0.0000 (0.0000)	loss 0.4821 (0.4821)	grad_norm 1.9599 (1.9599)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:49:20 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][10/156]	eta 0:02:04 lr 0.000078	 wd 0.0500	time 0.4345 (0.8507)	data time 0.0021 (0.3649)	model time 0.0000 (0.0000)	loss 0.4627 (0.5378)	grad_norm 2.8307 (2.5145)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:49:25 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][20/156]	eta 0:01:34 lr 0.000078	 wd 0.0500	time 0.5453 (0.6919)	data time 0.0042 (0.2057)	model time 0.0000 (0.0000)	loss 0.5495 (0.5443)	grad_norm 1.9039 (2.3621)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:49:30 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][30/156]	eta 0:01:20 lr 0.000078	 wd 0.0500	time 0.4408 (0.6362)	data time 0.0010 (0.1441)	model time 0.0000 (0.0000)	loss 0.5071 (0.5415)	grad_norm 2.3920 (2.3419)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:49:36 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][40/156]	eta 0:01:11 lr 0.000078	 wd 0.0500	time 0.5211 (0.6205)	data time 0.0128 (0.1229)	model time 0.0000 (0.0000)	loss 0.6057 (0.5544)	grad_norm 2.3997 (2.4026)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:49:41 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][50/156]	eta 0:01:03 lr 0.000078	 wd 0.0500	time 0.6372 (0.5998)	data time 0.0063 (0.1012)	model time 0.0000 (0.0000)	loss 0.6111 (0.5605)	grad_norm 2.3964 (2.3662)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:49:46 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][60/156]	eta 0:00:56 lr 0.000078	 wd 0.0500	time 0.6395 (0.5887)	data time 0.0224 (0.0894)	model time 0.6170 (0.5029)	loss 0.6084 (0.5650)	grad_norm 2.3734 (2.3429)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:49:52 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][70/156]	eta 0:00:49 lr 0.000078	 wd 0.0500	time 0.5498 (0.5794)	data time 0.0010 (0.0780)	model time 0.5488 (0.5084)	loss 0.6366 (0.5615)	grad_norm 1.9932 (2.3812)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:49:57 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][80/156]	eta 0:00:43 lr 0.000078	 wd 0.0500	time 0.4122 (0.5681)	data time 0.0015 (0.0698)	model time 0.4106 (0.4978)	loss 0.3894 (0.5579)	grad_norm 3.3387 (2.4283)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:50:01 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][90/156]	eta 0:00:36 lr 0.000078	 wd 0.0500	time 0.5483 (0.5603)	data time 0.0232 (0.0646)	model time 0.5251 (0.4920)	loss 0.5655 (0.5563)	grad_norm 2.4262 (2.5466)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:50:07 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][100/156]	eta 0:00:31 lr 0.000078	 wd 0.0500	time 0.5202 (0.5551)	data time 0.0152 (0.0606)	model time 0.5050 (0.4903)	loss 0.6245 (0.5604)	grad_norm 2.9467 (2.6167)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:50:12 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][110/156]	eta 0:00:25 lr 0.000078	 wd 0.0500	time 0.7303 (0.5504)	data time 0.0343 (0.0563)	model time 0.6959 (0.4903)	loss 0.6325 (0.5622)	grad_norm 2.3398 (2.5693)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:50:17 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][120/156]	eta 0:00:19 lr 0.000078	 wd 0.0500	time 0.4549 (0.5463)	data time 0.0423 (0.0528)	model time 0.4127 (0.4898)	loss 0.6292 (0.5653)	grad_norm 2.5411 (2.5203)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:50:22 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][130/156]	eta 0:00:14 lr 0.000078	 wd 0.0500	time 0.4613 (0.5435)	data time 0.0048 (0.0506)	model time 0.4565 (0.4893)	loss 0.5072 (0.5628)	grad_norm 2.1930 (2.4961)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:50:26 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][140/156]	eta 0:00:08 lr 0.000078	 wd 0.0500	time 0.4595 (0.5387)	data time 0.0272 (0.0481)	model time 0.4323 (0.4861)	loss 0.5875 (0.5640)	grad_norm 2.1416 (2.5336)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:50:31 vssm1_tiny_0230s](training.py 201): INFO Train: [138/300][150/156]	eta 0:00:03 lr 0.000078	 wd 0.0500	time 0.5887 (0.5363)	data time 0.0005 (0.0453)	model time 0.5882 (0.4873)	loss 0.5966 (0.5664)	grad_norm 1.8957 (2.5424)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:50:35 vssm1_tiny_0230s](training.py 212): INFO EPOCH 138 training takes 0:01:24
[2024-11-09 14:50:35 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_138.pth saving......
[2024-11-09 14:50:35 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_138.pth saved !!!
[2024-11-09 14:50:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.381 (2.381)	Loss 0.2778 (0.2778)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:50:40 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.194 (0.428)	Loss 0.2974 (0.2877)	Acc@1 93.750 (93.324)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:50:42 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.144 (0.325)	Loss 0.2290 (0.2981)	Acc@1 96.094 (92.001)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:50:44 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.285)	Loss 0.2808 (0.2870)	Acc@1 91.406 (92.692)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:50:46 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.160 Acc@5 100.000
[2024-11-09 14:50:46 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.2%
[2024-11-09 14:50:46 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.38%
[2024-11-09 14:50:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.159 (1.159)	Loss 0.3042 (0.3042)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:50:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.242)	Loss 0.3108 (0.3115)	Acc@1 96.875 (97.301)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:50:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.194)	Loss 0.6196 (0.3403)	Acc@1 60.156 (93.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:50:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.144 (0.176)	Loss 0.7109 (0.4513)	Acc@1 54.688 (80.973)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:50:52 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 75.360 Acc@5 100.000
[2024-11-09 14:50:52 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 75.4%
[2024-11-09 14:50:52 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 75.36%
[2024-11-09 14:50:56 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][0/156]	eta 0:08:08 lr 0.000078	 wd 0.0500	time 3.1344 (3.1344)	data time 2.6535 (2.6535)	model time 0.0000 (0.0000)	loss 0.4710 (0.4710)	grad_norm 1.3282 (1.3282)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:02 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][10/156]	eta 0:02:03 lr 0.000078	 wd 0.0500	time 0.5607 (0.8482)	data time 0.0073 (0.3546)	model time 0.0000 (0.0000)	loss 0.6233 (0.5839)	grad_norm 2.4378 (1.9239)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:07 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][20/156]	eta 0:01:32 lr 0.000077	 wd 0.0500	time 0.4826 (0.6813)	data time 0.0290 (0.1908)	model time 0.0000 (0.0000)	loss 0.6230 (0.5745)	grad_norm 1.4562 (2.0926)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:12 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][30/156]	eta 0:01:18 lr 0.000077	 wd 0.0500	time 0.6006 (0.6260)	data time 0.0214 (0.1316)	model time 0.0000 (0.0000)	loss 0.6169 (0.5791)	grad_norm 1.8272 (2.2915)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:17 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][40/156]	eta 0:01:09 lr 0.000077	 wd 0.0500	time 0.7354 (0.5982)	data time 0.0831 (0.1031)	model time 0.0000 (0.0000)	loss 0.5918 (0.5773)	grad_norm 2.6000 (2.2466)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:22 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][50/156]	eta 0:01:01 lr 0.000077	 wd 0.0500	time 0.4184 (0.5813)	data time 0.0030 (0.0855)	model time 0.0000 (0.0000)	loss 0.5746 (0.5722)	grad_norm 2.6386 (2.3152)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:27 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][60/156]	eta 0:00:54 lr 0.000077	 wd 0.0500	time 0.4632 (0.5716)	data time 0.0208 (0.0730)	model time 0.4425 (0.5128)	loss 0.5623 (0.5681)	grad_norm 1.6590 (2.3497)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:32 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][70/156]	eta 0:00:47 lr 0.000077	 wd 0.0500	time 0.4306 (0.5574)	data time 0.0218 (0.0647)	model time 0.4088 (0.4849)	loss 0.4961 (0.5694)	grad_norm 4.7188 (2.4077)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:37 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][80/156]	eta 0:00:42 lr 0.000077	 wd 0.0500	time 0.7569 (0.5556)	data time 0.1247 (0.0591)	model time 0.6322 (0.4977)	loss 0.5761 (0.5753)	grad_norm 1.5588 (2.4006)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:42 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][90/156]	eta 0:00:36 lr 0.000077	 wd 0.0500	time 0.4371 (0.5483)	data time 0.0112 (0.0543)	model time 0.4259 (0.4918)	loss 0.6213 (0.5737)	grad_norm 1.9896 (2.3920)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:48 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][100/156]	eta 0:00:30 lr 0.000077	 wd 0.0500	time 0.4488 (0.5455)	data time 0.0076 (0.0510)	model time 0.4413 (0.4934)	loss 0.6419 (0.5732)	grad_norm 1.8717 (2.4356)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:53 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][110/156]	eta 0:00:25 lr 0.000077	 wd 0.0500	time 0.4260 (0.5438)	data time 0.0179 (0.0489)	model time 0.4082 (0.4941)	loss 0.6107 (0.5732)	grad_norm 2.2295 (2.5102)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:51:58 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][120/156]	eta 0:00:19 lr 0.000077	 wd 0.0500	time 0.5270 (0.5414)	data time 0.0027 (0.0461)	model time 0.5244 (0.4950)	loss 0.5179 (0.5733)	grad_norm 1.6980 (2.4792)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:52:03 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][130/156]	eta 0:00:14 lr 0.000077	 wd 0.0500	time 0.5503 (0.5397)	data time 0.0366 (0.0441)	model time 0.5136 (0.4954)	loss 0.6528 (0.5744)	grad_norm 3.1804 (2.4516)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:52:08 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][140/156]	eta 0:00:08 lr 0.000077	 wd 0.0500	time 0.4760 (0.5380)	data time 0.0011 (0.0417)	model time 0.4749 (0.4966)	loss 0.6322 (0.5751)	grad_norm 3.1470 (2.4280)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:52:14 vssm1_tiny_0230s](training.py 201): INFO Train: [139/300][150/156]	eta 0:00:03 lr 0.000077	 wd 0.0500	time 0.4205 (0.5371)	data time 0.0005 (0.0413)	model time 0.4201 (0.4958)	loss 0.5206 (0.5750)	grad_norm 2.6312 (2.3944)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:52:16 vssm1_tiny_0230s](training.py 212): INFO EPOCH 139 training takes 0:01:23
[2024-11-09 14:52:16 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_139.pth saving......
[2024-11-09 14:52:17 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_139.pth saved !!!
[2024-11-09 14:52:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.596 (1.596)	Loss 0.2769 (0.2769)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:52:21 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.434 (0.439)	Loss 0.2849 (0.2867)	Acc@1 92.188 (89.986)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:52:25 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.153 (0.395)	Loss 0.1840 (0.2948)	Acc@1 97.656 (89.658)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:52:27 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.340)	Loss 0.2274 (0.2679)	Acc@1 94.531 (91.885)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:52:30 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.840 Acc@5 100.000
[2024-11-09 14:52:30 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.8%
[2024-11-09 14:52:30 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.38%
[2024-11-09 14:52:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.344 (4.344)	Loss 0.3035 (0.3035)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:52:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.145 (0.666)	Loss 0.3101 (0.3110)	Acc@1 96.875 (97.301)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:52:39 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.151 (0.446)	Loss 0.6138 (0.3395)	Acc@1 60.938 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:52:42 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.407)	Loss 0.7041 (0.4487)	Acc@1 55.469 (81.200)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:52:46 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 75.660 Acc@5 100.000
[2024-11-09 14:52:46 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 75.7%
[2024-11-09 14:52:46 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 75.66%
[2024-11-09 14:52:49 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][0/156]	eta 0:09:46 lr 0.000077	 wd 0.0500	time 3.7600 (3.7600)	data time 3.3227 (3.3227)	model time 0.0000 (0.0000)	loss 0.6479 (0.6479)	grad_norm 2.6375 (2.6375)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:52:55 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][10/156]	eta 0:02:03 lr 0.000077	 wd 0.0500	time 0.5708 (0.8483)	data time 0.0077 (0.3359)	model time 0.0000 (0.0000)	loss 0.6003 (0.5686)	grad_norm 2.2860 (2.5576)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:00 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][20/156]	eta 0:01:35 lr 0.000077	 wd 0.0500	time 0.6959 (0.7035)	data time 0.0040 (0.1834)	model time 0.0000 (0.0000)	loss 0.5014 (0.5609)	grad_norm 3.2135 (2.7880)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:06 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][30/156]	eta 0:01:21 lr 0.000077	 wd 0.0500	time 0.6957 (0.6501)	data time 0.0880 (0.1347)	model time 0.0000 (0.0000)	loss 0.6307 (0.5716)	grad_norm 2.2690 (2.6717)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:11 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][40/156]	eta 0:01:10 lr 0.000077	 wd 0.0500	time 0.4760 (0.6067)	data time 0.0243 (0.1070)	model time 0.0000 (0.0000)	loss 0.5355 (0.5745)	grad_norm 1.2736 (2.6202)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:16 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][50/156]	eta 0:01:02 lr 0.000077	 wd 0.0500	time 0.5038 (0.5921)	data time 0.0219 (0.0898)	model time 0.0000 (0.0000)	loss 0.6501 (0.5710)	grad_norm 2.7058 (2.5280)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:21 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][60/156]	eta 0:00:55 lr 0.000077	 wd 0.0500	time 0.4748 (0.5769)	data time 0.0033 (0.0778)	model time 0.4715 (0.4824)	loss 0.6098 (0.5741)	grad_norm 1.2158 (2.4438)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:26 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][70/156]	eta 0:00:49 lr 0.000077	 wd 0.0500	time 0.4814 (0.5748)	data time 0.0156 (0.0690)	model time 0.4659 (0.5146)	loss 0.5165 (0.5699)	grad_norm 1.5854 (2.4519)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:31 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][80/156]	eta 0:00:42 lr 0.000077	 wd 0.0500	time 0.4277 (0.5621)	data time 0.0160 (0.0625)	model time 0.4117 (0.4952)	loss 0.4779 (0.5710)	grad_norm 1.6841 (2.4004)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:36 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][90/156]	eta 0:00:36 lr 0.000077	 wd 0.0500	time 0.5483 (0.5579)	data time 0.0721 (0.0577)	model time 0.4762 (0.4976)	loss 0.5403 (0.5728)	grad_norm 2.6071 (2.3776)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:42 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][100/156]	eta 0:00:31 lr 0.000076	 wd 0.0500	time 0.5988 (0.5563)	data time 0.1549 (0.0548)	model time 0.4438 (0.5006)	loss 0.5795 (0.5720)	grad_norm 1.6389 (2.3568)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:47 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][110/156]	eta 0:00:25 lr 0.000076	 wd 0.0500	time 0.5617 (0.5543)	data time 0.0157 (0.0520)	model time 0.5459 (0.5024)	loss 0.5744 (0.5697)	grad_norm 1.5960 (2.3269)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:52 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][120/156]	eta 0:00:19 lr 0.000076	 wd 0.0500	time 0.4711 (0.5502)	data time 0.0031 (0.0492)	model time 0.4680 (0.5000)	loss 0.6427 (0.5704)	grad_norm 1.8099 (2.3386)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:53:57 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][130/156]	eta 0:00:14 lr 0.000076	 wd 0.0500	time 0.6306 (0.5461)	data time 0.0029 (0.0468)	model time 0.6277 (0.4973)	loss 0.5343 (0.5701)	grad_norm 2.5603 (2.3639)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:54:02 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][140/156]	eta 0:00:08 lr 0.000076	 wd 0.0500	time 0.4131 (0.5419)	data time 0.0009 (0.0449)	model time 0.4121 (0.4939)	loss 0.4715 (0.5719)	grad_norm 2.3374 (2.3714)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:54:07 vssm1_tiny_0230s](training.py 201): INFO Train: [140/300][150/156]	eta 0:00:03 lr 0.000076	 wd 0.0500	time 0.5621 (0.5392)	data time 0.0007 (0.0421)	model time 0.5614 (0.4944)	loss 0.4969 (0.5732)	grad_norm 2.3385 (2.3585)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:54:10 vssm1_tiny_0230s](training.py 212): INFO EPOCH 140 training takes 0:01:24
[2024-11-09 14:54:10 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_140.pth saving......
[2024-11-09 14:54:10 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_140.pth saved !!!
[2024-11-09 14:54:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 5.098 (5.098)	Loss 0.2424 (0.2424)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:54:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.153 (0.619)	Loss 0.2527 (0.2495)	Acc@1 95.312 (94.815)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:54:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.509)	Loss 0.2585 (0.2622)	Acc@1 95.312 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:54:23 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.399)	Loss 0.3015 (0.2709)	Acc@1 91.406 (93.448)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:54:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.400 Acc@5 100.000
[2024-11-09 14:54:25 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.4%
[2024-11-09 14:54:25 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.40%
[2024-11-09 14:54:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.229 (3.229)	Loss 0.3035 (0.3035)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:54:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.510)	Loss 0.3101 (0.3110)	Acc@1 96.875 (97.159)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:54:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.429)	Loss 0.6069 (0.3391)	Acc@1 64.844 (93.527)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:54:37 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.160 (0.364)	Loss 0.6968 (0.4462)	Acc@1 55.469 (81.502)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:54:39 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 76.100 Acc@5 100.000
[2024-11-09 14:54:39 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 76.1%
[2024-11-09 14:54:39 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 76.10%
[2024-11-09 14:54:44 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][0/156]	eta 0:11:13 lr 0.000076	 wd 0.0500	time 4.3146 (4.3146)	data time 3.7542 (3.7542)	model time 0.0000 (0.0000)	loss 0.5860 (0.5860)	grad_norm 1.7757 (1.7757)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:54:49 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][10/156]	eta 0:02:05 lr 0.000076	 wd 0.0500	time 0.4845 (0.8613)	data time 0.0008 (0.3781)	model time 0.0000 (0.0000)	loss 0.6407 (0.5898)	grad_norm 2.2347 (2.1917)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:54:54 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][20/156]	eta 0:01:34 lr 0.000076	 wd 0.0500	time 0.4802 (0.6953)	data time 0.0079 (0.2093)	model time 0.0000 (0.0000)	loss 0.5994 (0.5804)	grad_norm 3.1784 (2.5001)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:54:59 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][30/156]	eta 0:01:21 lr 0.000076	 wd 0.0500	time 0.5831 (0.6438)	data time 0.0356 (0.1490)	model time 0.0000 (0.0000)	loss 0.6187 (0.5666)	grad_norm 2.1950 (2.4493)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:04 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][40/156]	eta 0:01:10 lr 0.000076	 wd 0.0500	time 0.4872 (0.6056)	data time 0.0238 (0.1164)	model time 0.0000 (0.0000)	loss 0.4859 (0.5557)	grad_norm 2.8414 (2.4982)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:10 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][50/156]	eta 0:01:02 lr 0.000076	 wd 0.0500	time 0.6016 (0.5899)	data time 0.0409 (0.0977)	model time 0.0000 (0.0000)	loss 0.4609 (0.5597)	grad_norm 2.9951 (2.5520)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:15 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][60/156]	eta 0:00:55 lr 0.000076	 wd 0.0500	time 0.5129 (0.5780)	data time 0.0267 (0.0847)	model time 0.4862 (0.4991)	loss 0.6644 (0.5629)	grad_norm 2.3891 (2.5609)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:20 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][70/156]	eta 0:00:48 lr 0.000076	 wd 0.0500	time 0.4569 (0.5676)	data time 0.0177 (0.0744)	model time 0.4392 (0.4959)	loss 0.5905 (0.5674)	grad_norm 1.5643 (2.5259)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:25 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][80/156]	eta 0:00:42 lr 0.000076	 wd 0.0500	time 0.5809 (0.5604)	data time 0.0110 (0.0671)	model time 0.5698 (0.4955)	loss 0.5223 (0.5697)	grad_norm 2.1939 (2.4939)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:30 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][90/156]	eta 0:00:36 lr 0.000076	 wd 0.0500	time 0.5577 (0.5520)	data time 0.0061 (0.0609)	model time 0.5516 (0.4898)	loss 0.4840 (0.5686)	grad_norm 3.1338 (2.5240)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:35 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][100/156]	eta 0:00:30 lr 0.000076	 wd 0.0500	time 0.5311 (0.5476)	data time 0.0349 (0.0558)	model time 0.4961 (0.4913)	loss 0.6036 (0.5662)	grad_norm 1.4550 (2.4894)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:40 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][110/156]	eta 0:00:24 lr 0.000076	 wd 0.0500	time 0.4480 (0.5424)	data time 0.0250 (0.0522)	model time 0.4231 (0.4885)	loss 0.6723 (0.5679)	grad_norm 3.0210 (2.5143)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:45 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][120/156]	eta 0:00:19 lr 0.000076	 wd 0.0500	time 0.6256 (0.5402)	data time 0.0174 (0.0497)	model time 0.6082 (0.4893)	loss 0.5737 (0.5680)	grad_norm 3.2342 (2.5491)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:50 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][130/156]	eta 0:00:14 lr 0.000076	 wd 0.0500	time 0.5167 (0.5395)	data time 0.0006 (0.0467)	model time 0.5160 (0.4932)	loss 0.5695 (0.5686)	grad_norm 2.9900 (2.6130)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:55:55 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][140/156]	eta 0:00:08 lr 0.000076	 wd 0.0500	time 0.5038 (0.5391)	data time 0.0009 (0.0444)	model time 0.5028 (0.4961)	loss 0.5649 (0.5707)	grad_norm 2.6006 (2.6060)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:56:00 vssm1_tiny_0230s](training.py 201): INFO Train: [141/300][150/156]	eta 0:00:03 lr 0.000076	 wd 0.0500	time 0.5361 (0.5358)	data time 0.0005 (0.0415)	model time 0.5356 (0.4953)	loss 0.6505 (0.5700)	grad_norm 1.2940 (2.6134)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:56:03 vssm1_tiny_0230s](training.py 212): INFO EPOCH 141 training takes 0:01:23
[2024-11-09 14:56:03 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_141.pth saving......
[2024-11-09 14:56:04 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_141.pth saved !!!
[2024-11-09 14:56:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.093 (4.093)	Loss 0.1909 (0.1909)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:56:11 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.635)	Loss 0.2026 (0.2001)	Acc@1 96.875 (97.017)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:56:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.432)	Loss 0.2710 (0.2181)	Acc@1 91.406 (95.573)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:56:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.180 (0.356)	Loss 0.3379 (0.2543)	Acc@1 89.062 (93.246)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:56:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.400 Acc@5 100.000
[2024-11-09 14:56:18 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.4%
[2024-11-09 14:56:18 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.40%
[2024-11-09 14:56:22 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.379 (4.379)	Loss 0.3030 (0.3030)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:56:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.593)	Loss 0.3096 (0.3107)	Acc@1 96.875 (97.159)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:56:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.424)	Loss 0.6001 (0.3384)	Acc@1 64.844 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:56:29 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.357)	Loss 0.6890 (0.4436)	Acc@1 56.250 (81.603)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:56:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 76.240 Acc@5 100.000
[2024-11-09 14:56:31 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 76.2%
[2024-11-09 14:56:31 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 76.24%
[2024-11-09 14:56:36 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][0/156]	eta 0:13:08 lr 0.000076	 wd 0.0500	time 5.0542 (5.0542)	data time 4.5209 (4.5209)	model time 0.0000 (0.0000)	loss 0.4751 (0.4751)	grad_norm 2.0729 (2.0729)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:56:41 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][10/156]	eta 0:02:20 lr 0.000075	 wd 0.0500	time 0.5126 (0.9599)	data time 0.0263 (0.4587)	model time 0.0000 (0.0000)	loss 0.5667 (0.5530)	grad_norm 1.6955 (2.2817)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:56:47 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][20/156]	eta 0:01:42 lr 0.000075	 wd 0.0500	time 0.5251 (0.7571)	data time 0.0155 (0.2516)	model time 0.0000 (0.0000)	loss 0.6649 (0.5679)	grad_norm 2.5144 (2.4016)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:56:52 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][30/156]	eta 0:01:26 lr 0.000075	 wd 0.0500	time 0.5702 (0.6841)	data time 0.0031 (0.1760)	model time 0.0000 (0.0000)	loss 0.5525 (0.5715)	grad_norm 1.8561 (2.4976)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:56:57 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][40/156]	eta 0:01:14 lr 0.000075	 wd 0.0500	time 0.5847 (0.6444)	data time 0.0006 (0.1376)	model time 0.0000 (0.0000)	loss 0.5251 (0.5665)	grad_norm 3.1484 (2.4230)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:02 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][50/156]	eta 0:01:05 lr 0.000075	 wd 0.0500	time 0.4719 (0.6179)	data time 0.0122 (0.1175)	model time 0.0000 (0.0000)	loss 0.6832 (0.5686)	grad_norm 2.6894 (2.5054)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:07 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][60/156]	eta 0:00:57 lr 0.000075	 wd 0.0500	time 0.4686 (0.6002)	data time 0.0021 (0.1001)	model time 0.4665 (0.4993)	loss 0.5938 (0.5688)	grad_norm 2.8467 (2.5469)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:12 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][70/156]	eta 0:00:50 lr 0.000075	 wd 0.0500	time 0.4844 (0.5845)	data time 0.0160 (0.0885)	model time 0.4684 (0.4851)	loss 0.5885 (0.5688)	grad_norm 2.6820 (2.5366)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:18 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][80/156]	eta 0:00:43 lr 0.000075	 wd 0.0500	time 0.7057 (0.5781)	data time 0.0791 (0.0806)	model time 0.6265 (0.4925)	loss 0.5909 (0.5679)	grad_norm 2.2292 (2.5976)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:22 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][90/156]	eta 0:00:37 lr 0.000075	 wd 0.0500	time 0.4395 (0.5666)	data time 0.0023 (0.0731)	model time 0.4372 (0.4849)	loss 0.4996 (0.5652)	grad_norm 1.9450 (2.6607)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:27 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][100/156]	eta 0:00:31 lr 0.000075	 wd 0.0500	time 0.5075 (0.5569)	data time 0.0157 (0.0674)	model time 0.4918 (0.4785)	loss 0.5962 (0.5664)	grad_norm 2.5359 (2.6677)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:32 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][110/156]	eta 0:00:25 lr 0.000075	 wd 0.0500	time 0.5814 (0.5540)	data time 0.0027 (0.0626)	model time 0.5786 (0.4839)	loss 0.6537 (0.5707)	grad_norm 1.5578 (2.6583)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:38 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][120/156]	eta 0:00:19 lr 0.000075	 wd 0.0500	time 0.5195 (0.5521)	data time 0.0314 (0.0589)	model time 0.4881 (0.4881)	loss 0.6057 (0.5733)	grad_norm 1.8552 (2.6075)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:43 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][130/156]	eta 0:00:14 lr 0.000075	 wd 0.0500	time 0.5189 (0.5501)	data time 0.0134 (0.0564)	model time 0.5056 (0.4895)	loss 0.5846 (0.5755)	grad_norm 1.7693 (2.5520)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:48 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][140/156]	eta 0:00:08 lr 0.000075	 wd 0.0500	time 0.4855 (0.5486)	data time 0.0009 (0.0539)	model time 0.4846 (0.4916)	loss 0.5821 (0.5734)	grad_norm 3.1409 (2.5469)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:53 vssm1_tiny_0230s](training.py 201): INFO Train: [142/300][150/156]	eta 0:00:03 lr 0.000075	 wd 0.0500	time 0.4289 (0.5434)	data time 0.0005 (0.0503)	model time 0.4284 (0.4893)	loss 0.6696 (0.5731)	grad_norm 1.8990 (2.5680)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:57:56 vssm1_tiny_0230s](training.py 212): INFO EPOCH 142 training takes 0:01:24
[2024-11-09 14:57:56 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_142.pth saving......
[2024-11-09 14:57:56 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_142.pth saved !!!
[2024-11-09 14:58:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.745 (3.745)	Loss 0.2063 (0.2063)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:58:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.251 (0.593)	Loss 0.2151 (0.2177)	Acc@1 93.750 (94.176)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:58:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.163 (0.441)	Loss 0.2239 (0.2325)	Acc@1 96.094 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:58:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.386)	Loss 0.2778 (0.2435)	Acc@1 93.750 (93.271)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:58:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.480 Acc@5 100.000
[2024-11-09 14:58:10 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.5%
[2024-11-09 14:58:10 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.48%
[2024-11-09 14:58:14 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.579 (3.579)	Loss 0.3025 (0.3025)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:58:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.618)	Loss 0.3091 (0.3102)	Acc@1 96.875 (97.159)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:58:19 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.433)	Loss 0.5938 (0.3376)	Acc@1 66.406 (93.564)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:58:21 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.350)	Loss 0.6821 (0.4410)	Acc@1 57.812 (81.956)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:58:23 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 76.740 Acc@5 100.000
[2024-11-09 14:58:23 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 76.7%
[2024-11-09 14:58:23 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 76.74%
[2024-11-09 14:58:28 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][0/156]	eta 0:12:40 lr 0.000075	 wd 0.0500	time 4.8740 (4.8740)	data time 4.2404 (4.2404)	model time 0.0000 (0.0000)	loss 0.5071 (0.5071)	grad_norm 1.6851 (1.6851)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:58:34 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][10/156]	eta 0:02:14 lr 0.000075	 wd 0.0500	time 0.4405 (0.9210)	data time 0.0006 (0.4097)	model time 0.0000 (0.0000)	loss 0.6044 (0.5800)	grad_norm 2.1566 (2.4647)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:58:39 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][20/156]	eta 0:01:38 lr 0.000075	 wd 0.0500	time 0.4125 (0.7209)	data time 0.0046 (0.2188)	model time 0.0000 (0.0000)	loss 0.6195 (0.5801)	grad_norm 1.4419 (2.2604)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:58:44 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][30/156]	eta 0:01:21 lr 0.000075	 wd 0.0500	time 0.5210 (0.6500)	data time 0.0129 (0.1552)	model time 0.0000 (0.0000)	loss 0.6235 (0.5860)	grad_norm 2.4174 (2.1713)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:58:49 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][40/156]	eta 0:01:10 lr 0.000075	 wd 0.0500	time 0.5068 (0.6114)	data time 0.0060 (0.1208)	model time 0.0000 (0.0000)	loss 0.5238 (0.5812)	grad_norm 2.7465 (2.1179)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:58:53 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][50/156]	eta 0:01:02 lr 0.000075	 wd 0.0500	time 0.4475 (0.5878)	data time 0.0383 (0.1005)	model time 0.0000 (0.0000)	loss 0.6048 (0.5795)	grad_norm 3.8170 (2.1758)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:58:58 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][60/156]	eta 0:00:54 lr 0.000075	 wd 0.0500	time 0.5407 (0.5714)	data time 0.0006 (0.0861)	model time 0.5401 (0.4753)	loss 0.4430 (0.5773)	grad_norm 2.8700 (2.2304)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:59:03 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][70/156]	eta 0:00:48 lr 0.000075	 wd 0.0500	time 0.4947 (0.5602)	data time 0.0252 (0.0765)	model time 0.4694 (0.4746)	loss 0.6351 (0.5758)	grad_norm 2.1480 (2.2175)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:59:08 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][80/156]	eta 0:00:41 lr 0.000075	 wd 0.0500	time 0.4686 (0.5518)	data time 0.0295 (0.0687)	model time 0.4391 (0.4760)	loss 0.6312 (0.5787)	grad_norm 1.9780 (2.1851)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:59:14 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][90/156]	eta 0:00:36 lr 0.000074	 wd 0.0500	time 0.9051 (0.5542)	data time 0.0008 (0.0630)	model time 0.9043 (0.4963)	loss 0.6129 (0.5784)	grad_norm 2.0250 (2.1843)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:59:19 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][100/156]	eta 0:00:30 lr 0.000074	 wd 0.0500	time 0.5322 (0.5496)	data time 0.0036 (0.0579)	model time 0.5286 (0.4961)	loss 0.5659 (0.5783)	grad_norm 1.9258 (2.1869)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:59:23 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][110/156]	eta 0:00:24 lr 0.000074	 wd 0.0500	time 0.4440 (0.5396)	data time 0.0006 (0.0540)	model time 0.4433 (0.4840)	loss 0.6324 (0.5802)	grad_norm 3.4616 (2.1977)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:59:28 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][120/156]	eta 0:00:19 lr 0.000074	 wd 0.0500	time 0.5161 (0.5363)	data time 0.0177 (0.0507)	model time 0.4984 (0.4844)	loss 0.5773 (0.5770)	grad_norm 1.7576 (2.1999)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:59:34 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][130/156]	eta 0:00:13 lr 0.000074	 wd 0.0500	time 0.5157 (0.5345)	data time 0.0024 (0.0483)	model time 0.5133 (0.4856)	loss 0.6195 (0.5786)	grad_norm 1.5200 (2.1789)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:59:38 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][140/156]	eta 0:00:08 lr 0.000074	 wd 0.0500	time 0.5803 (0.5317)	data time 0.0009 (0.0456)	model time 0.5793 (0.4854)	loss 0.5253 (0.5799)	grad_norm 3.1929 (2.1831)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:59:43 vssm1_tiny_0230s](training.py 201): INFO Train: [143/300][150/156]	eta 0:00:03 lr 0.000074	 wd 0.0500	time 0.5585 (0.5295)	data time 0.0006 (0.0430)	model time 0.5579 (0.4861)	loss 0.6102 (0.5803)	grad_norm 1.5312 (2.1910)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 14:59:47 vssm1_tiny_0230s](training.py 212): INFO EPOCH 143 training takes 0:01:23
[2024-11-09 14:59:47 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_143.pth saving......
[2024-11-09 14:59:47 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_143.pth saved !!!
[2024-11-09 14:59:50 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.189 (2.189)	Loss 0.2496 (0.2496)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:59:53 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.466)	Loss 0.2551 (0.2595)	Acc@1 96.875 (94.957)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:59:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.209 (0.356)	Loss 0.2382 (0.2707)	Acc@1 96.094 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:59:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.157 (0.313)	Loss 0.2854 (0.2736)	Acc@1 91.406 (93.095)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 14:59:59 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.320 Acc@5 100.000
[2024-11-09 14:59:59 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.3%
[2024-11-09 14:59:59 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.48%
[2024-11-09 15:00:02 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.537 (2.537)	Loss 0.3022 (0.3022)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:00:04 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.145 (0.446)	Loss 0.3088 (0.3101)	Acc@1 96.875 (96.804)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:00:06 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.323)	Loss 0.5869 (0.3371)	Acc@1 67.969 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:00:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.146 (0.282)	Loss 0.6743 (0.4385)	Acc@1 57.812 (82.157)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:00:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 76.980 Acc@5 100.000
[2024-11-09 15:00:10 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 77.0%
[2024-11-09 15:00:10 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 76.98%
[2024-11-09 15:00:15 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][0/156]	eta 0:12:54 lr 0.000074	 wd 0.0500	time 4.9620 (4.9620)	data time 4.5538 (4.5538)	model time 0.0000 (0.0000)	loss 0.4787 (0.4787)	grad_norm 2.4854 (2.4854)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:00:20 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][10/156]	eta 0:02:13 lr 0.000074	 wd 0.0500	time 0.4332 (0.9137)	data time 0.0006 (0.4327)	model time 0.0000 (0.0000)	loss 0.6445 (0.5545)	grad_norm 2.4868 (2.1874)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:00:25 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][20/156]	eta 0:01:37 lr 0.000074	 wd 0.0500	time 0.4778 (0.7206)	data time 0.0013 (0.2306)	model time 0.0000 (0.0000)	loss 0.5980 (0.5609)	grad_norm 2.5273 (2.3033)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:00:30 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][30/156]	eta 0:01:22 lr 0.000074	 wd 0.0500	time 0.5841 (0.6524)	data time 0.0201 (0.1593)	model time 0.0000 (0.0000)	loss 0.5594 (0.5613)	grad_norm 1.5637 (2.4846)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:00:36 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][40/156]	eta 0:01:13 lr 0.000074	 wd 0.0500	time 0.5721 (0.6355)	data time 0.0008 (0.1241)	model time 0.0000 (0.0000)	loss 0.6194 (0.5675)	grad_norm 2.2288 (2.6067)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:00:41 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][50/156]	eta 0:01:05 lr 0.000074	 wd 0.0500	time 0.7591 (0.6167)	data time 0.0009 (0.1059)	model time 0.0000 (0.0000)	loss 0.5864 (0.5770)	grad_norm 1.3683 (2.4987)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:00:47 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][60/156]	eta 0:00:57 lr 0.000074	 wd 0.0500	time 0.6051 (0.6025)	data time 0.0907 (0.0931)	model time 0.5144 (0.5018)	loss 0.6242 (0.5788)	grad_norm 1.9734 (2.4463)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:00:52 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][70/156]	eta 0:00:51 lr 0.000074	 wd 0.0500	time 0.6304 (0.5931)	data time 0.0050 (0.0814)	model time 0.6254 (0.5138)	loss 0.5057 (0.5786)	grad_norm 4.3892 (2.4096)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:00:57 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][80/156]	eta 0:00:43 lr 0.000074	 wd 0.0500	time 0.4360 (0.5780)	data time 0.0039 (0.0732)	model time 0.4321 (0.4944)	loss 0.4716 (0.5764)	grad_norm 2.6749 (2.4642)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:01:02 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][90/156]	eta 0:00:37 lr 0.000074	 wd 0.0500	time 0.5422 (0.5732)	data time 0.0098 (0.0662)	model time 0.5324 (0.5019)	loss 0.5765 (0.5775)	grad_norm 3.1042 (2.4594)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:01:07 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][100/156]	eta 0:00:31 lr 0.000074	 wd 0.0500	time 0.5652 (0.5679)	data time 0.0050 (0.0613)	model time 0.5602 (0.5022)	loss 0.6000 (0.5746)	grad_norm 1.5510 (2.4584)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:01:12 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][110/156]	eta 0:00:25 lr 0.000074	 wd 0.0500	time 0.5018 (0.5595)	data time 0.0394 (0.0570)	model time 0.4624 (0.4953)	loss 0.5756 (0.5752)	grad_norm 2.4164 (2.4624)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:01:17 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][120/156]	eta 0:00:19 lr 0.000074	 wd 0.0500	time 0.4134 (0.5512)	data time 0.0015 (0.0532)	model time 0.4119 (0.4887)	loss 0.6094 (0.5753)	grad_norm 2.1701 (2.4366)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:01:21 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][130/156]	eta 0:00:14 lr 0.000074	 wd 0.0500	time 0.4137 (0.5451)	data time 0.0010 (0.0504)	model time 0.4127 (0.4844)	loss 0.6237 (0.5707)	grad_norm 3.5736 (2.4592)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:01:27 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][140/156]	eta 0:00:08 lr 0.000074	 wd 0.0500	time 0.6013 (0.5439)	data time 0.0009 (0.0478)	model time 0.6004 (0.4877)	loss 0.4927 (0.5709)	grad_norm 2.8999 (2.4464)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:01:32 vssm1_tiny_0230s](training.py 201): INFO Train: [144/300][150/156]	eta 0:00:03 lr 0.000074	 wd 0.0500	time 0.4120 (0.5406)	data time 0.0004 (0.0450)	model time 0.4116 (0.4878)	loss 0.6151 (0.5713)	grad_norm 2.4249 (2.4593)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:01:35 vssm1_tiny_0230s](training.py 212): INFO EPOCH 144 training takes 0:01:24
[2024-11-09 15:01:35 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_144.pth saving......
[2024-11-09 15:01:35 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_144.pth saved !!!
[2024-11-09 15:01:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.613 (2.613)	Loss 0.2062 (0.2062)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:01:42 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.575)	Loss 0.2134 (0.2082)	Acc@1 95.312 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:01:44 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.563 (0.399)	Loss 0.2208 (0.2229)	Acc@1 96.094 (94.717)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:01:47 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.265 (0.370)	Loss 0.2900 (0.2386)	Acc@1 92.188 (93.876)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:01:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.640 Acc@5 100.000
[2024-11-09 15:01:49 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.6%
[2024-11-09 15:01:49 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.64%
[2024-11-09 15:01:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.079 (4.079)	Loss 0.3022 (0.3022)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:01:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.202 (0.589)	Loss 0.3088 (0.3102)	Acc@1 96.875 (96.804)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:01:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.157 (0.442)	Loss 0.5801 (0.3368)	Acc@1 69.531 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:02:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.381)	Loss 0.6665 (0.4360)	Acc@1 58.594 (82.434)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:02:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 77.300 Acc@5 100.000
[2024-11-09 15:02:03 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 77.3%
[2024-11-09 15:02:03 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 77.30%
[2024-11-09 15:02:08 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][0/156]	eta 0:12:02 lr 0.000073	 wd 0.0500	time 4.6319 (4.6319)	data time 4.1899 (4.1899)	model time 0.0000 (0.0000)	loss 0.6489 (0.6489)	grad_norm 3.2802 (3.2802)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:02:13 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][10/156]	eta 0:02:12 lr 0.000073	 wd 0.0500	time 0.4924 (0.9051)	data time 0.0019 (0.3872)	model time 0.0000 (0.0000)	loss 0.5128 (0.5859)	grad_norm 2.9082 (2.4597)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:02:18 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][20/156]	eta 0:01:39 lr 0.000073	 wd 0.0500	time 0.6792 (0.7350)	data time 0.0268 (0.2056)	model time 0.0000 (0.0000)	loss 0.5669 (0.5959)	grad_norm 2.4936 (2.2631)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:02:24 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][30/156]	eta 0:01:23 lr 0.000073	 wd 0.0500	time 0.4389 (0.6650)	data time 0.0007 (0.1525)	model time 0.0000 (0.0000)	loss 0.6473 (0.5831)	grad_norm 1.9337 (2.2108)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:02:29 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][40/156]	eta 0:01:13 lr 0.000073	 wd 0.0500	time 0.4214 (0.6326)	data time 0.0132 (0.1203)	model time 0.0000 (0.0000)	loss 0.6077 (0.5868)	grad_norm 1.2768 (2.2275)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:02:34 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][50/156]	eta 0:01:04 lr 0.000073	 wd 0.0500	time 0.5245 (0.6049)	data time 0.0111 (0.1001)	model time 0.0000 (0.0000)	loss 0.5187 (0.5837)	grad_norm 1.4936 (2.2001)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:02:39 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][60/156]	eta 0:00:56 lr 0.000073	 wd 0.0500	time 0.5479 (0.5867)	data time 0.0198 (0.0849)	model time 0.5281 (0.4864)	loss 0.5494 (0.5807)	grad_norm 3.2931 (2.3271)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:02:44 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][70/156]	eta 0:00:49 lr 0.000073	 wd 0.0500	time 0.6096 (0.5792)	data time 0.0036 (0.0743)	model time 0.6060 (0.5049)	loss 0.4885 (0.5710)	grad_norm 5.0141 (2.4901)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:02:49 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][80/156]	eta 0:00:43 lr 0.000073	 wd 0.0500	time 0.4596 (0.5676)	data time 0.0119 (0.0674)	model time 0.4477 (0.4923)	loss 0.6101 (0.5701)	grad_norm 1.9406 (2.4581)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:02:54 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][90/156]	eta 0:00:36 lr 0.000073	 wd 0.0500	time 0.4828 (0.5601)	data time 0.0556 (0.0617)	model time 0.4272 (0.4902)	loss 0.6321 (0.5702)	grad_norm 2.0868 (2.4630)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:02:59 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][100/156]	eta 0:00:30 lr 0.000073	 wd 0.0500	time 0.4821 (0.5536)	data time 0.0177 (0.0583)	model time 0.4644 (0.4855)	loss 0.5792 (0.5705)	grad_norm 2.3378 (2.4590)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:03:04 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][110/156]	eta 0:00:25 lr 0.000073	 wd 0.0500	time 0.5316 (0.5472)	data time 0.0067 (0.0547)	model time 0.5250 (0.4820)	loss 0.7011 (0.5710)	grad_norm 4.1992 (2.4441)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:03:09 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][120/156]	eta 0:00:19 lr 0.000073	 wd 0.0500	time 0.4634 (0.5434)	data time 0.0029 (0.0532)	model time 0.4605 (0.4796)	loss 0.4732 (0.5712)	grad_norm 2.2460 (2.4255)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:03:14 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][130/156]	eta 0:00:14 lr 0.000073	 wd 0.0500	time 0.4525 (0.5390)	data time 0.0062 (0.0503)	model time 0.4463 (0.4785)	loss 0.5884 (0.5718)	grad_norm 2.5517 (2.4083)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:03:19 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][140/156]	eta 0:00:08 lr 0.000073	 wd 0.0500	time 0.4325 (0.5371)	data time 0.0009 (0.0477)	model time 0.4316 (0.4807)	loss 0.6561 (0.5722)	grad_norm 2.8568 (2.3957)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:03:23 vssm1_tiny_0230s](training.py 201): INFO Train: [145/300][150/156]	eta 0:00:03 lr 0.000073	 wd 0.0500	time 0.4234 (0.5322)	data time 0.0006 (0.0446)	model time 0.4228 (0.4789)	loss 0.4825 (0.5710)	grad_norm 3.8960 (2.3948)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:03:26 vssm1_tiny_0230s](training.py 212): INFO EPOCH 145 training takes 0:01:23
[2024-11-09 15:03:26 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_145.pth saving......
[2024-11-09 15:03:27 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_145.pth saved !!!
[2024-11-09 15:03:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.004 (4.004)	Loss 0.2203 (0.2203)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:03:33 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.186 (0.542)	Loss 0.2302 (0.2317)	Acc@1 95.312 (94.673)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:03:35 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.405)	Loss 0.2003 (0.2443)	Acc@1 96.094 (93.862)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:03:37 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.167 (0.334)	Loss 0.2563 (0.2441)	Acc@1 93.750 (93.649)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:03:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.680 Acc@5 100.000
[2024-11-09 15:03:40 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.7%
[2024-11-09 15:03:40 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.68%
[2024-11-09 15:03:43 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.914 (2.914)	Loss 0.3013 (0.3013)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:03:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.184 (0.514)	Loss 0.3081 (0.3095)	Acc@1 96.875 (96.733)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:03:49 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 1.394 (0.445)	Loss 0.5737 (0.3358)	Acc@1 69.531 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:03:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.359)	Loss 0.6597 (0.4333)	Acc@1 58.594 (82.586)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:03:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 77.680 Acc@5 100.000
[2024-11-09 15:03:53 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 77.7%
[2024-11-09 15:03:53 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 77.68%
[2024-11-09 15:03:58 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][0/156]	eta 0:11:49 lr 0.000073	 wd 0.0500	time 4.5506 (4.5506)	data time 4.0878 (4.0878)	model time 0.0000 (0.0000)	loss 0.6585 (0.6585)	grad_norm 2.5003 (2.5003)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:03 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][10/156]	eta 0:02:07 lr 0.000073	 wd 0.0500	time 0.6245 (0.8754)	data time 0.0220 (0.3802)	model time 0.0000 (0.0000)	loss 0.5976 (0.6010)	grad_norm 2.3909 (2.1667)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:08 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][20/156]	eta 0:01:36 lr 0.000073	 wd 0.0500	time 0.5757 (0.7068)	data time 0.0052 (0.2140)	model time 0.0000 (0.0000)	loss 0.5093 (0.5800)	grad_norm 2.2188 (2.3473)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:13 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][30/156]	eta 0:01:22 lr 0.000073	 wd 0.0500	time 0.5025 (0.6548)	data time 0.0161 (0.1522)	model time 0.0000 (0.0000)	loss 0.6019 (0.5878)	grad_norm 1.5425 (2.2655)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:19 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][40/156]	eta 0:01:12 lr 0.000073	 wd 0.0500	time 0.6199 (0.6262)	data time 0.0070 (0.1215)	model time 0.0000 (0.0000)	loss 0.6072 (0.5854)	grad_norm 2.0778 (2.2250)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:24 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][50/156]	eta 0:01:04 lr 0.000073	 wd 0.0500	time 0.5639 (0.6097)	data time 0.0363 (0.1015)	model time 0.0000 (0.0000)	loss 0.5538 (0.5772)	grad_norm 1.6804 (2.1748)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:29 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][60/156]	eta 0:00:56 lr 0.000073	 wd 0.0500	time 0.4710 (0.5915)	data time 0.0163 (0.0879)	model time 0.4547 (0.4801)	loss 0.5463 (0.5758)	grad_norm 2.2051 (2.2441)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:34 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][70/156]	eta 0:00:49 lr 0.000072	 wd 0.0500	time 0.4087 (0.5795)	data time 0.0010 (0.0771)	model time 0.4077 (0.4876)	loss 0.5373 (0.5756)	grad_norm 1.8432 (2.3381)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:39 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][80/156]	eta 0:00:43 lr 0.000072	 wd 0.0500	time 0.4265 (0.5702)	data time 0.0006 (0.0686)	model time 0.4259 (0.4904)	loss 0.6493 (0.5771)	grad_norm 3.5465 (2.3644)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:45 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][90/156]	eta 0:00:37 lr 0.000072	 wd 0.0500	time 0.5410 (0.5669)	data time 0.0177 (0.0620)	model time 0.5233 (0.5007)	loss 0.6106 (0.5754)	grad_norm 1.3134 (2.3851)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:50 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][100/156]	eta 0:00:31 lr 0.000072	 wd 0.0500	time 0.4123 (0.5640)	data time 0.0042 (0.0568)	model time 0.4081 (0.5062)	loss 0.5084 (0.5718)	grad_norm 1.4228 (2.3889)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:04:55 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][110/156]	eta 0:00:25 lr 0.000072	 wd 0.0500	time 0.5536 (0.5611)	data time 0.0225 (0.0527)	model time 0.5311 (0.5085)	loss 0.6454 (0.5707)	grad_norm 2.4284 (2.4368)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:05:00 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][120/156]	eta 0:00:19 lr 0.000072	 wd 0.0500	time 0.5014 (0.5551)	data time 0.0065 (0.0495)	model time 0.4948 (0.5037)	loss 0.4611 (0.5714)	grad_norm 2.1355 (2.4350)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:05:05 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][130/156]	eta 0:00:14 lr 0.000072	 wd 0.0500	time 0.5279 (0.5497)	data time 0.0097 (0.0468)	model time 0.5182 (0.4995)	loss 0.5887 (0.5707)	grad_norm 3.8267 (2.4217)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:05:10 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][140/156]	eta 0:00:08 lr 0.000072	 wd 0.0500	time 0.5223 (0.5468)	data time 0.0010 (0.0452)	model time 0.5213 (0.4980)	loss 0.5342 (0.5707)	grad_norm 3.0777 (2.4100)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:05:16 vssm1_tiny_0230s](training.py 201): INFO Train: [146/300][150/156]	eta 0:00:03 lr 0.000072	 wd 0.0500	time 0.4151 (0.5461)	data time 0.0007 (0.0425)	model time 0.4144 (0.5013)	loss 0.5710 (0.5694)	grad_norm 2.9146 (2.3836)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:05:18 vssm1_tiny_0230s](training.py 212): INFO EPOCH 146 training takes 0:01:25
[2024-11-09 15:05:18 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_146.pth saving......
[2024-11-09 15:05:19 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_146.pth saved !!!
[2024-11-09 15:05:22 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.579 (2.579)	Loss 0.2598 (0.2598)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:05:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.476)	Loss 0.2769 (0.2758)	Acc@1 92.188 (91.974)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:05:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.345)	Loss 0.1656 (0.2831)	Acc@1 97.656 (91.071)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:05:29 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.169 (0.336)	Loss 0.2054 (0.2529)	Acc@1 94.531 (92.818)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:05:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.460 Acc@5 100.000
[2024-11-09 15:05:32 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.5%
[2024-11-09 15:05:32 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.68%
[2024-11-09 15:05:35 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.760 (2.760)	Loss 0.3003 (0.3003)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:05:38 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.156 (0.532)	Loss 0.3069 (0.3085)	Acc@1 96.875 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:05:41 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.217 (0.414)	Loss 0.5684 (0.3346)	Acc@1 69.531 (93.341)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:05:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.367)	Loss 0.6533 (0.4307)	Acc@1 59.375 (82.812)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:05:46 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 78.020 Acc@5 100.000
[2024-11-09 15:05:46 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 78.0%
[2024-11-09 15:05:46 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 78.02%
[2024-11-09 15:05:51 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][0/156]	eta 0:11:25 lr 0.000072	 wd 0.0500	time 4.3952 (4.3952)	data time 3.9252 (3.9252)	model time 0.0000 (0.0000)	loss 0.6295 (0.6295)	grad_norm 2.0058 (2.0058)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:05:58 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][10/156]	eta 0:02:37 lr 0.000072	 wd 0.0500	time 0.4698 (1.0774)	data time 0.0012 (0.4758)	model time 0.0000 (0.0000)	loss 0.5905 (0.5708)	grad_norm 1.3811 (2.7569)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:03 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][20/156]	eta 0:01:48 lr 0.000072	 wd 0.0500	time 0.4210 (0.7973)	data time 0.0008 (0.2589)	model time 0.0000 (0.0000)	loss 0.6488 (0.5778)	grad_norm 1.5569 (2.3320)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:08 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][30/156]	eta 0:01:27 lr 0.000072	 wd 0.0500	time 0.4773 (0.6928)	data time 0.0168 (0.1799)	model time 0.0000 (0.0000)	loss 0.5375 (0.5780)	grad_norm 2.7537 (2.3247)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:13 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][40/156]	eta 0:01:14 lr 0.000072	 wd 0.0500	time 0.4835 (0.6405)	data time 0.0240 (0.1419)	model time 0.0000 (0.0000)	loss 0.5757 (0.5714)	grad_norm 1.7745 (2.3625)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:18 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][50/156]	eta 0:01:05 lr 0.000072	 wd 0.0500	time 0.4971 (0.6200)	data time 0.0276 (0.1175)	model time 0.0000 (0.0000)	loss 0.5085 (0.5688)	grad_norm 3.2008 (2.3880)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:23 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][60/156]	eta 0:00:58 lr 0.000072	 wd 0.0500	time 0.4902 (0.6073)	data time 0.0042 (0.1025)	model time 0.4860 (0.5169)	loss 0.5982 (0.5661)	grad_norm 2.7062 (2.4342)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:29 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][70/156]	eta 0:00:51 lr 0.000072	 wd 0.0500	time 0.5542 (0.5969)	data time 0.0078 (0.0911)	model time 0.5465 (0.5144)	loss 0.6048 (0.5663)	grad_norm 2.4496 (2.4694)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:34 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][80/156]	eta 0:00:44 lr 0.000072	 wd 0.0500	time 0.9473 (0.5909)	data time 0.2946 (0.0860)	model time 0.6527 (0.5091)	loss 0.5867 (0.5718)	grad_norm 2.6017 (2.4124)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:40 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][90/156]	eta 0:00:38 lr 0.000072	 wd 0.0500	time 0.4897 (0.5858)	data time 0.0175 (0.0789)	model time 0.4722 (0.5125)	loss 0.5285 (0.5714)	grad_norm 1.6037 (2.3552)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:45 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][100/156]	eta 0:00:32 lr 0.000072	 wd 0.0500	time 0.4752 (0.5773)	data time 0.0007 (0.0722)	model time 0.4745 (0.5078)	loss 0.6228 (0.5710)	grad_norm 1.5970 (2.3313)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:50 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][110/156]	eta 0:00:26 lr 0.000072	 wd 0.0500	time 0.5616 (0.5746)	data time 0.0007 (0.0664)	model time 0.5608 (0.5131)	loss 0.6192 (0.5701)	grad_norm 2.9995 (2.3368)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:06:55 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][120/156]	eta 0:00:20 lr 0.000072	 wd 0.0500	time 0.4265 (0.5675)	data time 0.0012 (0.0620)	model time 0.4252 (0.5078)	loss 0.6307 (0.5687)	grad_norm 2.9089 (2.3727)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:07:00 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][130/156]	eta 0:00:14 lr 0.000072	 wd 0.0500	time 0.4420 (0.5612)	data time 0.0336 (0.0585)	model time 0.4085 (0.5029)	loss 0.5435 (0.5662)	grad_norm 4.3992 (2.4457)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:07:05 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][140/156]	eta 0:00:08 lr 0.000072	 wd 0.0500	time 0.4183 (0.5584)	data time 0.0008 (0.0550)	model time 0.4176 (0.5040)	loss 0.4480 (0.5656)	grad_norm 2.9156 (2.4501)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:07:10 vssm1_tiny_0230s](training.py 201): INFO Train: [147/300][150/156]	eta 0:00:03 lr 0.000071	 wd 0.0500	time 0.6127 (0.5566)	data time 0.0006 (0.0515)	model time 0.6122 (0.5066)	loss 0.6690 (0.5670)	grad_norm 2.4185 (2.4367)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:07:13 vssm1_tiny_0230s](training.py 212): INFO EPOCH 147 training takes 0:01:26
[2024-11-09 15:07:13 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_147.pth saving......
[2024-11-09 15:07:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_147.pth saved !!!
[2024-11-09 15:07:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.769 (3.769)	Loss 0.2391 (0.2391)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:07:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.234 (0.589)	Loss 0.2432 (0.2497)	Acc@1 95.312 (95.028)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:07:23 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.786 (0.470)	Loss 0.2573 (0.2615)	Acc@1 94.531 (93.676)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:07:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.373)	Loss 0.3076 (0.2702)	Acc@1 92.188 (93.196)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:07:28 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.200 Acc@5 100.000
[2024-11-09 15:07:28 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.2%
[2024-11-09 15:07:28 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.68%
[2024-11-09 15:07:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.360 (3.360)	Loss 0.2991 (0.2991)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:07:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.564)	Loss 0.3057 (0.3074)	Acc@1 96.875 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:07:37 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.175 (0.423)	Loss 0.5625 (0.3333)	Acc@1 70.312 (93.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:07:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.381)	Loss 0.6465 (0.4279)	Acc@1 59.375 (82.888)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:07:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 78.240 Acc@5 100.000
[2024-11-09 15:07:42 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 78.2%
[2024-11-09 15:07:42 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 78.24%
[2024-11-09 15:07:47 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][0/156]	eta 0:12:12 lr 0.000071	 wd 0.0500	time 4.6926 (4.6926)	data time 4.0456 (4.0456)	model time 0.0000 (0.0000)	loss 0.5595 (0.5595)	grad_norm 1.9541 (1.9541)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:07:52 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][10/156]	eta 0:02:09 lr 0.000071	 wd 0.0500	time 0.4459 (0.8892)	data time 0.0132 (0.3861)	model time 0.0000 (0.0000)	loss 0.5987 (0.5745)	grad_norm 2.1240 (2.1798)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:07:57 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][20/156]	eta 0:01:37 lr 0.000071	 wd 0.0500	time 0.4570 (0.7156)	data time 0.0008 (0.2120)	model time 0.0000 (0.0000)	loss 0.5724 (0.5820)	grad_norm 1.5214 (2.1489)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:02 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][30/156]	eta 0:01:21 lr 0.000071	 wd 0.0500	time 0.4761 (0.6435)	data time 0.0030 (0.1506)	model time 0.0000 (0.0000)	loss 0.6018 (0.5654)	grad_norm 2.1453 (2.2467)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:07 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][40/156]	eta 0:01:10 lr 0.000071	 wd 0.0500	time 0.5523 (0.6093)	data time 0.0434 (0.1184)	model time 0.0000 (0.0000)	loss 0.5535 (0.5694)	grad_norm 3.3883 (2.3524)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:13 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][50/156]	eta 0:01:02 lr 0.000071	 wd 0.0500	time 0.4406 (0.5922)	data time 0.0100 (0.0989)	model time 0.0000 (0.0000)	loss 0.6513 (0.5687)	grad_norm 1.8729 (2.3507)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:18 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][60/156]	eta 0:00:56 lr 0.000071	 wd 0.0500	time 0.4343 (0.5862)	data time 0.0185 (0.0855)	model time 0.4158 (0.5381)	loss 0.6219 (0.5686)	grad_norm 1.9577 (2.3178)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:23 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][70/156]	eta 0:00:49 lr 0.000071	 wd 0.0500	time 0.5071 (0.5727)	data time 0.0205 (0.0763)	model time 0.4867 (0.5042)	loss 0.6105 (0.5720)	grad_norm 2.0265 (2.2622)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:28 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][80/156]	eta 0:00:43 lr 0.000071	 wd 0.0500	time 0.4327 (0.5684)	data time 0.0103 (0.0688)	model time 0.4224 (0.5102)	loss 0.4288 (0.5676)	grad_norm 2.6602 (2.2743)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:34 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][90/156]	eta 0:00:37 lr 0.000071	 wd 0.0500	time 0.5466 (0.5633)	data time 0.0010 (0.0624)	model time 0.5456 (0.5104)	loss 0.5882 (0.5674)	grad_norm 1.3329 (2.2799)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:39 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][100/156]	eta 0:00:31 lr 0.000071	 wd 0.0500	time 0.4838 (0.5588)	data time 0.0121 (0.0578)	model time 0.4717 (0.5088)	loss 0.6125 (0.5649)	grad_norm 2.2637 (2.2886)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:44 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][110/156]	eta 0:00:25 lr 0.000071	 wd 0.0500	time 0.5408 (0.5544)	data time 0.0197 (0.0540)	model time 0.5211 (0.5063)	loss 0.5902 (0.5664)	grad_norm 2.5286 (2.3137)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:49 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][120/156]	eta 0:00:19 lr 0.000071	 wd 0.0500	time 0.5134 (0.5492)	data time 0.0371 (0.0510)	model time 0.4763 (0.5018)	loss 0.6114 (0.5675)	grad_norm 2.0530 (2.3113)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:53 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][130/156]	eta 0:00:14 lr 0.000071	 wd 0.0500	time 0.5398 (0.5435)	data time 0.0207 (0.0478)	model time 0.5192 (0.4972)	loss 0.6089 (0.5676)	grad_norm 2.4667 (2.2937)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:08:59 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][140/156]	eta 0:00:08 lr 0.000071	 wd 0.0500	time 0.4439 (0.5444)	data time 0.0011 (0.0454)	model time 0.4428 (0.5023)	loss 0.6331 (0.5689)	grad_norm 2.1307 (2.2801)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:09:04 vssm1_tiny_0230s](training.py 201): INFO Train: [148/300][150/156]	eta 0:00:03 lr 0.000071	 wd 0.0500	time 0.4660 (0.5397)	data time 0.0006 (0.0426)	model time 0.4654 (0.4990)	loss 0.5659 (0.5698)	grad_norm 1.1305 (2.2841)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:09:07 vssm1_tiny_0230s](training.py 212): INFO EPOCH 148 training takes 0:01:24
[2024-11-09 15:09:07 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_148.pth saving......
[2024-11-09 15:09:07 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_148.pth saved !!!
[2024-11-09 15:09:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.755 (3.755)	Loss 0.2258 (0.2258)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:09:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.455 (0.590)	Loss 0.2399 (0.2358)	Acc@1 93.750 (94.460)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:09:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.131 (0.487)	Loss 0.2319 (0.2493)	Acc@1 95.312 (93.676)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:09:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.164 (0.397)	Loss 0.2866 (0.2575)	Acc@1 92.969 (93.473)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:09:22 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.400 Acc@5 100.000
[2024-11-09 15:09:22 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.4%
[2024-11-09 15:09:22 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.68%
[2024-11-09 15:09:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.006 (4.006)	Loss 0.2979 (0.2979)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:09:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.146 (0.538)	Loss 0.3044 (0.3064)	Acc@1 96.875 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:09:31 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.167 (0.436)	Loss 0.5571 (0.3320)	Acc@1 71.094 (93.341)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:09:33 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.362)	Loss 0.6401 (0.4253)	Acc@1 60.938 (83.392)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:09:36 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 78.820 Acc@5 100.000
[2024-11-09 15:09:36 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 78.8%
[2024-11-09 15:09:36 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 78.82%
[2024-11-09 15:09:40 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][0/156]	eta 0:10:31 lr 0.000071	 wd 0.0500	time 4.0491 (4.0491)	data time 3.5425 (3.5425)	model time 0.0000 (0.0000)	loss 0.5171 (0.5171)	grad_norm 1.9417 (1.9417)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:09:45 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][10/156]	eta 0:02:00 lr 0.000071	 wd 0.0500	time 0.5743 (0.8240)	data time 0.0007 (0.3398)	model time 0.0000 (0.0000)	loss 0.5773 (0.5541)	grad_norm 2.5332 (2.9776)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:09:50 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][20/156]	eta 0:01:29 lr 0.000071	 wd 0.0500	time 0.4923 (0.6612)	data time 0.0031 (0.1873)	model time 0.0000 (0.0000)	loss 0.6536 (0.5671)	grad_norm 2.8073 (2.6659)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:09:55 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][30/156]	eta 0:01:16 lr 0.000071	 wd 0.0500	time 0.5078 (0.6072)	data time 0.0285 (0.1316)	model time 0.0000 (0.0000)	loss 0.6080 (0.5673)	grad_norm 2.1897 (2.5542)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:09:59 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][40/156]	eta 0:01:07 lr 0.000071	 wd 0.0500	time 0.4882 (0.5782)	data time 0.0189 (0.1025)	model time 0.0000 (0.0000)	loss 0.6079 (0.5647)	grad_norm 2.3569 (2.4637)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:04 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][50/156]	eta 0:00:58 lr 0.000071	 wd 0.0500	time 0.5465 (0.5536)	data time 0.0237 (0.0838)	model time 0.0000 (0.0000)	loss 0.5572 (0.5605)	grad_norm 1.9923 (2.5380)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:09 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][60/156]	eta 0:00:51 lr 0.000070	 wd 0.0500	time 0.4502 (0.5386)	data time 0.0008 (0.0718)	model time 0.4494 (0.4521)	loss 0.6527 (0.5609)	grad_norm 2.1522 (2.5680)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:13 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][70/156]	eta 0:00:45 lr 0.000070	 wd 0.0500	time 0.4771 (0.5319)	data time 0.0006 (0.0629)	model time 0.4765 (0.4672)	loss 0.5370 (0.5672)	grad_norm 2.1758 (2.5441)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:18 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][80/156]	eta 0:00:40 lr 0.000070	 wd 0.0500	time 0.4124 (0.5274)	data time 0.0047 (0.0566)	model time 0.4077 (0.4725)	loss 0.5186 (0.5647)	grad_norm 1.6705 (2.5135)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:23 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][90/156]	eta 0:00:34 lr 0.000070	 wd 0.0500	time 0.5838 (0.5215)	data time 0.0162 (0.0510)	model time 0.5676 (0.4715)	loss 0.4188 (0.5628)	grad_norm 2.6227 (2.5196)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:28 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][100/156]	eta 0:00:29 lr 0.000070	 wd 0.0500	time 0.4966 (0.5190)	data time 0.0243 (0.0471)	model time 0.4723 (0.4741)	loss 0.6195 (0.5637)	grad_norm 3.2611 (2.4913)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:33 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][110/156]	eta 0:00:23 lr 0.000070	 wd 0.0500	time 0.4114 (0.5158)	data time 0.0006 (0.0433)	model time 0.4108 (0.4748)	loss 0.6509 (0.5646)	grad_norm 1.7176 (2.4760)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:39 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][120/156]	eta 0:00:18 lr 0.000070	 wd 0.0500	time 0.4802 (0.5189)	data time 0.0546 (0.0408)	model time 0.4256 (0.4842)	loss 0.6698 (0.5656)	grad_norm 2.2984 (2.4585)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:43 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][130/156]	eta 0:00:13 lr 0.000070	 wd 0.0500	time 0.4436 (0.5164)	data time 0.0288 (0.0387)	model time 0.4148 (0.4828)	loss 0.4403 (0.5635)	grad_norm 2.4207 (2.4715)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:49 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][140/156]	eta 0:00:08 lr 0.000070	 wd 0.0500	time 0.4140 (0.5171)	data time 0.0042 (0.0375)	model time 0.4098 (0.4851)	loss 0.5286 (0.5627)	grad_norm 3.6663 (2.4781)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:53 vssm1_tiny_0230s](training.py 201): INFO Train: [149/300][150/156]	eta 0:00:03 lr 0.000070	 wd 0.0500	time 0.5136 (0.5144)	data time 0.0006 (0.0363)	model time 0.5130 (0.4823)	loss 0.4933 (0.5629)	grad_norm 3.2899 (2.4814)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:10:56 vssm1_tiny_0230s](training.py 212): INFO EPOCH 149 training takes 0:01:20
[2024-11-09 15:10:56 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_149.pth saving......
[2024-11-09 15:10:57 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_149.pth saved !!!
[2024-11-09 15:11:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.739 (2.739)	Loss 0.1766 (0.1766)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:11:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.485)	Loss 0.1881 (0.1883)	Acc@1 95.312 (96.165)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:11:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.279 (0.358)	Loss 0.2416 (0.2038)	Acc@1 92.969 (95.164)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:11:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.151 (0.328)	Loss 0.3008 (0.2283)	Acc@1 92.188 (93.926)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:11:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.600 Acc@5 100.000
[2024-11-09 15:11:10 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.6%
[2024-11-09 15:11:10 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 93.68%
[2024-11-09 15:11:12 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.453 (2.453)	Loss 0.2961 (0.2961)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:11:16 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.324 (0.534)	Loss 0.3027 (0.3048)	Acc@1 96.875 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:11:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.166 (0.386)	Loss 0.5527 (0.3304)	Acc@1 71.094 (93.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:11:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.341)	Loss 0.6348 (0.4226)	Acc@1 60.938 (83.594)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:11:22 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 79.140 Acc@5 100.000
[2024-11-09 15:11:22 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 79.1%
[2024-11-09 15:11:22 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 79.14%
[2024-11-09 15:11:25 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][0/156]	eta 0:07:19 lr 0.000070	 wd 0.0500	time 2.8178 (2.8178)	data time 2.2841 (2.2841)	model time 0.0000 (0.0000)	loss 0.5996 (0.5996)	grad_norm 4.5684 (4.5684)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:11:31 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][10/156]	eta 0:01:57 lr 0.000070	 wd 0.0500	time 0.4876 (0.8016)	data time 0.0014 (0.2896)	model time 0.0000 (0.0000)	loss 0.5460 (0.5523)	grad_norm 2.8317 (3.2545)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:11:36 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][20/156]	eta 0:01:27 lr 0.000070	 wd 0.0500	time 0.4226 (0.6437)	data time 0.0146 (0.1579)	model time 0.0000 (0.0000)	loss 0.6581 (0.5479)	grad_norm 2.4195 (3.1058)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:11:41 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][30/156]	eta 0:01:16 lr 0.000070	 wd 0.0500	time 0.5745 (0.6091)	data time 0.0696 (0.1138)	model time 0.0000 (0.0000)	loss 0.5936 (0.5491)	grad_norm 1.8853 (3.3705)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:11:47 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][40/156]	eta 0:01:08 lr 0.000070	 wd 0.0500	time 0.4750 (0.5891)	data time 0.0211 (0.0905)	model time 0.0000 (0.0000)	loss 0.5179 (0.5491)	grad_norm 4.0391 (3.1720)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:11:51 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][50/156]	eta 0:00:59 lr 0.000070	 wd 0.0500	time 0.5978 (0.5653)	data time 0.0567 (0.0767)	model time 0.0000 (0.0000)	loss 0.5512 (0.5554)	grad_norm 3.2797 (3.0136)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:11:57 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][60/156]	eta 0:00:54 lr 0.000070	 wd 0.0500	time 0.4860 (0.5652)	data time 0.0042 (0.0696)	model time 0.4818 (0.5311)	loss 0.5860 (0.5621)	grad_norm 2.7195 (2.9075)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:12:02 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][70/156]	eta 0:00:48 lr 0.000070	 wd 0.0500	time 0.5938 (0.5597)	data time 0.0010 (0.0634)	model time 0.5928 (0.5162)	loss 0.5528 (0.5635)	grad_norm 2.5503 (2.8077)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:12:07 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][80/156]	eta 0:00:41 lr 0.000070	 wd 0.0500	time 0.4422 (0.5515)	data time 0.0012 (0.0578)	model time 0.4411 (0.5025)	loss 0.5173 (0.5641)	grad_norm 1.6198 (2.7045)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:12:12 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][90/156]	eta 0:00:35 lr 0.000070	 wd 0.0500	time 0.4668 (0.5433)	data time 0.0007 (0.0528)	model time 0.4662 (0.4929)	loss 0.5703 (0.5650)	grad_norm 2.0496 (2.6401)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:12:17 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][100/156]	eta 0:00:30 lr 0.000070	 wd 0.0500	time 0.5519 (0.5400)	data time 0.0100 (0.0489)	model time 0.5419 (0.4936)	loss 0.4546 (0.5611)	grad_norm 1.6300 (2.6216)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:12:22 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][110/156]	eta 0:00:24 lr 0.000070	 wd 0.0500	time 0.4349 (0.5371)	data time 0.0045 (0.0453)	model time 0.4304 (0.4946)	loss 0.4885 (0.5610)	grad_norm 3.3436 (2.6473)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:12:27 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][120/156]	eta 0:00:19 lr 0.000070	 wd 0.0500	time 0.4135 (0.5337)	data time 0.0008 (0.0430)	model time 0.4127 (0.4922)	loss 0.4968 (0.5625)	grad_norm 2.6514 (2.6484)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:12:33 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][130/156]	eta 0:00:13 lr 0.000069	 wd 0.0500	time 0.6282 (0.5358)	data time 0.1134 (0.0413)	model time 0.5149 (0.4982)	loss 0.5778 (0.5624)	grad_norm 3.1298 (2.6132)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:12:38 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][140/156]	eta 0:00:08 lr 0.000069	 wd 0.0500	time 0.6375 (0.5364)	data time 0.0009 (0.0400)	model time 0.6367 (0.5007)	loss 0.6255 (0.5619)	grad_norm 2.3630 (2.5858)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:12:43 vssm1_tiny_0230s](training.py 201): INFO Train: [150/300][150/156]	eta 0:00:03 lr 0.000069	 wd 0.0500	time 0.4455 (0.5337)	data time 0.0005 (0.0375)	model time 0.4449 (0.5002)	loss 0.6321 (0.5625)	grad_norm 2.1084 (2.5746)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:12:46 vssm1_tiny_0230s](training.py 212): INFO EPOCH 150 training takes 0:01:23
[2024-11-09 15:12:46 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_150.pth saving......
[2024-11-09 15:12:47 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_150.pth saved !!!
[2024-11-09 15:12:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.939 (4.939)	Loss 0.2245 (0.2245)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:12:53 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.581)	Loss 0.2299 (0.2288)	Acc@1 92.969 (93.608)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:12:56 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.414)	Loss 0.2065 (0.2431)	Acc@1 98.438 (92.671)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:12:58 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.373)	Loss 0.2559 (0.2411)	Acc@1 93.750 (93.548)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:13:01 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.020 Acc@5 100.000
[2024-11-09 15:13:01 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.0%
[2024-11-09 15:13:01 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.02%
[2024-11-09 15:13:04 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.468 (2.468)	Loss 0.2947 (0.2947)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:13:07 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.504)	Loss 0.3015 (0.3036)	Acc@1 96.875 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:13:09 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.170 (0.396)	Loss 0.5474 (0.3289)	Acc@1 71.094 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:13:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.185 (0.365)	Loss 0.6284 (0.4197)	Acc@1 63.281 (83.795)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:13:15 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 79.420 Acc@5 100.000
[2024-11-09 15:13:15 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 79.4%
[2024-11-09 15:13:15 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 79.42%
[2024-11-09 15:13:19 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][0/156]	eta 0:11:38 lr 0.000069	 wd 0.0500	time 4.4803 (4.4803)	data time 3.9961 (3.9961)	model time 0.0000 (0.0000)	loss 0.5510 (0.5510)	grad_norm 1.6234 (1.6234)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:13:24 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][10/156]	eta 0:02:05 lr 0.000069	 wd 0.0500	time 0.4628 (0.8570)	data time 0.0008 (0.3709)	model time 0.0000 (0.0000)	loss 0.4957 (0.5602)	grad_norm 2.6426 (2.1897)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:13:29 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][20/156]	eta 0:01:34 lr 0.000069	 wd 0.0500	time 0.5397 (0.6923)	data time 0.0542 (0.2056)	model time 0.0000 (0.0000)	loss 0.6118 (0.5671)	grad_norm 3.2202 (2.1715)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:13:34 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][30/156]	eta 0:01:17 lr 0.000069	 wd 0.0500	time 0.4895 (0.6184)	data time 0.0017 (0.1419)	model time 0.0000 (0.0000)	loss 0.5468 (0.5664)	grad_norm 2.6872 (2.2153)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:13:39 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][40/156]	eta 0:01:08 lr 0.000069	 wd 0.0500	time 0.5230 (0.5935)	data time 0.0179 (0.1103)	model time 0.0000 (0.0000)	loss 0.6019 (0.5731)	grad_norm 1.6944 (2.2318)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:13:44 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][50/156]	eta 0:01:01 lr 0.000069	 wd 0.0500	time 0.5246 (0.5774)	data time 0.0263 (0.0921)	model time 0.0000 (0.0000)	loss 0.6542 (0.5767)	grad_norm 2.4993 (2.2106)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:13:49 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][60/156]	eta 0:00:54 lr 0.000069	 wd 0.0500	time 0.4164 (0.5630)	data time 0.0068 (0.0791)	model time 0.4096 (0.4767)	loss 0.6027 (0.5799)	grad_norm 1.9913 (2.2519)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:13:54 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][70/156]	eta 0:00:48 lr 0.000069	 wd 0.0500	time 0.4393 (0.5588)	data time 0.0305 (0.0736)	model time 0.4088 (0.4850)	loss 0.5743 (0.5804)	grad_norm 4.0409 (2.2581)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:13:59 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][80/156]	eta 0:00:42 lr 0.000069	 wd 0.0500	time 0.5906 (0.5535)	data time 0.0206 (0.0661)	model time 0.5701 (0.4907)	loss 0.6523 (0.5806)	grad_norm 2.7194 (2.3051)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:14:04 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][90/156]	eta 0:00:35 lr 0.000069	 wd 0.0500	time 0.4413 (0.5430)	data time 0.0108 (0.0603)	model time 0.4305 (0.4795)	loss 0.5998 (0.5799)	grad_norm 2.0474 (2.3127)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:14:09 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][100/156]	eta 0:00:30 lr 0.000069	 wd 0.0500	time 0.4664 (0.5423)	data time 0.0342 (0.0555)	model time 0.4322 (0.4884)	loss 0.5659 (0.5765)	grad_norm 2.1512 (2.3174)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:14:14 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][110/156]	eta 0:00:24 lr 0.000069	 wd 0.0500	time 0.6425 (0.5389)	data time 0.0205 (0.0520)	model time 0.6220 (0.4882)	loss 0.5806 (0.5782)	grad_norm 2.7042 (2.3028)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:14:19 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][120/156]	eta 0:00:19 lr 0.000069	 wd 0.0500	time 0.4791 (0.5342)	data time 0.0244 (0.0496)	model time 0.4547 (0.4842)	loss 0.5986 (0.5799)	grad_norm 1.6216 (2.3213)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:14:24 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][130/156]	eta 0:00:13 lr 0.000069	 wd 0.0500	time 0.5950 (0.5299)	data time 0.0220 (0.0469)	model time 0.5730 (0.4816)	loss 0.6329 (0.5781)	grad_norm 2.6366 (2.3161)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:14:29 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][140/156]	eta 0:00:08 lr 0.000069	 wd 0.0500	time 0.6116 (0.5293)	data time 0.0009 (0.0444)	model time 0.6107 (0.4847)	loss 0.6092 (0.5776)	grad_norm 1.7497 (2.3070)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:14:34 vssm1_tiny_0230s](training.py 201): INFO Train: [151/300][150/156]	eta 0:00:03 lr 0.000069	 wd 0.0500	time 0.5522 (0.5266)	data time 0.0005 (0.0415)	model time 0.5517 (0.4849)	loss 0.5602 (0.5760)	grad_norm 1.9637 (2.3062)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:14:37 vssm1_tiny_0230s](training.py 212): INFO EPOCH 151 training takes 0:01:22
[2024-11-09 15:14:37 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_151.pth saving......
[2024-11-09 15:14:37 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_151.pth saved !!!
[2024-11-09 15:14:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.992 (3.992)	Loss 0.1875 (0.1875)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:14:44 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.159 (0.632)	Loss 0.1991 (0.1909)	Acc@1 96.875 (97.727)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:14:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.488)	Loss 0.2734 (0.2070)	Acc@1 92.188 (96.391)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:14:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.437)	Loss 0.3301 (0.2400)	Acc@1 89.844 (93.926)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:14:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.800 Acc@5 100.000
[2024-11-09 15:14:53 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 92.8%
[2024-11-09 15:14:53 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.02%
[2024-11-09 15:14:57 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.831 (3.831)	Loss 0.2930 (0.2930)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:14:59 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.285 (0.538)	Loss 0.2998 (0.3018)	Acc@1 96.875 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:15:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.370)	Loss 0.5425 (0.3271)	Acc@1 71.094 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:15:03 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.316)	Loss 0.6226 (0.4170)	Acc@1 64.844 (84.047)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:15:05 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 79.740 Acc@5 100.000
[2024-11-09 15:15:05 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 79.7%
[2024-11-09 15:15:05 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 79.74%
[2024-11-09 15:15:10 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][0/156]	eta 0:12:19 lr 0.000069	 wd 0.0500	time 4.7429 (4.7429)	data time 4.2470 (4.2470)	model time 0.0000 (0.0000)	loss 0.5744 (0.5744)	grad_norm 2.1345 (2.1345)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:15:15 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][10/156]	eta 0:02:09 lr 0.000069	 wd 0.0500	time 0.7238 (0.8849)	data time 0.0057 (0.3922)	model time 0.0000 (0.0000)	loss 0.5489 (0.5771)	grad_norm 2.1887 (2.5132)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:15:20 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][20/156]	eta 0:01:32 lr 0.000069	 wd 0.0500	time 0.4729 (0.6820)	data time 0.0009 (0.2075)	model time 0.0000 (0.0000)	loss 0.5878 (0.5621)	grad_norm 2.8260 (2.5514)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:15:25 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][30/156]	eta 0:01:19 lr 0.000069	 wd 0.0500	time 0.5086 (0.6320)	data time 0.0008 (0.1478)	model time 0.0000 (0.0000)	loss 0.5256 (0.5587)	grad_norm 1.9947 (2.4952)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:15:30 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][40/156]	eta 0:01:10 lr 0.000068	 wd 0.0500	time 0.5637 (0.6046)	data time 0.0112 (0.1161)	model time 0.0000 (0.0000)	loss 0.6262 (0.5605)	grad_norm 2.9008 (2.4989)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:15:36 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][50/156]	eta 0:01:02 lr 0.000068	 wd 0.0500	time 0.5622 (0.5922)	data time 0.0210 (0.1002)	model time 0.0000 (0.0000)	loss 0.6519 (0.5618)	grad_norm 3.3620 (2.4403)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:15:41 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][60/156]	eta 0:00:55 lr 0.000068	 wd 0.0500	time 0.4443 (0.5758)	data time 0.0156 (0.0876)	model time 0.4287 (0.4692)	loss 0.5123 (0.5624)	grad_norm 2.6559 (2.3946)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:15:46 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][70/156]	eta 0:00:49 lr 0.000068	 wd 0.0500	time 0.4950 (0.5702)	data time 0.0196 (0.0773)	model time 0.4754 (0.4951)	loss 0.5034 (0.5606)	grad_norm 4.2364 (2.3817)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:15:51 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][80/156]	eta 0:00:42 lr 0.000068	 wd 0.0500	time 0.4323 (0.5602)	data time 0.0009 (0.0683)	model time 0.4314 (0.4916)	loss 0.5281 (0.5590)	grad_norm 2.6131 (2.4505)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:15:56 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][90/156]	eta 0:00:36 lr 0.000068	 wd 0.0500	time 0.4528 (0.5520)	data time 0.0025 (0.0624)	model time 0.4503 (0.4864)	loss 0.5765 (0.5589)	grad_norm 3.3825 (2.5094)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:16:01 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][100/156]	eta 0:00:30 lr 0.000068	 wd 0.0500	time 0.5387 (0.5484)	data time 0.0564 (0.0582)	model time 0.4823 (0.4883)	loss 0.6166 (0.5588)	grad_norm 2.0928 (2.4987)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:16:06 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][110/156]	eta 0:00:25 lr 0.000068	 wd 0.0500	time 0.5633 (0.5444)	data time 0.0612 (0.0552)	model time 0.5021 (0.4868)	loss 0.6088 (0.5575)	grad_norm 2.3616 (2.4858)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:16:11 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][120/156]	eta 0:00:19 lr 0.000068	 wd 0.0500	time 0.5555 (0.5440)	data time 0.0050 (0.0527)	model time 0.5505 (0.4907)	loss 0.6394 (0.5599)	grad_norm 3.6146 (2.4561)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:16:17 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][130/156]	eta 0:00:14 lr 0.000068	 wd 0.0500	time 0.4496 (0.5428)	data time 0.0012 (0.0502)	model time 0.4484 (0.4930)	loss 0.4411 (0.5604)	grad_norm 3.3683 (2.4757)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:16:22 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][140/156]	eta 0:00:08 lr 0.000068	 wd 0.0500	time 0.5243 (0.5421)	data time 0.0008 (0.0484)	model time 0.5235 (0.4946)	loss 0.4771 (0.5586)	grad_norm 2.5671 (2.4885)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:16:27 vssm1_tiny_0230s](training.py 201): INFO Train: [152/300][150/156]	eta 0:00:03 lr 0.000068	 wd 0.0500	time 0.4245 (0.5390)	data time 0.0009 (0.0452)	model time 0.4235 (0.4947)	loss 0.5713 (0.5604)	grad_norm 2.5600 (2.4890)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:16:30 vssm1_tiny_0230s](training.py 212): INFO EPOCH 152 training takes 0:01:24
[2024-11-09 15:16:30 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_152.pth saving......
[2024-11-09 15:16:30 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_152.pth saved !!!
[2024-11-09 15:16:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.179 (4.179)	Loss 0.2522 (0.2522)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:16:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.200 (0.612)	Loss 0.2695 (0.2570)	Acc@1 92.969 (94.247)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:16:40 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.344 (0.485)	Loss 0.2190 (0.2690)	Acc@1 97.656 (93.118)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:16:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.158 (0.396)	Loss 0.2778 (0.2626)	Acc@1 91.406 (93.397)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:16:45 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.820 Acc@5 100.000
[2024-11-09 15:16:45 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.8%
[2024-11-09 15:16:45 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.02%
[2024-11-09 15:16:48 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.736 (2.736)	Loss 0.2915 (0.2915)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:16:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.454)	Loss 0.2983 (0.3006)	Acc@1 96.875 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:16:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.369)	Loss 0.5371 (0.3257)	Acc@1 71.875 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:16:56 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.331)	Loss 0.6162 (0.4142)	Acc@1 65.625 (84.249)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:16:58 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 80.080 Acc@5 100.000
[2024-11-09 15:16:58 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 80.1%
[2024-11-09 15:16:58 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 80.08%
[2024-11-09 15:17:01 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][0/156]	eta 0:08:33 lr 0.000068	 wd 0.0500	time 3.2905 (3.2905)	data time 2.8351 (2.8351)	model time 0.0000 (0.0000)	loss 0.4740 (0.4740)	grad_norm 2.4546 (2.4546)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:17:07 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][10/156]	eta 0:01:58 lr 0.000068	 wd 0.0500	time 0.4249 (0.8098)	data time 0.0064 (0.3310)	model time 0.0000 (0.0000)	loss 0.4209 (0.5601)	grad_norm 2.3980 (3.0468)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:17:12 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][20/156]	eta 0:01:31 lr 0.000068	 wd 0.0500	time 0.4834 (0.6744)	data time 0.0186 (0.1826)	model time 0.0000 (0.0000)	loss 0.6208 (0.5675)	grad_norm 2.6904 (2.7998)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:17:17 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][30/156]	eta 0:01:17 lr 0.000068	 wd 0.0500	time 0.5667 (0.6141)	data time 0.0008 (0.1281)	model time 0.0000 (0.0000)	loss 0.6677 (0.5684)	grad_norm 2.0750 (2.7869)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:17:23 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][40/156]	eta 0:01:10 lr 0.000068	 wd 0.0500	time 0.4888 (0.6088)	data time 0.0009 (0.1026)	model time 0.0000 (0.0000)	loss 0.4775 (0.5702)	grad_norm 2.2704 (2.7958)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:17:28 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][50/156]	eta 0:01:01 lr 0.000068	 wd 0.0500	time 0.5512 (0.5817)	data time 0.0269 (0.0856)	model time 0.0000 (0.0000)	loss 0.5978 (0.5721)	grad_norm 2.0670 (2.7890)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:17:33 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][60/156]	eta 0:00:54 lr 0.000068	 wd 0.0500	time 0.4574 (0.5669)	data time 0.0155 (0.0738)	model time 0.4418 (0.4776)	loss 0.5497 (0.5697)	grad_norm 1.9323 (2.7485)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:17:38 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][70/156]	eta 0:00:48 lr 0.000068	 wd 0.0500	time 0.5178 (0.5593)	data time 0.0098 (0.0658)	model time 0.5080 (0.4867)	loss 0.6067 (0.5718)	grad_norm 2.3990 (2.6753)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:17:43 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][80/156]	eta 0:00:41 lr 0.000068	 wd 0.0500	time 0.5174 (0.5514)	data time 0.0009 (0.0599)	model time 0.5165 (0.4837)	loss 0.5204 (0.5703)	grad_norm 2.2349 (2.6539)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:17:48 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][90/156]	eta 0:00:35 lr 0.000068	 wd 0.0500	time 0.4767 (0.5436)	data time 0.0008 (0.0561)	model time 0.4758 (0.4764)	loss 0.6251 (0.5731)	grad_norm 2.5122 (inf)	loss_scale 32768.0000 (62655.2967)	mem 13675MB
[2024-11-09 15:17:53 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][100/156]	eta 0:00:30 lr 0.000068	 wd 0.0500	time 0.4339 (0.5408)	data time 0.0112 (0.0517)	model time 0.4227 (0.4819)	loss 0.5903 (0.5734)	grad_norm 2.6568 (inf)	loss_scale 32768.0000 (59696.1584)	mem 13675MB
[2024-11-09 15:17:58 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][110/156]	eta 0:00:24 lr 0.000067	 wd 0.0500	time 0.4620 (0.5358)	data time 0.0148 (0.0480)	model time 0.4472 (0.4808)	loss 0.5785 (0.5707)	grad_norm 2.0064 (inf)	loss_scale 32768.0000 (57270.1982)	mem 13675MB
[2024-11-09 15:18:03 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][120/156]	eta 0:00:19 lr 0.000067	 wd 0.0500	time 0.6223 (0.5355)	data time 0.1474 (0.0465)	model time 0.4748 (0.4838)	loss 0.5047 (0.5708)	grad_norm 1.7691 (inf)	loss_scale 32768.0000 (55245.2231)	mem 13675MB
[2024-11-09 15:18:09 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][130/156]	eta 0:00:13 lr 0.000067	 wd 0.0500	time 0.5939 (0.5368)	data time 0.0162 (0.0442)	model time 0.5777 (0.4903)	loss 0.4463 (0.5691)	grad_norm 2.8284 (inf)	loss_scale 32768.0000 (53529.4046)	mem 13675MB
[2024-11-09 15:18:13 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][140/156]	eta 0:00:08 lr 0.000067	 wd 0.0500	time 0.5050 (0.5336)	data time 0.0008 (0.0420)	model time 0.5042 (0.4890)	loss 0.5691 (0.5723)	grad_norm 1.4539 (inf)	loss_scale 32768.0000 (52056.9645)	mem 13675MB
[2024-11-09 15:18:18 vssm1_tiny_0230s](training.py 201): INFO Train: [153/300][150/156]	eta 0:00:03 lr 0.000067	 wd 0.0500	time 0.4410 (0.5312)	data time 0.0007 (0.0393)	model time 0.4403 (0.4898)	loss 0.5953 (0.5722)	grad_norm 2.4276 (inf)	loss_scale 32768.0000 (50779.5497)	mem 13675MB
[2024-11-09 15:18:21 vssm1_tiny_0230s](training.py 212): INFO EPOCH 153 training takes 0:01:22
[2024-11-09 15:18:21 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_153.pth saving......
[2024-11-09 15:18:22 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_153.pth saved !!!
[2024-11-09 15:18:25 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.980 (2.980)	Loss 0.2485 (0.2485)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:18:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.149 (0.582)	Loss 0.2571 (0.2551)	Acc@1 94.531 (94.318)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:18:30 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.244 (0.387)	Loss 0.2100 (0.2660)	Acc@1 97.656 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:18:33 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.367)	Loss 0.2615 (0.2603)	Acc@1 92.969 (93.775)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:18:35 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.980 Acc@5 100.000
[2024-11-09 15:18:35 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.0%
[2024-11-09 15:18:35 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.02%
[2024-11-09 15:18:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.493 (3.493)	Loss 0.2900 (0.2900)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:18:41 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.159 (0.558)	Loss 0.2966 (0.2991)	Acc@1 96.875 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:18:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.173 (0.399)	Loss 0.5327 (0.3240)	Acc@1 72.656 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:18:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.175 (0.371)	Loss 0.6108 (0.4115)	Acc@1 66.406 (84.299)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:18:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 80.320 Acc@5 100.000
[2024-11-09 15:18:48 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 80.3%
[2024-11-09 15:18:48 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 80.32%
[2024-11-09 15:18:52 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][0/156]	eta 0:08:13 lr 0.000067	 wd 0.0500	time 3.1635 (3.1635)	data time 2.6982 (2.6982)	model time 0.0000 (0.0000)	loss 0.6153 (0.6153)	grad_norm 1.5657 (1.5657)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:18:56 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][10/156]	eta 0:01:39 lr 0.000067	 wd 0.0500	time 0.4308 (0.6786)	data time 0.0036 (0.2498)	model time 0.0000 (0.0000)	loss 0.5768 (0.5258)	grad_norm 4.8383 (3.1668)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:01 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][20/156]	eta 0:01:19 lr 0.000067	 wd 0.0500	time 0.5362 (0.5854)	data time 0.0133 (0.1366)	model time 0.0000 (0.0000)	loss 0.6028 (0.5398)	grad_norm 2.4031 (2.8770)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:06 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][30/156]	eta 0:01:11 lr 0.000067	 wd 0.0500	time 0.5395 (0.5635)	data time 0.0008 (0.0966)	model time 0.0000 (0.0000)	loss 0.5982 (0.5519)	grad_norm 3.0829 (2.6849)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:11 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][40/156]	eta 0:01:03 lr 0.000067	 wd 0.0500	time 0.5322 (0.5491)	data time 0.0090 (0.0757)	model time 0.0000 (0.0000)	loss 0.5304 (0.5498)	grad_norm 2.0955 (2.7020)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:17 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][50/156]	eta 0:00:58 lr 0.000067	 wd 0.0500	time 0.4572 (0.5509)	data time 0.0300 (0.0675)	model time 0.0000 (0.0000)	loss 0.5510 (0.5529)	grad_norm 2.8936 (2.6380)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:22 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][60/156]	eta 0:00:52 lr 0.000067	 wd 0.0500	time 0.5427 (0.5433)	data time 0.0210 (0.0578)	model time 0.5216 (0.4958)	loss 0.5294 (0.5532)	grad_norm 1.9409 (2.6062)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:27 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][70/156]	eta 0:00:46 lr 0.000067	 wd 0.0500	time 0.6804 (0.5373)	data time 0.0282 (0.0513)	model time 0.6522 (0.4927)	loss 0.6271 (0.5623)	grad_norm 3.0033 (2.5451)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:31 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][80/156]	eta 0:00:40 lr 0.000067	 wd 0.0500	time 0.5156 (0.5286)	data time 0.0051 (0.0463)	model time 0.5105 (0.4802)	loss 0.5368 (0.5645)	grad_norm 5.5450 (2.5622)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:36 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][90/156]	eta 0:00:34 lr 0.000067	 wd 0.0500	time 0.4314 (0.5253)	data time 0.0145 (0.0436)	model time 0.4170 (0.4795)	loss 0.6064 (0.5648)	grad_norm 2.0203 (2.5027)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:41 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][100/156]	eta 0:00:29 lr 0.000067	 wd 0.0500	time 0.4513 (0.5211)	data time 0.0089 (0.0401)	model time 0.4424 (0.4785)	loss 0.5535 (0.5621)	grad_norm 2.6874 (2.4956)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:46 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][110/156]	eta 0:00:23 lr 0.000067	 wd 0.0500	time 0.5823 (0.5172)	data time 0.0006 (0.0371)	model time 0.5817 (0.4774)	loss 0.6558 (0.5631)	grad_norm 2.6271 (2.5053)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:51 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][120/156]	eta 0:00:18 lr 0.000067	 wd 0.0500	time 0.5837 (0.5152)	data time 0.0201 (0.0351)	model time 0.5637 (0.4776)	loss 0.4710 (0.5642)	grad_norm 3.4818 (2.4692)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:19:56 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][130/156]	eta 0:00:13 lr 0.000067	 wd 0.0500	time 0.4476 (0.5140)	data time 0.0223 (0.0347)	model time 0.4254 (0.4767)	loss 0.5236 (0.5663)	grad_norm 2.2580 (2.4676)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:20:01 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][140/156]	eta 0:00:08 lr 0.000067	 wd 0.0500	time 0.5444 (0.5129)	data time 0.0008 (0.0328)	model time 0.5436 (0.4782)	loss 0.6312 (0.5692)	grad_norm 3.4434 (2.4789)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:20:06 vssm1_tiny_0230s](training.py 201): INFO Train: [154/300][150/156]	eta 0:00:03 lr 0.000067	 wd 0.0500	time 0.4354 (0.5112)	data time 0.0007 (0.0308)	model time 0.4347 (0.4789)	loss 0.5223 (0.5679)	grad_norm 2.0874 (2.5060)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:20:08 vssm1_tiny_0230s](training.py 212): INFO EPOCH 154 training takes 0:01:19
[2024-11-09 15:20:08 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_154.pth saving......
[2024-11-09 15:20:09 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_154.pth saved !!!
[2024-11-09 15:20:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.914 (3.914)	Loss 0.2091 (0.2091)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:20:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.563)	Loss 0.2167 (0.2124)	Acc@1 96.875 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:20:17 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.374)	Loss 0.2328 (0.2264)	Acc@1 94.531 (95.275)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:20:19 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.225 (0.332)	Loss 0.2944 (0.2421)	Acc@1 92.188 (94.355)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:20:21 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.920 Acc@5 100.000
[2024-11-09 15:20:21 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.9%
[2024-11-09 15:20:21 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.02%
[2024-11-09 15:20:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.083 (3.083)	Loss 0.2886 (0.2886)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:20:26 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.467)	Loss 0.2954 (0.2978)	Acc@1 96.875 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:20:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.890 (0.372)	Loss 0.5273 (0.3225)	Acc@1 72.656 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:20:30 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.305)	Loss 0.6045 (0.4087)	Acc@1 66.406 (84.476)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:20:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 80.640 Acc@5 100.000
[2024-11-09 15:20:32 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 80.6%
[2024-11-09 15:20:32 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 80.64%
[2024-11-09 15:20:35 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][0/156]	eta 0:08:09 lr 0.000067	 wd 0.0500	time 3.1396 (3.1396)	data time 2.6334 (2.6334)	model time 0.0000 (0.0000)	loss 0.6071 (0.6071)	grad_norm 2.0645 (2.0645)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:20:40 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][10/156]	eta 0:01:43 lr 0.000067	 wd 0.0500	time 0.4296 (0.7057)	data time 0.0011 (0.2498)	model time 0.0000 (0.0000)	loss 0.5266 (0.5781)	grad_norm 3.0237 (2.4334)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:20:44 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][20/156]	eta 0:01:21 lr 0.000067	 wd 0.0500	time 0.4711 (0.5961)	data time 0.0213 (0.1381)	model time 0.0000 (0.0000)	loss 0.6530 (0.5922)	grad_norm 2.4047 (2.4967)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:20:49 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][30/156]	eta 0:01:11 lr 0.000066	 wd 0.0500	time 0.4321 (0.5650)	data time 0.0208 (0.0980)	model time 0.0000 (0.0000)	loss 0.5511 (0.5846)	grad_norm 1.7934 (2.3014)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:20:54 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][40/156]	eta 0:01:02 lr 0.000066	 wd 0.0500	time 0.4923 (0.5428)	data time 0.0116 (0.0768)	model time 0.0000 (0.0000)	loss 0.5167 (0.5748)	grad_norm 2.1220 (2.2011)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:00 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][50/156]	eta 0:00:57 lr 0.000066	 wd 0.0500	time 0.6137 (0.5443)	data time 0.0063 (0.0665)	model time 0.0000 (0.0000)	loss 0.5948 (0.5717)	grad_norm 1.7873 (2.2241)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:05 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][60/156]	eta 0:00:51 lr 0.000066	 wd 0.0500	time 0.5289 (0.5370)	data time 0.0005 (0.0594)	model time 0.5284 (0.4772)	loss 0.6260 (0.5649)	grad_norm 2.6265 (2.2273)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:10 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][70/156]	eta 0:00:45 lr 0.000066	 wd 0.0500	time 0.5377 (0.5303)	data time 0.0107 (0.0539)	model time 0.5271 (0.4731)	loss 0.4410 (0.5651)	grad_norm 3.4367 (2.3078)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:15 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][80/156]	eta 0:00:40 lr 0.000066	 wd 0.0500	time 0.6438 (0.5288)	data time 0.0455 (0.0498)	model time 0.5983 (0.4814)	loss 0.4677 (0.5651)	grad_norm 1.9051 (2.3420)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:20 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][90/156]	eta 0:00:34 lr 0.000066	 wd 0.0500	time 0.4272 (0.5235)	data time 0.0159 (0.0465)	model time 0.4113 (0.4761)	loss 0.5707 (0.5681)	grad_norm 2.5464 (2.3396)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:24 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][100/156]	eta 0:00:29 lr 0.000066	 wd 0.0500	time 0.4332 (0.5191)	data time 0.0044 (0.0435)	model time 0.4288 (0.4735)	loss 0.5114 (0.5708)	grad_norm 3.3075 (2.3864)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:29 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][110/156]	eta 0:00:23 lr 0.000066	 wd 0.0500	time 0.4743 (0.5178)	data time 0.0314 (0.0409)	model time 0.4429 (0.4764)	loss 0.6111 (0.5696)	grad_norm 1.7338 (2.3704)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:35 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][120/156]	eta 0:00:18 lr 0.000066	 wd 0.0500	time 0.4717 (0.5173)	data time 0.0174 (0.0386)	model time 0.4544 (0.4793)	loss 0.6002 (0.5690)	grad_norm 2.1201 (2.3595)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:39 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][130/156]	eta 0:00:13 lr 0.000066	 wd 0.0500	time 0.4462 (0.5156)	data time 0.0150 (0.0375)	model time 0.4311 (0.4783)	loss 0.6053 (0.5696)	grad_norm 2.5438 (2.3463)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:44 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][140/156]	eta 0:00:08 lr 0.000066	 wd 0.0500	time 0.4695 (0.5138)	data time 0.0012 (0.0362)	model time 0.4682 (0.4775)	loss 0.6298 (0.5701)	grad_norm 3.0294 (2.3624)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:50 vssm1_tiny_0230s](training.py 201): INFO Train: [155/300][150/156]	eta 0:00:03 lr 0.000066	 wd 0.0500	time 0.4376 (0.5157)	data time 0.0005 (0.0339)	model time 0.4371 (0.4839)	loss 0.6057 (0.5705)	grad_norm 1.8668 (2.3527)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:21:52 vssm1_tiny_0230s](training.py 212): INFO EPOCH 155 training takes 0:01:20
[2024-11-09 15:21:52 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_155.pth saving......
[2024-11-09 15:21:53 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_155.pth saved !!!
[2024-11-09 15:21:56 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.159 (3.159)	Loss 0.2294 (0.2294)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:21:59 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.220 (0.487)	Loss 0.2407 (0.2420)	Acc@1 96.094 (95.170)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:22:03 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 1.974 (0.466)	Loss 0.2195 (0.2534)	Acc@1 96.094 (94.234)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:22:05 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.189 (0.368)	Loss 0.2827 (0.2557)	Acc@1 92.969 (93.876)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:22:07 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.780 Acc@5 100.000
[2024-11-09 15:22:07 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.8%
[2024-11-09 15:22:07 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.02%
[2024-11-09 15:22:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.241 (4.241)	Loss 0.2874 (0.2874)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:22:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.177 (0.695)	Loss 0.2942 (0.2968)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:22:17 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.268 (0.484)	Loss 0.5220 (0.3213)	Acc@1 74.219 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:22:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.417)	Loss 0.5981 (0.4060)	Acc@1 68.750 (84.703)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:22:22 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 80.980 Acc@5 100.000
[2024-11-09 15:22:22 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 81.0%
[2024-11-09 15:22:22 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 80.98%
[2024-11-09 15:22:26 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][0/156]	eta 0:10:41 lr 0.000066	 wd 0.0500	time 4.1131 (4.1131)	data time 3.5184 (3.5184)	model time 0.0000 (0.0000)	loss 0.4396 (0.4396)	grad_norm 4.1122 (4.1122)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:22:31 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][10/156]	eta 0:02:07 lr 0.000066	 wd 0.0500	time 0.4873 (0.8718)	data time 0.0344 (0.3461)	model time 0.0000 (0.0000)	loss 0.6197 (0.5730)	grad_norm 1.1495 (2.4930)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:22:36 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][20/156]	eta 0:01:33 lr 0.000066	 wd 0.0500	time 0.6103 (0.6874)	data time 0.0370 (0.1881)	model time 0.0000 (0.0000)	loss 0.5352 (0.5608)	grad_norm 2.6031 (2.4740)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:22:41 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][30/156]	eta 0:01:20 lr 0.000066	 wd 0.0500	time 0.4817 (0.6361)	data time 0.0504 (0.1330)	model time 0.0000 (0.0000)	loss 0.4651 (0.5652)	grad_norm 4.6411 (2.6567)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:22:47 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][40/156]	eta 0:01:10 lr 0.000066	 wd 0.0500	time 0.6379 (0.6113)	data time 0.0110 (0.1019)	model time 0.0000 (0.0000)	loss 0.5555 (0.5637)	grad_norm 2.3837 (2.6717)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:22:52 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][50/156]	eta 0:01:02 lr 0.000066	 wd 0.0500	time 0.4987 (0.5886)	data time 0.0537 (0.0859)	model time 0.0000 (0.0000)	loss 0.4396 (0.5531)	grad_norm 3.9608 (2.7360)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:22:57 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][60/156]	eta 0:00:55 lr 0.000066	 wd 0.0500	time 0.4536 (0.5738)	data time 0.0195 (0.0740)	model time 0.4341 (0.4856)	loss 0.5576 (0.5580)	grad_norm 2.1254 (2.7539)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:23:01 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][70/156]	eta 0:00:47 lr 0.000066	 wd 0.0500	time 0.5123 (0.5569)	data time 0.0461 (0.0657)	model time 0.4662 (0.4621)	loss 0.5399 (0.5582)	grad_norm 3.3686 (2.6951)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:23:06 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][80/156]	eta 0:00:41 lr 0.000066	 wd 0.0500	time 0.4415 (0.5464)	data time 0.0019 (0.0597)	model time 0.4396 (0.4596)	loss 0.4991 (0.5603)	grad_norm 3.0836 (2.6290)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:23:11 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][90/156]	eta 0:00:35 lr 0.000066	 wd 0.0500	time 0.4600 (0.5411)	data time 0.0131 (0.0543)	model time 0.4470 (0.4664)	loss 0.6480 (0.5577)	grad_norm 3.6081 (2.6002)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:23:16 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][100/156]	eta 0:00:30 lr 0.000065	 wd 0.0500	time 0.4422 (0.5390)	data time 0.0040 (0.0516)	model time 0.4382 (0.4717)	loss 0.4652 (0.5560)	grad_norm 2.8997 (2.6135)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:23:21 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][110/156]	eta 0:00:24 lr 0.000065	 wd 0.0500	time 0.4772 (0.5353)	data time 0.0006 (0.0477)	model time 0.4766 (0.4749)	loss 0.5606 (0.5545)	grad_norm 4.7060 (2.6704)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:23:26 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][120/156]	eta 0:00:19 lr 0.000065	 wd 0.0500	time 0.5078 (0.5304)	data time 0.0243 (0.0442)	model time 0.4835 (0.4742)	loss 0.6445 (0.5529)	grad_norm 2.6492 (2.6991)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:23:31 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][130/156]	eta 0:00:13 lr 0.000065	 wd 0.0500	time 0.4479 (0.5297)	data time 0.0245 (0.0425)	model time 0.4235 (0.4775)	loss 0.6518 (0.5537)	grad_norm 2.8286 (2.7060)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:23:36 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][140/156]	eta 0:00:08 lr 0.000065	 wd 0.0500	time 0.4215 (0.5281)	data time 0.0007 (0.0401)	model time 0.4208 (0.4797)	loss 0.5943 (0.5560)	grad_norm 2.6055 (2.6977)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:23:42 vssm1_tiny_0230s](training.py 201): INFO Train: [156/300][150/156]	eta 0:00:03 lr 0.000065	 wd 0.0500	time 0.6554 (0.5283)	data time 0.0007 (0.0375)	model time 0.6547 (0.4847)	loss 0.5104 (0.5563)	grad_norm 2.7926 (2.6609)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:23:45 vssm1_tiny_0230s](training.py 212): INFO EPOCH 156 training takes 0:01:22
[2024-11-09 15:23:45 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_156.pth saving......
[2024-11-09 15:23:45 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_156.pth saved !!!
[2024-11-09 15:23:50 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.598 (4.598)	Loss 0.2435 (0.2435)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:23:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.266 (0.629)	Loss 0.2605 (0.2555)	Acc@1 92.969 (92.898)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:23:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.232 (0.463)	Loss 0.1981 (0.2656)	Acc@1 97.656 (92.150)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:23:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.173 (0.400)	Loss 0.2406 (0.2538)	Acc@1 94.531 (93.246)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:24:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.720 Acc@5 100.000
[2024-11-09 15:24:00 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.7%
[2024-11-09 15:24:00 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.02%
[2024-11-09 15:24:03 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.529 (3.529)	Loss 0.2859 (0.2859)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:24:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.139 (0.499)	Loss 0.2930 (0.2955)	Acc@1 96.094 (96.023)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:24:08 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.214 (0.413)	Loss 0.5166 (0.3198)	Acc@1 74.219 (93.341)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:24:10 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.343)	Loss 0.5913 (0.4032)	Acc@1 69.531 (84.879)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:24:14 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 81.220 Acc@5 100.000
[2024-11-09 15:24:14 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 81.2%
[2024-11-09 15:24:14 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 81.22%
[2024-11-09 15:24:18 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][0/156]	eta 0:09:24 lr 0.000065	 wd 0.0500	time 3.6198 (3.6198)	data time 3.1870 (3.1870)	model time 0.0000 (0.0000)	loss 0.5613 (0.5613)	grad_norm 1.7284 (1.7284)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:24:23 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][10/156]	eta 0:01:57 lr 0.000065	 wd 0.0500	time 0.5233 (0.8047)	data time 0.0054 (0.3401)	model time 0.0000 (0.0000)	loss 0.6391 (0.5608)	grad_norm 3.7135 (2.7784)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:24:28 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][20/156]	eta 0:01:33 lr 0.000065	 wd 0.0500	time 0.4324 (0.6854)	data time 0.0021 (0.1923)	model time 0.0000 (0.0000)	loss 0.4512 (0.5622)	grad_norm 2.1140 (2.7056)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:24:33 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][30/156]	eta 0:01:17 lr 0.000065	 wd 0.0500	time 0.4617 (0.6183)	data time 0.0204 (0.1337)	model time 0.0000 (0.0000)	loss 0.4653 (0.5588)	grad_norm 3.6504 (2.7525)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:24:38 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][40/156]	eta 0:01:08 lr 0.000065	 wd 0.0500	time 0.4931 (0.5935)	data time 0.0225 (0.1027)	model time 0.0000 (0.0000)	loss 0.6462 (0.5647)	grad_norm 1.6695 (2.7229)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:24:43 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][50/156]	eta 0:01:01 lr 0.000065	 wd 0.0500	time 0.4950 (0.5772)	data time 0.0074 (0.0867)	model time 0.0000 (0.0000)	loss 0.5755 (0.5713)	grad_norm 2.9163 (2.6592)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:24:48 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][60/156]	eta 0:00:54 lr 0.000065	 wd 0.0500	time 0.4730 (0.5643)	data time 0.0173 (0.0764)	model time 0.4557 (0.4752)	loss 0.4851 (0.5738)	grad_norm 1.9986 (2.5307)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:24:54 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][70/156]	eta 0:00:48 lr 0.000065	 wd 0.0500	time 0.4715 (0.5624)	data time 0.0023 (0.0710)	model time 0.4692 (0.4938)	loss 0.5695 (0.5691)	grad_norm 1.1986 (2.4650)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:24:59 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][80/156]	eta 0:00:42 lr 0.000065	 wd 0.0500	time 0.4985 (0.5568)	data time 0.0303 (0.0651)	model time 0.4682 (0.4939)	loss 0.6442 (0.5740)	grad_norm 1.7107 (2.4253)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:25:04 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][90/156]	eta 0:00:36 lr 0.000065	 wd 0.0500	time 0.4552 (0.5528)	data time 0.0039 (0.0592)	model time 0.4512 (0.4974)	loss 0.6355 (0.5743)	grad_norm 1.6899 (2.4249)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:25:09 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][100/156]	eta 0:00:30 lr 0.000065	 wd 0.0500	time 0.4760 (0.5467)	data time 0.0009 (0.0564)	model time 0.4751 (0.4902)	loss 0.6016 (0.5725)	grad_norm 2.2078 (2.4122)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:25:14 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][110/156]	eta 0:00:24 lr 0.000065	 wd 0.0500	time 0.4511 (0.5391)	data time 0.0149 (0.0526)	model time 0.4362 (0.4831)	loss 0.6053 (0.5719)	grad_norm 1.4753 (2.4049)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:25:19 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][120/156]	eta 0:00:19 lr 0.000065	 wd 0.0500	time 0.4566 (0.5371)	data time 0.0370 (0.0491)	model time 0.4196 (0.4863)	loss 0.5389 (0.5694)	grad_norm 2.1684 (2.4384)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:25:24 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][130/156]	eta 0:00:13 lr 0.000065	 wd 0.0500	time 0.5320 (0.5370)	data time 0.0177 (0.0465)	model time 0.5142 (0.4906)	loss 0.5315 (0.5691)	grad_norm 2.3734 (2.5084)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:25:30 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][140/156]	eta 0:00:08 lr 0.000065	 wd 0.0500	time 0.6608 (0.5373)	data time 0.0009 (0.0438)	model time 0.6599 (0.4953)	loss 0.6054 (0.5698)	grad_norm 2.4895 (2.5264)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:25:34 vssm1_tiny_0230s](training.py 201): INFO Train: [157/300][150/156]	eta 0:00:03 lr 0.000065	 wd 0.0500	time 0.4615 (0.5334)	data time 0.0005 (0.0414)	model time 0.4610 (0.4927)	loss 0.5966 (0.5698)	grad_norm 3.0255 (2.5373)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:25:37 vssm1_tiny_0230s](training.py 212): INFO EPOCH 157 training takes 0:01:23
[2024-11-09 15:25:37 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_157.pth saving......
[2024-11-09 15:25:38 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_157.pth saved !!!
[2024-11-09 15:25:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.741 (2.741)	Loss 0.2141 (0.2141)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:25:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.431)	Loss 0.2200 (0.2225)	Acc@1 95.312 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:25:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.189 (0.341)	Loss 0.2371 (0.2360)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:25:48 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.315)	Loss 0.2983 (0.2507)	Acc@1 92.969 (93.800)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:25:50 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.660 Acc@5 100.000
[2024-11-09 15:25:50 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.7%
[2024-11-09 15:25:50 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.02%
[2024-11-09 15:25:55 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.672 (4.672)	Loss 0.2847 (0.2847)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:25:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.145 (0.624)	Loss 0.2917 (0.2943)	Acc@1 96.875 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:25:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.442)	Loss 0.5107 (0.3184)	Acc@1 75.000 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:26:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.205 (0.368)	Loss 0.5850 (0.4003)	Acc@1 70.312 (85.207)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:26:04 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 81.700 Acc@5 100.000
[2024-11-09 15:26:04 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 81.7%
[2024-11-09 15:26:04 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 81.70%
[2024-11-09 15:26:08 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][0/156]	eta 0:09:50 lr 0.000065	 wd 0.0500	time 3.7878 (3.7878)	data time 3.2569 (3.2569)	model time 0.0000 (0.0000)	loss 0.5252 (0.5252)	grad_norm 2.0341 (2.0341)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:26:13 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][10/156]	eta 0:02:01 lr 0.000064	 wd 0.0500	time 0.4389 (0.8295)	data time 0.0110 (0.3308)	model time 0.0000 (0.0000)	loss 0.5791 (0.5580)	grad_norm 1.8758 (2.3528)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:26:18 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][20/156]	eta 0:01:30 lr 0.000064	 wd 0.0500	time 0.4125 (0.6670)	data time 0.0030 (0.1787)	model time 0.0000 (0.0000)	loss 0.5081 (0.5662)	grad_norm 1.8876 (2.2815)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:26:23 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][30/156]	eta 0:01:18 lr 0.000064	 wd 0.0500	time 0.7005 (0.6240)	data time 0.0056 (0.1269)	model time 0.0000 (0.0000)	loss 0.5613 (0.5623)	grad_norm 1.1622 (2.3267)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:26:28 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][40/156]	eta 0:01:08 lr 0.000064	 wd 0.0500	time 0.5274 (0.5922)	data time 0.0133 (0.0985)	model time 0.0000 (0.0000)	loss 0.5046 (0.5607)	grad_norm 2.4331 (2.4146)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:26:33 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][50/156]	eta 0:01:00 lr 0.000064	 wd 0.0500	time 0.4109 (0.5705)	data time 0.0026 (0.0832)	model time 0.0000 (0.0000)	loss 0.6569 (0.5649)	grad_norm 2.9444 (2.4860)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:26:38 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][60/156]	eta 0:00:53 lr 0.000064	 wd 0.0500	time 0.5721 (0.5600)	data time 0.0056 (0.0717)	model time 0.5665 (0.4933)	loss 0.5322 (0.5672)	grad_norm 3.3392 (2.6202)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:26:44 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][70/156]	eta 0:00:48 lr 0.000064	 wd 0.0500	time 0.5521 (0.5599)	data time 0.0048 (0.0646)	model time 0.5474 (0.5156)	loss 0.5899 (0.5686)	grad_norm 2.4791 (2.5504)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:26:49 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][80/156]	eta 0:00:42 lr 0.000064	 wd 0.0500	time 0.4763 (0.5562)	data time 0.0374 (0.0589)	model time 0.4389 (0.5142)	loss 0.5670 (0.5672)	grad_norm 2.8652 (2.5150)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:26:54 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][90/156]	eta 0:00:36 lr 0.000064	 wd 0.0500	time 0.5022 (0.5524)	data time 0.0185 (0.0534)	model time 0.4837 (0.5138)	loss 0.6543 (0.5715)	grad_norm 2.5511 (2.4886)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:26:59 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][100/156]	eta 0:00:30 lr 0.000064	 wd 0.0500	time 0.5157 (0.5477)	data time 0.0258 (0.0491)	model time 0.4899 (0.5102)	loss 0.6290 (0.5755)	grad_norm 1.8490 (2.5021)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:27:04 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][110/156]	eta 0:00:24 lr 0.000064	 wd 0.0500	time 0.4341 (0.5427)	data time 0.0231 (0.0465)	model time 0.4110 (0.5037)	loss 0.6217 (0.5762)	grad_norm 1.5174 (2.4524)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:27:09 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][120/156]	eta 0:00:19 lr 0.000064	 wd 0.0500	time 0.8151 (0.5410)	data time 0.0112 (0.0433)	model time 0.8039 (0.5053)	loss 0.5379 (0.5762)	grad_norm 1.7422 (2.4247)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:27:14 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][130/156]	eta 0:00:13 lr 0.000064	 wd 0.0500	time 0.4144 (0.5357)	data time 0.0008 (0.0405)	model time 0.4136 (0.5001)	loss 0.6075 (0.5762)	grad_norm 1.6502 (2.3924)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:27:19 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][140/156]	eta 0:00:08 lr 0.000064	 wd 0.0500	time 0.5540 (0.5328)	data time 0.0014 (0.0385)	model time 0.5525 (0.4982)	loss 0.5113 (0.5707)	grad_norm 2.1309 (2.4022)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:27:24 vssm1_tiny_0230s](training.py 201): INFO Train: [158/300][150/156]	eta 0:00:03 lr 0.000064	 wd 0.0500	time 0.4660 (0.5284)	data time 0.0005 (0.0360)	model time 0.4655 (0.4950)	loss 0.4260 (0.5692)	grad_norm 2.7033 (2.4324)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:27:26 vssm1_tiny_0230s](training.py 212): INFO EPOCH 158 training takes 0:01:22
[2024-11-09 15:27:26 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_158.pth saving......
[2024-11-09 15:27:27 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_158.pth saved !!!
[2024-11-09 15:27:30 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.162 (3.162)	Loss 0.1943 (0.1943)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:27:33 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.186 (0.550)	Loss 0.2078 (0.2024)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:27:35 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.420)	Loss 0.1841 (0.2172)	Acc@1 96.094 (94.382)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:27:38 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.379)	Loss 0.2445 (0.2203)	Acc@1 93.750 (94.204)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:27:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.160 Acc@5 100.000
[2024-11-09 15:27:40 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.2%
[2024-11-09 15:27:40 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.16%
[2024-11-09 15:27:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.391 (3.391)	Loss 0.2837 (0.2837)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:27:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.531)	Loss 0.2908 (0.2935)	Acc@1 96.875 (96.023)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:27:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.189 (0.463)	Loss 0.5044 (0.3173)	Acc@1 75.781 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:27:52 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.363)	Loss 0.5771 (0.3974)	Acc@1 70.312 (85.358)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:27:54 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 81.960 Acc@5 100.000
[2024-11-09 15:27:54 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 82.0%
[2024-11-09 15:27:54 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 81.96%
[2024-11-09 15:27:58 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][0/156]	eta 0:09:54 lr 0.000064	 wd 0.0500	time 3.8089 (3.8089)	data time 3.3885 (3.3885)	model time 0.0000 (0.0000)	loss 0.5605 (0.5605)	grad_norm 2.5347 (2.5347)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:04 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][10/156]	eta 0:02:09 lr 0.000064	 wd 0.0500	time 0.6671 (0.8846)	data time 0.0187 (0.3941)	model time 0.0000 (0.0000)	loss 0.5388 (0.5659)	grad_norm 2.2360 (2.7986)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:09 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][20/156]	eta 0:01:40 lr 0.000064	 wd 0.0500	time 0.6130 (0.7417)	data time 0.0172 (0.2149)	model time 0.0000 (0.0000)	loss 0.4485 (0.5720)	grad_norm 1.8757 (2.6034)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:15 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][30/156]	eta 0:01:24 lr 0.000064	 wd 0.0500	time 0.5417 (0.6670)	data time 0.0032 (0.1505)	model time 0.0000 (0.0000)	loss 0.5005 (0.5596)	grad_norm 2.0240 (2.6786)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:20 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][40/156]	eta 0:01:13 lr 0.000064	 wd 0.0500	time 0.5231 (0.6310)	data time 0.0109 (0.1172)	model time 0.0000 (0.0000)	loss 0.5231 (0.5563)	grad_norm 1.6543 (2.5610)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:25 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][50/156]	eta 0:01:04 lr 0.000064	 wd 0.0500	time 0.6691 (0.6079)	data time 0.0015 (0.0964)	model time 0.0000 (0.0000)	loss 0.5265 (0.5616)	grad_norm 3.5918 (2.5178)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:30 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][60/156]	eta 0:00:56 lr 0.000064	 wd 0.0500	time 0.4579 (0.5914)	data time 0.0195 (0.0824)	model time 0.4384 (0.4962)	loss 0.6430 (0.5662)	grad_norm 1.9214 (2.4112)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:35 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][70/156]	eta 0:00:50 lr 0.000064	 wd 0.0500	time 0.6884 (0.5829)	data time 0.0013 (0.0728)	model time 0.6871 (0.5063)	loss 0.6447 (0.5651)	grad_norm 1.7719 (2.3756)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:40 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][80/156]	eta 0:00:43 lr 0.000063	 wd 0.0500	time 0.4862 (0.5749)	data time 0.0225 (0.0666)	model time 0.4637 (0.5027)	loss 0.6267 (0.5632)	grad_norm 2.8527 (2.4025)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:45 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][90/156]	eta 0:00:37 lr 0.000063	 wd 0.0500	time 0.4466 (0.5671)	data time 0.0248 (0.0629)	model time 0.4218 (0.4948)	loss 0.5991 (0.5638)	grad_norm 1.9391 (2.4500)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:51 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][100/156]	eta 0:00:31 lr 0.000063	 wd 0.0500	time 0.4111 (0.5606)	data time 0.0062 (0.0586)	model time 0.4050 (0.4923)	loss 0.4768 (0.5617)	grad_norm 2.2535 (2.4537)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:28:55 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][110/156]	eta 0:00:25 lr 0.000063	 wd 0.0500	time 0.5275 (0.5551)	data time 0.0138 (0.0551)	model time 0.5137 (0.4903)	loss 0.5672 (0.5608)	grad_norm 1.9548 (2.4660)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:29:00 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][120/156]	eta 0:00:19 lr 0.000063	 wd 0.0500	time 0.4221 (0.5459)	data time 0.0080 (0.0520)	model time 0.4141 (0.4810)	loss 0.6276 (0.5620)	grad_norm 3.5103 (2.5013)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:29:04 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][130/156]	eta 0:00:13 lr 0.000063	 wd 0.0500	time 0.4314 (0.5376)	data time 0.0184 (0.0489)	model time 0.4131 (0.4741)	loss 0.5260 (0.5620)	grad_norm 3.2113 (2.4980)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:29:09 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][140/156]	eta 0:00:08 lr 0.000063	 wd 0.0500	time 0.4383 (0.5339)	data time 0.0009 (0.0460)	model time 0.4374 (0.4745)	loss 0.6361 (0.5644)	grad_norm 2.5305 (2.4721)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:29:14 vssm1_tiny_0230s](training.py 201): INFO Train: [159/300][150/156]	eta 0:00:03 lr 0.000063	 wd 0.0500	time 0.4129 (0.5277)	data time 0.0006 (0.0430)	model time 0.4123 (0.4710)	loss 0.6035 (0.5655)	grad_norm 2.5242 (2.5007)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:29:16 vssm1_tiny_0230s](training.py 212): INFO EPOCH 159 training takes 0:01:22
[2024-11-09 15:29:16 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_159.pth saving......
[2024-11-09 15:29:17 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_159.pth saved !!!
[2024-11-09 15:29:20 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.994 (2.994)	Loss 0.2061 (0.2061)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:29:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.146 (0.488)	Loss 0.2145 (0.2172)	Acc@1 96.875 (97.372)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:29:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.322 (0.449)	Loss 0.3074 (0.2338)	Acc@1 92.188 (95.945)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:29:31 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.383 (0.465)	Loss 0.3735 (0.2715)	Acc@1 89.062 (94.002)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:29:37 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.060 Acc@5 100.000
[2024-11-09 15:29:37 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.1%
[2024-11-09 15:29:37 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.16%
[2024-11-09 15:29:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 8.268 (8.268)	Loss 0.2827 (0.2827)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:29:49 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.139 (1.082)	Loss 0.2900 (0.2928)	Acc@1 96.094 (95.810)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:29:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.296 (0.751)	Loss 0.4985 (0.3162)	Acc@1 77.344 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:29:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.171 (0.599)	Loss 0.5703 (0.3946)	Acc@1 70.312 (85.534)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:29:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 82.160 Acc@5 100.000
[2024-11-09 15:29:57 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 82.2%
[2024-11-09 15:29:57 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 82.16%
[2024-11-09 15:30:00 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][0/156]	eta 0:07:20 lr 0.000063	 wd 0.0500	time 2.8252 (2.8252)	data time 2.3662 (2.3662)	model time 0.0000 (0.0000)	loss 0.5979 (0.5979)	grad_norm 2.0572 (2.0572)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:05 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][10/156]	eta 0:01:42 lr 0.000063	 wd 0.0500	time 0.5573 (0.7045)	data time 0.0009 (0.2478)	model time 0.0000 (0.0000)	loss 0.6262 (0.5885)	grad_norm 1.1685 (1.9602)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:10 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][20/156]	eta 0:01:23 lr 0.000063	 wd 0.0500	time 0.4705 (0.6105)	data time 0.0247 (0.1397)	model time 0.0000 (0.0000)	loss 0.5344 (0.5913)	grad_norm 2.1209 (2.0960)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:16 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][30/156]	eta 0:01:16 lr 0.000063	 wd 0.0500	time 0.5399 (0.6083)	data time 0.0073 (0.1034)	model time 0.0000 (0.0000)	loss 0.5252 (0.5742)	grad_norm 2.2728 (2.1994)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:22 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][40/156]	eta 0:01:09 lr 0.000063	 wd 0.0500	time 0.5237 (0.5961)	data time 0.0915 (0.0869)	model time 0.0000 (0.0000)	loss 0.6022 (0.5787)	grad_norm 2.1153 (2.3222)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:27 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][50/156]	eta 0:01:01 lr 0.000063	 wd 0.0500	time 0.5334 (0.5825)	data time 0.0011 (0.0726)	model time 0.0000 (0.0000)	loss 0.5889 (0.5765)	grad_norm 1.7942 (2.3207)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:32 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][60/156]	eta 0:00:55 lr 0.000063	 wd 0.0500	time 0.6777 (0.5741)	data time 0.0381 (0.0640)	model time 0.6396 (0.5109)	loss 0.5020 (0.5739)	grad_norm 3.3970 (2.3703)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:37 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][70/156]	eta 0:00:48 lr 0.000063	 wd 0.0500	time 0.6102 (0.5635)	data time 0.0011 (0.0564)	model time 0.6091 (0.4999)	loss 0.4457 (0.5723)	grad_norm 3.4003 (2.4190)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:42 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][80/156]	eta 0:00:41 lr 0.000063	 wd 0.0500	time 0.4618 (0.5492)	data time 0.0182 (0.0511)	model time 0.4436 (0.4779)	loss 0.4983 (0.5729)	grad_norm 4.0646 (2.4853)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:46 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][90/156]	eta 0:00:35 lr 0.000063	 wd 0.0500	time 0.4100 (0.5399)	data time 0.0006 (0.0471)	model time 0.4094 (0.4710)	loss 0.6488 (0.5702)	grad_norm 2.0075 (2.5426)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:52 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][100/156]	eta 0:00:30 lr 0.000063	 wd 0.0500	time 0.6355 (0.5374)	data time 0.0029 (0.0436)	model time 0.6326 (0.4774)	loss 0.4876 (0.5669)	grad_norm 3.2095 (2.5904)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:30:57 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][110/156]	eta 0:00:24 lr 0.000063	 wd 0.0500	time 0.4816 (0.5357)	data time 0.0320 (0.0415)	model time 0.4496 (0.4808)	loss 0.4425 (0.5648)	grad_norm 4.6702 (2.5818)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:31:02 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][120/156]	eta 0:00:19 lr 0.000063	 wd 0.0500	time 0.5475 (0.5361)	data time 0.0531 (0.0390)	model time 0.4945 (0.4877)	loss 0.5314 (0.5649)	grad_norm 3.0155 (2.5793)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:31:07 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][130/156]	eta 0:00:13 lr 0.000063	 wd 0.0500	time 0.4385 (0.5341)	data time 0.0139 (0.0370)	model time 0.4247 (0.4888)	loss 0.6017 (0.5658)	grad_norm 2.0463 (2.5725)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:31:12 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][140/156]	eta 0:00:08 lr 0.000063	 wd 0.0500	time 0.4736 (0.5316)	data time 0.0009 (0.0350)	model time 0.4727 (0.4890)	loss 0.6168 (0.5663)	grad_norm 1.4480 (2.5608)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:31:17 vssm1_tiny_0230s](training.py 201): INFO Train: [160/300][150/156]	eta 0:00:03 lr 0.000062	 wd 0.0500	time 0.4199 (0.5283)	data time 0.0007 (0.0328)	model time 0.4192 (0.4882)	loss 0.5336 (0.5651)	grad_norm 2.8681 (2.5626)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:31:20 vssm1_tiny_0230s](training.py 212): INFO EPOCH 160 training takes 0:01:22
[2024-11-09 15:31:20 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_160.pth saving......
[2024-11-09 15:31:21 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_160.pth saved !!!
[2024-11-09 15:31:25 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.173 (4.173)	Loss 0.1967 (0.1967)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:31:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.523 (0.645)	Loss 0.2111 (0.2119)	Acc@1 95.312 (94.886)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:31:30 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.172 (0.463)	Loss 0.2031 (0.2254)	Acc@1 96.094 (93.862)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:31:33 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.390)	Loss 0.2664 (0.2327)	Acc@1 92.188 (93.700)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:31:36 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.800 Acc@5 100.000
[2024-11-09 15:31:36 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.8%
[2024-11-09 15:31:36 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.16%
[2024-11-09 15:31:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.098 (4.098)	Loss 0.2817 (0.2817)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:31:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.257 (0.640)	Loss 0.2891 (0.2919)	Acc@1 96.094 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:31:46 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.465)	Loss 0.4927 (0.3151)	Acc@1 77.344 (93.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:31:48 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.376)	Loss 0.5630 (0.3918)	Acc@1 71.094 (85.912)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:31:50 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 82.620 Acc@5 100.000
[2024-11-09 15:31:50 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 82.6%
[2024-11-09 15:31:50 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 82.62%
[2024-11-09 15:31:54 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][0/156]	eta 0:09:42 lr 0.000062	 wd 0.0500	time 3.7337 (3.7337)	data time 2.9035 (2.9035)	model time 0.0000 (0.0000)	loss 0.4508 (0.4508)	grad_norm 2.4807 (2.4807)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:31:59 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][10/156]	eta 0:01:53 lr 0.000062	 wd 0.0500	time 0.4421 (0.7794)	data time 0.0172 (0.2931)	model time 0.0000 (0.0000)	loss 0.6446 (0.5371)	grad_norm 3.5651 (3.0114)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:04 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][20/156]	eta 0:01:29 lr 0.000062	 wd 0.0500	time 0.5860 (0.6557)	data time 0.0006 (0.1632)	model time 0.0000 (0.0000)	loss 0.4811 (0.5397)	grad_norm 2.7738 (3.0195)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:09 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][30/156]	eta 0:01:17 lr 0.000062	 wd 0.0500	time 0.4726 (0.6113)	data time 0.0073 (0.1134)	model time 0.0000 (0.0000)	loss 0.5257 (0.5374)	grad_norm 3.9451 (2.9974)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:14 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][40/156]	eta 0:01:07 lr 0.000062	 wd 0.0500	time 0.4824 (0.5853)	data time 0.0009 (0.0887)	model time 0.0000 (0.0000)	loss 0.5941 (0.5418)	grad_norm 1.4925 (2.9807)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:19 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][50/156]	eta 0:01:00 lr 0.000062	 wd 0.0500	time 0.5617 (0.5694)	data time 0.0214 (0.0761)	model time 0.0000 (0.0000)	loss 0.6102 (0.5519)	grad_norm 1.5154 (2.8562)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:25 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][60/156]	eta 0:00:54 lr 0.000062	 wd 0.0500	time 0.6428 (0.5671)	data time 0.0029 (0.0669)	model time 0.6399 (0.5356)	loss 0.6251 (0.5532)	grad_norm 1.9026 (2.7873)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:30 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][70/156]	eta 0:00:47 lr 0.000062	 wd 0.0500	time 0.4072 (0.5545)	data time 0.0011 (0.0591)	model time 0.4061 (0.5008)	loss 0.4283 (0.5490)	grad_norm 2.2394 (2.7117)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:34 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][80/156]	eta 0:00:41 lr 0.000062	 wd 0.0500	time 0.4835 (0.5404)	data time 0.0009 (0.0528)	model time 0.4826 (0.4779)	loss 0.6017 (0.5513)	grad_norm 2.6868 (2.6648)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:39 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][90/156]	eta 0:00:35 lr 0.000062	 wd 0.0500	time 0.4493 (0.5386)	data time 0.0277 (0.0486)	model time 0.4217 (0.4859)	loss 0.6051 (0.5556)	grad_norm 4.1887 (2.6678)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:45 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][100/156]	eta 0:00:30 lr 0.000062	 wd 0.0500	time 0.4045 (0.5373)	data time 0.0006 (0.0446)	model time 0.4039 (0.4921)	loss 0.5479 (0.5602)	grad_norm 2.1146 (2.6830)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:50 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][110/156]	eta 0:00:24 lr 0.000062	 wd 0.0500	time 0.4736 (0.5348)	data time 0.0098 (0.0424)	model time 0.4638 (0.4917)	loss 0.5772 (0.5629)	grad_norm 2.1565 (2.6056)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:32:55 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][120/156]	eta 0:00:19 lr 0.000062	 wd 0.0500	time 0.4164 (0.5310)	data time 0.0006 (0.0405)	model time 0.4158 (0.4886)	loss 0.5925 (0.5650)	grad_norm 1.8130 (2.5518)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:33:00 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][130/156]	eta 0:00:13 lr 0.000062	 wd 0.0500	time 0.4555 (0.5281)	data time 0.0097 (0.0386)	model time 0.4458 (0.4871)	loss 0.6101 (0.5633)	grad_norm 1.7975 (2.5611)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:33:05 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][140/156]	eta 0:00:08 lr 0.000062	 wd 0.0500	time 0.5657 (0.5264)	data time 0.0007 (0.0375)	model time 0.5650 (0.4864)	loss 0.5841 (0.5633)	grad_norm 2.2834 (2.5898)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:33:10 vssm1_tiny_0230s](training.py 201): INFO Train: [161/300][150/156]	eta 0:00:03 lr 0.000062	 wd 0.0500	time 0.6057 (0.5253)	data time 0.0007 (0.0352)	model time 0.6050 (0.4884)	loss 0.6369 (0.5618)	grad_norm 1.9067 (2.5974)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:33:13 vssm1_tiny_0230s](training.py 212): INFO EPOCH 161 training takes 0:01:22
[2024-11-09 15:33:13 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_161.pth saving......
[2024-11-09 15:33:13 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_161.pth saved !!!
[2024-11-09 15:33:15 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.627 (2.627)	Loss 0.1962 (0.1962)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:33:19 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.162 (0.570)	Loss 0.2015 (0.2004)	Acc@1 95.312 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:33:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.407)	Loss 0.2003 (0.2139)	Acc@1 95.312 (94.308)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:33:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.299 (0.386)	Loss 0.2673 (0.2206)	Acc@1 91.406 (94.204)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:33:28 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.340 Acc@5 100.000
[2024-11-09 15:33:28 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.3%
[2024-11-09 15:33:28 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.34%
[2024-11-09 15:33:33 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.695 (4.695)	Loss 0.2808 (0.2808)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:33:35 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.525 (0.651)	Loss 0.2881 (0.2909)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:33:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.172 (0.459)	Loss 0.4871 (0.3139)	Acc@1 77.344 (93.341)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:33:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.165 (0.392)	Loss 0.5562 (0.3890)	Acc@1 72.656 (86.139)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:33:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 82.940 Acc@5 100.000
[2024-11-09 15:33:42 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 82.9%
[2024-11-09 15:33:42 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 82.94%
[2024-11-09 15:33:46 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][0/156]	eta 0:10:01 lr 0.000062	 wd 0.0500	time 3.8578 (3.8578)	data time 3.3474 (3.3474)	model time 0.0000 (0.0000)	loss 0.5757 (0.5757)	grad_norm 2.4500 (2.4500)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:33:52 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][10/156]	eta 0:02:04 lr 0.000062	 wd 0.0500	time 0.4264 (0.8508)	data time 0.0006 (0.3763)	model time 0.0000 (0.0000)	loss 0.5792 (0.5709)	grad_norm 2.4855 (2.7316)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:33:57 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][20/156]	eta 0:01:35 lr 0.000062	 wd 0.0500	time 0.7131 (0.7043)	data time 0.0344 (0.2091)	model time 0.0000 (0.0000)	loss 0.6041 (0.5581)	grad_norm 2.5489 (2.6626)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:02 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][30/156]	eta 0:01:20 lr 0.000062	 wd 0.0500	time 0.4714 (0.6356)	data time 0.0121 (0.1462)	model time 0.0000 (0.0000)	loss 0.5951 (0.5625)	grad_norm 2.4641 (2.7747)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:07 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][40/156]	eta 0:01:09 lr 0.000062	 wd 0.0500	time 0.4175 (0.5980)	data time 0.0033 (0.1141)	model time 0.0000 (0.0000)	loss 0.6062 (0.5618)	grad_norm 1.4718 (2.6069)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:12 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][50/156]	eta 0:01:01 lr 0.000062	 wd 0.0500	time 0.4346 (0.5763)	data time 0.0254 (0.0944)	model time 0.0000 (0.0000)	loss 0.5569 (0.5610)	grad_norm 2.1153 (2.6056)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:18 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][60/156]	eta 0:00:55 lr 0.000061	 wd 0.0500	time 0.5233 (0.5801)	data time 0.0040 (0.0825)	model time 0.5194 (0.5776)	loss 0.5498 (0.5609)	grad_norm 2.6555 (2.5914)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:23 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][70/156]	eta 0:00:49 lr 0.000061	 wd 0.0500	time 0.4412 (0.5717)	data time 0.0233 (0.0725)	model time 0.4179 (0.5432)	loss 0.4065 (0.5600)	grad_norm 2.4843 (2.5695)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:28 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][80/156]	eta 0:00:42 lr 0.000061	 wd 0.0500	time 0.5413 (0.5609)	data time 0.0096 (0.0656)	model time 0.5317 (0.5181)	loss 0.6287 (0.5634)	grad_norm 2.1421 (2.5625)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:33 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][90/156]	eta 0:00:36 lr 0.000061	 wd 0.0500	time 0.4719 (0.5535)	data time 0.0008 (0.0589)	model time 0.4711 (0.5107)	loss 0.5975 (0.5667)	grad_norm 2.2034 (2.5310)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:38 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][100/156]	eta 0:00:30 lr 0.000061	 wd 0.0500	time 0.4550 (0.5522)	data time 0.0066 (0.0541)	model time 0.4484 (0.5147)	loss 0.5819 (0.5641)	grad_norm 2.0007 (2.5222)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:44 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][110/156]	eta 0:00:25 lr 0.000061	 wd 0.0500	time 0.4401 (0.5506)	data time 0.0017 (0.0529)	model time 0.4384 (0.5111)	loss 0.4639 (0.5616)	grad_norm 3.2957 (2.5508)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:49 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][120/156]	eta 0:00:19 lr 0.000061	 wd 0.0500	time 0.4827 (0.5492)	data time 0.0165 (0.0505)	model time 0.4662 (0.5109)	loss 0.4860 (0.5611)	grad_norm 2.4137 (2.5476)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:54 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][130/156]	eta 0:00:14 lr 0.000061	 wd 0.0500	time 0.4490 (0.5454)	data time 0.0079 (0.0477)	model time 0.4411 (0.5078)	loss 0.5125 (0.5621)	grad_norm 2.0917 (2.5418)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:34:59 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][140/156]	eta 0:00:08 lr 0.000061	 wd 0.0500	time 0.5849 (0.5425)	data time 0.0009 (0.0454)	model time 0.5839 (0.5058)	loss 0.6021 (0.5610)	grad_norm 1.4347 (2.5360)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:35:04 vssm1_tiny_0230s](training.py 201): INFO Train: [162/300][150/156]	eta 0:00:03 lr 0.000061	 wd 0.0500	time 0.4284 (0.5400)	data time 0.0005 (0.0425)	model time 0.4279 (0.5054)	loss 0.4868 (0.5591)	grad_norm 4.3866 (2.5506)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:35:07 vssm1_tiny_0230s](training.py 212): INFO EPOCH 162 training takes 0:01:24
[2024-11-09 15:35:07 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_162.pth saving......
[2024-11-09 15:35:08 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_162.pth saved !!!
[2024-11-09 15:35:12 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.025 (4.025)	Loss 0.2037 (0.2037)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:35:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.187 (0.642)	Loss 0.2134 (0.2166)	Acc@1 95.312 (94.815)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:35:17 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.452)	Loss 0.1964 (0.2286)	Acc@1 96.875 (94.085)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:35:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.382)	Loss 0.2534 (0.2295)	Acc@1 92.969 (94.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:35:22 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.440 Acc@5 100.000
[2024-11-09 15:35:22 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.4%
[2024-11-09 15:35:22 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.44%
[2024-11-09 15:35:25 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.233 (3.233)	Loss 0.2795 (0.2795)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:35:27 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.186 (0.524)	Loss 0.2869 (0.2900)	Acc@1 96.094 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:35:30 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.387)	Loss 0.4812 (0.3127)	Acc@1 77.344 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:35:32 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.212 (0.342)	Loss 0.5493 (0.3861)	Acc@1 74.219 (86.467)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:35:35 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 83.320 Acc@5 100.000
[2024-11-09 15:35:35 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 83.3%
[2024-11-09 15:35:35 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 83.32%
[2024-11-09 15:35:38 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][0/156]	eta 0:09:57 lr 0.000061	 wd 0.0500	time 3.8276 (3.8276)	data time 3.2425 (3.2425)	model time 0.0000 (0.0000)	loss 0.5186 (0.5186)	grad_norm 4.5211 (4.5211)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:35:43 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][10/156]	eta 0:01:54 lr 0.000061	 wd 0.0500	time 0.4273 (0.7860)	data time 0.0008 (0.3125)	model time 0.0000 (0.0000)	loss 0.5604 (0.5905)	grad_norm 3.2516 (2.5009)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:35:47 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][20/156]	eta 0:01:23 lr 0.000061	 wd 0.0500	time 0.4143 (0.6165)	data time 0.0059 (0.1654)	model time 0.0000 (0.0000)	loss 0.6603 (0.5857)	grad_norm 2.2310 (2.5014)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:35:52 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][30/156]	eta 0:01:09 lr 0.000061	 wd 0.0500	time 0.4864 (0.5547)	data time 0.0006 (0.1125)	model time 0.0000 (0.0000)	loss 0.5131 (0.5743)	grad_norm 2.7368 (2.6310)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:35:57 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][40/156]	eta 0:01:02 lr 0.000061	 wd 0.0500	time 0.5232 (0.5407)	data time 0.0049 (0.0880)	model time 0.0000 (0.0000)	loss 0.4781 (0.5619)	grad_norm 2.3135 (2.5746)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:02 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][50/156]	eta 0:00:56 lr 0.000061	 wd 0.0500	time 0.4378 (0.5319)	data time 0.0024 (0.0739)	model time 0.0000 (0.0000)	loss 0.6226 (0.5615)	grad_norm 2.2013 (2.6330)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:07 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][60/156]	eta 0:00:51 lr 0.000061	 wd 0.0500	time 0.5084 (0.5327)	data time 0.0009 (0.0653)	model time 0.5075 (0.5159)	loss 0.6416 (0.5640)	grad_norm 2.8021 (2.6664)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:13 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][70/156]	eta 0:00:46 lr 0.000061	 wd 0.0500	time 0.7752 (0.5388)	data time 0.1481 (0.0609)	model time 0.6271 (0.5288)	loss 0.4866 (0.5609)	grad_norm 3.4286 (2.6432)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:18 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][80/156]	eta 0:00:40 lr 0.000061	 wd 0.0500	time 0.6174 (0.5345)	data time 0.0006 (0.0543)	model time 0.6168 (0.5179)	loss 0.4389 (0.5577)	grad_norm 1.6146 (2.6655)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:23 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][90/156]	eta 0:00:35 lr 0.000061	 wd 0.0500	time 0.4901 (0.5309)	data time 0.0029 (0.0495)	model time 0.4872 (0.5112)	loss 0.5244 (0.5548)	grad_norm 2.0085 (2.7092)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:28 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][100/156]	eta 0:00:29 lr 0.000061	 wd 0.0500	time 0.4466 (0.5267)	data time 0.0315 (0.0460)	model time 0.4151 (0.5040)	loss 0.5064 (0.5521)	grad_norm 3.2838 (2.7244)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:33 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][110/156]	eta 0:00:24 lr 0.000061	 wd 0.0500	time 0.5828 (0.5304)	data time 0.0031 (0.0436)	model time 0.5797 (0.5114)	loss 0.5609 (0.5485)	grad_norm 3.0366 (2.7038)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:38 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][120/156]	eta 0:00:19 lr 0.000061	 wd 0.0500	time 0.4591 (0.5279)	data time 0.0008 (0.0405)	model time 0.4583 (0.5089)	loss 0.5796 (0.5499)	grad_norm 3.4487 (2.6992)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:44 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][130/156]	eta 0:00:13 lr 0.000060	 wd 0.0500	time 0.6044 (0.5281)	data time 0.0159 (0.0386)	model time 0.5884 (0.5096)	loss 0.4644 (0.5495)	grad_norm 3.4375 (2.7034)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:49 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][140/156]	eta 0:00:08 lr 0.000060	 wd 0.0500	time 0.6131 (0.5290)	data time 0.0008 (0.0370)	model time 0.6123 (0.5113)	loss 0.5948 (0.5501)	grad_norm 2.5956 (2.6934)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:54 vssm1_tiny_0230s](training.py 201): INFO Train: [163/300][150/156]	eta 0:00:03 lr 0.000060	 wd 0.0500	time 0.4192 (0.5255)	data time 0.0007 (0.0349)	model time 0.4185 (0.5073)	loss 0.5825 (0.5512)	grad_norm 2.1652 (2.7042)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:36:57 vssm1_tiny_0230s](training.py 212): INFO EPOCH 163 training takes 0:01:22
[2024-11-09 15:36:57 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_163.pth saving......
[2024-11-09 15:36:57 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_163.pth saved !!!
[2024-11-09 15:37:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.214 (3.214)	Loss 0.2336 (0.2336)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:37:04 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.177 (0.576)	Loss 0.2581 (0.2435)	Acc@1 92.188 (94.389)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:37:07 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.255 (0.445)	Loss 0.2021 (0.2531)	Acc@1 96.875 (93.676)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:37:09 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.172 (0.366)	Loss 0.2603 (0.2474)	Acc@1 91.406 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:37:11 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.140 Acc@5 100.000
[2024-11-09 15:37:11 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.1%
[2024-11-09 15:37:11 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.44%
[2024-11-09 15:37:14 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.310 (3.310)	Loss 0.2778 (0.2778)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:37:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.302 (0.525)	Loss 0.2854 (0.2884)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:37:19 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.388)	Loss 0.4763 (0.3110)	Acc@1 78.906 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:37:21 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.331)	Loss 0.5435 (0.3832)	Acc@1 74.219 (86.643)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:37:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 83.700 Acc@5 100.000
[2024-11-09 15:37:24 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 83.7%
[2024-11-09 15:37:24 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 83.70%
[2024-11-09 15:37:28 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][0/156]	eta 0:11:32 lr 0.000060	 wd 0.0500	time 4.4395 (4.4395)	data time 4.0311 (4.0311)	model time 0.0000 (0.0000)	loss 0.5322 (0.5322)	grad_norm 2.5581 (2.5581)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:37:33 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][10/156]	eta 0:02:03 lr 0.000060	 wd 0.0500	time 0.4248 (0.8438)	data time 0.0031 (0.3752)	model time 0.0000 (0.0000)	loss 0.6336 (0.5805)	grad_norm 1.5804 (2.5209)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:37:38 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][20/156]	eta 0:01:32 lr 0.000060	 wd 0.0500	time 0.6768 (0.6816)	data time 0.0386 (0.2036)	model time 0.0000 (0.0000)	loss 0.6124 (0.5610)	grad_norm 2.0447 (2.4520)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:37:43 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][30/156]	eta 0:01:20 lr 0.000060	 wd 0.0500	time 0.5225 (0.6374)	data time 0.0065 (0.1432)	model time 0.0000 (0.0000)	loss 0.6443 (0.5752)	grad_norm 3.8770 (2.3917)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:37:48 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][40/156]	eta 0:01:09 lr 0.000060	 wd 0.0500	time 0.4610 (0.6024)	data time 0.0020 (0.1104)	model time 0.0000 (0.0000)	loss 0.5027 (0.5721)	grad_norm 2.7708 (2.3921)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:37:54 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][50/156]	eta 0:01:03 lr 0.000060	 wd 0.0500	time 0.4510 (0.5960)	data time 0.0121 (0.0935)	model time 0.0000 (0.0000)	loss 0.4792 (0.5709)	grad_norm 2.5615 (2.4051)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:00 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][60/156]	eta 0:00:56 lr 0.000060	 wd 0.0500	time 0.4633 (0.5891)	data time 0.0218 (0.0821)	model time 0.4415 (0.5301)	loss 0.5794 (0.5690)	grad_norm 3.0013 (2.4015)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:05 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][70/156]	eta 0:00:49 lr 0.000060	 wd 0.0500	time 0.6909 (0.5781)	data time 0.0035 (0.0730)	model time 0.6874 (0.5115)	loss 0.5132 (0.5695)	grad_norm 1.9336 (2.4304)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:09 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][80/156]	eta 0:00:43 lr 0.000060	 wd 0.0500	time 0.4730 (0.5658)	data time 0.0027 (0.0662)	model time 0.4703 (0.4949)	loss 0.6028 (0.5695)	grad_norm 3.0645 (2.5020)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:14 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][90/156]	eta 0:00:36 lr 0.000060	 wd 0.0500	time 0.4239 (0.5575)	data time 0.0010 (0.0599)	model time 0.4229 (0.4914)	loss 0.6768 (0.5671)	grad_norm 2.1285 (2.5144)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:19 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][100/156]	eta 0:00:30 lr 0.000060	 wd 0.0500	time 0.4942 (0.5516)	data time 0.0554 (0.0561)	model time 0.4388 (0.4883)	loss 0.5143 (0.5635)	grad_norm 1.7239 (2.5149)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:24 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][110/156]	eta 0:00:25 lr 0.000060	 wd 0.0500	time 0.4122 (0.5468)	data time 0.0007 (0.0525)	model time 0.4115 (0.4873)	loss 0.5637 (0.5609)	grad_norm 1.8303 (2.5213)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:30 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][120/156]	eta 0:00:19 lr 0.000060	 wd 0.0500	time 0.5127 (0.5452)	data time 0.0376 (0.0500)	model time 0.4752 (0.4899)	loss 0.6672 (0.5619)	grad_norm 4.2632 (2.5438)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:35 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][130/156]	eta 0:00:14 lr 0.000060	 wd 0.0500	time 0.4578 (0.5415)	data time 0.0007 (0.0471)	model time 0.4571 (0.4892)	loss 0.5136 (0.5635)	grad_norm 1.5944 (2.5782)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:40 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][140/156]	eta 0:00:08 lr 0.000060	 wd 0.0500	time 0.4400 (0.5415)	data time 0.0009 (0.0447)	model time 0.4391 (0.4936)	loss 0.5404 (0.5641)	grad_norm 2.2444 (2.5461)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:45 vssm1_tiny_0230s](training.py 201): INFO Train: [164/300][150/156]	eta 0:00:03 lr 0.000060	 wd 0.0500	time 0.6009 (0.5390)	data time 0.0006 (0.0419)	model time 0.6003 (0.4944)	loss 0.6002 (0.5644)	grad_norm 1.5054 (2.5325)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:38:48 vssm1_tiny_0230s](training.py 212): INFO EPOCH 164 training takes 0:01:24
[2024-11-09 15:38:48 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_164.pth saving......
[2024-11-09 15:38:49 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_164.pth saved !!!
[2024-11-09 15:38:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.646 (3.646)	Loss 0.2262 (0.2262)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:38:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.143 (0.653)	Loss 0.2354 (0.2280)	Acc@1 94.531 (94.815)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:38:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.458)	Loss 0.2090 (0.2396)	Acc@1 96.094 (94.048)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:39:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.378)	Loss 0.2637 (0.2427)	Acc@1 93.750 (94.128)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:39:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.220 Acc@5 100.000
[2024-11-09 15:39:03 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.2%
[2024-11-09 15:39:03 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.44%
[2024-11-09 15:39:05 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.989 (1.989)	Loss 0.2761 (0.2761)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:39:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.193 (0.589)	Loss 0.2839 (0.2869)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:39:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.179 (0.437)	Loss 0.4712 (0.3094)	Acc@1 78.906 (93.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:39:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.207 (0.401)	Loss 0.5371 (0.3803)	Acc@1 74.219 (86.744)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:39:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 83.900 Acc@5 100.000
[2024-11-09 15:39:17 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 83.9%
[2024-11-09 15:39:17 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 83.90%
[2024-11-09 15:39:22 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][0/156]	eta 0:14:48 lr 0.000060	 wd 0.0500	time 5.6957 (5.6957)	data time 5.0331 (5.0331)	model time 0.0000 (0.0000)	loss 0.5884 (0.5884)	grad_norm 1.4790 (1.4790)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:39:28 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][10/156]	eta 0:02:24 lr 0.000060	 wd 0.0500	time 0.4718 (0.9867)	data time 0.0189 (0.4723)	model time 0.0000 (0.0000)	loss 0.6212 (0.5438)	grad_norm 1.7403 (2.5751)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:39:33 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][20/156]	eta 0:01:42 lr 0.000060	 wd 0.0500	time 0.4560 (0.7515)	data time 0.0079 (0.2518)	model time 0.0000 (0.0000)	loss 0.5688 (0.5615)	grad_norm 1.9383 (2.3985)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:39:37 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][30/156]	eta 0:01:22 lr 0.000060	 wd 0.0500	time 0.4647 (0.6560)	data time 0.0022 (0.1733)	model time 0.0000 (0.0000)	loss 0.6314 (0.5492)	grad_norm 2.1545 (2.4632)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:39:43 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][40/156]	eta 0:01:13 lr 0.000059	 wd 0.0500	time 0.6888 (0.6368)	data time 0.0006 (0.1374)	model time 0.0000 (0.0000)	loss 0.4836 (0.5469)	grad_norm 3.0574 (2.4940)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:39:48 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][50/156]	eta 0:01:04 lr 0.000059	 wd 0.0500	time 0.4841 (0.6075)	data time 0.0407 (0.1130)	model time 0.0000 (0.0000)	loss 0.5916 (0.5503)	grad_norm 2.4488 (2.5505)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:39:53 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][60/156]	eta 0:00:57 lr 0.000059	 wd 0.0500	time 0.6216 (0.5970)	data time 0.0010 (0.0969)	model time 0.6206 (0.5283)	loss 0.5822 (0.5535)	grad_norm 2.4808 (2.5741)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:39:59 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][70/156]	eta 0:00:50 lr 0.000059	 wd 0.0500	time 0.5040 (0.5900)	data time 0.0020 (0.0855)	model time 0.5020 (0.5303)	loss 0.6215 (0.5559)	grad_norm 1.7089 (2.5262)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:40:04 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][80/156]	eta 0:00:44 lr 0.000059	 wd 0.0500	time 0.4082 (0.5874)	data time 0.0006 (0.0764)	model time 0.4076 (0.5392)	loss 0.4908 (0.5562)	grad_norm 2.3731 (2.4775)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:40:09 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][90/156]	eta 0:00:37 lr 0.000059	 wd 0.0500	time 0.4205 (0.5749)	data time 0.0028 (0.0695)	model time 0.4176 (0.5192)	loss 0.4807 (0.5559)	grad_norm 3.6519 (2.4864)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:40:14 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][100/156]	eta 0:00:31 lr 0.000059	 wd 0.0500	time 0.4475 (0.5666)	data time 0.0048 (0.0637)	model time 0.4427 (0.5115)	loss 0.6892 (0.5571)	grad_norm 2.8477 (2.5167)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:40:19 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][110/156]	eta 0:00:25 lr 0.000059	 wd 0.0500	time 0.4286 (0.5584)	data time 0.0171 (0.0587)	model time 0.4115 (0.5042)	loss 0.5542 (0.5596)	grad_norm 2.9302 (2.5077)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:40:24 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][120/156]	eta 0:00:19 lr 0.000059	 wd 0.0500	time 0.4430 (0.5532)	data time 0.0008 (0.0545)	model time 0.4422 (0.5017)	loss 0.6640 (0.5617)	grad_norm 2.1688 (2.5077)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:40:28 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][130/156]	eta 0:00:14 lr 0.000059	 wd 0.0500	time 0.5577 (0.5476)	data time 0.0057 (0.0514)	model time 0.5520 (0.4974)	loss 0.5288 (0.5621)	grad_norm 2.4289 (2.4938)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:40:33 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][140/156]	eta 0:00:08 lr 0.000059	 wd 0.0500	time 0.4340 (0.5438)	data time 0.0008 (0.0484)	model time 0.4332 (0.4958)	loss 0.4187 (0.5596)	grad_norm 3.5361 (2.5084)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:40:38 vssm1_tiny_0230s](training.py 201): INFO Train: [165/300][150/156]	eta 0:00:03 lr 0.000059	 wd 0.0500	time 0.4771 (0.5392)	data time 0.0005 (0.0453)	model time 0.4766 (0.4937)	loss 0.5120 (0.5571)	grad_norm 3.3654 (2.5309)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:40:41 vssm1_tiny_0230s](training.py 212): INFO EPOCH 165 training takes 0:01:24
[2024-11-09 15:40:41 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_165.pth saving......
[2024-11-09 15:40:42 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_165.pth saved !!!
[2024-11-09 15:40:46 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.691 (3.691)	Loss 0.2112 (0.2112)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:40:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.681)	Loss 0.2198 (0.2122)	Acc@1 96.094 (93.963)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:40:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.153 (0.510)	Loss 0.1617 (0.2228)	Acc@1 96.875 (93.192)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:40:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.176 (0.412)	Loss 0.2339 (0.2164)	Acc@1 93.750 (93.700)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:40:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.840 Acc@5 100.000
[2024-11-09 15:40:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.8%
[2024-11-09 15:40:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.44%
[2024-11-09 15:41:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.511 (2.511)	Loss 0.2747 (0.2747)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:41:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.152 (0.455)	Loss 0.2827 (0.2856)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:41:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.162 (0.354)	Loss 0.4656 (0.3079)	Acc@1 78.906 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:41:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.229 (0.334)	Loss 0.5308 (0.3774)	Acc@1 74.219 (86.870)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:41:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 84.100 Acc@5 100.000
[2024-11-09 15:41:10 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 84.1%
[2024-11-09 15:41:10 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 84.10%
[2024-11-09 15:41:15 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][0/156]	eta 0:11:10 lr 0.000059	 wd 0.0500	time 4.2968 (4.2968)	data time 3.8327 (3.8327)	model time 0.0000 (0.0000)	loss 0.5944 (0.5944)	grad_norm 2.4673 (2.4673)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:41:20 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][10/156]	eta 0:02:03 lr 0.000059	 wd 0.0500	time 0.4384 (0.8449)	data time 0.0007 (0.3515)	model time 0.0000 (0.0000)	loss 0.6103 (0.5338)	grad_norm 2.6663 (3.2743)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:41:25 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][20/156]	eta 0:01:32 lr 0.000059	 wd 0.0500	time 0.4138 (0.6811)	data time 0.0022 (0.1909)	model time 0.0000 (0.0000)	loss 0.5322 (0.5478)	grad_norm 2.2221 (3.1088)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:41:29 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][30/156]	eta 0:01:17 lr 0.000059	 wd 0.0500	time 0.5455 (0.6148)	data time 0.0009 (0.1336)	model time 0.0000 (0.0000)	loss 0.5542 (0.5617)	grad_norm 2.1247 (2.9409)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:41:35 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][40/156]	eta 0:01:09 lr 0.000059	 wd 0.0500	time 0.4651 (0.6006)	data time 0.0224 (0.1088)	model time 0.0000 (0.0000)	loss 0.4388 (0.5575)	grad_norm 2.1301 (2.7341)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:41:40 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][50/156]	eta 0:01:01 lr 0.000059	 wd 0.0500	time 0.5417 (0.5799)	data time 0.0183 (0.0899)	model time 0.0000 (0.0000)	loss 0.5229 (0.5600)	grad_norm 3.4105 (2.6897)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 15:41:45 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][60/156]	eta 0:00:54 lr 0.000059	 wd 0.0500	time 0.4853 (0.5667)	data time 0.0061 (0.0785)	model time 0.4791 (0.4790)	loss 0.5260 (0.5557)	grad_norm 2.7614 (2.6447)	loss_scale 65536.0000 (35991.0820)	mem 13675MB
[2024-11-09 15:41:50 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][70/156]	eta 0:00:48 lr 0.000059	 wd 0.0500	time 0.4553 (0.5599)	data time 0.0208 (0.0688)	model time 0.4345 (0.4940)	loss 0.6296 (0.5581)	grad_norm 2.1960 (2.5905)	loss_scale 65536.0000 (40152.3380)	mem 13675MB
[2024-11-09 15:41:55 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][80/156]	eta 0:00:42 lr 0.000059	 wd 0.0500	time 0.5616 (0.5543)	data time 0.0255 (0.0620)	model time 0.5361 (0.4963)	loss 0.5452 (0.5557)	grad_norm 3.0177 (2.5866)	loss_scale 65536.0000 (43286.1235)	mem 13675MB
[2024-11-09 15:42:01 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][90/156]	eta 0:00:36 lr 0.000059	 wd 0.0500	time 0.4293 (0.5507)	data time 0.0171 (0.0583)	model time 0.4122 (0.4953)	loss 0.5066 (0.5534)	grad_norm 2.1667 (2.5725)	loss_scale 65536.0000 (45731.1648)	mem 13675MB
[2024-11-09 15:42:06 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][100/156]	eta 0:00:30 lr 0.000059	 wd 0.0500	time 0.6214 (0.5487)	data time 0.0007 (0.0543)	model time 0.6208 (0.4988)	loss 0.5676 (0.5542)	grad_norm 2.7878 (2.6164)	loss_scale 65536.0000 (47692.0396)	mem 13675MB
[2024-11-09 15:42:11 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][110/156]	eta 0:00:25 lr 0.000058	 wd 0.0500	time 0.4348 (0.5469)	data time 0.0070 (0.0508)	model time 0.4278 (0.5012)	loss 0.5714 (0.5552)	grad_norm 2.4264 (2.6652)	loss_scale 65536.0000 (49299.6036)	mem 13675MB
[2024-11-09 15:42:16 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][120/156]	eta 0:00:19 lr 0.000058	 wd 0.0500	time 0.5663 (0.5436)	data time 0.0379 (0.0483)	model time 0.5284 (0.4993)	loss 0.4913 (0.5550)	grad_norm 2.9734 (2.6638)	loss_scale 65536.0000 (50641.4545)	mem 13675MB
[2024-11-09 15:42:21 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][130/156]	eta 0:00:14 lr 0.000058	 wd 0.0500	time 0.5311 (0.5398)	data time 0.0164 (0.0453)	model time 0.5148 (0.4974)	loss 0.6117 (0.5561)	grad_norm 1.7010 (2.6227)	loss_scale 65536.0000 (51778.4427)	mem 13675MB
[2024-11-09 15:42:26 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][140/156]	eta 0:00:08 lr 0.000058	 wd 0.0500	time 0.4115 (0.5360)	data time 0.0008 (0.0434)	model time 0.4108 (0.4941)	loss 0.5688 (0.5559)	grad_norm 3.1425 (2.6071)	loss_scale 65536.0000 (52754.1560)	mem 13675MB
[2024-11-09 15:42:31 vssm1_tiny_0230s](training.py 201): INFO Train: [166/300][150/156]	eta 0:00:03 lr 0.000058	 wd 0.0500	time 0.4997 (0.5340)	data time 0.0004 (0.0407)	model time 0.4993 (0.4949)	loss 0.4471 (0.5552)	grad_norm 1.5661 (2.5668)	loss_scale 65536.0000 (53600.6358)	mem 13675MB
[2024-11-09 15:42:34 vssm1_tiny_0230s](training.py 212): INFO EPOCH 166 training takes 0:01:23
[2024-11-09 15:42:34 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_166.pth saving......
[2024-11-09 15:42:35 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_166.pth saved !!!
[2024-11-09 15:42:39 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.994 (3.994)	Loss 0.2162 (0.2162)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:42:41 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.228 (0.613)	Loss 0.2126 (0.2144)	Acc@1 95.312 (94.886)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:42:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.243 (0.409)	Loss 0.1871 (0.2269)	Acc@1 96.875 (94.122)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:42:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.353)	Loss 0.2583 (0.2302)	Acc@1 92.188 (93.952)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:42:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.000 Acc@5 100.000
[2024-11-09 15:42:48 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.0%
[2024-11-09 15:42:48 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.44%
[2024-11-09 15:42:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.202 (4.202)	Loss 0.2732 (0.2732)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:42:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.169 (0.615)	Loss 0.2812 (0.2842)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:42:57 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.155 (0.408)	Loss 0.4602 (0.3062)	Acc@1 78.906 (93.266)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:43:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.385)	Loss 0.5249 (0.3744)	Acc@1 74.219 (86.971)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:43:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 84.260 Acc@5 100.000
[2024-11-09 15:43:02 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 84.3%
[2024-11-09 15:43:02 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 84.26%
[2024-11-09 15:43:07 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][0/156]	eta 0:12:54 lr 0.000058	 wd 0.0500	time 4.9637 (4.9637)	data time 4.3513 (4.3513)	model time 0.0000 (0.0000)	loss 0.5688 (0.5688)	grad_norm 2.8350 (2.8350)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:43:12 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][10/156]	eta 0:02:15 lr 0.000058	 wd 0.0500	time 0.6332 (0.9252)	data time 0.0011 (0.4091)	model time 0.0000 (0.0000)	loss 0.6546 (0.5540)	grad_norm 1.8731 (2.7103)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:43:17 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][20/156]	eta 0:01:37 lr 0.000058	 wd 0.0500	time 0.5624 (0.7202)	data time 0.0144 (0.2195)	model time 0.0000 (0.0000)	loss 0.5244 (0.5507)	grad_norm 2.8545 (2.7479)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:43:23 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][30/156]	eta 0:01:24 lr 0.000058	 wd 0.0500	time 0.4201 (0.6736)	data time 0.0017 (0.1524)	model time 0.0000 (0.0000)	loss 0.6059 (0.5523)	grad_norm 1.9091 (2.6085)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:43:28 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][40/156]	eta 0:01:13 lr 0.000058	 wd 0.0500	time 0.4494 (0.6324)	data time 0.0115 (0.1192)	model time 0.0000 (0.0000)	loss 0.4491 (0.5498)	grad_norm 1.8473 (2.6809)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:43:33 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][50/156]	eta 0:01:04 lr 0.000058	 wd 0.0500	time 0.4259 (0.6073)	data time 0.0153 (0.0993)	model time 0.0000 (0.0000)	loss 0.5441 (0.5523)	grad_norm 1.7201 (2.5839)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:43:38 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][60/156]	eta 0:00:57 lr 0.000058	 wd 0.0500	time 0.4495 (0.5953)	data time 0.0009 (0.0866)	model time 0.4487 (0.5125)	loss 0.4555 (0.5567)	grad_norm 3.7093 (2.5918)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:43:44 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][70/156]	eta 0:00:50 lr 0.000058	 wd 0.0500	time 0.4354 (0.5821)	data time 0.0087 (0.0765)	model time 0.4267 (0.4996)	loss 0.5941 (0.5522)	grad_norm 3.0984 (2.5640)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:43:49 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][80/156]	eta 0:00:43 lr 0.000058	 wd 0.0500	time 0.5950 (0.5734)	data time 0.0076 (0.0681)	model time 0.5873 (0.5010)	loss 0.6244 (0.5519)	grad_norm 1.6816 (2.5058)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:43:53 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][90/156]	eta 0:00:37 lr 0.000058	 wd 0.0500	time 0.4691 (0.5639)	data time 0.0125 (0.0635)	model time 0.4566 (0.4909)	loss 0.4480 (0.5516)	grad_norm 1.6300 (2.4745)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:43:59 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][100/156]	eta 0:00:31 lr 0.000058	 wd 0.0500	time 0.4377 (0.5596)	data time 0.0182 (0.0587)	model time 0.4194 (0.4938)	loss 0.6151 (0.5535)	grad_norm 2.9314 (2.4507)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:44:04 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][110/156]	eta 0:00:25 lr 0.000058	 wd 0.0500	time 0.4571 (0.5555)	data time 0.0237 (0.0548)	model time 0.4334 (0.4946)	loss 0.5308 (0.5498)	grad_norm 2.5901 (2.4904)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:44:09 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][120/156]	eta 0:00:19 lr 0.000058	 wd 0.0500	time 0.5782 (0.5553)	data time 0.0166 (0.0517)	model time 0.5616 (0.5004)	loss 0.5946 (0.5525)	grad_norm 2.9383 (2.5163)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:44:14 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][130/156]	eta 0:00:14 lr 0.000058	 wd 0.0500	time 0.6237 (0.5511)	data time 0.0555 (0.0490)	model time 0.5682 (0.4985)	loss 0.5260 (0.5539)	grad_norm 3.1562 (2.5071)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:44:19 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][140/156]	eta 0:00:08 lr 0.000058	 wd 0.0500	time 0.4189 (0.5470)	data time 0.0009 (0.0465)	model time 0.4180 (0.4963)	loss 0.6328 (0.5549)	grad_norm 2.6395 (2.5008)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:44:25 vssm1_tiny_0230s](training.py 201): INFO Train: [167/300][150/156]	eta 0:00:03 lr 0.000058	 wd 0.0500	time 0.5594 (0.5453)	data time 0.0005 (0.0437)	model time 0.5589 (0.4983)	loss 0.4862 (0.5547)	grad_norm 2.9768 (2.5039)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:44:28 vssm1_tiny_0230s](training.py 212): INFO EPOCH 167 training takes 0:01:25
[2024-11-09 15:44:28 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_167.pth saving......
[2024-11-09 15:44:28 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_167.pth saved !!!
[2024-11-09 15:44:32 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.887 (3.887)	Loss 0.2347 (0.2347)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:44:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.155 (0.525)	Loss 0.2512 (0.2356)	Acc@1 93.750 (94.673)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:44:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.397)	Loss 0.1949 (0.2457)	Acc@1 96.094 (94.122)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:44:39 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.198 (0.344)	Loss 0.2642 (0.2414)	Acc@1 92.188 (94.254)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:44:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.460 Acc@5 100.000
[2024-11-09 15:44:40 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.5%
[2024-11-09 15:44:40 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.46%
[2024-11-09 15:44:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.900 (3.900)	Loss 0.2720 (0.2720)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:44:47 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.582)	Loss 0.2800 (0.2830)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:44:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.202 (0.434)	Loss 0.4543 (0.3048)	Acc@1 78.906 (93.229)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:44:52 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.183 (0.371)	Loss 0.5181 (0.3715)	Acc@1 75.000 (87.273)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:44:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 84.600 Acc@5 100.000
[2024-11-09 15:44:55 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 84.6%
[2024-11-09 15:44:55 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 84.60%
[2024-11-09 15:44:59 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][0/156]	eta 0:09:17 lr 0.000058	 wd 0.0500	time 3.5726 (3.5726)	data time 2.9331 (2.9331)	model time 0.0000 (0.0000)	loss 0.5430 (0.5430)	grad_norm 2.8946 (2.8946)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:04 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][10/156]	eta 0:02:02 lr 0.000058	 wd 0.0500	time 0.4859 (0.8372)	data time 0.0008 (0.3268)	model time 0.0000 (0.0000)	loss 0.4798 (0.5713)	grad_norm 2.5735 (2.7216)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:09 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][20/156]	eta 0:01:31 lr 0.000057	 wd 0.0500	time 0.5826 (0.6739)	data time 0.0037 (0.1820)	model time 0.0000 (0.0000)	loss 0.4591 (0.5614)	grad_norm 2.9566 (2.6874)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:14 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][30/156]	eta 0:01:17 lr 0.000057	 wd 0.0500	time 0.5551 (0.6182)	data time 0.0587 (0.1288)	model time 0.0000 (0.0000)	loss 0.5694 (0.5600)	grad_norm 2.4284 (2.8705)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:19 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][40/156]	eta 0:01:06 lr 0.000057	 wd 0.0500	time 0.4117 (0.5750)	data time 0.0022 (0.0998)	model time 0.0000 (0.0000)	loss 0.6801 (0.5610)	grad_norm 1.8207 (2.7324)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:23 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][50/156]	eta 0:00:58 lr 0.000057	 wd 0.0500	time 0.4569 (0.5565)	data time 0.0471 (0.0827)	model time 0.0000 (0.0000)	loss 0.5725 (0.5631)	grad_norm 1.5737 (2.7239)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:29 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][60/156]	eta 0:00:52 lr 0.000057	 wd 0.0500	time 0.5137 (0.5513)	data time 0.0212 (0.0723)	model time 0.4925 (0.5057)	loss 0.5114 (0.5608)	grad_norm 1.4731 (2.6233)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:34 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][70/156]	eta 0:00:47 lr 0.000057	 wd 0.0500	time 0.6649 (0.5483)	data time 0.0169 (0.0647)	model time 0.6480 (0.5089)	loss 0.4985 (0.5619)	grad_norm 2.1751 (2.6072)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:40 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][80/156]	eta 0:00:42 lr 0.000057	 wd 0.0500	time 0.4449 (0.5533)	data time 0.0243 (0.0606)	model time 0.4207 (0.5250)	loss 0.6713 (0.5665)	grad_norm 3.2833 (2.5999)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:46 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][90/156]	eta 0:00:37 lr 0.000057	 wd 0.0500	time 0.6609 (0.5616)	data time 0.0209 (0.0558)	model time 0.6400 (0.5466)	loss 0.6261 (0.5639)	grad_norm 2.8138 (2.6172)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:52 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][100/156]	eta 0:00:31 lr 0.000057	 wd 0.0500	time 0.4180 (0.5603)	data time 0.0004 (0.0519)	model time 0.4175 (0.5437)	loss 0.6426 (0.5661)	grad_norm 1.5196 (2.5804)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:45:57 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][110/156]	eta 0:00:25 lr 0.000057	 wd 0.0500	time 0.4497 (0.5582)	data time 0.0006 (0.0489)	model time 0.4491 (0.5396)	loss 0.5474 (0.5633)	grad_norm 1.6632 (2.5405)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:46:02 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][120/156]	eta 0:00:19 lr 0.000057	 wd 0.0500	time 0.4889 (0.5545)	data time 0.0007 (0.0461)	model time 0.4882 (0.5337)	loss 0.6148 (0.5653)	grad_norm 1.8983 (2.5215)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:46:07 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][130/156]	eta 0:00:14 lr 0.000057	 wd 0.0500	time 0.4735 (0.5509)	data time 0.0203 (0.0440)	model time 0.4533 (0.5279)	loss 0.5984 (0.5642)	grad_norm 1.6895 (2.4925)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:46:12 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][140/156]	eta 0:00:08 lr 0.000057	 wd 0.0500	time 0.5854 (0.5487)	data time 0.0010 (0.0412)	model time 0.5844 (0.5266)	loss 0.5463 (0.5658)	grad_norm 2.2069 (2.4807)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:46:17 vssm1_tiny_0230s](training.py 201): INFO Train: [168/300][150/156]	eta 0:00:03 lr 0.000057	 wd 0.0500	time 0.5309 (0.5456)	data time 0.0005 (0.0385)	model time 0.5304 (0.5241)	loss 0.5855 (0.5637)	grad_norm 1.8113 (2.5136)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:46:20 vssm1_tiny_0230s](training.py 212): INFO EPOCH 168 training takes 0:01:25
[2024-11-09 15:46:20 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_168.pth saving......
[2024-11-09 15:46:20 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_168.pth saved !!!
[2024-11-09 15:46:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.782 (3.782)	Loss 0.2297 (0.2297)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:46:26 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.551)	Loss 0.2303 (0.2249)	Acc@1 96.094 (94.886)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:46:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.389)	Loss 0.2032 (0.2377)	Acc@1 98.438 (93.899)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:46:31 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.156 (0.339)	Loss 0.2664 (0.2381)	Acc@1 93.750 (94.405)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:46:33 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.560 Acc@5 100.000
[2024-11-09 15:46:33 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.6%
[2024-11-09 15:46:33 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.56%
[2024-11-09 15:46:36 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.440 (2.440)	Loss 0.2703 (0.2703)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:46:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.174 (0.495)	Loss 0.2786 (0.2815)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:46:41 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.144 (0.349)	Loss 0.4492 (0.3031)	Acc@1 80.469 (93.229)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:46:45 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.920 (0.360)	Loss 0.5122 (0.3685)	Acc@1 75.000 (87.450)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:46:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 84.920 Acc@5 100.000
[2024-11-09 15:46:48 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 84.9%
[2024-11-09 15:46:48 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 84.92%
[2024-11-09 15:46:52 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][0/156]	eta 0:09:47 lr 0.000057	 wd 0.0500	time 3.7635 (3.7635)	data time 3.2911 (3.2911)	model time 0.0000 (0.0000)	loss 0.5461 (0.5461)	grad_norm 2.3492 (2.3492)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:46:57 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][10/156]	eta 0:01:58 lr 0.000057	 wd 0.0500	time 0.4109 (0.8097)	data time 0.0007 (0.3372)	model time 0.0000 (0.0000)	loss 0.6385 (0.5928)	grad_norm 2.6518 (2.7144)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:02 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][20/156]	eta 0:01:31 lr 0.000057	 wd 0.0500	time 0.5591 (0.6718)	data time 0.0054 (0.1902)	model time 0.0000 (0.0000)	loss 0.5769 (0.5778)	grad_norm 1.8482 (2.6982)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:07 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][30/156]	eta 0:01:18 lr 0.000057	 wd 0.0500	time 0.5266 (0.6220)	data time 0.0271 (0.1370)	model time 0.0000 (0.0000)	loss 0.6098 (0.5711)	grad_norm 2.6685 (2.5366)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:12 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][40/156]	eta 0:01:07 lr 0.000057	 wd 0.0500	time 0.4669 (0.5852)	data time 0.0145 (0.1064)	model time 0.0000 (0.0000)	loss 0.4685 (0.5639)	grad_norm 2.3887 (2.6629)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:17 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][50/156]	eta 0:00:59 lr 0.000057	 wd 0.0500	time 0.4134 (0.5632)	data time 0.0045 (0.0885)	model time 0.0000 (0.0000)	loss 0.6244 (0.5633)	grad_norm 1.5751 (2.6097)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:21 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][60/156]	eta 0:00:52 lr 0.000057	 wd 0.0500	time 0.4349 (0.5436)	data time 0.0145 (0.0756)	model time 0.4204 (0.4345)	loss 0.6639 (0.5667)	grad_norm 3.1616 (2.6496)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:26 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][70/156]	eta 0:00:45 lr 0.000057	 wd 0.0500	time 0.5104 (0.5315)	data time 0.0006 (0.0653)	model time 0.5098 (0.4447)	loss 0.5042 (0.5658)	grad_norm 1.8796 (2.5750)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:31 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][80/156]	eta 0:00:40 lr 0.000057	 wd 0.0500	time 0.4774 (0.5264)	data time 0.0046 (0.0590)	model time 0.4728 (0.4551)	loss 0.6160 (0.5670)	grad_norm 2.0922 (2.5506)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:36 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][90/156]	eta 0:00:34 lr 0.000056	 wd 0.0500	time 0.4801 (0.5247)	data time 0.0009 (0.0543)	model time 0.4791 (0.4649)	loss 0.4991 (0.5674)	grad_norm 2.2760 (2.5297)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:40 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][100/156]	eta 0:00:29 lr 0.000056	 wd 0.0500	time 0.4361 (0.5191)	data time 0.0145 (0.0497)	model time 0.4216 (0.4640)	loss 0.4769 (0.5675)	grad_norm 2.3059 (2.5167)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:46 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][110/156]	eta 0:00:23 lr 0.000056	 wd 0.0500	time 0.4645 (0.5195)	data time 0.0064 (0.0468)	model time 0.4581 (0.4712)	loss 0.5017 (0.5656)	grad_norm 3.0447 (2.5075)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:51 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][120/156]	eta 0:00:18 lr 0.000056	 wd 0.0500	time 0.4927 (0.5201)	data time 0.0250 (0.0447)	model time 0.4678 (0.4760)	loss 0.5965 (0.5635)	grad_norm 1.3697 (2.5296)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:47:56 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][130/156]	eta 0:00:13 lr 0.000056	 wd 0.0500	time 0.4372 (0.5180)	data time 0.0271 (0.0421)	model time 0.4101 (0.4767)	loss 0.5304 (0.5620)	grad_norm 2.6336 (2.5391)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:48:01 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][140/156]	eta 0:00:08 lr 0.000056	 wd 0.0500	time 0.5636 (0.5198)	data time 0.0008 (0.0398)	model time 0.5628 (0.4830)	loss 0.5036 (0.5622)	grad_norm 3.5424 (2.5473)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:48:06 vssm1_tiny_0230s](training.py 201): INFO Train: [169/300][150/156]	eta 0:00:03 lr 0.000056	 wd 0.0500	time 0.4360 (0.5192)	data time 0.0007 (0.0377)	model time 0.4353 (0.4851)	loss 0.5437 (0.5631)	grad_norm 2.4592 (2.5294)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:48:09 vssm1_tiny_0230s](training.py 212): INFO EPOCH 169 training takes 0:01:21
[2024-11-09 15:48:09 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_169.pth saving......
[2024-11-09 15:48:10 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_169.pth saved !!!
[2024-11-09 15:48:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.729 (3.729)	Loss 0.2106 (0.2106)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:48:16 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.155 (0.604)	Loss 0.2234 (0.2120)	Acc@1 94.531 (95.810)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:48:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.211 (0.417)	Loss 0.2317 (0.2248)	Acc@1 95.312 (94.829)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:48:21 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.376)	Loss 0.2876 (0.2362)	Acc@1 92.969 (94.783)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:48:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.660 Acc@5 100.000
[2024-11-09 15:48:24 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.7%
[2024-11-09 15:48:24 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 15:48:28 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.586 (3.586)	Loss 0.2693 (0.2693)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:48:29 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.167 (0.486)	Loss 0.2776 (0.2806)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:48:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.167 (0.364)	Loss 0.4431 (0.3020)	Acc@1 80.469 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:48:34 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.322)	Loss 0.5054 (0.3657)	Acc@1 75.000 (87.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:48:37 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 85.140 Acc@5 100.000
[2024-11-09 15:48:37 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 85.1%
[2024-11-09 15:48:37 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 85.14%
[2024-11-09 15:48:42 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][0/156]	eta 0:13:30 lr 0.000056	 wd 0.0500	time 5.1965 (5.1965)	data time 4.6130 (4.6130)	model time 0.0000 (0.0000)	loss 0.5548 (0.5548)	grad_norm 2.5663 (2.5663)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:48:48 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][10/156]	eta 0:02:25 lr 0.000056	 wd 0.0500	time 0.4821 (0.9941)	data time 0.0220 (0.4475)	model time 0.0000 (0.0000)	loss 0.5762 (0.5680)	grad_norm 2.5757 (2.3256)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:48:53 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][20/156]	eta 0:01:44 lr 0.000056	 wd 0.0500	time 0.4852 (0.7688)	data time 0.0127 (0.2479)	model time 0.0000 (0.0000)	loss 0.6338 (0.5764)	grad_norm 2.0129 (2.4346)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:48:59 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][30/156]	eta 0:01:28 lr 0.000056	 wd 0.0500	time 0.6212 (0.7045)	data time 0.0155 (0.1721)	model time 0.0000 (0.0000)	loss 0.6237 (0.5757)	grad_norm 3.6730 (2.4732)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:04 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][40/156]	eta 0:01:16 lr 0.000056	 wd 0.0500	time 0.4796 (0.6556)	data time 0.0154 (0.1360)	model time 0.0000 (0.0000)	loss 0.6237 (0.5730)	grad_norm 2.5777 (2.4511)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:10 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][50/156]	eta 0:01:07 lr 0.000056	 wd 0.0500	time 0.6010 (0.6412)	data time 0.0531 (0.1131)	model time 0.0000 (0.0000)	loss 0.6872 (0.5753)	grad_norm 2.1596 (2.4742)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:15 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][60/156]	eta 0:00:59 lr 0.000056	 wd 0.0500	time 0.5127 (0.6215)	data time 0.0010 (0.0975)	model time 0.5117 (0.5031)	loss 0.6365 (0.5734)	grad_norm 3.0934 (2.5019)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:20 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][70/156]	eta 0:00:52 lr 0.000056	 wd 0.0500	time 0.4531 (0.6092)	data time 0.0199 (0.0864)	model time 0.4332 (0.5094)	loss 0.5738 (0.5713)	grad_norm 2.8818 (2.5352)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:26 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][80/156]	eta 0:00:46 lr 0.000056	 wd 0.0500	time 0.4804 (0.6060)	data time 0.0006 (0.0765)	model time 0.4799 (0.5320)	loss 0.4952 (0.5705)	grad_norm 1.3273 (2.5393)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:31 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][90/156]	eta 0:00:39 lr 0.000056	 wd 0.0500	time 0.4530 (0.5963)	data time 0.0007 (0.0696)	model time 0.4524 (0.5249)	loss 0.4522 (0.5672)	grad_norm 4.4116 (2.5451)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:36 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][100/156]	eta 0:00:33 lr 0.000056	 wd 0.0500	time 0.5159 (0.5894)	data time 0.0147 (0.0636)	model time 0.5012 (0.5235)	loss 0.5236 (0.5656)	grad_norm 2.6318 (2.5657)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:41 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][110/156]	eta 0:00:26 lr 0.000056	 wd 0.0500	time 0.5961 (0.5804)	data time 0.0053 (0.0595)	model time 0.5908 (0.5149)	loss 0.6210 (0.5641)	grad_norm 1.8998 (2.5729)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:47 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][120/156]	eta 0:00:20 lr 0.000056	 wd 0.0500	time 0.5535 (0.5769)	data time 0.0360 (0.0564)	model time 0.5176 (0.5148)	loss 0.4234 (0.5584)	grad_norm 4.4893 (2.6043)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:52 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][130/156]	eta 0:00:14 lr 0.000056	 wd 0.0500	time 0.5019 (0.5735)	data time 0.0180 (0.0531)	model time 0.4839 (0.5156)	loss 0.6034 (0.5593)	grad_norm 1.8957 (2.6114)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:49:57 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][140/156]	eta 0:00:09 lr 0.000056	 wd 0.0500	time 0.4535 (0.5664)	data time 0.0009 (0.0505)	model time 0.4526 (0.5090)	loss 0.5755 (0.5611)	grad_norm 2.4607 (2.5860)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:50:02 vssm1_tiny_0230s](training.py 201): INFO Train: [170/300][150/156]	eta 0:00:03 lr 0.000056	 wd 0.0500	time 0.4114 (0.5615)	data time 0.0007 (0.0475)	model time 0.4107 (0.5069)	loss 0.5324 (0.5628)	grad_norm 2.7892 (2.5727)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:50:04 vssm1_tiny_0230s](training.py 212): INFO EPOCH 170 training takes 0:01:27
[2024-11-09 15:50:04 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_170.pth saving......
[2024-11-09 15:50:05 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_170.pth saved !!!
[2024-11-09 15:50:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.349 (2.349)	Loss 0.2502 (0.2502)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:50:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.368)	Loss 0.2654 (0.2598)	Acc@1 94.531 (95.099)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:50:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.262)	Loss 0.2170 (0.2683)	Acc@1 96.875 (94.159)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:50:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.224)	Loss 0.2649 (0.2639)	Acc@1 94.531 (94.128)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:50:13 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.200 Acc@5 100.000
[2024-11-09 15:50:13 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.2%
[2024-11-09 15:50:13 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 15:50:15 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.564 (1.564)	Loss 0.2676 (0.2676)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:50:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.343)	Loss 0.2761 (0.2790)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:50:19 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.285)	Loss 0.4382 (0.3002)	Acc@1 81.250 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:50:21 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.180 (0.252)	Loss 0.4998 (0.3628)	Acc@1 75.000 (87.702)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:50:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 85.340 Acc@5 100.000
[2024-11-09 15:50:24 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 85.3%
[2024-11-09 15:50:24 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 85.34%
[2024-11-09 15:50:29 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][0/156]	eta 0:13:03 lr 0.000056	 wd 0.0500	time 5.0236 (5.0236)	data time 4.6085 (4.6085)	model time 0.0000 (0.0000)	loss 0.5116 (0.5116)	grad_norm 2.8432 (2.8432)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:50:34 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][10/156]	eta 0:02:13 lr 0.000055	 wd 0.0500	time 0.4503 (0.9174)	data time 0.0028 (0.4379)	model time 0.0000 (0.0000)	loss 0.6056 (0.5469)	grad_norm 1.5205 (2.5720)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:50:39 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][20/156]	eta 0:01:39 lr 0.000055	 wd 0.0500	time 0.6293 (0.7281)	data time 0.0010 (0.2376)	model time 0.0000 (0.0000)	loss 0.6599 (0.5628)	grad_norm 1.8709 (2.7193)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:50:44 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][30/156]	eta 0:01:21 lr 0.000055	 wd 0.0500	time 0.4746 (0.6472)	data time 0.0008 (0.1654)	model time 0.0000 (0.0000)	loss 0.5799 (0.5685)	grad_norm 2.9791 (2.6920)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:50:49 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][40/156]	eta 0:01:11 lr 0.000055	 wd 0.0500	time 0.4745 (0.6145)	data time 0.0007 (0.1284)	model time 0.0000 (0.0000)	loss 0.6133 (0.5644)	grad_norm 2.9190 (2.6915)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:50:54 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][50/156]	eta 0:01:03 lr 0.000055	 wd 0.0500	time 0.6485 (0.5985)	data time 0.0028 (0.1061)	model time 0.0000 (0.0000)	loss 0.5872 (0.5653)	grad_norm 1.5877 (2.6356)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:50:59 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][60/156]	eta 0:00:56 lr 0.000055	 wd 0.0500	time 0.5648 (0.5848)	data time 0.0009 (0.0900)	model time 0.5639 (0.5071)	loss 0.4966 (0.5640)	grad_norm 3.0222 (2.5865)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:51:05 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][70/156]	eta 0:00:49 lr 0.000055	 wd 0.0500	time 0.4381 (0.5797)	data time 0.0242 (0.0803)	model time 0.4139 (0.5171)	loss 0.6674 (0.5637)	grad_norm 3.3441 (2.6302)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:51:09 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][80/156]	eta 0:00:43 lr 0.000055	 wd 0.0500	time 0.6027 (0.5661)	data time 0.0201 (0.0714)	model time 0.5826 (0.4984)	loss 0.5614 (0.5599)	grad_norm 2.1904 (2.6863)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:51:14 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][90/156]	eta 0:00:36 lr 0.000055	 wd 0.0500	time 0.4666 (0.5589)	data time 0.0256 (0.0648)	model time 0.4410 (0.4964)	loss 0.5729 (0.5591)	grad_norm 2.2273 (2.7088)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:51:20 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][100/156]	eta 0:00:31 lr 0.000055	 wd 0.0500	time 0.4597 (0.5581)	data time 0.0205 (0.0608)	model time 0.4392 (0.5022)	loss 0.4979 (0.5581)	grad_norm 3.0932 (2.7096)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:51:25 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][110/156]	eta 0:00:25 lr 0.000055	 wd 0.0500	time 0.4841 (0.5561)	data time 0.0262 (0.0575)	model time 0.4578 (0.5038)	loss 0.5996 (0.5610)	grad_norm 3.4252 (2.6881)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:51:31 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][120/156]	eta 0:00:19 lr 0.000055	 wd 0.0500	time 0.4349 (0.5543)	data time 0.0234 (0.0540)	model time 0.4114 (0.5061)	loss 0.6327 (0.5615)	grad_norm 2.0722 (2.6590)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:51:36 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][130/156]	eta 0:00:14 lr 0.000055	 wd 0.0500	time 0.5152 (0.5501)	data time 0.0149 (0.0509)	model time 0.5003 (0.5036)	loss 0.5571 (0.5623)	grad_norm 1.5751 (2.6247)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:51:41 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][140/156]	eta 0:00:08 lr 0.000055	 wd 0.0500	time 0.5603 (0.5480)	data time 0.0010 (0.0484)	model time 0.5593 (0.5036)	loss 0.5718 (0.5605)	grad_norm 2.2733 (2.6300)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:51:46 vssm1_tiny_0230s](training.py 201): INFO Train: [171/300][150/156]	eta 0:00:03 lr 0.000055	 wd 0.0500	time 0.6493 (0.5457)	data time 0.0007 (0.0454)	model time 0.6486 (0.5043)	loss 0.6484 (0.5632)	grad_norm 2.2965 (2.5967)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:51:49 vssm1_tiny_0230s](training.py 212): INFO EPOCH 171 training takes 0:01:25
[2024-11-09 15:51:49 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_171.pth saving......
[2024-11-09 15:51:49 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_171.pth saved !!!
[2024-11-09 15:51:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.841 (3.841)	Loss 0.2411 (0.2411)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:51:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.181 (0.581)	Loss 0.2559 (0.2424)	Acc@1 92.969 (94.460)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:51:57 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.382)	Loss 0.2216 (0.2509)	Acc@1 98.438 (94.085)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:52:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.347)	Loss 0.2751 (0.2513)	Acc@1 93.750 (94.456)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:52:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.580 Acc@5 100.000
[2024-11-09 15:52:02 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.6%
[2024-11-09 15:52:02 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 15:52:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.189 (4.189)	Loss 0.2661 (0.2661)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:52:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.173 (0.622)	Loss 0.2749 (0.2777)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:52:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.465)	Loss 0.4329 (0.2987)	Acc@1 81.250 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:52:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.266 (0.375)	Loss 0.4939 (0.3599)	Acc@1 75.000 (87.777)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:52:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 85.520 Acc@5 100.000
[2024-11-09 15:52:16 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 85.5%
[2024-11-09 15:52:16 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 85.52%
[2024-11-09 15:52:21 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][0/156]	eta 0:11:11 lr 0.000055	 wd 0.0500	time 4.3025 (4.3025)	data time 3.7876 (3.7876)	model time 0.0000 (0.0000)	loss 0.4158 (0.4158)	grad_norm 2.1615 (2.1615)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:52:26 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][10/156]	eta 0:02:09 lr 0.000055	 wd 0.0500	time 0.6453 (0.8877)	data time 0.0008 (0.3811)	model time 0.0000 (0.0000)	loss 0.5420 (0.5155)	grad_norm 3.6718 (2.7026)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:52:32 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][20/156]	eta 0:01:40 lr 0.000055	 wd 0.0500	time 0.4403 (0.7366)	data time 0.0007 (0.2166)	model time 0.0000 (0.0000)	loss 0.5965 (0.5459)	grad_norm 2.8411 (2.7118)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:52:37 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][30/156]	eta 0:01:24 lr 0.000055	 wd 0.0500	time 0.4962 (0.6677)	data time 0.0495 (0.1530)	model time 0.0000 (0.0000)	loss 0.5946 (0.5594)	grad_norm 1.5692 (2.5949)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:52:42 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][40/156]	eta 0:01:13 lr 0.000055	 wd 0.0500	time 0.4129 (0.6357)	data time 0.0008 (0.1211)	model time 0.0000 (0.0000)	loss 0.5894 (0.5594)	grad_norm 1.6188 (2.6067)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:52:48 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][50/156]	eta 0:01:04 lr 0.000055	 wd 0.0500	time 0.5895 (0.6118)	data time 0.0033 (0.1008)	model time 0.0000 (0.0000)	loss 0.5761 (0.5620)	grad_norm 1.4878 (2.5641)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:52:53 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][60/156]	eta 0:00:57 lr 0.000055	 wd 0.0500	time 0.6428 (0.6000)	data time 0.0011 (0.0875)	model time 0.6416 (0.5202)	loss 0.4269 (0.5565)	grad_norm 3.1342 (2.5858)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:52:58 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][70/156]	eta 0:00:50 lr 0.000055	 wd 0.0500	time 0.5727 (0.5887)	data time 0.0018 (0.0768)	model time 0.5709 (0.5141)	loss 0.5518 (0.5579)	grad_norm 2.4310 (2.6194)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:53:03 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][80/156]	eta 0:00:43 lr 0.000054	 wd 0.0500	time 0.4128 (0.5779)	data time 0.0007 (0.0692)	model time 0.4121 (0.5048)	loss 0.4944 (0.5570)	grad_norm 1.9703 (2.5939)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:53:08 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][90/156]	eta 0:00:37 lr 0.000054	 wd 0.0500	time 0.4380 (0.5680)	data time 0.0047 (0.0626)	model time 0.4332 (0.4982)	loss 0.5107 (0.5581)	grad_norm 2.2321 (2.5768)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:53:14 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][100/156]	eta 0:00:31 lr 0.000054	 wd 0.0500	time 0.5392 (0.5673)	data time 0.0217 (0.0587)	model time 0.5175 (0.5064)	loss 0.6375 (0.5580)	grad_norm 2.6166 (2.5910)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:53:19 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][110/156]	eta 0:00:25 lr 0.000054	 wd 0.0500	time 0.5532 (0.5638)	data time 0.0095 (0.0549)	model time 0.5437 (0.5072)	loss 0.5463 (0.5582)	grad_norm 1.6112 (2.5490)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:53:24 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][120/156]	eta 0:00:20 lr 0.000054	 wd 0.0500	time 0.5497 (0.5607)	data time 0.0115 (0.0525)	model time 0.5382 (0.5062)	loss 0.6495 (0.5617)	grad_norm 4.2529 (2.5582)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:53:29 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][130/156]	eta 0:00:14 lr 0.000054	 wd 0.0500	time 0.4871 (0.5573)	data time 0.0080 (0.0497)	model time 0.4791 (0.5054)	loss 0.4952 (0.5613)	grad_norm 3.0477 (2.5140)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:53:35 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][140/156]	eta 0:00:08 lr 0.000054	 wd 0.0500	time 0.4123 (0.5543)	data time 0.0007 (0.0479)	model time 0.4116 (0.5039)	loss 0.5089 (0.5614)	grad_norm 2.9220 (2.5050)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:53:40 vssm1_tiny_0230s](training.py 201): INFO Train: [172/300][150/156]	eta 0:00:03 lr 0.000054	 wd 0.0500	time 0.6383 (0.5516)	data time 0.0005 (0.0448)	model time 0.6378 (0.5047)	loss 0.5174 (0.5594)	grad_norm 3.1507 (2.5198)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:53:43 vssm1_tiny_0230s](training.py 212): INFO EPOCH 172 training takes 0:01:26
[2024-11-09 15:53:43 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_172.pth saving......
[2024-11-09 15:53:43 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_172.pth saved !!!
[2024-11-09 15:53:46 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.495 (2.495)	Loss 0.2062 (0.2062)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:53:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.139 (0.410)	Loss 0.2303 (0.2183)	Acc@1 92.969 (93.963)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:53:52 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 1.827 (0.409)	Loss 0.1793 (0.2312)	Acc@1 98.438 (93.229)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:53:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.252 (0.363)	Loss 0.2493 (0.2289)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:53:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.240 Acc@5 100.000
[2024-11-09 15:53:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.2%
[2024-11-09 15:53:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 15:54:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.183 (3.183)	Loss 0.2644 (0.2644)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:54:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.217 (0.523)	Loss 0.2734 (0.2761)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:54:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.392)	Loss 0.4282 (0.2970)	Acc@1 81.250 (93.266)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:54:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.188 (0.361)	Loss 0.4890 (0.3572)	Acc@1 75.781 (87.853)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:54:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 85.680 Acc@5 100.000
[2024-11-09 15:54:10 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 85.7%
[2024-11-09 15:54:10 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 85.68%
[2024-11-09 15:54:16 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][0/156]	eta 0:15:10 lr 0.000054	 wd 0.0500	time 5.8384 (5.8384)	data time 5.4234 (5.4234)	model time 0.0000 (0.0000)	loss 0.5116 (0.5116)	grad_norm 1.9986 (1.9986)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:54:21 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][10/156]	eta 0:02:22 lr 0.000054	 wd 0.0500	time 0.4486 (0.9756)	data time 0.0270 (0.5217)	model time 0.0000 (0.0000)	loss 0.5973 (0.5656)	grad_norm 2.3559 (2.7556)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:54:26 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][20/156]	eta 0:01:40 lr 0.000054	 wd 0.0500	time 0.7314 (0.7424)	data time 0.0487 (0.2815)	model time 0.0000 (0.0000)	loss 0.4144 (0.5560)	grad_norm 5.0143 (2.8507)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:54:31 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][30/156]	eta 0:01:25 lr 0.000054	 wd 0.0500	time 0.4837 (0.6765)	data time 0.0073 (0.1978)	model time 0.0000 (0.0000)	loss 0.5440 (0.5537)	grad_norm 3.0086 (2.7292)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:54:37 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][40/156]	eta 0:01:14 lr 0.000054	 wd 0.0500	time 0.5865 (0.6426)	data time 0.0020 (0.1546)	model time 0.0000 (0.0000)	loss 0.4896 (0.5632)	grad_norm 4.1944 (2.7816)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:54:42 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][50/156]	eta 0:01:05 lr 0.000054	 wd 0.0500	time 0.6535 (0.6210)	data time 0.0262 (0.1268)	model time 0.0000 (0.0000)	loss 0.5848 (0.5592)	grad_norm 3.4404 (2.7165)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:54:47 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][60/156]	eta 0:00:57 lr 0.000054	 wd 0.0500	time 0.6294 (0.6024)	data time 0.0391 (0.1084)	model time 0.5902 (0.4927)	loss 0.6102 (0.5641)	grad_norm 2.6637 (2.7021)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:54:52 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][70/156]	eta 0:00:50 lr 0.000054	 wd 0.0500	time 0.6024 (0.5923)	data time 0.0214 (0.0950)	model time 0.5810 (0.5049)	loss 0.5176 (0.5627)	grad_norm 2.2626 (2.7185)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:54:58 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][80/156]	eta 0:00:44 lr 0.000054	 wd 0.0500	time 0.6993 (0.5814)	data time 0.0297 (0.0851)	model time 0.6696 (0.4999)	loss 0.6112 (0.5628)	grad_norm 1.8587 (2.6504)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:55:02 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][90/156]	eta 0:00:37 lr 0.000054	 wd 0.0500	time 0.5255 (0.5703)	data time 0.0302 (0.0780)	model time 0.4953 (0.4900)	loss 0.5703 (0.5622)	grad_norm 3.0097 (2.6274)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:55:07 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][100/156]	eta 0:00:31 lr 0.000054	 wd 0.0500	time 0.5564 (0.5650)	data time 0.0135 (0.0730)	model time 0.5429 (0.4896)	loss 0.6300 (0.5653)	grad_norm 1.5014 (2.6172)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:55:12 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][110/156]	eta 0:00:25 lr 0.000054	 wd 0.0500	time 0.5635 (0.5574)	data time 0.0150 (0.0674)	model time 0.5485 (0.4864)	loss 0.6303 (0.5665)	grad_norm 2.1678 (2.6129)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:55:18 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][120/156]	eta 0:00:19 lr 0.000054	 wd 0.0500	time 0.5768 (0.5549)	data time 0.0314 (0.0636)	model time 0.5455 (0.4892)	loss 0.5762 (0.5659)	grad_norm 2.8672 (2.6214)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:55:23 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][130/156]	eta 0:00:14 lr 0.000054	 wd 0.0500	time 0.5586 (0.5517)	data time 0.0185 (0.0602)	model time 0.5402 (0.4899)	loss 0.4939 (0.5664)	grad_norm 2.3260 (2.5737)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:55:28 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][140/156]	eta 0:00:08 lr 0.000054	 wd 0.0500	time 0.6313 (0.5477)	data time 0.0635 (0.0570)	model time 0.5678 (0.4888)	loss 0.5539 (0.5668)	grad_norm 1.9677 (2.5538)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:55:33 vssm1_tiny_0230s](training.py 201): INFO Train: [173/300][150/156]	eta 0:00:03 lr 0.000053	 wd 0.0500	time 0.4879 (0.5449)	data time 0.0029 (0.0534)	model time 0.4850 (0.4902)	loss 0.5276 (0.5664)	grad_norm 1.8340 (2.5621)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:55:36 vssm1_tiny_0230s](training.py 212): INFO EPOCH 173 training takes 0:01:25
[2024-11-09 15:55:36 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_173.pth saving......
[2024-11-09 15:55:36 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_173.pth saved !!!
[2024-11-09 15:55:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.445 (3.445)	Loss 0.2620 (0.2620)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:55:42 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.158 (0.538)	Loss 0.2827 (0.2740)	Acc@1 91.406 (92.614)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:55:44 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.365)	Loss 0.1664 (0.2810)	Acc@1 99.219 (92.039)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:55:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.328)	Loss 0.2155 (0.2544)	Acc@1 95.312 (93.624)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:55:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.220 Acc@5 100.000
[2024-11-09 15:55:49 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.2%
[2024-11-09 15:55:49 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 15:55:51 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.597 (2.597)	Loss 0.2632 (0.2632)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:55:54 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.142 (0.534)	Loss 0.2725 (0.2751)	Acc@1 96.094 (95.384)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:55:57 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.144 (0.410)	Loss 0.4229 (0.2957)	Acc@1 82.812 (93.304)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:55:59 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.348)	Loss 0.4827 (0.3545)	Acc@1 75.781 (88.004)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:56:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 85.960 Acc@5 100.000
[2024-11-09 15:56:02 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 86.0%
[2024-11-09 15:56:02 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 85.96%
[2024-11-09 15:56:06 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][0/156]	eta 0:11:34 lr 0.000053	 wd 0.0500	time 4.4535 (4.4535)	data time 3.9800 (3.9800)	model time 0.0000 (0.0000)	loss 0.5516 (0.5516)	grad_norm 2.0040 (2.0040)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:56:12 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][10/156]	eta 0:02:09 lr 0.000053	 wd 0.0500	time 0.4859 (0.8859)	data time 0.0272 (0.4084)	model time 0.0000 (0.0000)	loss 0.5668 (0.5785)	grad_norm 3.0431 (2.5856)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:56:17 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][20/156]	eta 0:01:38 lr 0.000053	 wd 0.0500	time 0.4874 (0.7218)	data time 0.0007 (0.2280)	model time 0.0000 (0.0000)	loss 0.5858 (0.5722)	grad_norm 2.7756 (2.3407)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:56:22 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][30/156]	eta 0:01:23 lr 0.000053	 wd 0.0500	time 0.4820 (0.6641)	data time 0.0157 (0.1603)	model time 0.0000 (0.0000)	loss 0.5387 (0.5699)	grad_norm 2.2522 (2.4804)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:56:28 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][40/156]	eta 0:01:13 lr 0.000053	 wd 0.0500	time 0.4934 (0.6318)	data time 0.0068 (0.1253)	model time 0.0000 (0.0000)	loss 0.5196 (0.5599)	grad_norm 2.0807 (2.6069)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:56:33 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][50/156]	eta 0:01:04 lr 0.000053	 wd 0.0500	time 0.4956 (0.6050)	data time 0.0040 (0.1024)	model time 0.0000 (0.0000)	loss 0.6042 (0.5609)	grad_norm 2.2338 (2.5900)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:56:37 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][60/156]	eta 0:00:56 lr 0.000053	 wd 0.0500	time 0.4269 (0.5835)	data time 0.0007 (0.0867)	model time 0.4262 (0.4673)	loss 0.5342 (0.5634)	grad_norm 3.6586 (2.6309)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:56:43 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][70/156]	eta 0:00:49 lr 0.000053	 wd 0.0500	time 0.6252 (0.5754)	data time 0.0251 (0.0776)	model time 0.6001 (0.4854)	loss 0.5699 (0.5597)	grad_norm 1.8314 (2.6484)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:56:48 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][80/156]	eta 0:00:43 lr 0.000053	 wd 0.0500	time 0.5034 (0.5716)	data time 0.0194 (0.0696)	model time 0.4840 (0.5009)	loss 0.5015 (0.5556)	grad_norm 2.3121 (2.6107)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:56:54 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][90/156]	eta 0:00:37 lr 0.000053	 wd 0.0500	time 0.4758 (0.5680)	data time 0.0007 (0.0636)	model time 0.4752 (0.5066)	loss 0.5955 (0.5516)	grad_norm 2.9898 (2.6370)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:56:59 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][100/156]	eta 0:00:31 lr 0.000053	 wd 0.0500	time 0.5788 (0.5637)	data time 0.0129 (0.0614)	model time 0.5658 (0.5019)	loss 0.4637 (0.5494)	grad_norm 4.2724 (2.6657)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:57:04 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][110/156]	eta 0:00:25 lr 0.000053	 wd 0.0500	time 0.4782 (0.5587)	data time 0.0133 (0.0576)	model time 0.4649 (0.4998)	loss 0.5959 (0.5533)	grad_norm 1.7960 (2.6470)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:57:09 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][120/156]	eta 0:00:20 lr 0.000053	 wd 0.0500	time 0.5468 (0.5585)	data time 0.0029 (0.0540)	model time 0.5440 (0.5060)	loss 0.5841 (0.5554)	grad_norm 1.8560 (2.6133)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:57:15 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][130/156]	eta 0:00:14 lr 0.000053	 wd 0.0500	time 0.5720 (0.5564)	data time 0.0844 (0.0513)	model time 0.4875 (0.5065)	loss 0.4777 (0.5556)	grad_norm 2.4003 (2.5729)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:57:20 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][140/156]	eta 0:00:08 lr 0.000053	 wd 0.0500	time 0.4986 (0.5538)	data time 0.0087 (0.0490)	model time 0.4898 (0.5060)	loss 0.6251 (0.5565)	grad_norm 2.4267 (2.5976)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:57:25 vssm1_tiny_0230s](training.py 201): INFO Train: [174/300][150/156]	eta 0:00:03 lr 0.000053	 wd 0.0500	time 0.5364 (0.5487)	data time 0.0106 (0.0459)	model time 0.5258 (0.5030)	loss 0.4108 (0.5559)	grad_norm 2.6856 (2.5735)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:57:28 vssm1_tiny_0230s](training.py 212): INFO EPOCH 174 training takes 0:01:26
[2024-11-09 15:57:28 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_174.pth saving......
[2024-11-09 15:57:29 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_174.pth saved !!!
[2024-11-09 15:57:32 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.902 (3.902)	Loss 0.2281 (0.2281)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:57:35 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.168 (0.608)	Loss 0.2334 (0.2297)	Acc@1 93.750 (94.247)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:57:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.167 (0.442)	Loss 0.1858 (0.2397)	Acc@1 99.219 (93.787)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:57:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.363)	Loss 0.2496 (0.2363)	Acc@1 92.188 (93.952)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:57:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.160 Acc@5 100.000
[2024-11-09 15:57:43 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.2%
[2024-11-09 15:57:43 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 15:57:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.975 (3.975)	Loss 0.2615 (0.2615)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:57:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.636)	Loss 0.2708 (0.2733)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:57:52 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.270 (0.429)	Loss 0.4177 (0.2938)	Acc@1 83.594 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:57:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.383)	Loss 0.4773 (0.3515)	Acc@1 76.562 (88.382)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:57:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 86.380 Acc@5 100.000
[2024-11-09 15:57:57 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 86.4%
[2024-11-09 15:57:57 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 86.38%
[2024-11-09 15:58:02 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][0/156]	eta 0:13:47 lr 0.000053	 wd 0.0500	time 5.3038 (5.3038)	data time 4.5947 (4.5947)	model time 0.0000 (0.0000)	loss 0.5168 (0.5168)	grad_norm 1.9864 (1.9864)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:58:08 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][10/156]	eta 0:02:22 lr 0.000053	 wd 0.0500	time 0.4895 (0.9748)	data time 0.0009 (0.4258)	model time 0.0000 (0.0000)	loss 0.4545 (0.5390)	grad_norm 5.7219 (2.8801)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:58:13 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][20/156]	eta 0:01:42 lr 0.000053	 wd 0.0500	time 0.4371 (0.7539)	data time 0.0039 (0.2311)	model time 0.0000 (0.0000)	loss 0.5785 (0.5525)	grad_norm 2.1586 (2.7419)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:58:18 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][30/156]	eta 0:01:25 lr 0.000053	 wd 0.0500	time 0.5760 (0.6782)	data time 0.0452 (0.1623)	model time 0.0000 (0.0000)	loss 0.5729 (0.5595)	grad_norm 1.9031 (2.6398)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:58:23 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][40/156]	eta 0:01:13 lr 0.000053	 wd 0.0500	time 0.5447 (0.6356)	data time 0.0351 (0.1293)	model time 0.0000 (0.0000)	loss 0.4273 (0.5532)	grad_norm 2.8000 (2.5282)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:58:28 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][50/156]	eta 0:01:04 lr 0.000053	 wd 0.0500	time 0.4950 (0.6127)	data time 0.0023 (0.1070)	model time 0.0000 (0.0000)	loss 0.4362 (0.5541)	grad_norm 2.3354 (2.5361)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:58:33 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][60/156]	eta 0:00:56 lr 0.000052	 wd 0.0500	time 0.4159 (0.5906)	data time 0.0008 (0.0912)	model time 0.4151 (0.4668)	loss 0.5798 (0.5560)	grad_norm 2.0778 (2.5518)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:58:39 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][70/156]	eta 0:00:50 lr 0.000052	 wd 0.0500	time 0.4980 (0.5869)	data time 0.0511 (0.0825)	model time 0.4469 (0.5009)	loss 0.6188 (0.5527)	grad_norm 2.9043 (2.5429)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:58:44 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][80/156]	eta 0:00:43 lr 0.000052	 wd 0.0500	time 0.6052 (0.5777)	data time 0.0009 (0.0740)	model time 0.6043 (0.5002)	loss 0.4971 (0.5544)	grad_norm 4.1033 (2.5364)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:58:49 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][90/156]	eta 0:00:37 lr 0.000052	 wd 0.0500	time 0.4930 (0.5710)	data time 0.0135 (0.0679)	model time 0.4795 (0.4998)	loss 0.5767 (0.5578)	grad_norm 3.2474 (2.5475)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:58:54 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][100/156]	eta 0:00:31 lr 0.000052	 wd 0.0500	time 0.4343 (0.5668)	data time 0.0194 (0.0634)	model time 0.4149 (0.5011)	loss 0.5925 (0.5583)	grad_norm 1.9003 (2.5034)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:59:00 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][110/156]	eta 0:00:25 lr 0.000052	 wd 0.0500	time 0.5601 (0.5645)	data time 0.0260 (0.0589)	model time 0.5342 (0.5055)	loss 0.5331 (0.5568)	grad_norm 2.9004 (2.5184)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:59:04 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][120/156]	eta 0:00:20 lr 0.000052	 wd 0.0500	time 0.5438 (0.5556)	data time 0.0170 (0.0551)	model time 0.5267 (0.4967)	loss 0.5785 (0.5568)	grad_norm 2.6860 (2.5783)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:59:09 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][130/156]	eta 0:00:14 lr 0.000052	 wd 0.0500	time 0.4872 (0.5492)	data time 0.0406 (0.0519)	model time 0.4466 (0.4918)	loss 0.5932 (0.5549)	grad_norm 3.3277 (2.5788)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:59:14 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][140/156]	eta 0:00:08 lr 0.000052	 wd 0.0500	time 0.4601 (0.5426)	data time 0.0063 (0.0487)	model time 0.4539 (0.4873)	loss 0.6519 (0.5555)	grad_norm 4.0043 (2.5661)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:59:18 vssm1_tiny_0230s](training.py 201): INFO Train: [175/300][150/156]	eta 0:00:03 lr 0.000052	 wd 0.0500	time 0.4497 (0.5385)	data time 0.0006 (0.0456)	model time 0.4491 (0.4865)	loss 0.6069 (0.5562)	grad_norm 2.8412 (2.6298)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 15:59:22 vssm1_tiny_0230s](training.py 212): INFO EPOCH 175 training takes 0:01:24
[2024-11-09 15:59:22 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_175.pth saving......
[2024-11-09 15:59:22 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_175.pth saved !!!
[2024-11-09 15:59:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.824 (1.824)	Loss 0.2046 (0.2046)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:59:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.246 (0.522)	Loss 0.2047 (0.2018)	Acc@1 96.875 (97.088)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:59:33 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.740 (0.500)	Loss 0.2446 (0.2133)	Acc@1 94.531 (96.317)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:59:37 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.144 (0.466)	Loss 0.3174 (0.2381)	Acc@1 90.625 (94.481)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:59:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.920 Acc@5 100.000
[2024-11-09 15:59:40 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 93.9%
[2024-11-09 15:59:40 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 15:59:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.166 (4.166)	Loss 0.2598 (0.2598)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:59:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.271 (0.892)	Loss 0.2693 (0.2717)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:59:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.683)	Loss 0.4131 (0.2921)	Acc@1 83.594 (93.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 15:59:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.540)	Loss 0.4724 (0.3488)	Acc@1 76.562 (88.432)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:00:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 86.520 Acc@5 100.000
[2024-11-09 16:00:00 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 86.5%
[2024-11-09 16:00:00 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 86.52%
[2024-11-09 16:00:02 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][0/156]	eta 0:06:45 lr 0.000052	 wd 0.0500	time 2.6015 (2.6015)	data time 2.1689 (2.1689)	model time 0.0000 (0.0000)	loss 0.4497 (0.4497)	grad_norm 2.9293 (2.9293)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:08 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][10/156]	eta 0:01:46 lr 0.000052	 wd 0.0500	time 0.6096 (0.7266)	data time 0.0237 (0.2799)	model time 0.0000 (0.0000)	loss 0.5159 (0.5289)	grad_norm 3.4699 (2.9091)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:12 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][20/156]	eta 0:01:19 lr 0.000052	 wd 0.0500	time 0.4121 (0.5854)	data time 0.0030 (0.1497)	model time 0.0000 (0.0000)	loss 0.4669 (0.5497)	grad_norm 4.1120 (3.0747)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:17 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][30/156]	eta 0:01:10 lr 0.000052	 wd 0.0500	time 0.6171 (0.5562)	data time 0.0164 (0.1049)	model time 0.0000 (0.0000)	loss 0.5435 (0.5536)	grad_norm 4.0441 (2.9280)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:23 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][40/156]	eta 0:01:05 lr 0.000052	 wd 0.0500	time 0.4847 (0.5615)	data time 0.0037 (0.0863)	model time 0.0000 (0.0000)	loss 0.6290 (0.5559)	grad_norm 2.6377 (2.8463)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:28 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][50/156]	eta 0:00:59 lr 0.000052	 wd 0.0500	time 0.5312 (0.5632)	data time 0.0199 (0.0801)	model time 0.0000 (0.0000)	loss 0.5893 (0.5560)	grad_norm 2.4354 (2.7571)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:33 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][60/156]	eta 0:00:52 lr 0.000052	 wd 0.0500	time 0.5664 (0.5498)	data time 0.0256 (0.0684)	model time 0.5408 (0.4722)	loss 0.4994 (0.5517)	grad_norm 3.7685 (2.7756)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:38 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][70/156]	eta 0:00:46 lr 0.000052	 wd 0.0500	time 0.4937 (0.5416)	data time 0.0209 (0.0605)	model time 0.4728 (0.4759)	loss 0.5191 (0.5522)	grad_norm 3.2619 (2.7436)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:43 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][80/156]	eta 0:00:40 lr 0.000052	 wd 0.0500	time 0.6502 (0.5394)	data time 0.0006 (0.0565)	model time 0.6496 (0.4827)	loss 0.4523 (0.5544)	grad_norm 5.2212 (2.7602)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:48 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][90/156]	eta 0:00:35 lr 0.000052	 wd 0.0500	time 0.5026 (0.5353)	data time 0.0010 (0.0518)	model time 0.5017 (0.4840)	loss 0.6293 (0.5558)	grad_norm 2.1245 (2.7613)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:53 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][100/156]	eta 0:00:29 lr 0.000052	 wd 0.0500	time 0.4496 (0.5304)	data time 0.0253 (0.0487)	model time 0.4243 (0.4803)	loss 0.5726 (0.5574)	grad_norm 2.0200 (2.6914)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:00:58 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][110/156]	eta 0:00:24 lr 0.000052	 wd 0.0500	time 0.6601 (0.5271)	data time 0.0009 (0.0452)	model time 0.6592 (0.4807)	loss 0.4663 (0.5558)	grad_norm 3.2129 (2.6697)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:01:03 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][120/156]	eta 0:00:18 lr 0.000052	 wd 0.0500	time 0.5426 (0.5264)	data time 0.0017 (0.0423)	model time 0.5409 (0.4849)	loss 0.6121 (0.5555)	grad_norm 2.6854 (2.6639)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:01:09 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][130/156]	eta 0:00:13 lr 0.000052	 wd 0.0500	time 0.5866 (0.5258)	data time 0.0561 (0.0414)	model time 0.5305 (0.4853)	loss 0.5868 (0.5554)	grad_norm 1.6340 (2.6513)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:01:14 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][140/156]	eta 0:00:08 lr 0.000051	 wd 0.0500	time 0.4843 (0.5285)	data time 0.0010 (0.0398)	model time 0.4833 (0.4919)	loss 0.5719 (0.5543)	grad_norm 1.5112 (2.6371)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:01:19 vssm1_tiny_0230s](training.py 201): INFO Train: [176/300][150/156]	eta 0:00:03 lr 0.000051	 wd 0.0500	time 0.4697 (0.5284)	data time 0.0007 (0.0372)	model time 0.4690 (0.4952)	loss 0.5882 (0.5547)	grad_norm 1.3886 (2.6307)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:01:22 vssm1_tiny_0230s](training.py 212): INFO EPOCH 176 training takes 0:01:22
[2024-11-09 16:01:22 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_176.pth saving......
[2024-11-09 16:01:23 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_176.pth saved !!!
[2024-11-09 16:01:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.424 (3.424)	Loss 0.2000 (0.2000)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:01:29 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.235 (0.618)	Loss 0.2147 (0.2042)	Acc@1 94.531 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:01:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.204 (0.464)	Loss 0.1996 (0.2141)	Acc@1 97.656 (95.201)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:01:34 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.363)	Loss 0.2529 (0.2222)	Acc@1 92.969 (94.783)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:01:36 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.560 Acc@5 100.000
[2024-11-09 16:01:36 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.6%
[2024-11-09 16:01:36 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 16:01:39 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.774 (2.774)	Loss 0.2581 (0.2581)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:01:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.233 (0.630)	Loss 0.2678 (0.2700)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:01:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.132 (0.428)	Loss 0.4077 (0.2902)	Acc@1 83.594 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:01:48 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.386)	Loss 0.4666 (0.3457)	Acc@1 77.344 (88.558)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:01:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 86.680 Acc@5 100.000
[2024-11-09 16:01:51 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 86.7%
[2024-11-09 16:01:51 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 86.68%
[2024-11-09 16:01:56 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][0/156]	eta 0:13:58 lr 0.000051	 wd 0.0500	time 5.3740 (5.3740)	data time 4.8706 (4.8706)	model time 0.0000 (0.0000)	loss 0.5113 (0.5113)	grad_norm 1.9328 (1.9328)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:01 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][10/156]	eta 0:02:19 lr 0.000051	 wd 0.0500	time 0.5727 (0.9532)	data time 0.0186 (0.4558)	model time 0.0000 (0.0000)	loss 0.5533 (0.5275)	grad_norm 1.5743 (2.5230)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:06 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][20/156]	eta 0:01:38 lr 0.000051	 wd 0.0500	time 0.4814 (0.7257)	data time 0.0396 (0.2462)	model time 0.0000 (0.0000)	loss 0.4693 (0.5461)	grad_norm 2.2589 (2.5212)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:12 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][30/156]	eta 0:01:24 lr 0.000051	 wd 0.0500	time 0.4666 (0.6685)	data time 0.0009 (0.1704)	model time 0.0000 (0.0000)	loss 0.5363 (0.5403)	grad_norm 2.6193 (2.4743)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:17 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][40/156]	eta 0:01:12 lr 0.000051	 wd 0.0500	time 0.4999 (0.6272)	data time 0.0047 (0.1331)	model time 0.0000 (0.0000)	loss 0.6449 (0.5385)	grad_norm 3.1771 (2.4682)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:22 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][50/156]	eta 0:01:04 lr 0.000051	 wd 0.0500	time 0.4784 (0.6115)	data time 0.0007 (0.1093)	model time 0.0000 (0.0000)	loss 0.5794 (0.5444)	grad_norm 2.1329 (2.4982)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:27 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][60/156]	eta 0:00:56 lr 0.000051	 wd 0.0500	time 0.4184 (0.5928)	data time 0.0110 (0.0940)	model time 0.4074 (0.4812)	loss 0.4499 (0.5478)	grad_norm 2.2237 (2.5921)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:32 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][70/156]	eta 0:00:50 lr 0.000051	 wd 0.0500	time 0.5632 (0.5837)	data time 0.0523 (0.0835)	model time 0.5109 (0.4952)	loss 0.4400 (0.5440)	grad_norm 2.5009 (2.6098)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:37 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][80/156]	eta 0:00:43 lr 0.000051	 wd 0.0500	time 0.4346 (0.5743)	data time 0.0026 (0.0760)	model time 0.4320 (0.4917)	loss 0.4419 (0.5458)	grad_norm 2.8024 (2.6404)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:43 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][90/156]	eta 0:00:37 lr 0.000051	 wd 0.0500	time 0.4980 (0.5686)	data time 0.0206 (0.0696)	model time 0.4774 (0.4950)	loss 0.5212 (0.5487)	grad_norm 2.2716 (2.6251)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:47 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][100/156]	eta 0:00:31 lr 0.000051	 wd 0.0500	time 0.4661 (0.5601)	data time 0.0058 (0.0636)	model time 0.4603 (0.4908)	loss 0.4386 (0.5484)	grad_norm 3.1647 (2.6441)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:53 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][110/156]	eta 0:00:25 lr 0.000051	 wd 0.0500	time 0.5050 (0.5594)	data time 0.0487 (0.0603)	model time 0.4563 (0.4965)	loss 0.5492 (0.5491)	grad_norm 1.7735 (2.6080)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:02:58 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][120/156]	eta 0:00:20 lr 0.000051	 wd 0.0500	time 0.4961 (0.5580)	data time 0.0008 (0.0570)	model time 0.4953 (0.5001)	loss 0.5089 (0.5504)	grad_norm 2.5526 (2.5991)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:03:04 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][130/156]	eta 0:00:14 lr 0.000051	 wd 0.0500	time 0.4136 (0.5557)	data time 0.0007 (0.0537)	model time 0.4129 (0.5018)	loss 0.6069 (0.5495)	grad_norm 3.3063 (2.6091)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:03:09 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][140/156]	eta 0:00:08 lr 0.000051	 wd 0.0500	time 0.4735 (0.5534)	data time 0.0009 (0.0505)	model time 0.4726 (0.5032)	loss 0.4531 (0.5500)	grad_norm 3.4465 (2.6229)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:03:14 vssm1_tiny_0230s](training.py 201): INFO Train: [177/300][150/156]	eta 0:00:03 lr 0.000051	 wd 0.0500	time 0.4802 (0.5533)	data time 0.0005 (0.0472)	model time 0.4797 (0.5081)	loss 0.5929 (0.5503)	grad_norm 2.1655 (2.5954)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:03:18 vssm1_tiny_0230s](training.py 212): INFO EPOCH 177 training takes 0:01:26
[2024-11-09 16:03:18 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_177.pth saving......
[2024-11-09 16:03:18 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_177.pth saved !!!
[2024-11-09 16:03:22 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.151 (4.151)	Loss 0.2295 (0.2295)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:03:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.149 (0.551)	Loss 0.2399 (0.2316)	Acc@1 92.188 (94.105)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:03:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.372)	Loss 0.1802 (0.2396)	Acc@1 98.438 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:03:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.154 (0.323)	Loss 0.2366 (0.2310)	Acc@1 93.750 (94.254)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:03:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.660 Acc@5 100.000
[2024-11-09 16:03:32 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.7%
[2024-11-09 16:03:32 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 16:03:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.180 (2.180)	Loss 0.2566 (0.2566)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:03:38 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.691 (0.562)	Loss 0.2666 (0.2688)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:03:40 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.425)	Loss 0.4026 (0.2888)	Acc@1 84.375 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:03:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.381)	Loss 0.4609 (0.3430)	Acc@1 78.906 (88.710)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:03:47 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 86.960 Acc@5 100.000
[2024-11-09 16:03:47 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 87.0%
[2024-11-09 16:03:47 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 86.96%
[2024-11-09 16:03:51 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][0/156]	eta 0:11:47 lr 0.000051	 wd 0.0500	time 4.5377 (4.5377)	data time 3.7761 (3.7761)	model time 0.0000 (0.0000)	loss 0.6032 (0.6032)	grad_norm 2.1155 (2.1155)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:03:56 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][10/156]	eta 0:02:07 lr 0.000051	 wd 0.0500	time 0.5626 (0.8736)	data time 0.0102 (0.3610)	model time 0.0000 (0.0000)	loss 0.5288 (0.5793)	grad_norm 2.1701 (2.4135)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:01 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][20/156]	eta 0:01:35 lr 0.000051	 wd 0.0500	time 0.5028 (0.7012)	data time 0.0013 (0.1917)	model time 0.0000 (0.0000)	loss 0.5883 (0.5694)	grad_norm 1.7261 (2.4670)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:06 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][30/156]	eta 0:01:20 lr 0.000051	 wd 0.0500	time 0.4904 (0.6351)	data time 0.0196 (0.1354)	model time 0.0000 (0.0000)	loss 0.5941 (0.5637)	grad_norm 1.7424 (2.6239)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:11 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][40/156]	eta 0:01:09 lr 0.000051	 wd 0.0500	time 0.4880 (0.6027)	data time 0.0197 (0.1041)	model time 0.0000 (0.0000)	loss 0.5900 (0.5660)	grad_norm 3.2058 (2.6348)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:17 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][50/156]	eta 0:01:02 lr 0.000050	 wd 0.0500	time 0.4379 (0.5867)	data time 0.0193 (0.0861)	model time 0.0000 (0.0000)	loss 0.6360 (0.5649)	grad_norm 2.2368 (2.6256)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:22 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][60/156]	eta 0:00:54 lr 0.000050	 wd 0.0500	time 0.4521 (0.5708)	data time 0.0040 (0.0741)	model time 0.4481 (0.4763)	loss 0.6215 (0.5645)	grad_norm 2.8091 (2.5701)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:27 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][70/156]	eta 0:00:48 lr 0.000050	 wd 0.0500	time 0.4701 (0.5634)	data time 0.0109 (0.0657)	model time 0.4592 (0.4901)	loss 0.5828 (0.5633)	grad_norm 1.9224 (2.6653)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:32 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][80/156]	eta 0:00:42 lr 0.000050	 wd 0.0500	time 0.4653 (0.5577)	data time 0.0059 (0.0605)	model time 0.4594 (0.4913)	loss 0.6139 (0.5666)	grad_norm 2.7027 (2.6650)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:37 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][90/156]	eta 0:00:36 lr 0.000050	 wd 0.0500	time 0.5179 (0.5509)	data time 0.0224 (0.0559)	model time 0.4956 (0.4879)	loss 0.6850 (0.5701)	grad_norm 2.1970 (2.6550)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:42 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][100/156]	eta 0:00:30 lr 0.000050	 wd 0.0500	time 0.5741 (0.5485)	data time 0.0241 (0.0522)	model time 0.5499 (0.4919)	loss 0.4322 (0.5688)	grad_norm 2.4952 (2.6534)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:47 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][110/156]	eta 0:00:25 lr 0.000050	 wd 0.0500	time 0.5248 (0.5473)	data time 0.0007 (0.0487)	model time 0.5241 (0.4967)	loss 0.5907 (0.5689)	grad_norm 2.5661 (2.6254)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:52 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][120/156]	eta 0:00:19 lr 0.000050	 wd 0.0500	time 0.4445 (0.5425)	data time 0.0072 (0.0459)	model time 0.4372 (0.4936)	loss 0.6460 (0.5671)	grad_norm 2.2877 (2.6496)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:04:58 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][130/156]	eta 0:00:14 lr 0.000050	 wd 0.0500	time 0.5392 (0.5423)	data time 0.0240 (0.0441)	model time 0.5152 (0.4966)	loss 0.4781 (0.5652)	grad_norm 2.6711 (2.6647)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:05:03 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][140/156]	eta 0:00:08 lr 0.000050	 wd 0.0500	time 0.4611 (0.5385)	data time 0.0009 (0.0419)	model time 0.4602 (0.4942)	loss 0.4768 (0.5625)	grad_norm 2.2866 (2.6841)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:05:08 vssm1_tiny_0230s](training.py 201): INFO Train: [178/300][150/156]	eta 0:00:03 lr 0.000050	 wd 0.0500	time 0.4913 (0.5352)	data time 0.0006 (0.0392)	model time 0.4908 (0.4936)	loss 0.5888 (0.5617)	grad_norm 2.1267 (2.6815)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:05:11 vssm1_tiny_0230s](training.py 212): INFO EPOCH 178 training takes 0:01:23
[2024-11-09 16:05:11 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_178.pth saving......
[2024-11-09 16:05:11 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_178.pth saved !!!
[2024-11-09 16:05:15 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.688 (3.688)	Loss 0.2600 (0.2600)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:05:18 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.503 (0.610)	Loss 0.2627 (0.2628)	Acc@1 92.188 (92.472)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:05:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.454)	Loss 0.1536 (0.2691)	Acc@1 98.438 (92.150)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:05:23 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.383)	Loss 0.2081 (0.2408)	Acc@1 93.750 (93.674)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:05:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.420 Acc@5 100.000
[2024-11-09 16:05:25 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.4%
[2024-11-09 16:05:25 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 16:05:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.025 (4.025)	Loss 0.2549 (0.2549)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:05:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.553)	Loss 0.2651 (0.2673)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:05:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.192 (0.428)	Loss 0.3979 (0.2871)	Acc@1 85.156 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:05:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.194 (0.356)	Loss 0.4561 (0.3403)	Acc@1 80.469 (88.886)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:05:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.220 Acc@5 100.000
[2024-11-09 16:05:38 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 87.2%
[2024-11-09 16:05:38 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 87.22%
[2024-11-09 16:05:43 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][0/156]	eta 0:11:47 lr 0.000050	 wd 0.0500	time 4.5355 (4.5355)	data time 3.9850 (3.9850)	model time 0.0000 (0.0000)	loss 0.6266 (0.6266)	grad_norm 2.5442 (2.5442)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:05:48 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][10/156]	eta 0:02:09 lr 0.000050	 wd 0.0500	time 0.5161 (0.8860)	data time 0.0059 (0.3778)	model time 0.0000 (0.0000)	loss 0.5193 (0.5627)	grad_norm 2.6856 (2.6975)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:05:53 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][20/156]	eta 0:01:36 lr 0.000050	 wd 0.0500	time 0.4918 (0.7083)	data time 0.0266 (0.2128)	model time 0.0000 (0.0000)	loss 0.5821 (0.5505)	grad_norm 1.9055 (2.6241)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:05:59 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][30/156]	eta 0:01:22 lr 0.000050	 wd 0.0500	time 0.6231 (0.6520)	data time 0.0023 (0.1477)	model time 0.0000 (0.0000)	loss 0.6118 (0.5529)	grad_norm 3.2220 (inf)	loss_scale 65536.0000 (69764.1290)	mem 13675MB
[2024-11-09 16:06:04 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][40/156]	eta 0:01:12 lr 0.000050	 wd 0.0500	time 0.5756 (0.6288)	data time 0.0061 (0.1148)	model time 0.0000 (0.0000)	loss 0.6209 (0.5612)	grad_norm 2.4606 (inf)	loss_scale 65536.0000 (68732.8780)	mem 13675MB
[2024-11-09 16:06:10 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][50/156]	eta 0:01:05 lr 0.000050	 wd 0.0500	time 0.5627 (0.6146)	data time 0.0010 (0.0941)	model time 0.0000 (0.0000)	loss 0.4989 (0.5621)	grad_norm 3.0678 (inf)	loss_scale 65536.0000 (68106.0392)	mem 13675MB
[2024-11-09 16:06:16 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][60/156]	eta 0:00:59 lr 0.000050	 wd 0.0500	time 0.4299 (0.6173)	data time 0.0019 (0.0813)	model time 0.4280 (0.6147)	loss 0.6007 (0.5574)	grad_norm 5.0239 (inf)	loss_scale 65536.0000 (67684.7213)	mem 13675MB
[2024-11-09 16:06:22 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][70/156]	eta 0:00:52 lr 0.000050	 wd 0.0500	time 0.5555 (0.6152)	data time 0.0238 (0.0747)	model time 0.5317 (0.5915)	loss 0.6171 (0.5586)	grad_norm 1.7717 (inf)	loss_scale 32768.0000 (63228.3944)	mem 13675MB
[2024-11-09 16:06:27 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][80/156]	eta 0:00:45 lr 0.000050	 wd 0.0500	time 0.5585 (0.6018)	data time 0.0099 (0.0669)	model time 0.5486 (0.5595)	loss 0.5618 (0.5597)	grad_norm 1.9093 (inf)	loss_scale 32768.0000 (59467.8519)	mem 13675MB
[2024-11-09 16:06:32 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][90/156]	eta 0:00:38 lr 0.000050	 wd 0.0500	time 0.4984 (0.5900)	data time 0.0335 (0.0625)	model time 0.4648 (0.5365)	loss 0.5838 (0.5583)	grad_norm 3.9018 (inf)	loss_scale 32768.0000 (56533.8022)	mem 13675MB
[2024-11-09 16:06:38 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][100/156]	eta 0:00:32 lr 0.000050	 wd 0.0500	time 0.4224 (0.5878)	data time 0.0134 (0.0581)	model time 0.4090 (0.5391)	loss 0.6210 (0.5575)	grad_norm 1.4543 (inf)	loss_scale 32768.0000 (54180.7525)	mem 13675MB
[2024-11-09 16:06:43 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][110/156]	eta 0:00:26 lr 0.000050	 wd 0.0500	time 0.4325 (0.5836)	data time 0.0105 (0.0544)	model time 0.4219 (0.5365)	loss 0.5746 (0.5579)	grad_norm 2.0078 (inf)	loss_scale 32768.0000 (52251.6757)	mem 13675MB
[2024-11-09 16:06:48 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][120/156]	eta 0:00:20 lr 0.000050	 wd 0.0500	time 0.5021 (0.5750)	data time 0.0644 (0.0513)	model time 0.4376 (0.5261)	loss 0.4516 (0.5554)	grad_norm 2.1724 (inf)	loss_scale 32768.0000 (50641.4545)	mem 13675MB
[2024-11-09 16:06:53 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][130/156]	eta 0:00:14 lr 0.000049	 wd 0.0500	time 0.5059 (0.5723)	data time 0.0356 (0.0487)	model time 0.4702 (0.5257)	loss 0.4987 (0.5546)	grad_norm 3.6818 (inf)	loss_scale 32768.0000 (49277.0687)	mem 13675MB
[2024-11-09 16:06:58 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][140/156]	eta 0:00:09 lr 0.000049	 wd 0.0500	time 0.4520 (0.5671)	data time 0.0171 (0.0464)	model time 0.4349 (0.5208)	loss 0.5524 (0.5538)	grad_norm 4.0465 (inf)	loss_scale 32768.0000 (48106.2128)	mem 13675MB
[2024-11-09 16:07:04 vssm1_tiny_0230s](training.py 201): INFO Train: [179/300][150/156]	eta 0:00:03 lr 0.000049	 wd 0.0500	time 0.6504 (0.5654)	data time 0.0007 (0.0433)	model time 0.6497 (0.5229)	loss 0.6315 (0.5543)	grad_norm 2.4892 (inf)	loss_scale 32768.0000 (47090.4371)	mem 13675MB
[2024-11-09 16:07:08 vssm1_tiny_0230s](training.py 212): INFO EPOCH 179 training takes 0:01:29
[2024-11-09 16:07:08 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_179.pth saving......
[2024-11-09 16:07:08 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_179.pth saved !!!
[2024-11-09 16:07:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.722 (4.722)	Loss 0.2102 (0.2102)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:07:16 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.732)	Loss 0.2198 (0.2165)	Acc@1 93.750 (94.815)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:07:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.163 (0.498)	Loss 0.2076 (0.2255)	Acc@1 97.656 (94.606)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:07:21 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.333 (0.421)	Loss 0.2747 (0.2314)	Acc@1 92.188 (94.481)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:07:23 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.500 Acc@5 100.000
[2024-11-09 16:07:23 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.5%
[2024-11-09 16:07:23 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 16:07:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.889 (2.889)	Loss 0.2532 (0.2532)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:07:29 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.143 (0.561)	Loss 0.2639 (0.2657)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:07:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.359 (0.434)	Loss 0.3931 (0.2854)	Acc@1 85.156 (93.527)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:07:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.375)	Loss 0.4509 (0.3375)	Acc@1 80.469 (88.987)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:07:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.360 Acc@5 100.000
[2024-11-09 16:07:38 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 87.4%
[2024-11-09 16:07:38 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 87.36%
[2024-11-09 16:07:41 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][0/156]	eta 0:09:59 lr 0.000049	 wd 0.0500	time 3.8428 (3.8428)	data time 3.4335 (3.4335)	model time 0.0000 (0.0000)	loss 0.4458 (0.4458)	grad_norm 2.6552 (2.6552)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:07:46 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][10/156]	eta 0:01:57 lr 0.000049	 wd 0.0500	time 0.5355 (0.8066)	data time 0.0006 (0.3489)	model time 0.0000 (0.0000)	loss 0.6222 (0.5781)	grad_norm 2.6482 (2.7448)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:07:52 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][20/156]	eta 0:01:30 lr 0.000049	 wd 0.0500	time 0.5226 (0.6635)	data time 0.0458 (0.1930)	model time 0.0000 (0.0000)	loss 0.5374 (0.5557)	grad_norm 2.5836 (2.6992)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:07:57 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][30/156]	eta 0:01:18 lr 0.000049	 wd 0.0500	time 0.5518 (0.6247)	data time 0.0059 (0.1363)	model time 0.0000 (0.0000)	loss 0.5557 (0.5552)	grad_norm 3.1970 (2.7269)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:03 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][40/156]	eta 0:01:10 lr 0.000049	 wd 0.0500	time 0.4939 (0.6107)	data time 0.0124 (0.1081)	model time 0.0000 (0.0000)	loss 0.5286 (0.5535)	grad_norm 1.9623 (2.7431)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:08 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][50/156]	eta 0:01:03 lr 0.000049	 wd 0.0500	time 0.4756 (0.5985)	data time 0.0019 (0.0892)	model time 0.0000 (0.0000)	loss 0.6233 (0.5513)	grad_norm 2.0919 (2.6699)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:13 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][60/156]	eta 0:00:56 lr 0.000049	 wd 0.0500	time 0.5455 (0.5878)	data time 0.0007 (0.0762)	model time 0.5449 (0.5235)	loss 0.6010 (0.5439)	grad_norm 2.4410 (2.6596)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:19 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][70/156]	eta 0:00:49 lr 0.000049	 wd 0.0500	time 0.5339 (0.5778)	data time 0.0067 (0.0671)	model time 0.5272 (0.5141)	loss 0.5581 (0.5509)	grad_norm 2.4823 (2.6437)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:24 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][80/156]	eta 0:00:43 lr 0.000049	 wd 0.0500	time 0.4480 (0.5675)	data time 0.0006 (0.0603)	model time 0.4474 (0.5037)	loss 0.6169 (0.5493)	grad_norm 2.5274 (2.6770)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:28 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][90/156]	eta 0:00:36 lr 0.000049	 wd 0.0500	time 0.4831 (0.5590)	data time 0.0063 (0.0567)	model time 0.4768 (0.4932)	loss 0.5952 (0.5506)	grad_norm 2.2658 (2.6425)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:34 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][100/156]	eta 0:00:31 lr 0.000049	 wd 0.0500	time 0.5334 (0.5559)	data time 0.0058 (0.0530)	model time 0.5276 (0.4963)	loss 0.5242 (0.5524)	grad_norm 1.8319 (2.6419)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:39 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][110/156]	eta 0:00:25 lr 0.000049	 wd 0.0500	time 0.5830 (0.5529)	data time 0.0044 (0.0496)	model time 0.5786 (0.4981)	loss 0.5588 (0.5515)	grad_norm 2.7429 (2.6434)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:44 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][120/156]	eta 0:00:19 lr 0.000049	 wd 0.0500	time 0.5175 (0.5528)	data time 0.0182 (0.0470)	model time 0.4993 (0.5031)	loss 0.5904 (0.5523)	grad_norm 2.3070 (2.6585)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:50 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][130/156]	eta 0:00:14 lr 0.000049	 wd 0.0500	time 0.5815 (0.5489)	data time 0.0509 (0.0451)	model time 0.5307 (0.5002)	loss 0.4903 (0.5528)	grad_norm 2.3285 (2.6355)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:54 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][140/156]	eta 0:00:08 lr 0.000049	 wd 0.0500	time 0.4690 (0.5445)	data time 0.0010 (0.0429)	model time 0.4680 (0.4972)	loss 0.5959 (0.5522)	grad_norm 2.7876 (2.6392)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:08:59 vssm1_tiny_0230s](training.py 201): INFO Train: [180/300][150/156]	eta 0:00:03 lr 0.000049	 wd 0.0500	time 0.4595 (0.5385)	data time 0.0006 (0.0401)	model time 0.4588 (0.4928)	loss 0.6009 (0.5543)	grad_norm 2.8302 (2.6621)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:09:02 vssm1_tiny_0230s](training.py 212): INFO EPOCH 180 training takes 0:01:24
[2024-11-09 16:09:02 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_180.pth saving......
[2024-11-09 16:09:02 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_180.pth saved !!!
[2024-11-09 16:09:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.673 (3.673)	Loss 0.2712 (0.2712)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:09:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.969 (0.610)	Loss 0.2876 (0.2779)	Acc@1 91.406 (91.974)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:09:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.132 (0.456)	Loss 0.1548 (0.2816)	Acc@1 99.219 (91.704)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:09:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.161 (0.386)	Loss 0.1969 (0.2488)	Acc@1 94.531 (93.498)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:09:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.320 Acc@5 100.000
[2024-11-09 16:09:17 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.3%
[2024-11-09 16:09:17 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 94.66%
[2024-11-09 16:09:21 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.437 (3.437)	Loss 0.2515 (0.2515)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:09:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.622)	Loss 0.2622 (0.2640)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:09:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.443)	Loss 0.3889 (0.2836)	Acc@1 85.938 (93.601)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:09:30 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.413)	Loss 0.4465 (0.3349)	Acc@1 81.250 (89.264)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:09:33 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.680 Acc@5 100.000
[2024-11-09 16:09:33 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 87.7%
[2024-11-09 16:09:33 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 87.68%
[2024-11-09 16:09:38 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][0/156]	eta 0:13:10 lr 0.000049	 wd 0.0500	time 5.0677 (5.0677)	data time 4.6209 (4.6209)	model time 0.0000 (0.0000)	loss 0.5894 (0.5894)	grad_norm 1.7910 (1.7910)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:09:43 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][10/156]	eta 0:02:11 lr 0.000049	 wd 0.0500	time 0.4042 (0.9009)	data time 0.0006 (0.4276)	model time 0.0000 (0.0000)	loss 0.5512 (0.5275)	grad_norm 2.7807 (2.7897)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:09:48 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][20/156]	eta 0:01:37 lr 0.000049	 wd 0.0500	time 0.6720 (0.7162)	data time 0.0019 (0.2277)	model time 0.0000 (0.0000)	loss 0.5734 (0.5498)	grad_norm 1.5329 (2.6715)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:09:53 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][30/156]	eta 0:01:21 lr 0.000049	 wd 0.0500	time 0.4765 (0.6479)	data time 0.0027 (0.1606)	model time 0.0000 (0.0000)	loss 0.6605 (0.5637)	grad_norm 1.3181 (2.7010)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:09:58 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][40/156]	eta 0:01:11 lr 0.000049	 wd 0.0500	time 0.5658 (0.6141)	data time 0.0159 (0.1263)	model time 0.0000 (0.0000)	loss 0.6515 (0.5641)	grad_norm 2.7807 (2.6512)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:03 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][50/156]	eta 0:01:03 lr 0.000048	 wd 0.0500	time 0.5725 (0.5963)	data time 0.0298 (0.1047)	model time 0.0000 (0.0000)	loss 0.5854 (0.5592)	grad_norm 2.2870 (2.6085)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:08 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][60/156]	eta 0:00:55 lr 0.000048	 wd 0.0500	time 0.4358 (0.5766)	data time 0.0107 (0.0894)	model time 0.4250 (0.4653)	loss 0.6041 (0.5580)	grad_norm 2.7157 (2.6502)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:12 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][70/156]	eta 0:00:47 lr 0.000048	 wd 0.0500	time 0.4099 (0.5567)	data time 0.0014 (0.0784)	model time 0.4085 (0.4446)	loss 0.5965 (0.5596)	grad_norm 2.0206 (2.6337)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:18 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][80/156]	eta 0:00:42 lr 0.000048	 wd 0.0500	time 0.4851 (0.5528)	data time 0.0091 (0.0703)	model time 0.4760 (0.4671)	loss 0.4459 (0.5582)	grad_norm 3.0465 (2.6473)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:22 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][90/156]	eta 0:00:35 lr 0.000048	 wd 0.0500	time 0.4724 (0.5421)	data time 0.0076 (0.0641)	model time 0.4648 (0.4610)	loss 0.5373 (0.5574)	grad_norm 3.0487 (2.6788)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:27 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][100/156]	eta 0:00:29 lr 0.000048	 wd 0.0500	time 0.5211 (0.5346)	data time 0.0271 (0.0583)	model time 0.4941 (0.4607)	loss 0.5438 (0.5551)	grad_norm 3.1581 (2.7545)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:32 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][110/156]	eta 0:00:24 lr 0.000048	 wd 0.0500	time 0.4228 (0.5285)	data time 0.0042 (0.0546)	model time 0.4186 (0.4588)	loss 0.5507 (0.5529)	grad_norm 2.0718 (2.8433)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:36 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][120/156]	eta 0:00:18 lr 0.000048	 wd 0.0500	time 0.5936 (0.5252)	data time 0.0174 (0.0509)	model time 0.5762 (0.4617)	loss 0.5992 (0.5527)	grad_norm 3.4994 (2.8601)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:42 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][130/156]	eta 0:00:13 lr 0.000048	 wd 0.0500	time 0.5867 (0.5250)	data time 0.0006 (0.0482)	model time 0.5860 (0.4674)	loss 0.6525 (0.5533)	grad_norm 2.0831 (2.8329)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:47 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][140/156]	eta 0:00:08 lr 0.000048	 wd 0.0500	time 0.4154 (0.5260)	data time 0.0009 (0.0467)	model time 0.4145 (0.4724)	loss 0.5817 (0.5514)	grad_norm 3.4713 (2.8134)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:53 vssm1_tiny_0230s](training.py 201): INFO Train: [181/300][150/156]	eta 0:00:03 lr 0.000048	 wd 0.0500	time 0.6257 (0.5281)	data time 0.0007 (0.0441)	model time 0.6250 (0.4802)	loss 0.5903 (0.5510)	grad_norm 3.1341 (2.7910)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:10:56 vssm1_tiny_0230s](training.py 212): INFO EPOCH 181 training takes 0:01:22
[2024-11-09 16:10:56 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_181.pth saving......
[2024-11-09 16:10:56 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_181.pth saved !!!
[2024-11-09 16:11:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.940 (3.940)	Loss 0.2036 (0.2036)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:11:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.189 (0.600)	Loss 0.2086 (0.2013)	Acc@1 96.094 (96.165)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:11:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.171 (0.443)	Loss 0.2067 (0.2133)	Acc@1 96.875 (95.424)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:11:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.245 (0.373)	Loss 0.2686 (0.2230)	Acc@1 92.969 (95.010)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:11:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.020 Acc@5 100.000
[2024-11-09 16:11:10 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 16:11:10 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.02%
[2024-11-09 16:11:14 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.443 (3.443)	Loss 0.2499 (0.2499)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:11:16 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.523)	Loss 0.2610 (0.2625)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:11:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.290 (0.365)	Loss 0.3843 (0.2819)	Acc@1 85.938 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:11:21 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.331)	Loss 0.4419 (0.3323)	Acc@1 81.250 (89.340)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:11:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.780 Acc@5 100.000
[2024-11-09 16:11:24 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 87.8%
[2024-11-09 16:11:24 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 87.78%
[2024-11-09 16:11:29 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][0/156]	eta 0:14:31 lr 0.000048	 wd 0.0500	time 5.5873 (5.5873)	data time 5.0473 (5.0473)	model time 0.0000 (0.0000)	loss 0.5134 (0.5134)	grad_norm 3.3091 (3.3091)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:11:35 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][10/156]	eta 0:02:23 lr 0.000048	 wd 0.0500	time 0.5354 (0.9847)	data time 0.0411 (0.4765)	model time 0.0000 (0.0000)	loss 0.6433 (0.5463)	grad_norm 2.1374 (2.8339)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:11:40 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][20/156]	eta 0:01:42 lr 0.000048	 wd 0.0500	time 0.5966 (0.7572)	data time 0.0200 (0.2570)	model time 0.0000 (0.0000)	loss 0.5934 (0.5470)	grad_norm 1.8009 (2.7554)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:11:45 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][30/156]	eta 0:01:25 lr 0.000048	 wd 0.0500	time 0.4510 (0.6747)	data time 0.0238 (0.1797)	model time 0.0000 (0.0000)	loss 0.6129 (0.5505)	grad_norm 2.3519 (2.7987)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:11:50 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][40/156]	eta 0:01:12 lr 0.000048	 wd 0.0500	time 0.5193 (0.6293)	data time 0.0229 (0.1395)	model time 0.0000 (0.0000)	loss 0.4697 (0.5506)	grad_norm 3.2634 (2.7335)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:11:54 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][50/156]	eta 0:01:03 lr 0.000048	 wd 0.0500	time 0.4577 (0.6026)	data time 0.0018 (0.1160)	model time 0.0000 (0.0000)	loss 0.5808 (0.5503)	grad_norm 2.1885 (2.7106)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:00 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][60/156]	eta 0:00:56 lr 0.000048	 wd 0.0500	time 0.4155 (0.5873)	data time 0.0006 (0.0996)	model time 0.4149 (0.4931)	loss 0.5470 (0.5498)	grad_norm 5.4603 (2.7327)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:05 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][70/156]	eta 0:00:49 lr 0.000048	 wd 0.0500	time 0.5391 (0.5759)	data time 0.0035 (0.0878)	model time 0.5356 (0.4921)	loss 0.5681 (0.5519)	grad_norm 2.8149 (2.7286)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:10 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][80/156]	eta 0:00:43 lr 0.000048	 wd 0.0500	time 0.4708 (0.5728)	data time 0.0008 (0.0791)	model time 0.4699 (0.5056)	loss 0.5825 (0.5528)	grad_norm 2.1664 (2.7207)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:15 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][90/156]	eta 0:00:37 lr 0.000048	 wd 0.0500	time 0.5564 (0.5664)	data time 0.0194 (0.0728)	model time 0.5370 (0.5026)	loss 0.5994 (0.5541)	grad_norm 2.1815 (2.7365)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:20 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][100/156]	eta 0:00:31 lr 0.000048	 wd 0.0500	time 0.5509 (0.5592)	data time 0.0055 (0.0663)	model time 0.5454 (0.4994)	loss 0.5082 (0.5553)	grad_norm 2.5023 (2.7196)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:25 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][110/156]	eta 0:00:25 lr 0.000048	 wd 0.0500	time 0.6175 (0.5526)	data time 0.0057 (0.0614)	model time 0.6118 (0.4951)	loss 0.5646 (0.5542)	grad_norm 2.4426 (2.6885)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:30 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][120/156]	eta 0:00:19 lr 0.000047	 wd 0.0500	time 0.4352 (0.5480)	data time 0.0010 (0.0574)	model time 0.4342 (0.4935)	loss 0.5819 (0.5553)	grad_norm 1.9280 (2.6789)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:35 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][130/156]	eta 0:00:14 lr 0.000047	 wd 0.0500	time 0.5016 (0.5435)	data time 0.0178 (0.0543)	model time 0.4839 (0.4909)	loss 0.5699 (0.5547)	grad_norm 2.0364 (2.6651)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:40 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][140/156]	eta 0:00:08 lr 0.000047	 wd 0.0500	time 0.5069 (0.5424)	data time 0.0010 (0.0511)	model time 0.5059 (0.4940)	loss 0.5316 (0.5540)	grad_norm 1.7067 (2.6461)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:45 vssm1_tiny_0230s](training.py 201): INFO Train: [182/300][150/156]	eta 0:00:03 lr 0.000047	 wd 0.0500	time 0.4603 (0.5407)	data time 0.0005 (0.0479)	model time 0.4598 (0.4961)	loss 0.6311 (0.5547)	grad_norm 3.3248 (2.6522)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:12:48 vssm1_tiny_0230s](training.py 212): INFO EPOCH 182 training takes 0:01:24
[2024-11-09 16:12:48 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_182.pth saving......
[2024-11-09 16:12:49 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_182.pth saved !!!
[2024-11-09 16:12:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.014 (4.014)	Loss 0.2347 (0.2347)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:12:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.148 (0.594)	Loss 0.2395 (0.2433)	Acc@1 94.531 (93.892)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:12:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.215 (0.429)	Loss 0.1831 (0.2517)	Acc@1 96.875 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:13:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.196 (0.356)	Loss 0.2351 (0.2399)	Acc@1 94.531 (94.330)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:13:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.800 Acc@5 100.000
[2024-11-09 16:13:02 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.8%
[2024-11-09 16:13:02 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.02%
[2024-11-09 16:13:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.911 (3.911)	Loss 0.2482 (0.2482)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:13:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.155 (0.663)	Loss 0.2595 (0.2609)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:13:11 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.175 (0.439)	Loss 0.3801 (0.2802)	Acc@1 86.719 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:13:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.385)	Loss 0.4373 (0.3297)	Acc@1 81.250 (89.390)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:13:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 87.880 Acc@5 100.000
[2024-11-09 16:13:16 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 87.9%
[2024-11-09 16:13:16 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 87.88%
[2024-11-09 16:13:19 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][0/156]	eta 0:07:18 lr 0.000047	 wd 0.0500	time 2.8123 (2.8123)	data time 2.3528 (2.3528)	model time 0.0000 (0.0000)	loss 0.4060 (0.4060)	grad_norm 3.3910 (3.3910)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:13:25 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][10/156]	eta 0:01:53 lr 0.000047	 wd 0.0500	time 0.5202 (0.7759)	data time 0.0038 (0.2936)	model time 0.0000 (0.0000)	loss 0.6081 (0.5645)	grad_norm 1.7555 (2.7788)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:13:30 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][20/156]	eta 0:01:28 lr 0.000047	 wd 0.0500	time 0.4863 (0.6510)	data time 0.0300 (0.1624)	model time 0.0000 (0.0000)	loss 0.6166 (0.5613)	grad_norm 1.7011 (2.5650)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:13:35 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][30/156]	eta 0:01:15 lr 0.000047	 wd 0.0500	time 0.4609 (0.5995)	data time 0.0187 (0.1142)	model time 0.0000 (0.0000)	loss 0.5854 (0.5596)	grad_norm 1.7046 (2.5360)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:13:40 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][40/156]	eta 0:01:06 lr 0.000047	 wd 0.0500	time 0.5515 (0.5771)	data time 0.0182 (0.0894)	model time 0.0000 (0.0000)	loss 0.5990 (0.5619)	grad_norm 2.2498 (2.4533)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:13:45 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][50/156]	eta 0:00:59 lr 0.000047	 wd 0.0500	time 0.4321 (0.5570)	data time 0.0191 (0.0739)	model time 0.0000 (0.0000)	loss 0.6023 (0.5594)	grad_norm 1.9345 (2.4467)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:13:50 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][60/156]	eta 0:00:52 lr 0.000047	 wd 0.0500	time 0.5618 (0.5460)	data time 0.0197 (0.0649)	model time 0.5421 (0.4708)	loss 0.6625 (0.5604)	grad_norm 2.6457 (2.4654)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:13:55 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][70/156]	eta 0:00:46 lr 0.000047	 wd 0.0500	time 0.4427 (0.5422)	data time 0.0058 (0.0595)	model time 0.4369 (0.4819)	loss 0.6449 (0.5667)	grad_norm 2.1638 (2.4619)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:14:00 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][80/156]	eta 0:00:40 lr 0.000047	 wd 0.0500	time 0.4231 (0.5370)	data time 0.0019 (0.0533)	model time 0.4212 (0.4846)	loss 0.5851 (0.5668)	grad_norm 1.8282 (2.4482)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:14:06 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][90/156]	eta 0:00:35 lr 0.000047	 wd 0.0500	time 0.5371 (0.5436)	data time 0.0006 (0.0488)	model time 0.5365 (0.5097)	loss 0.5840 (0.5675)	grad_norm 2.8119 (2.4538)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:14:11 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][100/156]	eta 0:00:30 lr 0.000047	 wd 0.0500	time 0.5973 (0.5407)	data time 0.0007 (0.0448)	model time 0.5966 (0.5089)	loss 0.6062 (0.5656)	grad_norm 3.1811 (2.4780)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:14:17 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][110/156]	eta 0:00:25 lr 0.000047	 wd 0.0500	time 0.5410 (0.5459)	data time 0.0181 (0.0427)	model time 0.5229 (0.5204)	loss 0.5671 (0.5655)	grad_norm 2.9366 (2.4792)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:14:22 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][120/156]	eta 0:00:19 lr 0.000047	 wd 0.0500	time 0.5245 (0.5438)	data time 0.0008 (0.0405)	model time 0.5237 (0.5180)	loss 0.5948 (0.5634)	grad_norm 4.1869 (2.4978)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:14:27 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][130/156]	eta 0:00:14 lr 0.000047	 wd 0.0500	time 0.5631 (0.5407)	data time 0.0586 (0.0388)	model time 0.5045 (0.5138)	loss 0.6030 (0.5621)	grad_norm 3.3004 (2.5334)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:14:33 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][140/156]	eta 0:00:08 lr 0.000047	 wd 0.0500	time 0.4552 (0.5399)	data time 0.0091 (0.0369)	model time 0.4462 (0.5142)	loss 0.4799 (0.5615)	grad_norm 1.8620 (2.5317)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:14:38 vssm1_tiny_0230s](training.py 201): INFO Train: [183/300][150/156]	eta 0:00:03 lr 0.000047	 wd 0.0500	time 0.6026 (0.5384)	data time 0.0005 (0.0348)	model time 0.6021 (0.5140)	loss 0.6153 (0.5635)	grad_norm 2.3901 (2.5235)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:14:41 vssm1_tiny_0230s](training.py 212): INFO EPOCH 183 training takes 0:01:24
[2024-11-09 16:14:41 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_183.pth saving......
[2024-11-09 16:14:41 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_183.pth saved !!!
[2024-11-09 16:14:46 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.724 (4.724)	Loss 0.2473 (0.2473)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:14:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.195 (0.639)	Loss 0.2590 (0.2501)	Acc@1 93.750 (94.886)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:14:51 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.151 (0.455)	Loss 0.2032 (0.2589)	Acc@1 98.438 (94.159)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:14:54 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.142 (0.406)	Loss 0.2566 (0.2528)	Acc@1 92.969 (94.481)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:14:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.640 Acc@5 100.000
[2024-11-09 16:14:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.6%
[2024-11-09 16:14:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.02%
[2024-11-09 16:14:59 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.441 (2.441)	Loss 0.2467 (0.2467)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:15:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.508 (0.547)	Loss 0.2583 (0.2597)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:15:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.219 (0.420)	Loss 0.3755 (0.2787)	Acc@1 87.500 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:15:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.155 (0.380)	Loss 0.4324 (0.3272)	Acc@1 82.031 (89.491)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:15:11 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.060 Acc@5 100.000
[2024-11-09 16:15:11 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 88.1%
[2024-11-09 16:15:11 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 88.06%
[2024-11-09 16:15:17 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][0/156]	eta 0:14:11 lr 0.000047	 wd 0.0500	time 5.4593 (5.4593)	data time 5.0077 (5.0077)	model time 0.0000 (0.0000)	loss 0.5909 (0.5909)	grad_norm 1.0374 (1.0374)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:15:21 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][10/156]	eta 0:02:15 lr 0.000047	 wd 0.0500	time 0.5713 (0.9277)	data time 0.0116 (0.4592)	model time 0.0000 (0.0000)	loss 0.5759 (0.5310)	grad_norm 1.9022 (2.6971)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:15:26 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][20/156]	eta 0:01:36 lr 0.000047	 wd 0.0500	time 0.5215 (0.7071)	data time 0.0095 (0.2425)	model time 0.0000 (0.0000)	loss 0.4333 (0.5553)	grad_norm 3.1540 (2.5192)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:15:31 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][30/156]	eta 0:01:18 lr 0.000047	 wd 0.0500	time 0.5645 (0.6261)	data time 0.0182 (0.1671)	model time 0.0000 (0.0000)	loss 0.6082 (0.5615)	grad_norm 1.8965 (2.5445)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:15:36 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][40/156]	eta 0:01:09 lr 0.000046	 wd 0.0500	time 0.5304 (0.5955)	data time 0.0083 (0.1308)	model time 0.0000 (0.0000)	loss 0.5594 (0.5534)	grad_norm 1.3409 (2.5251)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:15:41 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][50/156]	eta 0:01:02 lr 0.000046	 wd 0.0500	time 0.6093 (0.5915)	data time 0.0009 (0.1102)	model time 0.0000 (0.0000)	loss 0.4364 (0.5524)	grad_norm 2.6597 (2.4681)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:15:46 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][60/156]	eta 0:00:54 lr 0.000046	 wd 0.0500	time 0.4915 (0.5728)	data time 0.0008 (0.0937)	model time 0.4907 (0.4677)	loss 0.4860 (0.5509)	grad_norm 3.5982 (2.5548)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:15:51 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][70/156]	eta 0:00:48 lr 0.000046	 wd 0.0500	time 0.4281 (0.5657)	data time 0.0006 (0.0820)	model time 0.4275 (0.4899)	loss 0.4943 (0.5478)	grad_norm 2.3757 (2.5552)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:15:56 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][80/156]	eta 0:00:42 lr 0.000046	 wd 0.0500	time 0.4504 (0.5585)	data time 0.0369 (0.0739)	model time 0.4134 (0.4904)	loss 0.4790 (0.5451)	grad_norm 2.7554 (2.5996)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:16:02 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][90/156]	eta 0:00:36 lr 0.000046	 wd 0.0500	time 0.5476 (0.5539)	data time 0.0046 (0.0675)	model time 0.5431 (0.4928)	loss 0.4834 (0.5472)	grad_norm 3.6397 (2.5967)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:16:07 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][100/156]	eta 0:00:30 lr 0.000046	 wd 0.0500	time 0.4746 (0.5501)	data time 0.0129 (0.0638)	model time 0.4617 (0.4914)	loss 0.5660 (0.5485)	grad_norm 4.0207 (2.6778)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:16:12 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][110/156]	eta 0:00:25 lr 0.000046	 wd 0.0500	time 0.5584 (0.5443)	data time 0.0376 (0.0598)	model time 0.5209 (0.4871)	loss 0.5942 (0.5481)	grad_norm 3.1900 (2.7057)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:16:17 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][120/156]	eta 0:00:19 lr 0.000046	 wd 0.0500	time 0.5117 (0.5436)	data time 0.0164 (0.0567)	model time 0.4953 (0.4911)	loss 0.5418 (0.5477)	grad_norm 3.6848 (2.7560)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:16:22 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][130/156]	eta 0:00:14 lr 0.000046	 wd 0.0500	time 0.5031 (0.5395)	data time 0.0009 (0.0533)	model time 0.5022 (0.4894)	loss 0.6119 (0.5494)	grad_norm 3.1377 (2.7680)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:16:27 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][140/156]	eta 0:00:08 lr 0.000046	 wd 0.0500	time 0.5869 (0.5396)	data time 0.0011 (0.0504)	model time 0.5858 (0.4936)	loss 0.5519 (0.5492)	grad_norm 2.9641 (2.7949)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:16:32 vssm1_tiny_0230s](training.py 201): INFO Train: [184/300][150/156]	eta 0:00:03 lr 0.000046	 wd 0.0500	time 0.4646 (0.5354)	data time 0.0007 (0.0472)	model time 0.4640 (0.4916)	loss 0.6133 (0.5495)	grad_norm 2.9745 (2.7829)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:16:35 vssm1_tiny_0230s](training.py 212): INFO EPOCH 184 training takes 0:01:23
[2024-11-09 16:16:35 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_184.pth saving......
[2024-11-09 16:16:35 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_184.pth saved !!!
[2024-11-09 16:16:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.898 (2.898)	Loss 0.2198 (0.2198)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:16:41 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.597 (0.514)	Loss 0.2329 (0.2244)	Acc@1 92.969 (94.105)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:16:44 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.703 (0.400)	Loss 0.1843 (0.2325)	Acc@1 97.656 (93.936)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:16:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.337)	Loss 0.2413 (0.2275)	Acc@1 92.188 (94.355)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:16:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.640 Acc@5 100.000
[2024-11-09 16:16:48 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.6%
[2024-11-09 16:16:48 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.02%
[2024-11-09 16:16:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.507 (3.507)	Loss 0.2451 (0.2451)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:16:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.159 (0.567)	Loss 0.2568 (0.2582)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:16:57 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.440 (0.435)	Loss 0.3708 (0.2771)	Acc@1 87.500 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:17:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.779 (0.417)	Loss 0.4275 (0.3246)	Acc@1 82.031 (89.667)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:17:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.280 Acc@5 100.000
[2024-11-09 16:17:03 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 88.3%
[2024-11-09 16:17:03 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 88.28%
[2024-11-09 16:17:08 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][0/156]	eta 0:12:50 lr 0.000046	 wd 0.0500	time 4.9374 (4.9374)	data time 4.5171 (4.5171)	model time 0.0000 (0.0000)	loss 0.6106 (0.6106)	grad_norm 2.8982 (2.8982)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:17:14 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][10/156]	eta 0:02:20 lr 0.000046	 wd 0.0500	time 0.4317 (0.9602)	data time 0.0099 (0.4453)	model time 0.0000 (0.0000)	loss 0.5685 (0.5938)	grad_norm 1.7355 (2.2869)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:17:18 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][20/156]	eta 0:01:38 lr 0.000046	 wd 0.0500	time 0.4462 (0.7249)	data time 0.0106 (0.2368)	model time 0.0000 (0.0000)	loss 0.5745 (0.5673)	grad_norm 1.6193 (2.4802)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:17:24 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][30/156]	eta 0:01:22 lr 0.000046	 wd 0.0500	time 0.4913 (0.6547)	data time 0.0023 (0.1639)	model time 0.0000 (0.0000)	loss 0.5550 (0.5556)	grad_norm 3.7169 (2.6079)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:17:29 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][40/156]	eta 0:01:13 lr 0.000046	 wd 0.0500	time 0.5518 (0.6327)	data time 0.0105 (0.1277)	model time 0.0000 (0.0000)	loss 0.5871 (0.5480)	grad_norm 3.1688 (2.8011)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:17:34 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][50/156]	eta 0:01:03 lr 0.000046	 wd 0.0500	time 0.5938 (0.6014)	data time 0.0896 (0.1058)	model time 0.0000 (0.0000)	loss 0.4586 (0.5471)	grad_norm 2.9875 (2.7946)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:17:39 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][60/156]	eta 0:00:55 lr 0.000046	 wd 0.0500	time 0.4483 (0.5808)	data time 0.0207 (0.0907)	model time 0.4275 (0.4616)	loss 0.5693 (0.5499)	grad_norm 2.7046 (2.8242)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:17:44 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][70/156]	eta 0:00:49 lr 0.000046	 wd 0.0500	time 0.4948 (0.5743)	data time 0.0008 (0.0807)	model time 0.4939 (0.4884)	loss 0.4498 (0.5459)	grad_norm 3.1814 (2.8351)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:17:49 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][80/156]	eta 0:00:43 lr 0.000046	 wd 0.0500	time 0.4128 (0.5677)	data time 0.0032 (0.0735)	model time 0.4096 (0.4916)	loss 0.5346 (0.5454)	grad_norm 3.2292 (2.7932)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:17:55 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][90/156]	eta 0:00:37 lr 0.000046	 wd 0.0500	time 0.5605 (0.5644)	data time 0.0278 (0.0680)	model time 0.5327 (0.4974)	loss 0.4541 (0.5428)	grad_norm 5.3192 (2.8295)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:18:00 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][100/156]	eta 0:00:31 lr 0.000046	 wd 0.0500	time 0.5215 (0.5601)	data time 0.0007 (0.0621)	model time 0.5208 (0.5004)	loss 0.5866 (0.5452)	grad_norm 4.8484 (2.9016)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:18:05 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][110/156]	eta 0:00:25 lr 0.000046	 wd 0.0500	time 0.4805 (0.5517)	data time 0.0115 (0.0580)	model time 0.4690 (0.4922)	loss 0.5568 (0.5477)	grad_norm 1.7800 (2.9075)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:18:10 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][120/156]	eta 0:00:19 lr 0.000045	 wd 0.0500	time 0.4877 (0.5490)	data time 0.0057 (0.0559)	model time 0.4820 (0.4912)	loss 0.6513 (0.5502)	grad_norm 1.5964 (2.8474)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:18:15 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][130/156]	eta 0:00:14 lr 0.000045	 wd 0.0500	time 0.5372 (0.5444)	data time 0.0051 (0.0530)	model time 0.5320 (0.4887)	loss 0.5037 (0.5503)	grad_norm 3.6371 (2.8151)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:18:20 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][140/156]	eta 0:00:08 lr 0.000045	 wd 0.0500	time 0.4254 (0.5431)	data time 0.0011 (0.0504)	model time 0.4242 (0.4910)	loss 0.5804 (0.5498)	grad_norm 2.1403 (2.7825)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:18:25 vssm1_tiny_0230s](training.py 201): INFO Train: [185/300][150/156]	eta 0:00:03 lr 0.000045	 wd 0.0500	time 0.5155 (0.5410)	data time 0.0005 (0.0471)	model time 0.5150 (0.4929)	loss 0.4268 (0.5494)	grad_norm 2.7165 (2.7742)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:18:28 vssm1_tiny_0230s](training.py 212): INFO EPOCH 185 training takes 0:01:24
[2024-11-09 16:18:28 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_185.pth saving......
[2024-11-09 16:18:28 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_185.pth saved !!!
[2024-11-09 16:18:33 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.317 (4.317)	Loss 0.1929 (0.1929)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:18:36 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.132 (0.707)	Loss 0.2048 (0.2019)	Acc@1 95.312 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:18:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.467)	Loss 0.1868 (0.2118)	Acc@1 96.875 (95.610)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:18:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.185 (0.412)	Loss 0.2484 (0.2195)	Acc@1 92.188 (94.934)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:18:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.800 Acc@5 100.000
[2024-11-09 16:18:43 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.8%
[2024-11-09 16:18:43 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.02%
[2024-11-09 16:18:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.568 (2.568)	Loss 0.2439 (0.2439)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:18:49 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.468 (0.521)	Loss 0.2559 (0.2571)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:18:51 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.180 (0.388)	Loss 0.3657 (0.2758)	Acc@1 88.281 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:18:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.334)	Loss 0.4226 (0.3221)	Acc@1 82.031 (89.869)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:18:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.560 Acc@5 100.000
[2024-11-09 16:18:55 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 88.6%
[2024-11-09 16:18:55 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 88.56%
[2024-11-09 16:18:59 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][0/156]	eta 0:10:00 lr 0.000045	 wd 0.0500	time 3.8484 (3.8484)	data time 3.2384 (3.2384)	model time 0.0000 (0.0000)	loss 0.6768 (0.6768)	grad_norm 2.3798 (2.3798)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:04 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][10/156]	eta 0:01:56 lr 0.000045	 wd 0.0500	time 0.4100 (0.7996)	data time 0.0040 (0.3276)	model time 0.0000 (0.0000)	loss 0.6322 (0.5671)	grad_norm 3.3767 (2.8247)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:09 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][20/156]	eta 0:01:30 lr 0.000045	 wd 0.0500	time 0.5268 (0.6660)	data time 0.0235 (0.1773)	model time 0.0000 (0.0000)	loss 0.5240 (0.5594)	grad_norm 3.1349 (2.7122)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:14 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][30/156]	eta 0:01:17 lr 0.000045	 wd 0.0500	time 0.5080 (0.6118)	data time 0.0250 (0.1241)	model time 0.0000 (0.0000)	loss 0.5317 (0.5578)	grad_norm 2.8528 (2.5910)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:19 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][40/156]	eta 0:01:08 lr 0.000045	 wd 0.0500	time 0.4346 (0.5866)	data time 0.0066 (0.0991)	model time 0.0000 (0.0000)	loss 0.4945 (0.5575)	grad_norm 2.2435 (2.4961)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:24 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][50/156]	eta 0:01:00 lr 0.000045	 wd 0.0500	time 0.4520 (0.5684)	data time 0.0183 (0.0819)	model time 0.0000 (0.0000)	loss 0.4807 (0.5592)	grad_norm 2.6434 (2.5479)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:29 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][60/156]	eta 0:00:54 lr 0.000045	 wd 0.0500	time 0.4170 (0.5630)	data time 0.0022 (0.0715)	model time 0.4147 (0.5175)	loss 0.5558 (0.5570)	grad_norm 2.3566 (2.5415)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:34 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][70/156]	eta 0:00:47 lr 0.000045	 wd 0.0500	time 0.6536 (0.5567)	data time 0.0237 (0.0634)	model time 0.6299 (0.5105)	loss 0.6623 (0.5594)	grad_norm 1.7639 (2.5119)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:40 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][80/156]	eta 0:00:42 lr 0.000045	 wd 0.0500	time 0.4199 (0.5598)	data time 0.0006 (0.0574)	model time 0.4192 (0.5294)	loss 0.5023 (0.5581)	grad_norm 2.2261 (2.5204)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:45 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][90/156]	eta 0:00:36 lr 0.000045	 wd 0.0500	time 0.4749 (0.5535)	data time 0.0240 (0.0523)	model time 0.4510 (0.5200)	loss 0.4065 (0.5553)	grad_norm 3.6205 (2.5835)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:50 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][100/156]	eta 0:00:30 lr 0.000045	 wd 0.0500	time 0.4505 (0.5457)	data time 0.0007 (0.0484)	model time 0.4498 (0.5084)	loss 0.4448 (0.5549)	grad_norm 2.8741 (2.5816)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:54 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][110/156]	eta 0:00:24 lr 0.000045	 wd 0.0500	time 0.4259 (0.5372)	data time 0.0137 (0.0446)	model time 0.4122 (0.4978)	loss 0.5303 (0.5527)	grad_norm 2.8323 (2.6017)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:19:59 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][120/156]	eta 0:00:19 lr 0.000045	 wd 0.0500	time 0.6251 (0.5333)	data time 0.0098 (0.0420)	model time 0.6153 (0.4947)	loss 0.5871 (0.5535)	grad_norm 1.9910 (2.6096)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:20:04 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][130/156]	eta 0:00:13 lr 0.000045	 wd 0.0500	time 0.5349 (0.5322)	data time 0.0009 (0.0401)	model time 0.5340 (0.4957)	loss 0.5562 (0.5538)	grad_norm 2.2023 (2.5938)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:20:09 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][140/156]	eta 0:00:08 lr 0.000045	 wd 0.0500	time 0.4149 (0.5273)	data time 0.0010 (0.0383)	model time 0.4138 (0.4904)	loss 0.5881 (0.5534)	grad_norm 3.2643 (2.5894)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:20:14 vssm1_tiny_0230s](training.py 201): INFO Train: [186/300][150/156]	eta 0:00:03 lr 0.000045	 wd 0.0500	time 0.4724 (0.5231)	data time 0.0393 (0.0362)	model time 0.4332 (0.4872)	loss 0.5760 (0.5529)	grad_norm 1.7110 (2.5914)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:20:17 vssm1_tiny_0230s](training.py 212): INFO EPOCH 186 training takes 0:01:21
[2024-11-09 16:20:17 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_186.pth saving......
[2024-11-09 16:20:17 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_186.pth saved !!!
[2024-11-09 16:20:20 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.302 (3.302)	Loss 0.2051 (0.2051)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:20:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.438)	Loss 0.2046 (0.2032)	Acc@1 96.875 (95.952)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:20:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.163 (0.341)	Loss 0.1946 (0.2136)	Acc@1 96.875 (95.499)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:20:27 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.310)	Loss 0.2617 (0.2203)	Acc@1 92.969 (95.161)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:20:30 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.080 Acc@5 100.000
[2024-11-09 16:20:30 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 16:20:30 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.08%
[2024-11-09 16:20:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.193 (4.193)	Loss 0.2421 (0.2421)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:20:36 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.564)	Loss 0.2544 (0.2553)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:20:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.251 (0.412)	Loss 0.3618 (0.2739)	Acc@1 88.281 (93.527)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:20:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.211 (0.361)	Loss 0.4185 (0.3195)	Acc@1 82.031 (89.970)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:20:44 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.700 Acc@5 100.000
[2024-11-09 16:20:44 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 88.7%
[2024-11-09 16:20:44 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 88.70%
[2024-11-09 16:20:49 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][0/156]	eta 0:12:57 lr 0.000045	 wd 0.0500	time 4.9851 (4.9851)	data time 4.5520 (4.5520)	model time 0.0000 (0.0000)	loss 0.3989 (0.3989)	grad_norm 2.0502 (2.0502)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:20:53 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][10/156]	eta 0:02:09 lr 0.000045	 wd 0.0500	time 0.5385 (0.8874)	data time 0.0127 (0.4225)	model time 0.0000 (0.0000)	loss 0.5473 (0.5131)	grad_norm 3.1354 (2.8170)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:20:58 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][20/156]	eta 0:01:35 lr 0.000045	 wd 0.0500	time 0.4081 (0.7001)	data time 0.0006 (0.2267)	model time 0.0000 (0.0000)	loss 0.5287 (0.5285)	grad_norm 2.8119 (2.9000)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:03 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][30/156]	eta 0:01:19 lr 0.000045	 wd 0.0500	time 0.4702 (0.6293)	data time 0.0048 (0.1557)	model time 0.0000 (0.0000)	loss 0.6200 (0.5391)	grad_norm 2.2655 (2.9500)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:08 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][40/156]	eta 0:01:09 lr 0.000044	 wd 0.0500	time 0.5266 (0.5993)	data time 0.0356 (0.1241)	model time 0.0000 (0.0000)	loss 0.4065 (0.5423)	grad_norm 3.7542 (2.9160)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:13 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][50/156]	eta 0:01:02 lr 0.000044	 wd 0.0500	time 0.7247 (0.5850)	data time 0.0024 (0.1030)	model time 0.0000 (0.0000)	loss 0.6030 (0.5470)	grad_norm 2.6448 (2.8567)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:19 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][60/156]	eta 0:00:55 lr 0.000044	 wd 0.0500	time 0.4795 (0.5735)	data time 0.0021 (0.0889)	model time 0.4774 (0.4977)	loss 0.6191 (0.5440)	grad_norm 3.2131 (2.9265)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:24 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][70/156]	eta 0:00:48 lr 0.000044	 wd 0.0500	time 0.4843 (0.5685)	data time 0.0677 (0.0793)	model time 0.4166 (0.5077)	loss 0.6465 (0.5463)	grad_norm 2.2274 (2.8774)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:29 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][80/156]	eta 0:00:42 lr 0.000044	 wd 0.0500	time 0.6822 (0.5647)	data time 0.0072 (0.0716)	model time 0.6749 (0.5121)	loss 0.6140 (0.5480)	grad_norm 1.7488 (2.8091)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:35 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][90/156]	eta 0:00:36 lr 0.000044	 wd 0.0500	time 0.4790 (0.5598)	data time 0.0338 (0.0658)	model time 0.4451 (0.5094)	loss 0.6472 (0.5487)	grad_norm 2.4144 (2.7913)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:40 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][100/156]	eta 0:00:31 lr 0.000044	 wd 0.0500	time 0.5468 (0.5550)	data time 0.0046 (0.0603)	model time 0.5422 (0.5076)	loss 0.5959 (0.5484)	grad_norm 2.2912 (2.7681)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:45 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][110/156]	eta 0:00:25 lr 0.000044	 wd 0.0500	time 0.4315 (0.5528)	data time 0.0217 (0.0561)	model time 0.4098 (0.5091)	loss 0.6165 (0.5513)	grad_norm 2.3204 (2.7596)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:50 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][120/156]	eta 0:00:19 lr 0.000044	 wd 0.0500	time 0.5461 (0.5498)	data time 0.0179 (0.0525)	model time 0.5281 (0.5084)	loss 0.5145 (0.5547)	grad_norm 2.1351 (2.7122)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:21:56 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][130/156]	eta 0:00:14 lr 0.000044	 wd 0.0500	time 0.5511 (0.5524)	data time 0.0006 (0.0520)	model time 0.5504 (0.5123)	loss 0.6127 (0.5547)	grad_norm 2.0437 (2.6762)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:22:02 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][140/156]	eta 0:00:08 lr 0.000044	 wd 0.0500	time 0.5151 (0.5526)	data time 0.0009 (0.0493)	model time 0.5143 (0.5153)	loss 0.5681 (0.5546)	grad_norm 2.2303 (2.6298)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:22:06 vssm1_tiny_0230s](training.py 201): INFO Train: [187/300][150/156]	eta 0:00:03 lr 0.000044	 wd 0.0500	time 0.4211 (0.5464)	data time 0.0006 (0.0462)	model time 0.4204 (0.5095)	loss 0.4907 (0.5537)	grad_norm 3.4715 (2.6237)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:22:09 vssm1_tiny_0230s](training.py 212): INFO EPOCH 187 training takes 0:01:25
[2024-11-09 16:22:09 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_187.pth saving......
[2024-11-09 16:22:10 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_187.pth saved !!!
[2024-11-09 16:22:15 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.999 (4.999)	Loss 0.2109 (0.2109)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:22:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.150 (0.674)	Loss 0.2054 (0.2125)	Acc@1 96.875 (95.384)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:22:19 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.446)	Loss 0.1864 (0.2239)	Acc@1 97.656 (94.382)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:22:22 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.474 (0.385)	Loss 0.2384 (0.2257)	Acc@1 93.750 (94.506)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:22:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.780 Acc@5 100.000
[2024-11-09 16:22:25 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.8%
[2024-11-09 16:22:25 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.08%
[2024-11-09 16:22:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.725 (2.725)	Loss 0.2407 (0.2407)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:22:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.131 (0.565)	Loss 0.2529 (0.2540)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:22:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.367)	Loss 0.3577 (0.2724)	Acc@1 88.281 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:22:34 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.309)	Loss 0.4143 (0.3171)	Acc@1 82.812 (89.995)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:22:36 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.740 Acc@5 100.000
[2024-11-09 16:22:36 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 88.7%
[2024-11-09 16:22:36 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 88.74%
[2024-11-09 16:22:38 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][0/156]	eta 0:05:33 lr 0.000044	 wd 0.0500	time 2.1347 (2.1347)	data time 1.6623 (1.6623)	model time 0.0000 (0.0000)	loss 0.5804 (0.5804)	grad_norm 2.4582 (2.4582)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:22:42 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][10/156]	eta 0:01:26 lr 0.000044	 wd 0.0500	time 0.4170 (0.5903)	data time 0.0005 (0.1572)	model time 0.0000 (0.0000)	loss 0.6280 (0.5789)	grad_norm 2.5465 (2.9122)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:22:47 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][20/156]	eta 0:01:13 lr 0.000044	 wd 0.0500	time 0.4277 (0.5403)	data time 0.0195 (0.0885)	model time 0.0000 (0.0000)	loss 0.4985 (0.5703)	grad_norm 2.6589 (2.9341)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:22:52 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][30/156]	eta 0:01:07 lr 0.000044	 wd 0.0500	time 0.4332 (0.5353)	data time 0.0059 (0.0651)	model time 0.0000 (0.0000)	loss 0.5075 (0.5593)	grad_norm 2.0403 (2.7860)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:22:57 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][40/156]	eta 0:01:00 lr 0.000044	 wd 0.0500	time 0.5459 (0.5238)	data time 0.0006 (0.0532)	model time 0.0000 (0.0000)	loss 0.5179 (0.5570)	grad_norm 2.4766 (2.8100)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:03 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][50/156]	eta 0:00:55 lr 0.000044	 wd 0.0500	time 0.4626 (0.5268)	data time 0.0281 (0.0457)	model time 0.0000 (0.0000)	loss 0.4923 (0.5573)	grad_norm 2.5435 (2.8034)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:08 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][60/156]	eta 0:00:50 lr 0.000044	 wd 0.0500	time 0.4495 (0.5283)	data time 0.0193 (0.0409)	model time 0.4302 (0.5194)	loss 0.6148 (0.5490)	grad_norm 2.4851 (2.7810)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:13 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][70/156]	eta 0:00:45 lr 0.000044	 wd 0.0500	time 0.5640 (0.5282)	data time 0.0076 (0.0371)	model time 0.5564 (0.5163)	loss 0.4917 (0.5535)	grad_norm 4.3669 (2.7781)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:19 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][80/156]	eta 0:00:40 lr 0.000044	 wd 0.0500	time 0.5346 (0.5291)	data time 0.0015 (0.0346)	model time 0.5331 (0.5171)	loss 0.6146 (0.5510)	grad_norm 1.4176 (2.7749)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:24 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][90/156]	eta 0:00:34 lr 0.000044	 wd 0.0500	time 0.5444 (0.5277)	data time 0.0152 (0.0334)	model time 0.5293 (0.5111)	loss 0.5159 (0.5509)	grad_norm 3.7992 (2.7648)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:29 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][100/156]	eta 0:00:29 lr 0.000044	 wd 0.0500	time 0.4293 (0.5272)	data time 0.0193 (0.0331)	model time 0.4100 (0.5074)	loss 0.6568 (0.5523)	grad_norm 2.6033 (2.7820)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:34 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][110/156]	eta 0:00:24 lr 0.000044	 wd 0.0500	time 0.5360 (0.5277)	data time 0.0036 (0.0311)	model time 0.5325 (0.5097)	loss 0.6298 (0.5530)	grad_norm 1.9250 (2.7627)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:39 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][120/156]	eta 0:00:18 lr 0.000043	 wd 0.0500	time 0.6449 (0.5270)	data time 0.0266 (0.0311)	model time 0.6183 (0.5067)	loss 0.5079 (0.5503)	grad_norm 3.0386 (2.7927)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:45 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][130/156]	eta 0:00:13 lr 0.000043	 wd 0.0500	time 0.4929 (0.5287)	data time 0.0239 (0.0302)	model time 0.4690 (0.5097)	loss 0.5799 (0.5521)	grad_norm 2.4279 (2.8545)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:50 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][140/156]	eta 0:00:08 lr 0.000043	 wd 0.0500	time 0.4196 (0.5256)	data time 0.0010 (0.0289)	model time 0.4187 (0.5055)	loss 0.6077 (0.5534)	grad_norm 1.8744 (2.8624)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:55 vssm1_tiny_0230s](training.py 201): INFO Train: [188/300][150/156]	eta 0:00:03 lr 0.000043	 wd 0.0500	time 0.4830 (0.5219)	data time 0.0004 (0.0273)	model time 0.4826 (0.5015)	loss 0.6405 (0.5542)	grad_norm 1.8480 (2.8440)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:23:57 vssm1_tiny_0230s](training.py 212): INFO EPOCH 188 training takes 0:01:21
[2024-11-09 16:23:57 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_188.pth saving......
[2024-11-09 16:23:58 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_188.pth saved !!!
[2024-11-09 16:24:02 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.919 (3.919)	Loss 0.2444 (0.2444)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:24:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.607)	Loss 0.2539 (0.2524)	Acc@1 92.188 (94.460)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:24:08 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.183 (0.461)	Loss 0.1914 (0.2599)	Acc@1 98.438 (93.899)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:24:10 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.266 (0.387)	Loss 0.2406 (0.2487)	Acc@1 93.750 (94.355)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:24:12 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.680 Acc@5 100.000
[2024-11-09 16:24:12 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.7%
[2024-11-09 16:24:12 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.08%
[2024-11-09 16:24:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.931 (3.931)	Loss 0.2394 (0.2394)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:24:19 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.170 (0.591)	Loss 0.2520 (0.2527)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:24:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.160 (0.439)	Loss 0.3530 (0.2710)	Acc@1 88.281 (93.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:24:24 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.207 (0.393)	Loss 0.4099 (0.3147)	Acc@1 83.594 (90.071)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:24:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.900 Acc@5 100.000
[2024-11-09 16:24:27 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 88.9%
[2024-11-09 16:24:27 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 88.90%
[2024-11-09 16:24:30 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][0/156]	eta 0:09:55 lr 0.000043	 wd 0.0500	time 3.8145 (3.8145)	data time 3.3542 (3.3542)	model time 0.0000 (0.0000)	loss 0.4345 (0.4345)	grad_norm 3.9737 (3.9737)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:24:36 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][10/156]	eta 0:02:02 lr 0.000043	 wd 0.0500	time 0.6350 (0.8423)	data time 0.0025 (0.3182)	model time 0.0000 (0.0000)	loss 0.6198 (0.5638)	grad_norm 1.7454 (2.7198)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:24:41 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][20/156]	eta 0:01:32 lr 0.000043	 wd 0.0500	time 0.4435 (0.6827)	data time 0.0025 (0.1784)	model time 0.0000 (0.0000)	loss 0.6101 (0.5678)	grad_norm 2.6835 (2.6886)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:24:45 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][30/156]	eta 0:01:17 lr 0.000043	 wd 0.0500	time 0.4141 (0.6117)	data time 0.0021 (0.1237)	model time 0.0000 (0.0000)	loss 0.6647 (0.5674)	grad_norm 5.2763 (2.7378)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:24:50 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][40/156]	eta 0:01:07 lr 0.000043	 wd 0.0500	time 0.5343 (0.5843)	data time 0.0059 (0.0973)	model time 0.0000 (0.0000)	loss 0.5001 (0.5527)	grad_norm 2.1086 (2.7172)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:24:55 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][50/156]	eta 0:00:59 lr 0.000043	 wd 0.0500	time 0.4518 (0.5631)	data time 0.0098 (0.0806)	model time 0.0000 (0.0000)	loss 0.5728 (0.5504)	grad_norm 3.6546 (2.8365)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:00 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][60/156]	eta 0:00:52 lr 0.000043	 wd 0.0500	time 0.4351 (0.5481)	data time 0.0010 (0.0697)	model time 0.4341 (0.4576)	loss 0.5454 (0.5557)	grad_norm 2.0394 (2.8928)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:05 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][70/156]	eta 0:00:46 lr 0.000043	 wd 0.0500	time 0.5635 (0.5430)	data time 0.0050 (0.0613)	model time 0.5585 (0.4799)	loss 0.5732 (0.5505)	grad_norm 4.2333 (3.0224)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:10 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][80/156]	eta 0:00:40 lr 0.000043	 wd 0.0500	time 0.4573 (0.5376)	data time 0.0006 (0.0579)	model time 0.4567 (0.4750)	loss 0.5458 (0.5540)	grad_norm 3.3301 (3.0398)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:15 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][90/156]	eta 0:00:35 lr 0.000043	 wd 0.0500	time 0.5446 (0.5307)	data time 0.0049 (0.0522)	model time 0.5397 (0.4736)	loss 0.6081 (0.5567)	grad_norm 1.7621 (3.0270)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:20 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][100/156]	eta 0:00:29 lr 0.000043	 wd 0.0500	time 0.4642 (0.5269)	data time 0.0167 (0.0487)	model time 0.4475 (0.4737)	loss 0.4369 (0.5561)	grad_norm 4.4564 (3.0385)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:25 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][110/156]	eta 0:00:24 lr 0.000043	 wd 0.0500	time 0.5455 (0.5271)	data time 0.0043 (0.0464)	model time 0.5412 (0.4791)	loss 0.5776 (0.5555)	grad_norm 2.5514 (2.9802)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:30 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][120/156]	eta 0:00:19 lr 0.000043	 wd 0.0500	time 0.5243 (0.5279)	data time 0.0023 (0.0441)	model time 0.5221 (0.4848)	loss 0.5083 (0.5548)	grad_norm 1.8845 (3.0017)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:35 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][130/156]	eta 0:00:13 lr 0.000043	 wd 0.0500	time 0.5609 (0.5256)	data time 0.0006 (0.0421)	model time 0.5603 (0.4842)	loss 0.5773 (0.5551)	grad_norm 2.5985 (3.0064)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:40 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][140/156]	eta 0:00:08 lr 0.000043	 wd 0.0500	time 0.4132 (0.5246)	data time 0.0007 (0.0403)	model time 0.4125 (0.4853)	loss 0.4529 (0.5534)	grad_norm 5.1642 (3.0555)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:46 vssm1_tiny_0230s](training.py 201): INFO Train: [189/300][150/156]	eta 0:00:03 lr 0.000043	 wd 0.0500	time 0.5136 (0.5237)	data time 0.0005 (0.0377)	model time 0.5131 (0.4878)	loss 0.5873 (0.5540)	grad_norm 2.0219 (3.0591)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:25:49 vssm1_tiny_0230s](training.py 212): INFO EPOCH 189 training takes 0:01:22
[2024-11-09 16:25:49 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_189.pth saving......
[2024-11-09 16:25:49 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_189.pth saved !!!
[2024-11-09 16:25:54 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 5.063 (5.063)	Loss 0.1951 (0.1951)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:25:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.150 (0.700)	Loss 0.2009 (0.1981)	Acc@1 96.094 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:25:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.482)	Loss 0.2042 (0.2095)	Acc@1 96.875 (95.499)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:26:02 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.409)	Loss 0.2700 (0.2187)	Acc@1 92.188 (95.060)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:26:04 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.980 Acc@5 100.000
[2024-11-09 16:26:04 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 16:26:04 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.08%
[2024-11-09 16:26:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.044 (2.044)	Loss 0.2378 (0.2378)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:26:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 1.020 (0.555)	Loss 0.2505 (0.2512)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:26:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.167 (0.433)	Loss 0.3491 (0.2694)	Acc@1 88.281 (93.415)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:26:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.192 (0.377)	Loss 0.4060 (0.3123)	Acc@1 84.375 (90.096)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:26:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 88.980 Acc@5 100.000
[2024-11-09 16:26:17 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 89.0%
[2024-11-09 16:26:17 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 88.98%
[2024-11-09 16:26:21 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][0/156]	eta 0:09:59 lr 0.000043	 wd 0.0500	time 3.8445 (3.8445)	data time 3.3496 (3.3496)	model time 0.0000 (0.0000)	loss 0.5535 (0.5535)	grad_norm 2.0344 (2.0344)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:26:27 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][10/156]	eta 0:02:00 lr 0.000043	 wd 0.0500	time 0.5288 (0.8255)	data time 0.0215 (0.3385)	model time 0.0000 (0.0000)	loss 0.6637 (0.5527)	grad_norm 2.4220 (2.7143)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:26:32 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][20/156]	eta 0:01:32 lr 0.000043	 wd 0.0500	time 0.5456 (0.6774)	data time 0.1255 (0.1889)	model time 0.0000 (0.0000)	loss 0.4634 (0.5485)	grad_norm 3.2670 (2.5661)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:26:36 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][30/156]	eta 0:01:17 lr 0.000043	 wd 0.0500	time 0.4117 (0.6137)	data time 0.0052 (0.1320)	model time 0.0000 (0.0000)	loss 0.5952 (0.5592)	grad_norm 2.2048 (2.6192)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:26:41 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][40/156]	eta 0:01:06 lr 0.000043	 wd 0.0500	time 0.4236 (0.5739)	data time 0.0057 (0.1042)	model time 0.0000 (0.0000)	loss 0.6137 (0.5595)	grad_norm 2.0112 (2.4986)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:26:45 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][50/156]	eta 0:00:58 lr 0.000042	 wd 0.0500	time 0.5315 (0.5492)	data time 0.0045 (0.0856)	model time 0.0000 (0.0000)	loss 0.6323 (0.5608)	grad_norm 2.5283 (2.4445)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:26:51 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][60/156]	eta 0:00:52 lr 0.000042	 wd 0.0500	time 0.6020 (0.5420)	data time 0.0145 (0.0735)	model time 0.5875 (0.4937)	loss 0.6296 (0.5632)	grad_norm 2.1367 (2.4654)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:26:56 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][70/156]	eta 0:00:46 lr 0.000042	 wd 0.0500	time 0.6117 (0.5366)	data time 0.0499 (0.0681)	model time 0.5617 (0.4809)	loss 0.5429 (0.5625)	grad_norm 2.8659 (2.5038)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:27:00 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][80/156]	eta 0:00:40 lr 0.000042	 wd 0.0500	time 0.4834 (0.5307)	data time 0.0348 (0.0625)	model time 0.4485 (0.4759)	loss 0.5757 (0.5615)	grad_norm 2.2135 (2.4866)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:27:06 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][90/156]	eta 0:00:35 lr 0.000042	 wd 0.0500	time 0.4241 (0.5310)	data time 0.0019 (0.0574)	model time 0.4221 (0.4864)	loss 0.4176 (0.5604)	grad_norm 2.9972 (2.4883)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:27:11 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][100/156]	eta 0:00:29 lr 0.000042	 wd 0.0500	time 0.4276 (0.5254)	data time 0.0008 (0.0530)	model time 0.4268 (0.4813)	loss 0.5872 (0.5596)	grad_norm 2.5346 (2.4810)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:27:16 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][110/156]	eta 0:00:24 lr 0.000042	 wd 0.0500	time 0.4504 (0.5243)	data time 0.0213 (0.0496)	model time 0.4291 (0.4841)	loss 0.6492 (0.5592)	grad_norm 4.7571 (2.5474)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:27:21 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][120/156]	eta 0:00:18 lr 0.000042	 wd 0.0500	time 0.6612 (0.5215)	data time 0.0251 (0.0467)	model time 0.6361 (0.4829)	loss 0.4171 (0.5567)	grad_norm 1.7335 (2.5366)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:27:26 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][130/156]	eta 0:00:13 lr 0.000042	 wd 0.0500	time 0.5872 (0.5244)	data time 0.0688 (0.0454)	model time 0.5184 (0.4889)	loss 0.5376 (0.5564)	grad_norm 2.7989 (2.5615)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:27:31 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][140/156]	eta 0:00:08 lr 0.000042	 wd 0.0500	time 0.5850 (0.5247)	data time 0.0009 (0.0429)	model time 0.5841 (0.4921)	loss 0.4340 (0.5524)	grad_norm 3.3914 (2.6210)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:27:36 vssm1_tiny_0230s](training.py 201): INFO Train: [190/300][150/156]	eta 0:00:03 lr 0.000042	 wd 0.0500	time 0.5144 (0.5212)	data time 0.0007 (0.0401)	model time 0.5136 (0.4900)	loss 0.6567 (0.5531)	grad_norm 2.1281 (2.6401)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:27:39 vssm1_tiny_0230s](training.py 212): INFO EPOCH 190 training takes 0:01:21
[2024-11-09 16:27:39 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_190.pth saving......
[2024-11-09 16:27:40 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_190.pth saved !!!
[2024-11-09 16:27:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.730 (1.730)	Loss 0.2281 (0.2281)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:27:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.603 (0.507)	Loss 0.2311 (0.2320)	Acc@1 93.750 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:27:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.217 (0.384)	Loss 0.1835 (0.2416)	Acc@1 97.656 (93.973)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:27:50 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.345)	Loss 0.2362 (0.2327)	Acc@1 92.969 (94.330)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:27:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.640 Acc@5 100.000
[2024-11-09 16:27:53 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.6%
[2024-11-09 16:27:53 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.08%
[2024-11-09 16:27:56 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.084 (3.084)	Loss 0.2366 (0.2366)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:28:00 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.961 (0.577)	Loss 0.2495 (0.2500)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:28:02 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.444 (0.420)	Loss 0.3452 (0.2680)	Acc@1 89.062 (93.452)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:28:05 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.366)	Loss 0.4021 (0.3100)	Acc@1 84.375 (90.247)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:28:07 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.200 Acc@5 100.000
[2024-11-09 16:28:07 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 89.2%
[2024-11-09 16:28:07 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 89.20%
[2024-11-09 16:28:11 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][0/156]	eta 0:11:00 lr 0.000042	 wd 0.0500	time 4.2334 (4.2334)	data time 3.7406 (3.7406)	model time 0.0000 (0.0000)	loss 0.6121 (0.6121)	grad_norm 3.0453 (3.0453)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:28:16 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][10/156]	eta 0:02:01 lr 0.000042	 wd 0.0500	time 0.4255 (0.8326)	data time 0.0179 (0.3483)	model time 0.0000 (0.0000)	loss 0.5817 (0.5774)	grad_norm 1.9405 (2.4114)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:28:21 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][20/156]	eta 0:01:30 lr 0.000042	 wd 0.0500	time 0.5162 (0.6636)	data time 0.0007 (0.1907)	model time 0.0000 (0.0000)	loss 0.6303 (0.5646)	grad_norm 1.6653 (2.5153)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:28:26 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][30/156]	eta 0:01:16 lr 0.000042	 wd 0.0500	time 0.5346 (0.6106)	data time 0.0896 (0.1410)	model time 0.0000 (0.0000)	loss 0.6373 (0.5703)	grad_norm 1.8706 (2.4794)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:28:31 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][40/156]	eta 0:01:08 lr 0.000042	 wd 0.0500	time 0.5891 (0.5883)	data time 0.0109 (0.1161)	model time 0.0000 (0.0000)	loss 0.4275 (0.5702)	grad_norm 2.6344 (2.4595)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:28:36 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][50/156]	eta 0:01:00 lr 0.000042	 wd 0.0500	time 0.4469 (0.5721)	data time 0.0268 (0.0958)	model time 0.0000 (0.0000)	loss 0.5823 (0.5677)	grad_norm 2.8589 (2.4646)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:28:41 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][60/156]	eta 0:00:53 lr 0.000042	 wd 0.0500	time 0.5208 (0.5578)	data time 0.0063 (0.0810)	model time 0.5145 (0.4789)	loss 0.5892 (0.5636)	grad_norm 1.9773 (2.4365)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:28:46 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][70/156]	eta 0:00:47 lr 0.000042	 wd 0.0500	time 0.4748 (0.5557)	data time 0.0381 (0.0749)	model time 0.4367 (0.4923)	loss 0.6360 (0.5609)	grad_norm 1.5143 (2.4734)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:28:52 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][80/156]	eta 0:00:42 lr 0.000042	 wd 0.0500	time 0.6280 (0.5527)	data time 0.0037 (0.0680)	model time 0.6243 (0.4990)	loss 0.5014 (0.5578)	grad_norm 6.5009 (2.5400)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:28:57 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][90/156]	eta 0:00:36 lr 0.000042	 wd 0.0500	time 0.4776 (0.5499)	data time 0.0028 (0.0642)	model time 0.4748 (0.4975)	loss 0.4780 (0.5560)	grad_norm 2.6834 (2.5553)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:29:03 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][100/156]	eta 0:00:30 lr 0.000042	 wd 0.0500	time 0.4421 (0.5533)	data time 0.0118 (0.0588)	model time 0.4303 (0.5130)	loss 0.6448 (0.5543)	grad_norm 2.1998 (2.5599)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:29:08 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][110/156]	eta 0:00:25 lr 0.000042	 wd 0.0500	time 0.5525 (0.5514)	data time 0.0649 (0.0569)	model time 0.4875 (0.5100)	loss 0.6815 (0.5541)	grad_norm 4.3802 (2.5734)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:29:13 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][120/156]	eta 0:00:19 lr 0.000042	 wd 0.0500	time 0.5657 (0.5466)	data time 0.0088 (0.0527)	model time 0.5569 (0.5068)	loss 0.5890 (0.5526)	grad_norm 1.8855 (2.6064)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:29:18 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][130/156]	eta 0:00:14 lr 0.000041	 wd 0.0500	time 0.5522 (0.5436)	data time 0.0007 (0.0497)	model time 0.5515 (0.5051)	loss 0.4430 (0.5510)	grad_norm 2.6635 (2.6544)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:29:23 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][140/156]	eta 0:00:08 lr 0.000041	 wd 0.0500	time 0.5156 (0.5410)	data time 0.0010 (0.0477)	model time 0.5145 (0.5029)	loss 0.4618 (0.5502)	grad_norm 3.2779 (2.6505)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:29:28 vssm1_tiny_0230s](training.py 201): INFO Train: [191/300][150/156]	eta 0:00:03 lr 0.000041	 wd 0.0500	time 0.4864 (0.5387)	data time 0.0010 (0.0453)	model time 0.4854 (0.5022)	loss 0.5981 (0.5510)	grad_norm 4.0358 (2.6602)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:29:31 vssm1_tiny_0230s](training.py 212): INFO EPOCH 191 training takes 0:01:24
[2024-11-09 16:29:31 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_191.pth saving......
[2024-11-09 16:29:32 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_191.pth saved !!!
[2024-11-09 16:29:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.828 (2.828)	Loss 0.2205 (0.2205)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:29:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.719 (0.475)	Loss 0.2301 (0.2207)	Acc@1 93.750 (94.247)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:29:39 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.329)	Loss 0.1998 (0.2308)	Acc@1 96.875 (93.824)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:29:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.302)	Loss 0.2563 (0.2295)	Acc@1 92.188 (94.204)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:29:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.540 Acc@5 100.000
[2024-11-09 16:29:42 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.5%
[2024-11-09 16:29:42 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.08%
[2024-11-09 16:29:46 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.257 (3.257)	Loss 0.2355 (0.2355)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:29:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.230 (0.497)	Loss 0.2485 (0.2489)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:29:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.376)	Loss 0.3408 (0.2668)	Acc@1 89.844 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:29:52 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.315)	Loss 0.3977 (0.3078)	Acc@1 84.375 (90.398)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:29:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.340 Acc@5 100.000
[2024-11-09 16:29:55 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 89.3%
[2024-11-09 16:29:55 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 89.34%
[2024-11-09 16:29:59 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][0/156]	eta 0:12:01 lr 0.000041	 wd 0.0500	time 4.6272 (4.6272)	data time 4.0990 (4.0990)	model time 0.0000 (0.0000)	loss 0.5947 (0.5947)	grad_norm 2.8970 (2.8970)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:30:04 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][10/156]	eta 0:02:04 lr 0.000041	 wd 0.0500	time 0.4101 (0.8538)	data time 0.0009 (0.3808)	model time 0.0000 (0.0000)	loss 0.6069 (0.5527)	grad_norm 1.9632 (2.6376)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:30:09 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][20/156]	eta 0:01:33 lr 0.000041	 wd 0.0500	time 0.5188 (0.6895)	data time 0.0195 (0.2108)	model time 0.0000 (0.0000)	loss 0.6128 (0.5616)	grad_norm 1.7428 (2.4325)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:30:14 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][30/156]	eta 0:01:19 lr 0.000041	 wd 0.0500	time 0.4249 (0.6298)	data time 0.0097 (0.1481)	model time 0.0000 (0.0000)	loss 0.4748 (0.5504)	grad_norm 3.5519 (2.5197)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:30:19 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][40/156]	eta 0:01:09 lr 0.000041	 wd 0.0500	time 0.4954 (0.6026)	data time 0.0324 (0.1187)	model time 0.0000 (0.0000)	loss 0.5819 (0.5572)	grad_norm 4.1575 (2.6029)	loss_scale 65536.0000 (38362.5366)	mem 13675MB
[2024-11-09 16:30:24 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][50/156]	eta 0:01:01 lr 0.000041	 wd 0.0500	time 0.4815 (0.5843)	data time 0.0248 (0.0975)	model time 0.0000 (0.0000)	loss 0.4653 (0.5579)	grad_norm 1.9742 (2.6134)	loss_scale 65536.0000 (43690.6667)	mem 13675MB
[2024-11-09 16:30:29 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][60/156]	eta 0:00:54 lr 0.000041	 wd 0.0500	time 0.5784 (0.5719)	data time 0.0031 (0.0842)	model time 0.5753 (0.4923)	loss 0.5232 (0.5557)	grad_norm 2.7845 (2.6434)	loss_scale 65536.0000 (47271.8689)	mem 13675MB
[2024-11-09 16:30:35 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][70/156]	eta 0:00:48 lr 0.000041	 wd 0.0500	time 0.5600 (0.5630)	data time 0.0006 (0.0751)	model time 0.5594 (0.4908)	loss 0.5209 (0.5552)	grad_norm 2.9632 (2.6462)	loss_scale 65536.0000 (49844.2817)	mem 13675MB
[2024-11-09 16:30:39 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][80/156]	eta 0:00:42 lr 0.000041	 wd 0.0500	time 0.4951 (0.5543)	data time 0.0227 (0.0668)	model time 0.4724 (0.4887)	loss 0.6038 (0.5540)	grad_norm 2.3287 (2.6387)	loss_scale 65536.0000 (51781.5309)	mem 13675MB
[2024-11-09 16:30:45 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][90/156]	eta 0:00:36 lr 0.000041	 wd 0.0500	time 0.4586 (0.5491)	data time 0.0016 (0.0608)	model time 0.4570 (0.4903)	loss 0.5145 (0.5504)	grad_norm 3.1155 (2.6978)	loss_scale 65536.0000 (53293.0110)	mem 13675MB
[2024-11-09 16:30:49 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][100/156]	eta 0:00:30 lr 0.000041	 wd 0.0500	time 0.5401 (0.5420)	data time 0.0007 (0.0567)	model time 0.5394 (0.4838)	loss 0.5742 (0.5526)	grad_norm 2.2423 (2.7520)	loss_scale 65536.0000 (54505.1881)	mem 13675MB
[2024-11-09 16:30:54 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][110/156]	eta 0:00:24 lr 0.000041	 wd 0.0500	time 0.4652 (0.5376)	data time 0.0008 (0.0529)	model time 0.4645 (0.4829)	loss 0.5672 (0.5548)	grad_norm 1.8894 (2.7512)	loss_scale 65536.0000 (55498.9550)	mem 13675MB
[2024-11-09 16:30:59 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][120/156]	eta 0:00:19 lr 0.000041	 wd 0.0500	time 0.5270 (0.5352)	data time 0.0220 (0.0497)	model time 0.5050 (0.4845)	loss 0.4704 (0.5522)	grad_norm 2.3670 (2.7432)	loss_scale 65536.0000 (56328.4628)	mem 13675MB
[2024-11-09 16:31:05 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][130/156]	eta 0:00:13 lr 0.000041	 wd 0.0500	time 0.5580 (0.5363)	data time 0.0087 (0.0473)	model time 0.5493 (0.4904)	loss 0.5014 (0.5500)	grad_norm 3.2139 (2.7820)	loss_scale 65536.0000 (57031.3282)	mem 13675MB
[2024-11-09 16:31:10 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][140/156]	eta 0:00:08 lr 0.000041	 wd 0.0500	time 0.4243 (0.5321)	data time 0.0136 (0.0447)	model time 0.4107 (0.4877)	loss 0.4486 (0.5503)	grad_norm 3.6260 (2.7676)	loss_scale 65536.0000 (57634.4965)	mem 13675MB
[2024-11-09 16:31:15 vssm1_tiny_0230s](training.py 201): INFO Train: [192/300][150/156]	eta 0:00:03 lr 0.000041	 wd 0.0500	time 0.4729 (0.5311)	data time 0.0004 (0.0419)	model time 0.4726 (0.4904)	loss 0.5666 (0.5526)	grad_norm 2.0411 (2.7511)	loss_scale 65536.0000 (58157.7748)	mem 13675MB
[2024-11-09 16:31:18 vssm1_tiny_0230s](training.py 212): INFO EPOCH 192 training takes 0:01:23
[2024-11-09 16:31:18 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_192.pth saving......
[2024-11-09 16:31:18 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_192.pth saved !!!
[2024-11-09 16:31:22 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.960 (3.960)	Loss 0.2112 (0.2112)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:31:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.213 (0.558)	Loss 0.2115 (0.2082)	Acc@1 95.312 (95.952)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:31:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.404)	Loss 0.2076 (0.2202)	Acc@1 96.094 (95.164)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:31:30 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.582 (0.360)	Loss 0.2559 (0.2268)	Acc@1 93.750 (94.934)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:31:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.940 Acc@5 100.000
[2024-11-09 16:31:32 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.9%
[2024-11-09 16:31:32 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.08%
[2024-11-09 16:31:36 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.940 (3.940)	Loss 0.2340 (0.2340)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:31:38 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.177 (0.552)	Loss 0.2472 (0.2475)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:31:41 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.132 (0.396)	Loss 0.3372 (0.2653)	Acc@1 90.625 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:31:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.359)	Loss 0.3940 (0.3056)	Acc@1 84.375 (90.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:31:46 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.420 Acc@5 100.000
[2024-11-09 16:31:46 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 89.4%
[2024-11-09 16:31:46 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 89.42%
[2024-11-09 16:31:52 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][0/156]	eta 0:15:41 lr 0.000041	 wd 0.0500	time 6.0376 (6.0376)	data time 5.5523 (5.5523)	model time 0.0000 (0.0000)	loss 0.5774 (0.5774)	grad_norm 2.1765 (2.1765)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:31:57 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][10/156]	eta 0:02:35 lr 0.000041	 wd 0.0500	time 0.6867 (1.0623)	data time 0.0119 (0.5393)	model time 0.0000 (0.0000)	loss 0.6472 (0.5823)	grad_norm 1.6970 (2.5768)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:03 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][20/156]	eta 0:01:49 lr 0.000041	 wd 0.0500	time 0.4570 (0.8061)	data time 0.0298 (0.2915)	model time 0.0000 (0.0000)	loss 0.5969 (0.5764)	grad_norm 2.5581 (2.3984)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:08 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][30/156]	eta 0:01:29 lr 0.000041	 wd 0.0500	time 0.4893 (0.7078)	data time 0.0120 (0.2031)	model time 0.0000 (0.0000)	loss 0.5715 (0.5767)	grad_norm 3.7396 (2.4290)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:13 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][40/156]	eta 0:01:16 lr 0.000041	 wd 0.0500	time 0.4745 (0.6617)	data time 0.0007 (0.1629)	model time 0.0000 (0.0000)	loss 0.6504 (0.5734)	grad_norm 4.5437 (2.6549)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:18 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][50/156]	eta 0:01:07 lr 0.000041	 wd 0.0500	time 0.4151 (0.6357)	data time 0.0069 (0.1366)	model time 0.0000 (0.0000)	loss 0.6101 (0.5709)	grad_norm 2.2409 (2.6660)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:23 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][60/156]	eta 0:00:58 lr 0.000040	 wd 0.0500	time 0.4445 (0.6137)	data time 0.0034 (0.1159)	model time 0.4412 (0.4912)	loss 0.6343 (0.5656)	grad_norm 3.1750 (2.7417)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:28 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][70/156]	eta 0:00:51 lr 0.000040	 wd 0.0500	time 0.5395 (0.5986)	data time 0.0194 (0.1031)	model time 0.5201 (0.4863)	loss 0.5906 (0.5671)	grad_norm 2.2438 (2.7033)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:33 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][80/156]	eta 0:00:44 lr 0.000040	 wd 0.0500	time 0.4519 (0.5841)	data time 0.0263 (0.0917)	model time 0.4256 (0.4812)	loss 0.5767 (0.5658)	grad_norm 2.0528 (2.6614)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:39 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][90/156]	eta 0:00:38 lr 0.000040	 wd 0.0500	time 0.4674 (0.5805)	data time 0.0262 (0.0833)	model time 0.4412 (0.4948)	loss 0.5453 (0.5652)	grad_norm 3.7104 (2.7274)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:43 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][100/156]	eta 0:00:31 lr 0.000040	 wd 0.0500	time 0.4472 (0.5679)	data time 0.0221 (0.0765)	model time 0.4250 (0.4836)	loss 0.6117 (0.5669)	grad_norm 1.7246 (2.7261)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:48 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][110/156]	eta 0:00:25 lr 0.000040	 wd 0.0500	time 0.5391 (0.5652)	data time 0.0179 (0.0706)	model time 0.5212 (0.4907)	loss 0.5634 (0.5651)	grad_norm 2.7306 (2.7200)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:53 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][120/156]	eta 0:00:20 lr 0.000040	 wd 0.0500	time 0.4262 (0.5568)	data time 0.0054 (0.0659)	model time 0.4209 (0.4849)	loss 0.4863 (0.5587)	grad_norm 3.6255 (2.7316)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:32:58 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][130/156]	eta 0:00:14 lr 0.000040	 wd 0.0500	time 0.5601 (0.5550)	data time 0.0007 (0.0624)	model time 0.5594 (0.4884)	loss 0.6403 (0.5596)	grad_norm 3.4533 (2.7501)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:33:04 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][140/156]	eta 0:00:08 lr 0.000040	 wd 0.0500	time 0.4268 (0.5523)	data time 0.0009 (0.0584)	model time 0.4259 (0.4911)	loss 0.4553 (0.5580)	grad_norm 2.1948 (2.7552)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:33:08 vssm1_tiny_0230s](training.py 201): INFO Train: [193/300][150/156]	eta 0:00:03 lr 0.000040	 wd 0.0500	time 0.4989 (0.5479)	data time 0.0005 (0.0546)	model time 0.4984 (0.4903)	loss 0.5787 (0.5596)	grad_norm 1.7245 (2.7572)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:33:11 vssm1_tiny_0230s](training.py 212): INFO EPOCH 193 training takes 0:01:25
[2024-11-09 16:33:11 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_193.pth saving......
[2024-11-09 16:33:11 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_193.pth saved !!!
[2024-11-09 16:33:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.227 (4.227)	Loss 0.2445 (0.2445)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:33:18 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.152 (0.603)	Loss 0.2520 (0.2464)	Acc@1 92.969 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:33:20 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.155 (0.420)	Loss 0.1968 (0.2551)	Acc@1 97.656 (94.085)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:33:22 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.351)	Loss 0.2438 (0.2459)	Acc@1 92.969 (94.582)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:33:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.780 Acc@5 100.000
[2024-11-09 16:33:24 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.8%
[2024-11-09 16:33:24 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.08%
[2024-11-09 16:33:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.147 (3.147)	Loss 0.2327 (0.2327)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:33:29 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.131 (0.464)	Loss 0.2458 (0.2462)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:33:33 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.168 (0.410)	Loss 0.3333 (0.2638)	Acc@1 90.625 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:33:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.150 (0.359)	Loss 0.3904 (0.3033)	Acc@1 84.375 (90.474)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:33:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.460 Acc@5 100.000
[2024-11-09 16:33:38 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 89.5%
[2024-11-09 16:33:38 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 89.46%
[2024-11-09 16:33:42 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][0/156]	eta 0:11:37 lr 0.000040	 wd 0.0500	time 4.4735 (4.4735)	data time 3.9779 (3.9779)	model time 0.0000 (0.0000)	loss 0.5657 (0.5657)	grad_norm 1.7796 (1.7796)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:33:47 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][10/156]	eta 0:02:05 lr 0.000040	 wd 0.0500	time 0.5336 (0.8629)	data time 0.0010 (0.3684)	model time 0.0000 (0.0000)	loss 0.4576 (0.5367)	grad_norm 3.3568 (2.5798)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:33:53 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][20/156]	eta 0:01:38 lr 0.000040	 wd 0.0500	time 0.4965 (0.7249)	data time 0.0020 (0.2055)	model time 0.0000 (0.0000)	loss 0.4880 (0.5363)	grad_norm 4.7980 (2.7464)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:33:58 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][30/156]	eta 0:01:21 lr 0.000040	 wd 0.0500	time 0.4526 (0.6436)	data time 0.0047 (0.1410)	model time 0.0000 (0.0000)	loss 0.5244 (0.5396)	grad_norm 3.0034 (2.8190)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:02 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][40/156]	eta 0:01:10 lr 0.000040	 wd 0.0500	time 0.4267 (0.6050)	data time 0.0157 (0.1096)	model time 0.0000 (0.0000)	loss 0.4256 (0.5500)	grad_norm 2.8472 (2.8918)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:07 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][50/156]	eta 0:01:01 lr 0.000040	 wd 0.0500	time 0.5706 (0.5828)	data time 0.0208 (0.0925)	model time 0.0000 (0.0000)	loss 0.5514 (0.5509)	grad_norm 3.1570 (2.8779)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:12 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][60/156]	eta 0:00:54 lr 0.000040	 wd 0.0500	time 0.4344 (0.5677)	data time 0.0039 (0.0811)	model time 0.4305 (0.4678)	loss 0.5360 (0.5502)	grad_norm 3.9277 (2.8558)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:17 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][70/156]	eta 0:00:47 lr 0.000040	 wd 0.0500	time 0.4351 (0.5579)	data time 0.0020 (0.0709)	model time 0.4331 (0.4785)	loss 0.4791 (0.5486)	grad_norm 5.5617 (2.8871)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:22 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][80/156]	eta 0:00:41 lr 0.000040	 wd 0.0500	time 0.4467 (0.5495)	data time 0.0170 (0.0630)	model time 0.4297 (0.4801)	loss 0.6320 (0.5500)	grad_norm 3.8953 (2.8891)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:27 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][90/156]	eta 0:00:36 lr 0.000040	 wd 0.0500	time 0.5256 (0.5458)	data time 0.0056 (0.0574)	model time 0.5200 (0.4862)	loss 0.4760 (0.5484)	grad_norm 2.0714 (2.8975)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:32 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][100/156]	eta 0:00:30 lr 0.000040	 wd 0.0500	time 0.4498 (0.5380)	data time 0.0245 (0.0531)	model time 0.4253 (0.4793)	loss 0.4844 (0.5491)	grad_norm 2.9955 (2.8298)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:37 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][110/156]	eta 0:00:24 lr 0.000040	 wd 0.0500	time 0.7117 (0.5334)	data time 0.0582 (0.0493)	model time 0.6535 (0.4788)	loss 0.4882 (0.5487)	grad_norm 3.7688 (2.8198)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:42 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][120/156]	eta 0:00:19 lr 0.000040	 wd 0.0500	time 0.4420 (0.5283)	data time 0.0227 (0.0463)	model time 0.4193 (0.4760)	loss 0.4658 (0.5488)	grad_norm 3.1991 (2.8748)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:46 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][130/156]	eta 0:00:13 lr 0.000040	 wd 0.0500	time 0.6450 (0.5249)	data time 0.0187 (0.0441)	model time 0.6263 (0.4748)	loss 0.5766 (0.5482)	grad_norm 2.9673 (2.8636)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:52 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][140/156]	eta 0:00:08 lr 0.000040	 wd 0.0500	time 0.6331 (0.5241)	data time 0.0078 (0.0417)	model time 0.6254 (0.4779)	loss 0.5608 (0.5470)	grad_norm 2.3912 (2.8645)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:34:57 vssm1_tiny_0230s](training.py 201): INFO Train: [194/300][150/156]	eta 0:00:03 lr 0.000039	 wd 0.0500	time 0.6694 (0.5247)	data time 0.0005 (0.0391)	model time 0.6690 (0.4832)	loss 0.5228 (0.5444)	grad_norm 4.5630 (2.8966)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:35:00 vssm1_tiny_0230s](training.py 212): INFO EPOCH 194 training takes 0:01:22
[2024-11-09 16:35:00 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_194.pth saving......
[2024-11-09 16:35:00 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_194.pth saved !!!
[2024-11-09 16:35:04 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.206 (4.206)	Loss 0.2001 (0.2001)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:35:07 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.169 (0.597)	Loss 0.2041 (0.2056)	Acc@1 94.531 (94.673)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:35:09 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.155 (0.431)	Loss 0.1677 (0.2157)	Acc@1 97.656 (94.494)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:35:11 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.146 (0.364)	Loss 0.2203 (0.2108)	Acc@1 93.750 (94.884)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:35:14 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.120 Acc@5 100.000
[2024-11-09 16:35:14 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 16:35:14 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.12%
[2024-11-09 16:35:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.150 (3.150)	Loss 0.2312 (0.2312)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:35:21 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.148 (0.622)	Loss 0.2445 (0.2448)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:35:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.189 (0.463)	Loss 0.3291 (0.2623)	Acc@1 90.625 (93.787)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:35:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.168 (0.372)	Loss 0.3862 (0.3010)	Acc@1 84.375 (90.701)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:35:28 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.720 Acc@5 100.000
[2024-11-09 16:35:28 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 89.7%
[2024-11-09 16:35:28 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 89.72%
[2024-11-09 16:35:32 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][0/156]	eta 0:10:32 lr 0.000039	 wd 0.0500	time 4.0559 (4.0559)	data time 3.6061 (3.6061)	model time 0.0000 (0.0000)	loss 0.6537 (0.6537)	grad_norm 2.3679 (2.3679)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:35:37 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][10/156]	eta 0:02:00 lr 0.000039	 wd 0.0500	time 0.5030 (0.8280)	data time 0.0007 (0.3374)	model time 0.0000 (0.0000)	loss 0.5232 (0.5569)	grad_norm 2.9324 (2.8242)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:35:42 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][20/156]	eta 0:01:30 lr 0.000039	 wd 0.0500	time 0.5632 (0.6631)	data time 0.0007 (0.1804)	model time 0.0000 (0.0000)	loss 0.5751 (0.5538)	grad_norm 3.6446 (2.9443)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:35:47 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][30/156]	eta 0:01:18 lr 0.000039	 wd 0.0500	time 0.6045 (0.6209)	data time 0.0233 (0.1321)	model time 0.0000 (0.0000)	loss 0.6705 (0.5518)	grad_norm 2.1026 (2.8853)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:35:53 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][40/156]	eta 0:01:08 lr 0.000039	 wd 0.0500	time 0.4110 (0.5933)	data time 0.0008 (0.1054)	model time 0.0000 (0.0000)	loss 0.5396 (0.5536)	grad_norm 3.2188 (2.7817)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:35:58 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][50/156]	eta 0:01:01 lr 0.000039	 wd 0.0500	time 0.5015 (0.5781)	data time 0.0008 (0.0882)	model time 0.0000 (0.0000)	loss 0.6801 (0.5570)	grad_norm 2.8542 (2.7770)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:03 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][60/156]	eta 0:00:54 lr 0.000039	 wd 0.0500	time 0.4589 (0.5632)	data time 0.0194 (0.0754)	model time 0.4395 (0.4772)	loss 0.5704 (0.5584)	grad_norm 2.6354 (2.7848)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:08 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][70/156]	eta 0:00:48 lr 0.000039	 wd 0.0500	time 0.5810 (0.5583)	data time 0.0013 (0.0659)	model time 0.5796 (0.4988)	loss 0.5712 (0.5600)	grad_norm 1.3824 (2.7447)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:13 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][80/156]	eta 0:00:41 lr 0.000039	 wd 0.0500	time 0.4788 (0.5510)	data time 0.0034 (0.0596)	model time 0.4754 (0.4941)	loss 0.4724 (0.5589)	grad_norm 3.8910 (2.7919)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:18 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][90/156]	eta 0:00:36 lr 0.000039	 wd 0.0500	time 0.5996 (0.5463)	data time 0.0081 (0.0540)	model time 0.5915 (0.4954)	loss 0.4545 (0.5570)	grad_norm 3.0316 (2.8114)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:23 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][100/156]	eta 0:00:30 lr 0.000039	 wd 0.0500	time 0.5254 (0.5458)	data time 0.0054 (0.0499)	model time 0.5201 (0.5021)	loss 0.5063 (0.5527)	grad_norm 2.2365 (2.8403)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:28 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][110/156]	eta 0:00:24 lr 0.000039	 wd 0.0500	time 0.6867 (0.5404)	data time 0.0778 (0.0476)	model time 0.6089 (0.4953)	loss 0.5037 (0.5490)	grad_norm 2.8779 (2.8723)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:33 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][120/156]	eta 0:00:19 lr 0.000039	 wd 0.0500	time 0.5301 (0.5381)	data time 0.0192 (0.0449)	model time 0.5109 (0.4956)	loss 0.4366 (0.5500)	grad_norm 3.0050 (2.9242)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:39 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][130/156]	eta 0:00:13 lr 0.000039	 wd 0.0500	time 0.4763 (0.5380)	data time 0.0397 (0.0434)	model time 0.4365 (0.4975)	loss 0.5909 (0.5488)	grad_norm 2.7783 (2.9539)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:44 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][140/156]	eta 0:00:08 lr 0.000039	 wd 0.0500	time 0.4253 (0.5366)	data time 0.0120 (0.0415)	model time 0.4132 (0.4982)	loss 0.4655 (0.5473)	grad_norm 2.3085 (2.9656)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:49 vssm1_tiny_0230s](training.py 201): INFO Train: [195/300][150/156]	eta 0:00:03 lr 0.000039	 wd 0.0500	time 0.5662 (0.5339)	data time 0.0006 (0.0388)	model time 0.5656 (0.4978)	loss 0.4976 (0.5462)	grad_norm 4.4797 (2.9764)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:36:52 vssm1_tiny_0230s](training.py 212): INFO EPOCH 195 training takes 0:01:23
[2024-11-09 16:36:52 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_195.pth saving......
[2024-11-09 16:36:52 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_195.pth saved !!!
[2024-11-09 16:36:55 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.270 (3.270)	Loss 0.2184 (0.2184)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:36:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.459)	Loss 0.2249 (0.2214)	Acc@1 93.750 (94.460)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:37:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.447 (0.394)	Loss 0.1704 (0.2299)	Acc@1 96.875 (94.010)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:37:03 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.345)	Loss 0.2222 (0.2207)	Acc@1 93.750 (94.834)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:37:06 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.280 Acc@5 100.000
[2024-11-09 16:37:06 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.3%
[2024-11-09 16:37:06 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:37:10 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.912 (3.912)	Loss 0.2301 (0.2301)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:37:12 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.169 (0.534)	Loss 0.2434 (0.2437)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:37:14 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.365)	Loss 0.3252 (0.2610)	Acc@1 90.625 (93.787)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:37:17 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.349)	Loss 0.3823 (0.2988)	Acc@1 84.375 (90.776)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:37:19 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.820 Acc@5 100.000
[2024-11-09 16:37:19 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 89.8%
[2024-11-09 16:37:19 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 89.82%
[2024-11-09 16:37:23 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][0/156]	eta 0:08:55 lr 0.000039	 wd 0.0500	time 3.4322 (3.4322)	data time 2.9910 (2.9910)	model time 0.0000 (0.0000)	loss 0.5411 (0.5411)	grad_norm 2.5465 (2.5465)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:37:28 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][10/156]	eta 0:01:55 lr 0.000039	 wd 0.0500	time 0.4244 (0.7902)	data time 0.0007 (0.2909)	model time 0.0000 (0.0000)	loss 0.5590 (0.5602)	grad_norm 3.1828 (2.7331)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:37:33 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][20/156]	eta 0:01:28 lr 0.000039	 wd 0.0500	time 0.5636 (0.6532)	data time 0.0154 (0.1589)	model time 0.0000 (0.0000)	loss 0.4878 (0.5540)	grad_norm 2.3189 (2.7012)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:37:38 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][30/156]	eta 0:01:15 lr 0.000039	 wd 0.0500	time 0.4590 (0.5982)	data time 0.0393 (0.1141)	model time 0.0000 (0.0000)	loss 0.5258 (0.5575)	grad_norm 1.8067 (2.7481)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:37:43 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][40/156]	eta 0:01:07 lr 0.000039	 wd 0.0500	time 0.4994 (0.5808)	data time 0.0098 (0.0889)	model time 0.0000 (0.0000)	loss 0.5159 (0.5539)	grad_norm 2.8143 (2.6943)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:37:48 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][50/156]	eta 0:01:00 lr 0.000039	 wd 0.0500	time 0.5909 (0.5681)	data time 0.0915 (0.0753)	model time 0.0000 (0.0000)	loss 0.6136 (0.5564)	grad_norm 2.8805 (2.7262)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:37:53 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][60/156]	eta 0:00:52 lr 0.000039	 wd 0.0500	time 0.4830 (0.5521)	data time 0.0066 (0.0648)	model time 0.4763 (0.4590)	loss 0.4725 (0.5541)	grad_norm 4.2336 (2.8486)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 16:37:58 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][70/156]	eta 0:00:47 lr 0.000039	 wd 0.0500	time 0.4208 (0.5517)	data time 0.0077 (0.0582)	model time 0.4132 (0.4951)	loss 0.4347 (0.5512)	grad_norm inf (inf)	loss_scale 32768.0000 (65074.4789)	mem 13675MB
[2024-11-09 16:38:04 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][80/156]	eta 0:00:41 lr 0.000038	 wd 0.0500	time 0.4729 (0.5475)	data time 0.0425 (0.0533)	model time 0.4304 (0.4965)	loss 0.6528 (0.5581)	grad_norm 2.0642 (inf)	loss_scale 32768.0000 (61086.0247)	mem 13675MB
[2024-11-09 16:38:09 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][90/156]	eta 0:00:35 lr 0.000038	 wd 0.0500	time 0.5905 (0.5451)	data time 0.0053 (0.0500)	model time 0.5852 (0.4980)	loss 0.4246 (0.5595)	grad_norm 3.0168 (inf)	loss_scale 32768.0000 (57974.1538)	mem 13675MB
[2024-11-09 16:38:14 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][100/156]	eta 0:00:30 lr 0.000038	 wd 0.0500	time 0.4315 (0.5381)	data time 0.0243 (0.0465)	model time 0.4072 (0.4904)	loss 0.4736 (0.5567)	grad_norm 3.1391 (inf)	loss_scale 32768.0000 (55478.4950)	mem 13675MB
[2024-11-09 16:38:19 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][110/156]	eta 0:00:24 lr 0.000038	 wd 0.0500	time 0.6172 (0.5371)	data time 0.0568 (0.0439)	model time 0.5604 (0.4934)	loss 0.3701 (0.5494)	grad_norm 3.4604 (inf)	loss_scale 32768.0000 (53432.5045)	mem 13675MB
[2024-11-09 16:38:24 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][120/156]	eta 0:00:19 lr 0.000038	 wd 0.0500	time 0.5260 (0.5330)	data time 0.0177 (0.0418)	model time 0.5083 (0.4899)	loss 0.5904 (0.5491)	grad_norm 2.6532 (inf)	loss_scale 32768.0000 (51724.6942)	mem 13675MB
[2024-11-09 16:38:29 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][130/156]	eta 0:00:13 lr 0.000038	 wd 0.0500	time 0.5044 (0.5308)	data time 0.0007 (0.0400)	model time 0.5037 (0.4896)	loss 0.4260 (0.5490)	grad_norm 2.9373 (inf)	loss_scale 32768.0000 (50277.6183)	mem 13675MB
[2024-11-09 16:38:34 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][140/156]	eta 0:00:08 lr 0.000038	 wd 0.0500	time 0.5525 (0.5331)	data time 0.0009 (0.0387)	model time 0.5515 (0.4953)	loss 0.5495 (0.5504)	grad_norm 3.0238 (inf)	loss_scale 32768.0000 (49035.8014)	mem 13675MB
[2024-11-09 16:38:39 vssm1_tiny_0230s](training.py 201): INFO Train: [196/300][150/156]	eta 0:00:03 lr 0.000038	 wd 0.0500	time 0.4951 (0.5292)	data time 0.0005 (0.0362)	model time 0.4947 (0.4931)	loss 0.6183 (0.5509)	grad_norm 3.2194 (inf)	loss_scale 32768.0000 (47958.4636)	mem 13675MB
[2024-11-09 16:38:42 vssm1_tiny_0230s](training.py 212): INFO EPOCH 196 training takes 0:01:23
[2024-11-09 16:38:42 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_196.pth saving......
[2024-11-09 16:38:43 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_196.pth saved !!!
[2024-11-09 16:38:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.759 (3.759)	Loss 0.2297 (0.2297)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:38:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.148 (0.576)	Loss 0.2421 (0.2396)	Acc@1 94.531 (94.673)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:38:52 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.406)	Loss 0.1716 (0.2460)	Acc@1 98.438 (94.606)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:38:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.193 (0.383)	Loss 0.2202 (0.2333)	Acc@1 92.969 (95.111)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:38:58 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.280 Acc@5 100.000
[2024-11-09 16:38:58 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.3%
[2024-11-09 16:38:58 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:39:01 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.013 (3.013)	Loss 0.2283 (0.2283)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:39:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.744 (0.498)	Loss 0.2417 (0.2418)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:39:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.334)	Loss 0.3220 (0.2591)	Acc@1 90.625 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:39:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.154 (0.330)	Loss 0.3792 (0.2965)	Acc@1 85.156 (90.852)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:39:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.900 Acc@5 100.000
[2024-11-09 16:39:10 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 89.9%
[2024-11-09 16:39:10 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 89.90%
[2024-11-09 16:39:15 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][0/156]	eta 0:12:49 lr 0.000038	 wd 0.0500	time 4.9330 (4.9330)	data time 4.3675 (4.3675)	model time 0.0000 (0.0000)	loss 0.5099 (0.5099)	grad_norm 4.0706 (4.0706)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:39:20 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][10/156]	eta 0:02:04 lr 0.000038	 wd 0.0500	time 0.4071 (0.8508)	data time 0.0018 (0.4014)	model time 0.0000 (0.0000)	loss 0.6108 (0.5527)	grad_norm 2.1824 (3.4012)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:39:24 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][20/156]	eta 0:01:32 lr 0.000038	 wd 0.0500	time 0.5612 (0.6826)	data time 0.0418 (0.2165)	model time 0.0000 (0.0000)	loss 0.4776 (0.5561)	grad_norm 2.8665 (3.0580)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:39:29 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][30/156]	eta 0:01:17 lr 0.000038	 wd 0.0500	time 0.5849 (0.6183)	data time 0.0007 (0.1495)	model time 0.0000 (0.0000)	loss 0.5763 (0.5525)	grad_norm 2.0569 (2.9820)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:39:34 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][40/156]	eta 0:01:08 lr 0.000038	 wd 0.0500	time 0.5289 (0.5882)	data time 0.0010 (0.1156)	model time 0.0000 (0.0000)	loss 0.6035 (0.5628)	grad_norm 2.3433 (2.8183)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:39:39 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][50/156]	eta 0:01:00 lr 0.000038	 wd 0.0500	time 0.4657 (0.5672)	data time 0.0050 (0.0952)	model time 0.0000 (0.0000)	loss 0.5788 (0.5623)	grad_norm 3.5532 (2.7351)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:39:44 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][60/156]	eta 0:00:53 lr 0.000038	 wd 0.0500	time 0.4517 (0.5599)	data time 0.0211 (0.0822)	model time 0.4306 (0.5068)	loss 0.6046 (0.5652)	grad_norm 2.8574 (2.7613)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:39:50 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][70/156]	eta 0:00:47 lr 0.000038	 wd 0.0500	time 0.6494 (0.5550)	data time 0.0138 (0.0727)	model time 0.6355 (0.5087)	loss 0.5709 (0.5657)	grad_norm 2.2425 (2.7168)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:39:55 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][80/156]	eta 0:00:41 lr 0.000038	 wd 0.0500	time 0.5403 (0.5481)	data time 0.0005 (0.0645)	model time 0.5398 (0.5034)	loss 0.5879 (0.5663)	grad_norm 1.9880 (2.7389)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:40:00 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][90/156]	eta 0:00:36 lr 0.000038	 wd 0.0500	time 0.4238 (0.5527)	data time 0.0069 (0.0589)	model time 0.4169 (0.5217)	loss 0.5472 (0.5703)	grad_norm 2.3995 (2.7036)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:40:05 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][100/156]	eta 0:00:30 lr 0.000038	 wd 0.0500	time 0.4672 (0.5473)	data time 0.0175 (0.0546)	model time 0.4497 (0.5138)	loss 0.6112 (0.5704)	grad_norm 2.2819 (2.6521)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:40:10 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][110/156]	eta 0:00:24 lr 0.000038	 wd 0.0500	time 0.5239 (0.5413)	data time 0.0323 (0.0507)	model time 0.4915 (0.5064)	loss 0.6236 (0.5693)	grad_norm 1.3780 (2.6435)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:40:15 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][120/156]	eta 0:00:19 lr 0.000038	 wd 0.0500	time 0.4120 (0.5343)	data time 0.0005 (0.0470)	model time 0.4115 (0.4984)	loss 0.5462 (0.5696)	grad_norm 2.6024 (2.6324)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:40:20 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][130/156]	eta 0:00:13 lr 0.000038	 wd 0.0500	time 0.5580 (0.5322)	data time 0.0240 (0.0443)	model time 0.5340 (0.4980)	loss 0.5266 (0.5693)	grad_norm 1.8810 (2.6258)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:40:25 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][140/156]	eta 0:00:08 lr 0.000038	 wd 0.0500	time 0.4723 (0.5284)	data time 0.0010 (0.0418)	model time 0.4713 (0.4949)	loss 0.5862 (0.5699)	grad_norm 1.7593 (2.6186)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:40:29 vssm1_tiny_0230s](training.py 201): INFO Train: [197/300][150/156]	eta 0:00:03 lr 0.000038	 wd 0.0500	time 0.4300 (0.5253)	data time 0.0005 (0.0391)	model time 0.4296 (0.4934)	loss 0.5032 (0.5688)	grad_norm 2.1826 (2.6179)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:40:32 vssm1_tiny_0230s](training.py 212): INFO EPOCH 197 training takes 0:01:22
[2024-11-09 16:40:32 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_197.pth saving......
[2024-11-09 16:40:33 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_197.pth saved !!!
[2024-11-09 16:40:36 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.441 (3.441)	Loss 0.2053 (0.2053)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:40:40 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.132 (0.636)	Loss 0.2153 (0.2133)	Acc@1 95.312 (96.733)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:40:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.145 (0.476)	Loss 0.2213 (0.2235)	Acc@1 96.094 (95.871)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:40:45 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.397)	Loss 0.2881 (0.2350)	Acc@1 92.188 (95.161)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:40:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.860 Acc@5 100.000
[2024-11-09 16:40:48 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.9%
[2024-11-09 16:40:48 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:40:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.440 (4.440)	Loss 0.2273 (0.2273)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:40:54 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.154 (0.549)	Loss 0.2408 (0.2409)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:40:56 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.182 (0.404)	Loss 0.3188 (0.2580)	Acc@1 90.625 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:40:58 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.204 (0.352)	Loss 0.3762 (0.2947)	Acc@1 85.156 (90.953)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:41:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 89.980 Acc@5 100.000
[2024-11-09 16:41:00 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 90.0%
[2024-11-09 16:41:00 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 89.98%
[2024-11-09 16:41:04 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][0/156]	eta 0:11:22 lr 0.000038	 wd 0.0500	time 4.3779 (4.3779)	data time 3.8127 (3.8127)	model time 0.0000 (0.0000)	loss 0.5667 (0.5667)	grad_norm 2.9972 (2.9972)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:41:10 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][10/156]	eta 0:02:10 lr 0.000037	 wd 0.0500	time 0.5122 (0.8921)	data time 0.0122 (0.3696)	model time 0.0000 (0.0000)	loss 0.5196 (0.5355)	grad_norm 2.5834 (2.6348)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:41:15 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][20/156]	eta 0:01:34 lr 0.000037	 wd 0.0500	time 0.4300 (0.6969)	data time 0.0027 (0.2005)	model time 0.0000 (0.0000)	loss 0.5341 (0.5485)	grad_norm 2.6611 (2.5240)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:41:20 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][30/156]	eta 0:01:21 lr 0.000037	 wd 0.0500	time 0.5707 (0.6470)	data time 0.0007 (0.1430)	model time 0.0000 (0.0000)	loss 0.4893 (0.5551)	grad_norm 2.9432 (2.4936)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:41:25 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][40/156]	eta 0:01:11 lr 0.000037	 wd 0.0500	time 0.4286 (0.6172)	data time 0.0082 (0.1129)	model time 0.0000 (0.0000)	loss 0.6113 (0.5531)	grad_norm 2.9183 (2.5542)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:41:31 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][50/156]	eta 0:01:03 lr 0.000037	 wd 0.0500	time 0.5044 (0.5994)	data time 0.0149 (0.0953)	model time 0.0000 (0.0000)	loss 0.4435 (0.5526)	grad_norm 3.5787 (2.5652)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:41:35 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][60/156]	eta 0:00:55 lr 0.000037	 wd 0.0500	time 0.4386 (0.5793)	data time 0.0177 (0.0829)	model time 0.4209 (0.4575)	loss 0.5889 (0.5499)	grad_norm 3.9598 (2.6194)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:41:41 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][70/156]	eta 0:00:49 lr 0.000037	 wd 0.0500	time 0.5028 (0.5758)	data time 0.0307 (0.0760)	model time 0.4721 (0.4890)	loss 0.6077 (0.5498)	grad_norm 3.1005 (2.7811)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:41:46 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][80/156]	eta 0:00:43 lr 0.000037	 wd 0.0500	time 0.4465 (0.5676)	data time 0.0162 (0.0684)	model time 0.4303 (0.4910)	loss 0.4605 (0.5466)	grad_norm 3.2871 (2.8571)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:41:51 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][90/156]	eta 0:00:36 lr 0.000037	 wd 0.0500	time 0.5238 (0.5605)	data time 0.0044 (0.0622)	model time 0.5194 (0.4911)	loss 0.5415 (0.5494)	grad_norm 3.0433 (2.8890)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:41:56 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][100/156]	eta 0:00:31 lr 0.000037	 wd 0.0500	time 0.4229 (0.5552)	data time 0.0148 (0.0587)	model time 0.4081 (0.4889)	loss 0.5965 (0.5475)	grad_norm 2.2434 (2.8800)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:42:02 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][110/156]	eta 0:00:25 lr 0.000037	 wd 0.0500	time 0.4890 (0.5533)	data time 0.0272 (0.0551)	model time 0.4617 (0.4933)	loss 0.5484 (0.5467)	grad_norm 1.9036 (2.8606)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:42:06 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][120/156]	eta 0:00:19 lr 0.000037	 wd 0.0500	time 0.4418 (0.5451)	data time 0.0019 (0.0514)	model time 0.4399 (0.4861)	loss 0.4046 (0.5453)	grad_norm 2.1581 (2.8646)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:42:11 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][130/156]	eta 0:00:14 lr 0.000037	 wd 0.0500	time 0.4653 (0.5403)	data time 0.0207 (0.0490)	model time 0.4446 (0.4833)	loss 0.5761 (0.5462)	grad_norm 1.9073 (2.8305)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:42:16 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][140/156]	eta 0:00:08 lr 0.000037	 wd 0.0500	time 0.5751 (0.5400)	data time 0.0009 (0.0468)	model time 0.5742 (0.4870)	loss 0.6165 (0.5468)	grad_norm 2.6916 (2.8326)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:42:21 vssm1_tiny_0230s](training.py 201): INFO Train: [198/300][150/156]	eta 0:00:03 lr 0.000037	 wd 0.0500	time 0.4924 (0.5378)	data time 0.0284 (0.0444)	model time 0.4639 (0.4880)	loss 0.5828 (0.5475)	grad_norm 3.8641 (2.8428)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:42:24 vssm1_tiny_0230s](training.py 212): INFO EPOCH 198 training takes 0:01:24
[2024-11-09 16:42:24 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_198.pth saving......
[2024-11-09 16:42:25 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_198.pth saved !!!
[2024-11-09 16:42:28 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.893 (2.893)	Loss 0.2046 (0.2046)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:42:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.579)	Loss 0.2126 (0.2115)	Acc@1 97.656 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:42:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.173 (0.414)	Loss 0.2030 (0.2213)	Acc@1 96.875 (95.647)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:42:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.146 (0.369)	Loss 0.2573 (0.2281)	Acc@1 92.188 (95.186)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:42:39 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.060 Acc@5 100.000
[2024-11-09 16:42:39 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 16:42:39 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:42:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.579 (3.579)	Loss 0.2263 (0.2263)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:42:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.526)	Loss 0.2399 (0.2398)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:42:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.158 (0.405)	Loss 0.3147 (0.2568)	Acc@1 90.625 (93.713)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:42:50 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.363)	Loss 0.3723 (0.2926)	Acc@1 85.156 (91.003)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:42:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.020 Acc@5 100.000
[2024-11-09 16:42:53 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 90.0%
[2024-11-09 16:42:53 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.02%
[2024-11-09 16:42:57 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][0/156]	eta 0:10:22 lr 0.000037	 wd 0.0500	time 3.9926 (3.9926)	data time 3.4961 (3.4961)	model time 0.0000 (0.0000)	loss 0.5542 (0.5542)	grad_norm 2.3639 (2.3639)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:02 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][10/156]	eta 0:02:03 lr 0.000037	 wd 0.0500	time 0.4257 (0.8484)	data time 0.0006 (0.3775)	model time 0.0000 (0.0000)	loss 0.4620 (0.5909)	grad_norm 2.7877 (2.3820)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:07 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][20/156]	eta 0:01:32 lr 0.000037	 wd 0.0500	time 0.4174 (0.6822)	data time 0.0008 (0.2047)	model time 0.0000 (0.0000)	loss 0.5744 (0.5832)	grad_norm 1.5688 (2.3517)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:12 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][30/156]	eta 0:01:18 lr 0.000037	 wd 0.0500	time 0.4913 (0.6196)	data time 0.0008 (0.1432)	model time 0.0000 (0.0000)	loss 0.4785 (0.5750)	grad_norm 4.7215 (2.3921)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:17 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][40/156]	eta 0:01:08 lr 0.000037	 wd 0.0500	time 0.4173 (0.5919)	data time 0.0006 (0.1130)	model time 0.0000 (0.0000)	loss 0.4983 (0.5737)	grad_norm 1.7209 (2.4099)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:22 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][50/156]	eta 0:01:00 lr 0.000037	 wd 0.0500	time 0.4719 (0.5708)	data time 0.0014 (0.0942)	model time 0.0000 (0.0000)	loss 0.6187 (0.5711)	grad_norm 2.9485 (2.4716)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:27 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][60/156]	eta 0:00:54 lr 0.000037	 wd 0.0500	time 0.4674 (0.5635)	data time 0.0066 (0.0824)	model time 0.4607 (0.5040)	loss 0.6457 (0.5709)	grad_norm 1.6777 (2.4847)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:32 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][70/156]	eta 0:00:47 lr 0.000037	 wd 0.0500	time 0.4593 (0.5521)	data time 0.0006 (0.0718)	model time 0.4586 (0.4899)	loss 0.5441 (0.5706)	grad_norm 3.4754 (2.4716)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:37 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][80/156]	eta 0:00:41 lr 0.000037	 wd 0.0500	time 0.4135 (0.5415)	data time 0.0036 (0.0645)	model time 0.4100 (0.4777)	loss 0.6276 (0.5704)	grad_norm 1.7675 (2.4606)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:41 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][90/156]	eta 0:00:35 lr 0.000037	 wd 0.0500	time 0.5084 (0.5333)	data time 0.0222 (0.0590)	model time 0.4863 (0.4714)	loss 0.5209 (0.5725)	grad_norm 2.1181 (2.5197)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:47 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][100/156]	eta 0:00:29 lr 0.000037	 wd 0.0500	time 0.6734 (0.5328)	data time 0.0050 (0.0547)	model time 0.6683 (0.4796)	loss 0.5983 (0.5737)	grad_norm 2.6558 (2.5213)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:52 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][110/156]	eta 0:00:24 lr 0.000036	 wd 0.0500	time 0.7158 (0.5328)	data time 0.0007 (0.0521)	model time 0.7151 (0.4842)	loss 0.5636 (0.5712)	grad_norm 3.3502 (2.5073)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:43:57 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][120/156]	eta 0:00:19 lr 0.000036	 wd 0.0500	time 0.4788 (0.5286)	data time 0.0306 (0.0489)	model time 0.4482 (0.4819)	loss 0.5994 (0.5689)	grad_norm 1.9379 (2.5071)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:44:02 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][130/156]	eta 0:00:13 lr 0.000036	 wd 0.0500	time 0.5701 (0.5259)	data time 0.0160 (0.0470)	model time 0.5541 (0.4803)	loss 0.6042 (0.5684)	grad_norm 2.3869 (2.5443)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:44:07 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][140/156]	eta 0:00:08 lr 0.000036	 wd 0.0500	time 0.5403 (0.5275)	data time 0.0008 (0.0450)	model time 0.5394 (0.4859)	loss 0.5716 (0.5653)	grad_norm 4.5447 (2.5819)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:44:12 vssm1_tiny_0230s](training.py 201): INFO Train: [199/300][150/156]	eta 0:00:03 lr 0.000036	 wd 0.0500	time 0.4691 (0.5250)	data time 0.0007 (0.0420)	model time 0.4685 (0.4861)	loss 0.5086 (0.5624)	grad_norm 2.8085 (2.5862)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:44:15 vssm1_tiny_0230s](training.py 212): INFO EPOCH 199 training takes 0:01:22
[2024-11-09 16:44:15 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_199.pth saving......
[2024-11-09 16:44:15 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_199.pth saved !!!
[2024-11-09 16:44:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.437 (2.437)	Loss 0.1925 (0.1925)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:44:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.146 (0.457)	Loss 0.1941 (0.1934)	Acc@1 96.094 (95.881)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:44:22 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.340)	Loss 0.1814 (0.2040)	Acc@1 98.438 (95.424)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:44:24 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.288)	Loss 0.2406 (0.2090)	Acc@1 92.969 (95.262)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:44:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.200 Acc@5 100.000
[2024-11-09 16:44:27 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.2%
[2024-11-09 16:44:27 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:44:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.241 (3.241)	Loss 0.2251 (0.2251)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:44:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.146 (0.607)	Loss 0.2386 (0.2386)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:44:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.417)	Loss 0.3115 (0.2555)	Acc@1 92.188 (93.824)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:44:39 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.344 (0.390)	Loss 0.3689 (0.2906)	Acc@1 85.156 (91.154)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:44:41 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.140 Acc@5 100.000
[2024-11-09 16:44:41 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 90.1%
[2024-11-09 16:44:41 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.14%
[2024-11-09 16:44:46 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][0/156]	eta 0:11:18 lr 0.000036	 wd 0.0500	time 4.3519 (4.3519)	data time 3.7134 (3.7134)	model time 0.0000 (0.0000)	loss 0.4778 (0.4778)	grad_norm 3.8738 (3.8738)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:44:51 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][10/156]	eta 0:02:06 lr 0.000036	 wd 0.0500	time 0.5731 (0.8657)	data time 0.0107 (0.3504)	model time 0.0000 (0.0000)	loss 0.4689 (0.5296)	grad_norm 4.9565 (3.1480)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:44:56 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][20/156]	eta 0:01:37 lr 0.000036	 wd 0.0500	time 0.5721 (0.7168)	data time 0.0188 (0.1951)	model time 0.0000 (0.0000)	loss 0.4920 (0.5378)	grad_norm 4.7295 (3.3237)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:01 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][30/156]	eta 0:01:21 lr 0.000036	 wd 0.0500	time 0.4895 (0.6479)	data time 0.0025 (0.1372)	model time 0.0000 (0.0000)	loss 0.5755 (0.5479)	grad_norm 2.2166 (3.5106)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:07 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][40/156]	eta 0:01:11 lr 0.000036	 wd 0.0500	time 0.5005 (0.6205)	data time 0.0008 (0.1072)	model time 0.0000 (0.0000)	loss 0.5476 (0.5555)	grad_norm 5.6194 (3.4155)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:12 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][50/156]	eta 0:01:03 lr 0.000036	 wd 0.0500	time 0.4662 (0.6009)	data time 0.0008 (0.0882)	model time 0.0000 (0.0000)	loss 0.6353 (0.5567)	grad_norm 3.3165 (3.2499)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:17 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][60/156]	eta 0:00:55 lr 0.000036	 wd 0.0500	time 0.5578 (0.5833)	data time 0.0008 (0.0757)	model time 0.5570 (0.4816)	loss 0.4291 (0.5573)	grad_norm 3.1007 (3.1697)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:22 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][70/156]	eta 0:00:48 lr 0.000036	 wd 0.0500	time 0.5689 (0.5693)	data time 0.0232 (0.0671)	model time 0.5458 (0.4757)	loss 0.5702 (0.5536)	grad_norm 3.8389 (3.1883)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:27 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][80/156]	eta 0:00:42 lr 0.000036	 wd 0.0500	time 0.5513 (0.5617)	data time 0.0296 (0.0612)	model time 0.5218 (0.4798)	loss 0.5744 (0.5570)	grad_norm 3.1717 (3.1360)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:32 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][90/156]	eta 0:00:36 lr 0.000036	 wd 0.0500	time 0.6355 (0.5571)	data time 0.0224 (0.0556)	model time 0.6131 (0.4874)	loss 0.5848 (0.5569)	grad_norm 2.3217 (3.0877)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:37 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][100/156]	eta 0:00:30 lr 0.000036	 wd 0.0500	time 0.4825 (0.5525)	data time 0.0043 (0.0526)	model time 0.4782 (0.4869)	loss 0.5853 (0.5542)	grad_norm 2.8177 (3.1193)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:42 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][110/156]	eta 0:00:25 lr 0.000036	 wd 0.0500	time 0.5416 (0.5490)	data time 0.0006 (0.0486)	model time 0.5410 (0.4898)	loss 0.5665 (0.5551)	grad_norm 2.0504 (3.1108)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:48 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][120/156]	eta 0:00:19 lr 0.000036	 wd 0.0500	time 0.7317 (0.5496)	data time 0.0008 (0.0455)	model time 0.7309 (0.4978)	loss 0.4818 (0.5505)	grad_norm 4.9208 (3.0889)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:53 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][130/156]	eta 0:00:14 lr 0.000036	 wd 0.0500	time 0.6019 (0.5464)	data time 0.0133 (0.0430)	model time 0.5886 (0.4975)	loss 0.6233 (0.5511)	grad_norm 3.1871 (3.0761)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:45:58 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][140/156]	eta 0:00:08 lr 0.000036	 wd 0.0500	time 0.4128 (0.5435)	data time 0.0007 (0.0420)	model time 0.4120 (0.4953)	loss 0.5475 (0.5540)	grad_norm 1.3865 (3.0422)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:46:03 vssm1_tiny_0230s](training.py 201): INFO Train: [200/300][150/156]	eta 0:00:03 lr 0.000036	 wd 0.0500	time 0.4725 (0.5423)	data time 0.0007 (0.0392)	model time 0.4718 (0.4981)	loss 0.5774 (0.5525)	grad_norm 1.7931 (3.0444)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:46:06 vssm1_tiny_0230s](training.py 212): INFO EPOCH 200 training takes 0:01:25
[2024-11-09 16:46:06 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_200.pth saving......
[2024-11-09 16:46:07 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_200.pth saved !!!
[2024-11-09 16:46:12 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.837 (4.837)	Loss 0.2081 (0.2081)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:46:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.715)	Loss 0.2178 (0.2198)	Acc@1 94.531 (94.886)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:46:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.199 (0.515)	Loss 0.1848 (0.2277)	Acc@1 96.875 (94.457)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:46:19 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.154 (0.398)	Loss 0.2308 (0.2229)	Acc@1 92.188 (94.985)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:46:21 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.140 Acc@5 100.000
[2024-11-09 16:46:21 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 16:46:21 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:46:25 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.340 (3.340)	Loss 0.2238 (0.2238)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:46:27 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.208 (0.517)	Loss 0.2374 (0.2372)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:46:30 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.406)	Loss 0.3081 (0.2540)	Acc@1 92.188 (93.787)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:46:32 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.354)	Loss 0.3657 (0.2885)	Acc@1 85.156 (91.255)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:46:35 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.260 Acc@5 100.000
[2024-11-09 16:46:35 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 90.3%
[2024-11-09 16:46:35 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.26%
[2024-11-09 16:46:40 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][0/156]	eta 0:11:49 lr 0.000036	 wd 0.0500	time 4.5471 (4.5471)	data time 4.0495 (4.0495)	model time 0.0000 (0.0000)	loss 0.5456 (0.5456)	grad_norm 2.0890 (2.0890)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:46:45 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][10/156]	eta 0:02:08 lr 0.000036	 wd 0.0500	time 0.5322 (0.8807)	data time 0.0006 (0.3969)	model time 0.0000 (0.0000)	loss 0.4021 (0.5437)	grad_norm 3.3860 (2.7529)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:46:50 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][20/156]	eta 0:01:34 lr 0.000036	 wd 0.0500	time 0.4646 (0.6971)	data time 0.0233 (0.2177)	model time 0.0000 (0.0000)	loss 0.4226 (0.5464)	grad_norm 5.2205 (2.7552)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:46:55 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][30/156]	eta 0:01:18 lr 0.000036	 wd 0.0500	time 0.5182 (0.6261)	data time 0.0253 (0.1496)	model time 0.0000 (0.0000)	loss 0.5953 (0.5509)	grad_norm 2.3145 (2.7888)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:46:59 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][40/156]	eta 0:01:07 lr 0.000035	 wd 0.0500	time 0.4205 (0.5861)	data time 0.0151 (0.1175)	model time 0.0000 (0.0000)	loss 0.4366 (0.5493)	grad_norm 1.8673 (3.0544)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:04 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][50/156]	eta 0:00:59 lr 0.000035	 wd 0.0500	time 0.4794 (0.5625)	data time 0.0044 (0.0969)	model time 0.0000 (0.0000)	loss 0.4990 (0.5508)	grad_norm 2.0685 (2.9428)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:09 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][60/156]	eta 0:00:52 lr 0.000035	 wd 0.0500	time 0.4143 (0.5489)	data time 0.0012 (0.0827)	model time 0.4131 (0.4696)	loss 0.5368 (0.5488)	grad_norm 3.4173 (2.9067)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:14 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][70/156]	eta 0:00:46 lr 0.000035	 wd 0.0500	time 0.4678 (0.5410)	data time 0.0006 (0.0728)	model time 0.4672 (0.4748)	loss 0.5713 (0.5532)	grad_norm 1.7323 (2.8209)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:18 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][80/156]	eta 0:00:40 lr 0.000035	 wd 0.0500	time 0.5286 (0.5333)	data time 0.0007 (0.0651)	model time 0.5279 (0.4726)	loss 0.5595 (0.5547)	grad_norm 1.7231 (2.8303)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:23 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][90/156]	eta 0:00:35 lr 0.000035	 wd 0.0500	time 0.5546 (0.5314)	data time 0.0411 (0.0593)	model time 0.5134 (0.4804)	loss 0.5602 (0.5535)	grad_norm 2.0273 (2.7809)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:28 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][100/156]	eta 0:00:29 lr 0.000035	 wd 0.0500	time 0.4646 (0.5274)	data time 0.0033 (0.0548)	model time 0.4613 (0.4798)	loss 0.5614 (0.5545)	grad_norm 2.7783 (2.8326)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:34 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][110/156]	eta 0:00:24 lr 0.000035	 wd 0.0500	time 0.5311 (0.5301)	data time 0.0211 (0.0511)	model time 0.5100 (0.4904)	loss 0.5598 (0.5558)	grad_norm 2.1291 (2.8319)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:40 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][120/156]	eta 0:00:19 lr 0.000035	 wd 0.0500	time 0.5315 (0.5329)	data time 0.0047 (0.0482)	model time 0.5268 (0.4986)	loss 0.4970 (0.5567)	grad_norm 2.6627 (2.8644)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:45 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][130/156]	eta 0:00:13 lr 0.000035	 wd 0.0500	time 0.5057 (0.5325)	data time 0.0008 (0.0454)	model time 0.5049 (0.5007)	loss 0.6203 (0.5569)	grad_norm 2.2909 (2.8674)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:50 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][140/156]	eta 0:00:08 lr 0.000035	 wd 0.0500	time 0.4986 (0.5305)	data time 0.0008 (0.0430)	model time 0.4977 (0.4999)	loss 0.5410 (0.5555)	grad_norm 1.8485 (2.8634)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:55 vssm1_tiny_0230s](training.py 201): INFO Train: [201/300][150/156]	eta 0:00:03 lr 0.000035	 wd 0.0500	time 0.4992 (0.5269)	data time 0.0006 (0.0407)	model time 0.4986 (0.4967)	loss 0.5444 (0.5554)	grad_norm 4.3881 (2.8397)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:47:57 vssm1_tiny_0230s](training.py 212): INFO EPOCH 201 training takes 0:01:22
[2024-11-09 16:47:58 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_201.pth saving......
[2024-11-09 16:47:58 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_201.pth saved !!!
[2024-11-09 16:48:02 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.188 (4.188)	Loss 0.2162 (0.2162)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:48:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.175 (0.616)	Loss 0.2180 (0.2186)	Acc@1 95.312 (94.815)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:48:09 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.181 (0.510)	Loss 0.1792 (0.2284)	Acc@1 97.656 (94.382)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:48:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.166 (0.439)	Loss 0.2308 (0.2264)	Acc@1 93.750 (94.657)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:48:14 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.740 Acc@5 100.000
[2024-11-09 16:48:14 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.7%
[2024-11-09 16:48:14 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:48:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.756 (3.756)	Loss 0.2227 (0.2227)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:48:19 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.373 (0.500)	Loss 0.2362 (0.2360)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:48:22 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.371)	Loss 0.3054 (0.2527)	Acc@1 92.188 (93.713)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:48:24 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.146 (0.335)	Loss 0.3635 (0.2868)	Acc@1 85.938 (91.255)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:48:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.280 Acc@5 100.000
[2024-11-09 16:48:27 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 90.3%
[2024-11-09 16:48:27 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.28%
[2024-11-09 16:48:31 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][0/156]	eta 0:09:52 lr 0.000035	 wd 0.0500	time 3.7964 (3.7964)	data time 3.3426 (3.3426)	model time 0.0000 (0.0000)	loss 0.5216 (0.5216)	grad_norm 3.1479 (3.1479)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:48:37 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][10/156]	eta 0:02:13 lr 0.000035	 wd 0.0500	time 0.4622 (0.9138)	data time 0.0076 (0.4098)	model time 0.0000 (0.0000)	loss 0.5475 (0.5779)	grad_norm 3.9196 (3.0058)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:48:42 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][20/156]	eta 0:01:37 lr 0.000035	 wd 0.0500	time 0.4482 (0.7171)	data time 0.0039 (0.2213)	model time 0.0000 (0.0000)	loss 0.4731 (0.5612)	grad_norm 1.4715 (2.8949)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:48:47 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][30/156]	eta 0:01:23 lr 0.000035	 wd 0.0500	time 0.7084 (0.6591)	data time 0.0174 (0.1547)	model time 0.0000 (0.0000)	loss 0.4457 (0.5566)	grad_norm 3.1606 (2.9286)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:48:53 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][40/156]	eta 0:01:13 lr 0.000035	 wd 0.0500	time 0.4983 (0.6325)	data time 0.0010 (0.1244)	model time 0.0000 (0.0000)	loss 0.5138 (0.5486)	grad_norm 3.0100 (2.9303)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:48:58 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][50/156]	eta 0:01:05 lr 0.000035	 wd 0.0500	time 0.5099 (0.6155)	data time 0.0315 (0.1063)	model time 0.0000 (0.0000)	loss 0.5115 (0.5475)	grad_norm 3.3007 (3.0062)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:04 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][60/156]	eta 0:00:57 lr 0.000035	 wd 0.0500	time 0.5880 (0.6012)	data time 0.0114 (0.0926)	model time 0.5766 (0.5059)	loss 0.4640 (0.5488)	grad_norm 1.5867 (2.9207)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:08 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][70/156]	eta 0:00:50 lr 0.000035	 wd 0.0500	time 0.4404 (0.5859)	data time 0.0049 (0.0807)	model time 0.4355 (0.4950)	loss 0.5362 (0.5550)	grad_norm 2.2089 (3.0191)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:13 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][80/156]	eta 0:00:43 lr 0.000035	 wd 0.0500	time 0.5329 (0.5709)	data time 0.0039 (0.0723)	model time 0.5290 (0.4809)	loss 0.6132 (0.5562)	grad_norm 1.9643 (2.9975)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:18 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][90/156]	eta 0:00:36 lr 0.000035	 wd 0.0500	time 0.4370 (0.5604)	data time 0.0007 (0.0657)	model time 0.4363 (0.4763)	loss 0.4503 (0.5528)	grad_norm 3.7327 (2.9369)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:23 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][100/156]	eta 0:00:31 lr 0.000035	 wd 0.0500	time 0.5360 (0.5555)	data time 0.0007 (0.0610)	model time 0.5353 (0.4796)	loss 0.4349 (0.5497)	grad_norm 4.0368 (2.9236)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:28 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][110/156]	eta 0:00:25 lr 0.000035	 wd 0.0500	time 0.5967 (0.5515)	data time 0.0028 (0.0567)	model time 0.5939 (0.4825)	loss 0.4878 (0.5489)	grad_norm 2.9262 (2.8992)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:33 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][120/156]	eta 0:00:19 lr 0.000035	 wd 0.0500	time 0.5792 (0.5486)	data time 0.0277 (0.0537)	model time 0.5516 (0.4845)	loss 0.4532 (0.5479)	grad_norm 2.6901 (2.9366)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:39 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][130/156]	eta 0:00:14 lr 0.000035	 wd 0.0500	time 0.6313 (0.5473)	data time 0.0261 (0.0509)	model time 0.6052 (0.4883)	loss 0.4733 (0.5491)	grad_norm 3.8403 (2.9394)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:43 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][140/156]	eta 0:00:08 lr 0.000034	 wd 0.0500	time 0.4345 (0.5434)	data time 0.0008 (0.0488)	model time 0.4336 (0.4865)	loss 0.6224 (0.5517)	grad_norm 2.2199 (2.9099)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:48 vssm1_tiny_0230s](training.py 201): INFO Train: [202/300][150/156]	eta 0:00:03 lr 0.000034	 wd 0.0500	time 0.5723 (0.5400)	data time 0.0007 (0.0456)	model time 0.5717 (0.4869)	loss 0.5768 (0.5504)	grad_norm 2.3538 (2.8850)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:49:51 vssm1_tiny_0230s](training.py 212): INFO EPOCH 202 training takes 0:01:24
[2024-11-09 16:49:51 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_202.pth saving......
[2024-11-09 16:49:52 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_202.pth saved !!!
[2024-11-09 16:49:55 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.391 (3.391)	Loss 0.2186 (0.2186)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:49:58 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.304 (0.587)	Loss 0.2273 (0.2231)	Acc@1 95.312 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:50:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.149 (0.442)	Loss 0.2023 (0.2314)	Acc@1 96.875 (94.792)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:50:03 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.377)	Loss 0.2457 (0.2334)	Acc@1 93.750 (94.909)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:50:06 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.900 Acc@5 100.000
[2024-11-09 16:50:06 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.9%
[2024-11-09 16:50:06 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:50:09 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.180 (3.180)	Loss 0.2220 (0.2220)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:50:12 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.139 (0.529)	Loss 0.2356 (0.2354)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:50:14 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.169 (0.362)	Loss 0.3020 (0.2519)	Acc@1 92.188 (93.787)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:50:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.307)	Loss 0.3599 (0.2850)	Acc@1 86.719 (91.331)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:50:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.440 Acc@5 100.000
[2024-11-09 16:50:17 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 90.4%
[2024-11-09 16:50:17 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.44%
[2024-11-09 16:50:22 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][0/156]	eta 0:13:41 lr 0.000034	 wd 0.0500	time 5.2667 (5.2667)	data time 4.7863 (4.7863)	model time 0.0000 (0.0000)	loss 0.6007 (0.6007)	grad_norm 2.0846 (2.0846)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:50:27 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][10/156]	eta 0:02:16 lr 0.000034	 wd 0.0500	time 0.5724 (0.9324)	data time 0.0009 (0.4502)	model time 0.0000 (0.0000)	loss 0.5499 (0.5630)	grad_norm 2.1119 (2.5270)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:50:32 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][20/156]	eta 0:01:37 lr 0.000034	 wd 0.0500	time 0.5015 (0.7193)	data time 0.0039 (0.2456)	model time 0.0000 (0.0000)	loss 0.6064 (0.5661)	grad_norm 3.1707 (2.3974)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:50:37 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][30/156]	eta 0:01:21 lr 0.000034	 wd 0.0500	time 0.4557 (0.6432)	data time 0.0109 (0.1701)	model time 0.0000 (0.0000)	loss 0.5332 (0.5622)	grad_norm 2.7163 (2.7275)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:50:42 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][40/156]	eta 0:01:11 lr 0.000034	 wd 0.0500	time 0.5894 (0.6136)	data time 0.0096 (0.1341)	model time 0.0000 (0.0000)	loss 0.4857 (0.5666)	grad_norm 2.5974 (2.6564)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:50:48 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][50/156]	eta 0:01:03 lr 0.000034	 wd 0.0500	time 0.5806 (0.5970)	data time 0.0010 (0.1103)	model time 0.0000 (0.0000)	loss 0.5731 (0.5622)	grad_norm 2.2998 (2.6802)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:50:53 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][60/156]	eta 0:00:56 lr 0.000034	 wd 0.0500	time 0.5304 (0.5844)	data time 0.0183 (0.0948)	model time 0.5121 (0.5046)	loss 0.4660 (0.5623)	grad_norm 3.5868 (2.7389)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:50:58 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][70/156]	eta 0:00:49 lr 0.000034	 wd 0.0500	time 0.4148 (0.5741)	data time 0.0039 (0.0826)	model time 0.4110 (0.5042)	loss 0.5290 (0.5535)	grad_norm 2.9521 (2.7968)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:51:03 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][80/156]	eta 0:00:43 lr 0.000034	 wd 0.0500	time 0.4925 (0.5667)	data time 0.0014 (0.0733)	model time 0.4912 (0.5049)	loss 0.6680 (0.5555)	grad_norm 4.1448 (2.7888)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:51:08 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][90/156]	eta 0:00:37 lr 0.000034	 wd 0.0500	time 0.5166 (0.5631)	data time 0.0074 (0.0669)	model time 0.5092 (0.5084)	loss 0.6819 (0.5563)	grad_norm 3.7564 (2.8188)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:51:14 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][100/156]	eta 0:00:31 lr 0.000034	 wd 0.0500	time 0.5513 (0.5633)	data time 0.0115 (0.0616)	model time 0.5398 (0.5171)	loss 0.6064 (0.5600)	grad_norm 2.6523 (2.8114)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:51:19 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][110/156]	eta 0:00:25 lr 0.000034	 wd 0.0500	time 0.4862 (0.5602)	data time 0.0006 (0.0576)	model time 0.4855 (0.5161)	loss 0.5651 (0.5594)	grad_norm 2.0303 (2.7786)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:51:24 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][120/156]	eta 0:00:19 lr 0.000034	 wd 0.0500	time 0.5878 (0.5554)	data time 0.0007 (0.0544)	model time 0.5871 (0.5116)	loss 0.4296 (0.5596)	grad_norm 2.2123 (2.7426)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:51:29 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][130/156]	eta 0:00:14 lr 0.000034	 wd 0.0500	time 0.4860 (0.5520)	data time 0.0278 (0.0518)	model time 0.4582 (0.5089)	loss 0.5281 (0.5609)	grad_norm 2.3490 (2.7117)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:51:35 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][140/156]	eta 0:00:08 lr 0.000034	 wd 0.0500	time 0.5574 (0.5490)	data time 0.0006 (0.0493)	model time 0.5568 (0.5072)	loss 0.5128 (0.5596)	grad_norm 1.9659 (2.7239)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:51:40 vssm1_tiny_0230s](training.py 201): INFO Train: [203/300][150/156]	eta 0:00:03 lr 0.000034	 wd 0.0500	time 0.6240 (0.5468)	data time 0.0368 (0.0464)	model time 0.5872 (0.5075)	loss 0.5821 (0.5592)	grad_norm 1.8154 (2.7399)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:51:43 vssm1_tiny_0230s](training.py 212): INFO EPOCH 203 training takes 0:01:25
[2024-11-09 16:51:43 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_203.pth saving......
[2024-11-09 16:51:43 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_203.pth saved !!!
[2024-11-09 16:51:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.222 (3.222)	Loss 0.2131 (0.2131)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:51:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.199 (0.631)	Loss 0.2205 (0.2213)	Acc@1 95.312 (94.460)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:51:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.155 (0.449)	Loss 0.1951 (0.2305)	Acc@1 97.656 (94.085)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:51:56 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.160 (0.400)	Loss 0.2360 (0.2290)	Acc@1 93.750 (94.582)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:51:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.840 Acc@5 100.000
[2024-11-09 16:51:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.8%
[2024-11-09 16:51:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:52:01 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.293 (3.293)	Loss 0.2212 (0.2212)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:52:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.169 (0.527)	Loss 0.2346 (0.2344)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:52:06 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.188 (0.421)	Loss 0.2986 (0.2508)	Acc@1 92.969 (93.899)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:52:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.171 (0.351)	Loss 0.3567 (0.2832)	Acc@1 86.719 (91.482)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:52:11 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.580 Acc@5 100.000
[2024-11-09 16:52:11 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 90.6%
[2024-11-09 16:52:11 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.58%
[2024-11-09 16:52:16 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][0/156]	eta 0:12:01 lr 0.000034	 wd 0.0500	time 4.6268 (4.6268)	data time 4.0333 (4.0333)	model time 0.0000 (0.0000)	loss 0.6433 (0.6433)	grad_norm 4.5125 (4.5125)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:52:21 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][10/156]	eta 0:02:13 lr 0.000034	 wd 0.0500	time 0.5435 (0.9153)	data time 0.0013 (0.3711)	model time 0.0000 (0.0000)	loss 0.5500 (0.5505)	grad_norm 1.3153 (2.9062)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:52:26 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][20/156]	eta 0:01:37 lr 0.000034	 wd 0.0500	time 0.4645 (0.7157)	data time 0.0593 (0.2009)	model time 0.0000 (0.0000)	loss 0.6028 (0.5501)	grad_norm 2.4424 (2.7715)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:52:31 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][30/156]	eta 0:01:19 lr 0.000034	 wd 0.0500	time 0.4214 (0.6283)	data time 0.0005 (0.1400)	model time 0.0000 (0.0000)	loss 0.4182 (0.5463)	grad_norm 3.2047 (3.2264)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:52:35 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][40/156]	eta 0:01:08 lr 0.000034	 wd 0.0500	time 0.4490 (0.5877)	data time 0.0164 (0.1077)	model time 0.0000 (0.0000)	loss 0.5843 (0.5463)	grad_norm 2.8489 (3.1140)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:52:40 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][50/156]	eta 0:01:00 lr 0.000034	 wd 0.0500	time 0.4268 (0.5680)	data time 0.0182 (0.0902)	model time 0.0000 (0.0000)	loss 0.5524 (0.5501)	grad_norm 3.2911 (3.1178)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:52:46 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][60/156]	eta 0:00:54 lr 0.000034	 wd 0.0500	time 0.5229 (0.5700)	data time 0.0221 (0.0781)	model time 0.5008 (0.5635)	loss 0.5809 (0.5482)	grad_norm 3.6190 (3.0902)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:52:51 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][70/156]	eta 0:00:48 lr 0.000034	 wd 0.0500	time 0.4701 (0.5596)	data time 0.0073 (0.0684)	model time 0.4628 (0.5252)	loss 0.4481 (0.5464)	grad_norm 2.7444 (3.1040)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:52:56 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][80/156]	eta 0:00:42 lr 0.000033	 wd 0.0500	time 0.6588 (0.5558)	data time 0.1799 (0.0638)	model time 0.4789 (0.5160)	loss 0.4981 (0.5472)	grad_norm 2.9044 (3.0628)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:53:02 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][90/156]	eta 0:00:36 lr 0.000033	 wd 0.0500	time 0.4787 (0.5531)	data time 0.0120 (0.0593)	model time 0.4667 (0.5141)	loss 0.5630 (0.5480)	grad_norm 3.0079 (3.0476)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:53:07 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][100/156]	eta 0:00:30 lr 0.000033	 wd 0.0500	time 0.5467 (0.5479)	data time 0.0606 (0.0555)	model time 0.4861 (0.5073)	loss 0.5740 (0.5488)	grad_norm 1.8019 (2.9861)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:53:12 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][110/156]	eta 0:00:25 lr 0.000033	 wd 0.0500	time 0.5806 (0.5471)	data time 0.0007 (0.0523)	model time 0.5799 (0.5091)	loss 0.4730 (0.5519)	grad_norm 5.0110 (2.9884)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:53:17 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][120/156]	eta 0:00:19 lr 0.000033	 wd 0.0500	time 0.5742 (0.5451)	data time 0.0050 (0.0489)	model time 0.5691 (0.5095)	loss 0.5543 (0.5523)	grad_norm 3.5738 (2.9608)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:53:23 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][130/156]	eta 0:00:14 lr 0.000033	 wd 0.0500	time 0.4603 (0.5431)	data time 0.0012 (0.0474)	model time 0.4591 (0.5070)	loss 0.5654 (0.5531)	grad_norm 1.7962 (2.9510)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:53:28 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][140/156]	eta 0:00:08 lr 0.000033	 wd 0.0500	time 0.6281 (0.5409)	data time 0.0010 (0.0454)	model time 0.6271 (0.5054)	loss 0.5873 (0.5515)	grad_norm 2.8716 (2.9153)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:53:34 vssm1_tiny_0230s](training.py 201): INFO Train: [204/300][150/156]	eta 0:00:03 lr 0.000033	 wd 0.0500	time 0.6225 (0.5454)	data time 0.0005 (0.0427)	model time 0.6220 (0.5153)	loss 0.5236 (0.5508)	grad_norm 2.4049 (2.8975)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:53:37 vssm1_tiny_0230s](training.py 212): INFO EPOCH 204 training takes 0:01:25
[2024-11-09 16:53:37 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_204.pth saving......
[2024-11-09 16:53:38 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_204.pth saved !!!
[2024-11-09 16:53:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.571 (3.571)	Loss 0.1964 (0.1964)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:53:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.709 (0.637)	Loss 0.2062 (0.2038)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:53:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.219 (0.446)	Loss 0.2020 (0.2138)	Acc@1 96.094 (95.387)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:53:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.154 (0.375)	Loss 0.2581 (0.2196)	Acc@1 92.969 (95.010)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:53:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.820 Acc@5 100.000
[2024-11-09 16:53:51 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.8%
[2024-11-09 16:53:51 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:53:55 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.519 (3.519)	Loss 0.2201 (0.2201)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:53:58 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.151 (0.608)	Loss 0.2334 (0.2332)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:54:00 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.427)	Loss 0.2961 (0.2495)	Acc@1 92.969 (93.862)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:54:02 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.341)	Loss 0.3545 (0.2815)	Acc@1 89.062 (91.532)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:54:04 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.680 Acc@5 100.000
[2024-11-09 16:54:04 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 90.7%
[2024-11-09 16:54:04 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.68%
[2024-11-09 16:54:08 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][0/156]	eta 0:12:05 lr 0.000033	 wd 0.0500	time 4.6529 (4.6529)	data time 4.2136 (4.2136)	model time 0.0000 (0.0000)	loss 0.5760 (0.5760)	grad_norm 1.8653 (1.8653)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:54:13 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][10/156]	eta 0:02:08 lr 0.000033	 wd 0.0500	time 0.4271 (0.8795)	data time 0.0026 (0.3850)	model time 0.0000 (0.0000)	loss 0.5744 (0.5276)	grad_norm 3.2089 (2.8633)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:54:18 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][20/156]	eta 0:01:32 lr 0.000033	 wd 0.0500	time 0.4641 (0.6809)	data time 0.0279 (0.2064)	model time 0.0000 (0.0000)	loss 0.4834 (0.5216)	grad_norm 3.2706 (3.0128)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:54:23 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][30/156]	eta 0:01:18 lr 0.000033	 wd 0.0500	time 0.4952 (0.6202)	data time 0.0504 (0.1453)	model time 0.0000 (0.0000)	loss 0.5613 (0.5316)	grad_norm 2.5050 (3.0085)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:54:28 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][40/156]	eta 0:01:09 lr 0.000033	 wd 0.0500	time 0.7065 (0.5976)	data time 0.0280 (0.1141)	model time 0.0000 (0.0000)	loss 0.4326 (0.5340)	grad_norm 3.4165 (2.9877)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:54:33 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][50/156]	eta 0:01:01 lr 0.000033	 wd 0.0500	time 0.4558 (0.5759)	data time 0.0237 (0.0940)	model time 0.0000 (0.0000)	loss 0.5565 (0.5324)	grad_norm 1.7081 (3.0073)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:54:38 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][60/156]	eta 0:00:54 lr 0.000033	 wd 0.0500	time 0.5793 (0.5675)	data time 0.0596 (0.0815)	model time 0.5196 (0.5072)	loss 0.5843 (0.5311)	grad_norm 2.8430 (3.0008)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:54:44 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][70/156]	eta 0:00:48 lr 0.000033	 wd 0.0500	time 0.4984 (0.5614)	data time 0.0007 (0.0721)	model time 0.4977 (0.5082)	loss 0.5579 (0.5319)	grad_norm 2.1296 (3.0291)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:54:49 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][80/156]	eta 0:00:42 lr 0.000033	 wd 0.0500	time 0.5405 (0.5577)	data time 0.0182 (0.0647)	model time 0.5222 (0.5121)	loss 0.6299 (0.5380)	grad_norm 1.5923 (3.0210)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:54:54 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][90/156]	eta 0:00:36 lr 0.000033	 wd 0.0500	time 0.5223 (0.5513)	data time 0.0233 (0.0592)	model time 0.4990 (0.5051)	loss 0.5840 (0.5422)	grad_norm 3.9254 (3.0519)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:54:59 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][100/156]	eta 0:00:30 lr 0.000033	 wd 0.0500	time 0.5179 (0.5455)	data time 0.0007 (0.0557)	model time 0.5173 (0.4980)	loss 0.4522 (0.5427)	grad_norm 2.6586 (3.0234)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:55:04 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][110/156]	eta 0:00:24 lr 0.000033	 wd 0.0500	time 0.4580 (0.5417)	data time 0.0180 (0.0529)	model time 0.4400 (0.4947)	loss 0.3965 (0.5402)	grad_norm 1.7027 (2.9704)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:55:09 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][120/156]	eta 0:00:19 lr 0.000033	 wd 0.0500	time 0.4902 (0.5405)	data time 0.0009 (0.0495)	model time 0.4893 (0.4976)	loss 0.6121 (0.5427)	grad_norm 4.8395 (2.9945)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:55:14 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][130/156]	eta 0:00:13 lr 0.000033	 wd 0.0500	time 0.4889 (0.5379)	data time 0.0215 (0.0466)	model time 0.4674 (0.4973)	loss 0.5376 (0.5455)	grad_norm 2.2688 (2.9762)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:55:19 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][140/156]	eta 0:00:08 lr 0.000033	 wd 0.0500	time 0.4764 (0.5344)	data time 0.0009 (0.0444)	model time 0.4755 (0.4946)	loss 0.5950 (0.5472)	grad_norm 2.3897 (2.9286)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:55:24 vssm1_tiny_0230s](training.py 201): INFO Train: [205/300][150/156]	eta 0:00:03 lr 0.000033	 wd 0.0500	time 0.4420 (0.5313)	data time 0.0004 (0.0416)	model time 0.4416 (0.4937)	loss 0.5435 (0.5485)	grad_norm 2.8112 (2.9073)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:55:27 vssm1_tiny_0230s](training.py 212): INFO EPOCH 205 training takes 0:01:23
[2024-11-09 16:55:27 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_205.pth saving......
[2024-11-09 16:55:28 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_205.pth saved !!!
[2024-11-09 16:55:32 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.362 (4.362)	Loss 0.2201 (0.2201)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:55:35 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.224 (0.651)	Loss 0.2308 (0.2266)	Acc@1 93.750 (94.886)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:55:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.339 (0.477)	Loss 0.1997 (0.2350)	Acc@1 98.438 (94.940)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:55:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.393)	Loss 0.2500 (0.2337)	Acc@1 91.406 (94.909)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:55:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.040 Acc@5 100.000
[2024-11-09 16:55:42 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 16:55:42 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:55:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.484 (4.484)	Loss 0.2192 (0.2192)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:55:49 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.229 (0.647)	Loss 0.2324 (0.2321)	Acc@1 96.094 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:55:51 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.423)	Loss 0.2927 (0.2483)	Acc@1 92.969 (93.713)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:55:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.350)	Loss 0.3513 (0.2796)	Acc@1 89.062 (91.557)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:55:56 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.740 Acc@5 100.000
[2024-11-09 16:55:56 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 90.7%
[2024-11-09 16:55:56 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.74%
[2024-11-09 16:56:01 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][0/156]	eta 0:11:21 lr 0.000033	 wd 0.0500	time 4.3676 (4.3676)	data time 3.9614 (3.9614)	model time 0.0000 (0.0000)	loss 0.6340 (0.6340)	grad_norm 2.1177 (2.1177)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:06 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][10/156]	eta 0:02:11 lr 0.000033	 wd 0.0500	time 0.6370 (0.9009)	data time 0.0064 (0.4165)	model time 0.0000 (0.0000)	loss 0.5980 (0.5666)	grad_norm 1.4912 (2.4657)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:11 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][20/156]	eta 0:01:35 lr 0.000033	 wd 0.0500	time 0.5858 (0.7023)	data time 0.0015 (0.2231)	model time 0.0000 (0.0000)	loss 0.5158 (0.5676)	grad_norm 3.2777 (2.6784)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:16 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][30/156]	eta 0:01:18 lr 0.000032	 wd 0.0500	time 0.4518 (0.6235)	data time 0.0022 (0.1520)	model time 0.0000 (0.0000)	loss 0.5444 (0.5714)	grad_norm 1.6538 (2.7133)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:20 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][40/156]	eta 0:01:08 lr 0.000032	 wd 0.0500	time 0.4856 (0.5869)	data time 0.0040 (0.1174)	model time 0.0000 (0.0000)	loss 0.6186 (0.5684)	grad_norm 3.8396 (2.8238)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:25 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][50/156]	eta 0:01:00 lr 0.000032	 wd 0.0500	time 0.4750 (0.5700)	data time 0.0070 (0.0985)	model time 0.0000 (0.0000)	loss 0.6480 (0.5683)	grad_norm 2.8151 (2.8035)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:31 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][60/156]	eta 0:00:54 lr 0.000032	 wd 0.0500	time 0.6087 (0.5650)	data time 0.0627 (0.0879)	model time 0.5460 (0.5060)	loss 0.5976 (0.5681)	grad_norm 1.9767 (2.7392)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:36 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][70/156]	eta 0:00:48 lr 0.000032	 wd 0.0500	time 0.4488 (0.5586)	data time 0.0218 (0.0773)	model time 0.4269 (0.5063)	loss 0.5463 (0.5643)	grad_norm 3.3992 (2.7968)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:41 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][80/156]	eta 0:00:41 lr 0.000032	 wd 0.0500	time 0.4420 (0.5494)	data time 0.0035 (0.0697)	model time 0.4385 (0.4938)	loss 0.4826 (0.5647)	grad_norm 2.4338 (2.7830)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:46 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][90/156]	eta 0:00:36 lr 0.000032	 wd 0.0500	time 0.4278 (0.5458)	data time 0.0172 (0.0641)	model time 0.4106 (0.4948)	loss 0.6330 (0.5660)	grad_norm 2.0319 (2.8137)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:51 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][100/156]	eta 0:00:30 lr 0.000032	 wd 0.0500	time 0.4286 (0.5404)	data time 0.0013 (0.0588)	model time 0.4273 (0.4919)	loss 0.4737 (0.5609)	grad_norm 1.9678 (2.8210)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:56:56 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][110/156]	eta 0:00:24 lr 0.000032	 wd 0.0500	time 0.4444 (0.5402)	data time 0.0007 (0.0548)	model time 0.4437 (0.4972)	loss 0.4437 (0.5596)	grad_norm 3.0372 (2.8241)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:57:01 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][120/156]	eta 0:00:19 lr 0.000032	 wd 0.0500	time 0.4780 (0.5387)	data time 0.0017 (0.0517)	model time 0.4763 (0.4984)	loss 0.3843 (0.5581)	grad_norm 3.4641 (2.7984)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:57:07 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][130/156]	eta 0:00:13 lr 0.000032	 wd 0.0500	time 0.4769 (0.5376)	data time 0.0283 (0.0492)	model time 0.4486 (0.4992)	loss 0.4226 (0.5586)	grad_norm 6.0375 (2.8139)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:57:12 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][140/156]	eta 0:00:08 lr 0.000032	 wd 0.0500	time 0.5459 (0.5371)	data time 0.0007 (0.0469)	model time 0.5452 (0.5007)	loss 0.5697 (0.5590)	grad_norm 4.0968 (2.8145)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:57:17 vssm1_tiny_0230s](training.py 201): INFO Train: [206/300][150/156]	eta 0:00:03 lr 0.000032	 wd 0.0500	time 0.7201 (0.5363)	data time 0.0006 (0.0440)	model time 0.7195 (0.5030)	loss 0.4764 (0.5572)	grad_norm 3.6366 (2.8091)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:57:20 vssm1_tiny_0230s](training.py 212): INFO EPOCH 206 training takes 0:01:24
[2024-11-09 16:57:20 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_206.pth saving......
[2024-11-09 16:57:21 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_206.pth saved !!!
[2024-11-09 16:57:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.538 (3.538)	Loss 0.2390 (0.2390)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:57:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.614)	Loss 0.2449 (0.2410)	Acc@1 92.188 (94.318)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:57:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.141 (0.409)	Loss 0.1857 (0.2471)	Acc@1 99.219 (93.936)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:57:32 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.152 (0.368)	Loss 0.2357 (0.2358)	Acc@1 92.188 (94.582)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:57:35 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.880 Acc@5 100.000
[2024-11-09 16:57:35 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.9%
[2024-11-09 16:57:35 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:57:39 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.347 (3.347)	Loss 0.2180 (0.2180)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:57:41 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.353 (0.515)	Loss 0.2311 (0.2308)	Acc@1 96.094 (95.384)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:57:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.154 (0.379)	Loss 0.2908 (0.2470)	Acc@1 92.969 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:57:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.340)	Loss 0.3494 (0.2780)	Acc@1 89.062 (91.583)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:57:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.760 Acc@5 100.000
[2024-11-09 16:57:49 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 90.8%
[2024-11-09 16:57:49 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.76%
[2024-11-09 16:57:54 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][0/156]	eta 0:12:11 lr 0.000032	 wd 0.0500	time 4.6911 (4.6911)	data time 4.1963 (4.1963)	model time 0.0000 (0.0000)	loss 0.5902 (0.5902)	grad_norm 2.5048 (2.5048)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:57:59 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][10/156]	eta 0:02:11 lr 0.000032	 wd 0.0500	time 0.4947 (0.8977)	data time 0.0128 (0.3913)	model time 0.0000 (0.0000)	loss 0.6159 (0.5674)	grad_norm 3.6019 (3.0790)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:04 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][20/156]	eta 0:01:37 lr 0.000032	 wd 0.0500	time 0.4450 (0.7190)	data time 0.0315 (0.2112)	model time 0.0000 (0.0000)	loss 0.5133 (0.5571)	grad_norm 2.8600 (2.9481)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:10 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][30/156]	eta 0:01:23 lr 0.000032	 wd 0.0500	time 0.5013 (0.6645)	data time 0.0086 (0.1469)	model time 0.0000 (0.0000)	loss 0.5642 (0.5672)	grad_norm 2.9962 (2.8737)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:14 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][40/156]	eta 0:01:12 lr 0.000032	 wd 0.0500	time 0.4101 (0.6215)	data time 0.0008 (0.1159)	model time 0.0000 (0.0000)	loss 0.6292 (0.5647)	grad_norm 1.9618 (2.8426)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:19 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][50/156]	eta 0:01:03 lr 0.000032	 wd 0.0500	time 0.5500 (0.5971)	data time 0.0342 (0.0959)	model time 0.0000 (0.0000)	loss 0.5900 (0.5681)	grad_norm 2.6258 (2.9034)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:24 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][60/156]	eta 0:00:55 lr 0.000032	 wd 0.0500	time 0.4953 (0.5764)	data time 0.0008 (0.0824)	model time 0.4944 (0.4568)	loss 0.6276 (0.5654)	grad_norm 3.0563 (2.8525)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:29 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][70/156]	eta 0:00:48 lr 0.000032	 wd 0.0500	time 0.4265 (0.5638)	data time 0.0069 (0.0733)	model time 0.4196 (0.4631)	loss 0.5299 (0.5642)	grad_norm 2.2804 (2.8430)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:34 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][80/156]	eta 0:00:42 lr 0.000032	 wd 0.0500	time 0.4915 (0.5618)	data time 0.0130 (0.0653)	model time 0.4785 (0.4885)	loss 0.5357 (0.5611)	grad_norm 3.3738 (2.9224)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:40 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][90/156]	eta 0:00:36 lr 0.000032	 wd 0.0500	time 0.5036 (0.5555)	data time 0.0285 (0.0610)	model time 0.4752 (0.4858)	loss 0.5486 (0.5603)	grad_norm 1.9939 (2.8791)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:45 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][100/156]	eta 0:00:30 lr 0.000032	 wd 0.0500	time 0.4744 (0.5504)	data time 0.0231 (0.0569)	model time 0.4513 (0.4855)	loss 0.4378 (0.5592)	grad_norm 4.4569 (2.8833)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:50 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][110/156]	eta 0:00:25 lr 0.000032	 wd 0.0500	time 0.4607 (0.5463)	data time 0.0411 (0.0539)	model time 0.4197 (0.4850)	loss 0.3965 (0.5577)	grad_norm 2.8591 (2.8571)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:54 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][120/156]	eta 0:00:19 lr 0.000032	 wd 0.0500	time 0.5216 (0.5383)	data time 0.0006 (0.0503)	model time 0.5210 (0.4783)	loss 0.4571 (0.5581)	grad_norm 3.5455 (2.8963)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:58:59 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][130/156]	eta 0:00:13 lr 0.000031	 wd 0.0500	time 0.4503 (0.5327)	data time 0.0010 (0.0469)	model time 0.4493 (0.4761)	loss 0.4854 (0.5578)	grad_norm 4.1612 (2.9091)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:59:04 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][140/156]	eta 0:00:08 lr 0.000031	 wd 0.0500	time 0.6299 (0.5298)	data time 0.0015 (0.0443)	model time 0.6284 (0.4766)	loss 0.4542 (0.5556)	grad_norm 3.7960 (2.9578)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:59:09 vssm1_tiny_0230s](training.py 201): INFO Train: [207/300][150/156]	eta 0:00:03 lr 0.000031	 wd 0.0500	time 0.5262 (0.5301)	data time 0.0005 (0.0419)	model time 0.5257 (0.4816)	loss 0.6152 (0.5582)	grad_norm 2.0439 (2.9332)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:59:12 vssm1_tiny_0230s](training.py 212): INFO EPOCH 207 training takes 0:01:22
[2024-11-09 16:59:12 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_207.pth saving......
[2024-11-09 16:59:12 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_207.pth saved !!!
[2024-11-09 16:59:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.428 (3.428)	Loss 0.1748 (0.1748)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:59:18 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.162 (0.569)	Loss 0.1859 (0.1802)	Acc@1 96.875 (96.804)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:59:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.522 (0.420)	Loss 0.2188 (0.1929)	Acc@1 96.875 (96.057)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:59:24 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.223 (0.385)	Loss 0.2766 (0.2154)	Acc@1 91.406 (95.086)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:59:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.700 Acc@5 100.000
[2024-11-09 16:59:27 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.7%
[2024-11-09 16:59:27 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 16:59:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.832 (3.832)	Loss 0.2173 (0.2173)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:59:33 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.142 (0.596)	Loss 0.2301 (0.2299)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:59:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.446)	Loss 0.2881 (0.2460)	Acc@1 92.969 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:59:38 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.152 (0.360)	Loss 0.3469 (0.2764)	Acc@1 89.062 (91.784)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 16:59:41 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.960 Acc@5 100.000
[2024-11-09 16:59:41 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 91.0%
[2024-11-09 16:59:41 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.96%
[2024-11-09 16:59:45 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][0/156]	eta 0:10:53 lr 0.000031	 wd 0.0500	time 4.1922 (4.1922)	data time 3.7493 (3.7493)	model time 0.0000 (0.0000)	loss 0.4273 (0.4273)	grad_norm 3.3757 (3.3757)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:59:51 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][10/156]	eta 0:02:12 lr 0.000031	 wd 0.0500	time 0.6659 (0.9053)	data time 0.1529 (0.3756)	model time 0.0000 (0.0000)	loss 0.6697 (0.5349)	grad_norm 2.1350 (2.9926)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 16:59:55 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][20/156]	eta 0:01:35 lr 0.000031	 wd 0.0500	time 0.4103 (0.7001)	data time 0.0021 (0.2015)	model time 0.0000 (0.0000)	loss 0.5316 (0.5363)	grad_norm 4.8801 (2.8693)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:00 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][30/156]	eta 0:01:20 lr 0.000031	 wd 0.0500	time 0.4250 (0.6353)	data time 0.0069 (0.1416)	model time 0.0000 (0.0000)	loss 0.6907 (0.5510)	grad_norm 3.0190 (2.7945)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:05 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][40/156]	eta 0:01:09 lr 0.000031	 wd 0.0500	time 0.5023 (0.5985)	data time 0.0007 (0.1108)	model time 0.0000 (0.0000)	loss 0.4643 (0.5458)	grad_norm 3.7074 (2.8622)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:10 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][50/156]	eta 0:01:01 lr 0.000031	 wd 0.0500	time 0.5359 (0.5765)	data time 0.0474 (0.0939)	model time 0.0000 (0.0000)	loss 0.4638 (0.5413)	grad_norm 3.0440 (2.8418)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:15 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][60/156]	eta 0:00:53 lr 0.000031	 wd 0.0500	time 0.4663 (0.5609)	data time 0.0036 (0.0805)	model time 0.4627 (0.4691)	loss 0.4810 (0.5432)	grad_norm 2.3203 (2.8155)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:20 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][70/156]	eta 0:00:47 lr 0.000031	 wd 0.0500	time 0.6308 (0.5530)	data time 0.0073 (0.0707)	model time 0.6235 (0.4817)	loss 0.6114 (0.5438)	grad_norm 1.8372 (2.8100)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:25 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][80/156]	eta 0:00:41 lr 0.000031	 wd 0.0500	time 0.4933 (0.5456)	data time 0.0049 (0.0640)	model time 0.4884 (0.4802)	loss 0.5532 (0.5430)	grad_norm 2.8682 (2.9075)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:30 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][90/156]	eta 0:00:35 lr 0.000031	 wd 0.0500	time 0.5174 (0.5386)	data time 0.0008 (0.0593)	model time 0.5166 (0.4752)	loss 0.5683 (0.5442)	grad_norm 1.7904 (2.8535)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:35 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][100/156]	eta 0:00:30 lr 0.000031	 wd 0.0500	time 0.7475 (0.5388)	data time 0.0637 (0.0557)	model time 0.6838 (0.4836)	loss 0.5059 (0.5441)	grad_norm 1.8967 (2.8949)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:40 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][110/156]	eta 0:00:24 lr 0.000031	 wd 0.0500	time 0.5889 (0.5359)	data time 0.0006 (0.0514)	model time 0.5883 (0.4861)	loss 0.4282 (0.5428)	grad_norm 4.1617 (2.9299)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:45 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][120/156]	eta 0:00:19 lr 0.000031	 wd 0.0500	time 0.5336 (0.5346)	data time 0.0592 (0.0486)	model time 0.4743 (0.4884)	loss 0.5887 (0.5456)	grad_norm 3.1675 (2.9043)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:50 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][130/156]	eta 0:00:13 lr 0.000031	 wd 0.0500	time 0.4539 (0.5303)	data time 0.0044 (0.0456)	model time 0.4495 (0.4860)	loss 0.6038 (0.5475)	grad_norm 2.5616 (2.8910)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:00:55 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][140/156]	eta 0:00:08 lr 0.000031	 wd 0.0500	time 0.6371 (0.5298)	data time 0.0009 (0.0436)	model time 0.6362 (0.4883)	loss 0.5999 (0.5478)	grad_norm 2.4781 (2.8688)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:01:00 vssm1_tiny_0230s](training.py 201): INFO Train: [208/300][150/156]	eta 0:00:03 lr 0.000031	 wd 0.0500	time 0.6143 (0.5271)	data time 0.0007 (0.0407)	model time 0.6136 (0.4884)	loss 0.5688 (0.5471)	grad_norm 3.7956 (2.8886)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:01:03 vssm1_tiny_0230s](training.py 212): INFO EPOCH 208 training takes 0:01:22
[2024-11-09 17:01:03 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_208.pth saving......
[2024-11-09 17:01:04 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_208.pth saved !!!
[2024-11-09 17:01:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.806 (3.806)	Loss 0.2244 (0.2244)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:01:11 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.189 (0.616)	Loss 0.2366 (0.2337)	Acc@1 92.969 (94.034)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:01:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.177 (0.426)	Loss 0.1647 (0.2390)	Acc@1 98.438 (93.824)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:01:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.345)	Loss 0.2153 (0.2242)	Acc@1 92.969 (94.607)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:01:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.020 Acc@5 100.000
[2024-11-09 17:01:17 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 17:01:17 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 17:01:21 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.278 (3.278)	Loss 0.2164 (0.2164)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:01:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.558)	Loss 0.2292 (0.2289)	Acc@1 96.094 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:01:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.827 (0.421)	Loss 0.2854 (0.2449)	Acc@1 92.969 (93.676)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:01:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.161 (0.349)	Loss 0.3445 (0.2748)	Acc@1 89.062 (91.784)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:01:30 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 90.980 Acc@5 100.000
[2024-11-09 17:01:30 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 91.0%
[2024-11-09 17:01:30 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 90.98%
[2024-11-09 17:01:36 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][0/156]	eta 0:13:24 lr 0.000031	 wd 0.0500	time 5.1549 (5.1549)	data time 4.7318 (4.7318)	model time 0.0000 (0.0000)	loss 0.5898 (0.5898)	grad_norm 3.8375 (3.8375)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:01:41 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][10/156]	eta 0:02:15 lr 0.000031	 wd 0.0500	time 0.6037 (0.9275)	data time 0.0256 (0.4405)	model time 0.0000 (0.0000)	loss 0.5151 (0.5475)	grad_norm 7.2709 (3.6658)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:01:46 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][20/156]	eta 0:01:43 lr 0.000031	 wd 0.0500	time 0.4143 (0.7627)	data time 0.0009 (0.2349)	model time 0.0000 (0.0000)	loss 0.5408 (0.5362)	grad_norm 3.5925 (3.5419)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:01:52 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][30/156]	eta 0:01:29 lr 0.000031	 wd 0.0500	time 0.4466 (0.7093)	data time 0.0045 (0.1690)	model time 0.0000 (0.0000)	loss 0.5680 (0.5418)	grad_norm 2.4969 (3.6473)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:01:57 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][40/156]	eta 0:01:15 lr 0.000031	 wd 0.0500	time 0.4498 (0.6511)	data time 0.0005 (0.1310)	model time 0.0000 (0.0000)	loss 0.6350 (0.5490)	grad_norm 2.0388 (3.3945)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:02:02 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][50/156]	eta 0:01:06 lr 0.000031	 wd 0.0500	time 0.5839 (0.6241)	data time 0.0238 (0.1075)	model time 0.0000 (0.0000)	loss 0.5551 (0.5445)	grad_norm 2.1520 (3.3090)	loss_scale 65536.0000 (38550.5882)	mem 13675MB
[2024-11-09 17:02:07 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][60/156]	eta 0:00:58 lr 0.000031	 wd 0.0500	time 0.6547 (0.6079)	data time 0.1055 (0.0940)	model time 0.5491 (0.5001)	loss 0.6138 (0.5468)	grad_norm 3.4106 (3.2745)	loss_scale 65536.0000 (42974.4262)	mem 13675MB
[2024-11-09 17:02:13 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][70/156]	eta 0:00:51 lr 0.000031	 wd 0.0500	time 0.5303 (0.5946)	data time 0.0604 (0.0842)	model time 0.4699 (0.4949)	loss 0.6037 (0.5488)	grad_norm 2.5476 (3.2387)	loss_scale 65536.0000 (46152.1127)	mem 13675MB
[2024-11-09 17:02:18 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][80/156]	eta 0:00:44 lr 0.000030	 wd 0.0500	time 0.4352 (0.5819)	data time 0.0081 (0.0749)	model time 0.4271 (0.4907)	loss 0.5255 (0.5505)	grad_norm 4.1327 (3.2560)	loss_scale 65536.0000 (48545.1852)	mem 13675MB
[2024-11-09 17:02:23 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][90/156]	eta 0:00:37 lr 0.000030	 wd 0.0500	time 0.4616 (0.5741)	data time 0.0023 (0.0684)	model time 0.4593 (0.4919)	loss 0.4369 (0.5456)	grad_norm 2.2294 (3.2093)	loss_scale 65536.0000 (50412.3077)	mem 13675MB
[2024-11-09 17:02:28 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][100/156]	eta 0:00:32 lr 0.000030	 wd 0.0500	time 0.4505 (0.5720)	data time 0.0375 (0.0633)	model time 0.4130 (0.5007)	loss 0.5604 (0.5423)	grad_norm 3.3556 (3.2676)	loss_scale 65536.0000 (51909.7030)	mem 13675MB
[2024-11-09 17:02:34 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][110/156]	eta 0:00:26 lr 0.000030	 wd 0.0500	time 0.5456 (0.5696)	data time 0.0144 (0.0592)	model time 0.5312 (0.5051)	loss 0.6090 (0.5459)	grad_norm 3.5143 (3.2534)	loss_scale 65536.0000 (53137.2973)	mem 13675MB
[2024-11-09 17:02:39 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][120/156]	eta 0:00:20 lr 0.000030	 wd 0.0500	time 0.4516 (0.5633)	data time 0.0094 (0.0564)	model time 0.4422 (0.4999)	loss 0.4856 (0.5463)	grad_norm 4.4603 (3.2405)	loss_scale 65536.0000 (54161.9835)	mem 13675MB
[2024-11-09 17:02:43 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][130/156]	eta 0:00:14 lr 0.000030	 wd 0.0500	time 0.4447 (0.5563)	data time 0.0260 (0.0534)	model time 0.4187 (0.4943)	loss 0.6191 (0.5493)	grad_norm 2.0431 (3.1594)	loss_scale 65536.0000 (55030.2290)	mem 13675MB
[2024-11-09 17:02:48 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][140/156]	eta 0:00:08 lr 0.000030	 wd 0.0500	time 0.4860 (0.5525)	data time 0.0010 (0.0504)	model time 0.4849 (0.4940)	loss 0.6061 (0.5480)	grad_norm 3.2176 (3.1522)	loss_scale 65536.0000 (55775.3191)	mem 13675MB
[2024-11-09 17:02:53 vssm1_tiny_0230s](training.py 201): INFO Train: [209/300][150/156]	eta 0:00:03 lr 0.000030	 wd 0.0500	time 0.4115 (0.5501)	data time 0.0007 (0.0471)	model time 0.4108 (0.4960)	loss 0.5935 (0.5473)	grad_norm 1.8047 (3.1492)	loss_scale 65536.0000 (56421.7219)	mem 13675MB
[2024-11-09 17:02:56 vssm1_tiny_0230s](training.py 212): INFO EPOCH 209 training takes 0:01:25
[2024-11-09 17:02:56 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_209.pth saving......
[2024-11-09 17:02:56 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_209.pth saved !!!
[2024-11-09 17:03:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.392 (3.392)	Loss 0.1818 (0.1818)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:03:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.143 (0.462)	Loss 0.1915 (0.1838)	Acc@1 96.875 (97.230)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:03:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.193 (0.404)	Loss 0.2181 (0.1961)	Acc@1 96.875 (96.615)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:03:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.219 (0.381)	Loss 0.2773 (0.2170)	Acc@1 91.406 (95.514)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:03:11 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.960 Acc@5 100.000
[2024-11-09 17:03:11 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 17:03:11 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 17:03:15 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.300 (4.300)	Loss 0.2161 (0.2161)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:03:17 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.607)	Loss 0.2285 (0.2283)	Acc@1 96.094 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:03:20 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.429)	Loss 0.2825 (0.2441)	Acc@1 92.969 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:03:22 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.370)	Loss 0.3418 (0.2733)	Acc@1 89.844 (91.809)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:03:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.080 Acc@5 100.000
[2024-11-09 17:03:25 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 91.1%
[2024-11-09 17:03:25 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 91.08%
[2024-11-09 17:03:29 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][0/156]	eta 0:11:07 lr 0.000030	 wd 0.0500	time 4.2783 (4.2783)	data time 3.7171 (3.7171)	model time 0.0000 (0.0000)	loss 0.4106 (0.4106)	grad_norm 2.7746 (2.7746)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:03:34 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][10/156]	eta 0:01:59 lr 0.000030	 wd 0.0500	time 0.4212 (0.8207)	data time 0.0103 (0.3548)	model time 0.0000 (0.0000)	loss 0.6228 (0.5542)	grad_norm 2.9157 (2.7573)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:03:39 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][20/156]	eta 0:01:29 lr 0.000030	 wd 0.0500	time 0.5194 (0.6588)	data time 0.0006 (0.1879)	model time 0.0000 (0.0000)	loss 0.5080 (0.5518)	grad_norm 3.4523 (2.7600)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:03:44 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][30/156]	eta 0:01:16 lr 0.000030	 wd 0.0500	time 0.5370 (0.6104)	data time 0.0029 (0.1370)	model time 0.0000 (0.0000)	loss 0.5177 (0.5545)	grad_norm 1.8603 (2.7758)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:03:49 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][40/156]	eta 0:01:08 lr 0.000030	 wd 0.0500	time 0.5888 (0.5910)	data time 0.0247 (0.1075)	model time 0.0000 (0.0000)	loss 0.6072 (0.5546)	grad_norm 3.2100 (2.7190)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:03:54 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][50/156]	eta 0:01:00 lr 0.000030	 wd 0.0500	time 0.5295 (0.5718)	data time 0.0155 (0.0888)	model time 0.0000 (0.0000)	loss 0.6157 (0.5516)	grad_norm 2.8150 (2.6772)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:03:59 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][60/156]	eta 0:00:53 lr 0.000030	 wd 0.0500	time 0.5637 (0.5599)	data time 0.0168 (0.0771)	model time 0.5469 (0.4816)	loss 0.5816 (0.5565)	grad_norm 2.8536 (2.6614)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:04:04 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][70/156]	eta 0:00:47 lr 0.000030	 wd 0.0500	time 0.5092 (0.5517)	data time 0.0246 (0.0679)	model time 0.4845 (0.4859)	loss 0.5747 (0.5601)	grad_norm 2.5340 (2.6729)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:04:09 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][80/156]	eta 0:00:41 lr 0.000030	 wd 0.0500	time 0.5083 (0.5459)	data time 0.0080 (0.0622)	model time 0.5003 (0.4849)	loss 0.4432 (0.5571)	grad_norm 3.3462 (2.6541)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:04:14 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][90/156]	eta 0:00:35 lr 0.000030	 wd 0.0500	time 0.4432 (0.5446)	data time 0.0192 (0.0582)	model time 0.4240 (0.4909)	loss 0.6146 (0.5607)	grad_norm 2.8398 (2.6531)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:04:20 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][100/156]	eta 0:00:30 lr 0.000030	 wd 0.0500	time 0.5937 (0.5479)	data time 0.0014 (0.0547)	model time 0.5923 (0.5037)	loss 0.5910 (0.5618)	grad_norm 1.4050 (2.6505)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:04:25 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][110/156]	eta 0:00:25 lr 0.000030	 wd 0.0500	time 0.4577 (0.5435)	data time 0.0263 (0.0510)	model time 0.4313 (0.5007)	loss 0.5694 (0.5607)	grad_norm 2.3009 (2.6384)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:04:30 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][120/156]	eta 0:00:19 lr 0.000030	 wd 0.0500	time 0.5635 (0.5410)	data time 0.0053 (0.0478)	model time 0.5581 (0.5006)	loss 0.4274 (0.5578)	grad_norm 2.3026 (2.6473)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:04:35 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][130/156]	eta 0:00:13 lr 0.000030	 wd 0.0500	time 0.4964 (0.5374)	data time 0.0222 (0.0459)	model time 0.4742 (0.4970)	loss 0.5787 (0.5554)	grad_norm 3.5447 (2.6738)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:04:40 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][140/156]	eta 0:00:08 lr 0.000030	 wd 0.0500	time 0.4338 (0.5320)	data time 0.0008 (0.0436)	model time 0.4330 (0.4915)	loss 0.4270 (0.5548)	grad_norm 3.2249 (2.7219)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:04:45 vssm1_tiny_0230s](training.py 201): INFO Train: [210/300][150/156]	eta 0:00:03 lr 0.000030	 wd 0.0500	time 0.5667 (0.5303)	data time 0.0006 (0.0409)	model time 0.5661 (0.4928)	loss 0.6155 (0.5543)	grad_norm 1.5200 (2.7240)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:04:48 vssm1_tiny_0230s](training.py 212): INFO EPOCH 210 training takes 0:01:22
[2024-11-09 17:04:48 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_210.pth saving......
[2024-11-09 17:04:48 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_210.pth saved !!!
[2024-11-09 17:04:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.403 (3.403)	Loss 0.2230 (0.2230)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:04:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.640 (0.635)	Loss 0.2250 (0.2149)	Acc@1 93.750 (94.602)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:04:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.153 (0.456)	Loss 0.1699 (0.2231)	Acc@1 97.656 (94.196)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:05:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.387)	Loss 0.2263 (0.2167)	Acc@1 92.969 (94.708)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:05:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.980 Acc@5 100.000
[2024-11-09 17:05:02 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 17:05:02 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 17:05:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.669 (3.669)	Loss 0.2152 (0.2152)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:05:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.540 (0.594)	Loss 0.2274 (0.2273)	Acc@1 96.094 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:05:11 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.226 (0.408)	Loss 0.2800 (0.2431)	Acc@1 93.750 (93.676)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:05:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.503 (0.386)	Loss 0.3394 (0.2717)	Acc@1 90.625 (91.961)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:05:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.220 Acc@5 100.000
[2024-11-09 17:05:16 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 91.2%
[2024-11-09 17:05:16 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 91.22%
[2024-11-09 17:05:20 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][0/156]	eta 0:11:52 lr 0.000030	 wd 0.0500	time 4.5689 (4.5689)	data time 3.9962 (3.9962)	model time 0.0000 (0.0000)	loss 0.4664 (0.4664)	grad_norm 3.2847 (3.2847)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:05:25 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][10/156]	eta 0:02:06 lr 0.000030	 wd 0.0500	time 0.4648 (0.8677)	data time 0.0011 (0.3775)	model time 0.0000 (0.0000)	loss 0.5833 (0.5320)	grad_norm 2.6130 (3.0993)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:05:31 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][20/156]	eta 0:01:35 lr 0.000030	 wd 0.0500	time 0.4103 (0.7035)	data time 0.0007 (0.2095)	model time 0.0000 (0.0000)	loss 0.6628 (0.5518)	grad_norm 2.9353 (3.1517)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:05:36 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][30/156]	eta 0:01:21 lr 0.000030	 wd 0.0500	time 0.5207 (0.6460)	data time 0.0007 (0.1466)	model time 0.0000 (0.0000)	loss 0.6265 (0.5462)	grad_norm 4.1672 (3.1134)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:05:41 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][40/156]	eta 0:01:11 lr 0.000029	 wd 0.0500	time 0.5025 (0.6207)	data time 0.0009 (0.1168)	model time 0.0000 (0.0000)	loss 0.5718 (0.5428)	grad_norm 2.2152 (3.0706)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:05:47 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][50/156]	eta 0:01:03 lr 0.000029	 wd 0.0500	time 0.4779 (0.5997)	data time 0.0088 (0.0989)	model time 0.0000 (0.0000)	loss 0.5500 (0.5395)	grad_norm 2.2545 (3.0868)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:05:52 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][60/156]	eta 0:00:56 lr 0.000029	 wd 0.0500	time 0.5494 (0.5862)	data time 0.0746 (0.0872)	model time 0.4749 (0.4894)	loss 0.5359 (0.5390)	grad_norm 3.9373 (3.0541)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:05:57 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][70/156]	eta 0:00:49 lr 0.000029	 wd 0.0500	time 0.6152 (0.5782)	data time 0.0009 (0.0768)	model time 0.6144 (0.5027)	loss 0.6116 (0.5359)	grad_norm 3.3826 (3.1469)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:06:03 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][80/156]	eta 0:00:43 lr 0.000029	 wd 0.0500	time 0.5873 (0.5767)	data time 0.0249 (0.0694)	model time 0.5624 (0.5183)	loss 0.5704 (0.5363)	grad_norm 2.2495 (3.1107)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:06:08 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][90/156]	eta 0:00:37 lr 0.000029	 wd 0.0500	time 0.5049 (0.5739)	data time 0.0276 (0.0639)	model time 0.4772 (0.5217)	loss 0.5902 (0.5365)	grad_norm 2.2577 (3.0348)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:06:13 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][100/156]	eta 0:00:31 lr 0.000029	 wd 0.0500	time 0.4142 (0.5671)	data time 0.0010 (0.0587)	model time 0.4132 (0.5161)	loss 0.5534 (0.5374)	grad_norm 3.0067 (3.0238)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:06:18 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][110/156]	eta 0:00:25 lr 0.000029	 wd 0.0500	time 0.4776 (0.5634)	data time 0.0006 (0.0559)	model time 0.4770 (0.5131)	loss 0.6084 (0.5405)	grad_norm 2.2579 (2.9326)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:06:24 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][120/156]	eta 0:00:20 lr 0.000029	 wd 0.0500	time 0.5755 (0.5591)	data time 0.0037 (0.0533)	model time 0.5718 (0.5094)	loss 0.6240 (0.5421)	grad_norm 3.8967 (2.9301)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:06:29 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][130/156]	eta 0:00:14 lr 0.000029	 wd 0.0500	time 0.4949 (0.5567)	data time 0.0186 (0.0514)	model time 0.4762 (0.5081)	loss 0.5874 (0.5445)	grad_norm 2.4392 (2.8977)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:06:34 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][140/156]	eta 0:00:08 lr 0.000029	 wd 0.0500	time 0.5413 (0.5554)	data time 0.0011 (0.0491)	model time 0.5402 (0.5095)	loss 0.6046 (0.5469)	grad_norm 2.6340 (2.8856)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:06:40 vssm1_tiny_0230s](training.py 201): INFO Train: [211/300][150/156]	eta 0:00:03 lr 0.000029	 wd 0.0500	time 0.5409 (0.5547)	data time 0.0006 (0.0458)	model time 0.5403 (0.5130)	loss 0.5381 (0.5475)	grad_norm 2.4774 (2.8751)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:06:43 vssm1_tiny_0230s](training.py 212): INFO EPOCH 211 training takes 0:01:26
[2024-11-09 17:06:43 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_211.pth saving......
[2024-11-09 17:06:43 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_211.pth saved !!!
[2024-11-09 17:06:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.446 (3.446)	Loss 0.2300 (0.2300)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:06:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.593)	Loss 0.2418 (0.2391)	Acc@1 93.750 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:06:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.166 (0.436)	Loss 0.1935 (0.2456)	Acc@1 98.438 (94.234)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:06:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.375)	Loss 0.2360 (0.2388)	Acc@1 93.750 (94.733)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:06:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.020 Acc@5 100.000
[2024-11-09 17:06:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 17:06:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 17:07:01 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.737 (3.737)	Loss 0.2146 (0.2146)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:07:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.209 (0.530)	Loss 0.2267 (0.2265)	Acc@1 96.094 (95.170)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:07:06 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.160 (0.434)	Loss 0.2773 (0.2422)	Acc@1 93.750 (93.676)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:07:09 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.143 (0.385)	Loss 0.3372 (0.2703)	Acc@1 90.625 (92.011)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:07:12 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.260 Acc@5 100.000
[2024-11-09 17:07:12 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 91.3%
[2024-11-09 17:07:12 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 91.26%
[2024-11-09 17:07:16 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][0/156]	eta 0:10:58 lr 0.000029	 wd 0.0500	time 4.2217 (4.2217)	data time 3.6340 (3.6340)	model time 0.0000 (0.0000)	loss 0.5024 (0.5024)	grad_norm 1.9468 (1.9468)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:07:21 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][10/156]	eta 0:02:09 lr 0.000029	 wd 0.0500	time 0.5639 (0.8838)	data time 0.0035 (0.3794)	model time 0.0000 (0.0000)	loss 0.5447 (0.5696)	grad_norm 4.6102 (2.7016)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:07:27 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][20/156]	eta 0:01:36 lr 0.000029	 wd 0.0500	time 0.4992 (0.7062)	data time 0.0030 (0.2052)	model time 0.0000 (0.0000)	loss 0.5545 (0.5652)	grad_norm 3.2814 (2.7165)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:07:32 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][30/156]	eta 0:01:21 lr 0.000029	 wd 0.0500	time 0.5361 (0.6441)	data time 0.0109 (0.1406)	model time 0.0000 (0.0000)	loss 0.5203 (0.5514)	grad_norm 2.8680 (2.8929)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:07:37 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][40/156]	eta 0:01:10 lr 0.000029	 wd 0.0500	time 0.4846 (0.6096)	data time 0.0034 (0.1093)	model time 0.0000 (0.0000)	loss 0.5776 (0.5592)	grad_norm 2.1244 (2.8420)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:07:42 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][50/156]	eta 0:01:02 lr 0.000029	 wd 0.0500	time 0.5200 (0.5933)	data time 0.0161 (0.0891)	model time 0.0000 (0.0000)	loss 0.6303 (0.5582)	grad_norm 3.3775 (2.8603)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:07:47 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][60/156]	eta 0:00:55 lr 0.000029	 wd 0.0500	time 0.4292 (0.5799)	data time 0.0071 (0.0759)	model time 0.4221 (0.5028)	loss 0.5671 (0.5569)	grad_norm 3.0112 (2.8561)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:07:53 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][70/156]	eta 0:00:50 lr 0.000029	 wd 0.0500	time 0.7059 (0.5820)	data time 0.0422 (0.0700)	model time 0.6637 (0.5316)	loss 0.4317 (0.5467)	grad_norm 2.4339 (2.9132)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:07:59 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][80/156]	eta 0:00:43 lr 0.000029	 wd 0.0500	time 0.5396 (0.5784)	data time 0.0234 (0.0644)	model time 0.5161 (0.5308)	loss 0.5690 (0.5438)	grad_norm 1.7570 (2.8937)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:08:04 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][90/156]	eta 0:00:37 lr 0.000029	 wd 0.0500	time 0.4839 (0.5701)	data time 0.0305 (0.0603)	model time 0.4534 (0.5169)	loss 0.5225 (0.5459)	grad_norm 4.8082 (3.0295)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:08:09 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][100/156]	eta 0:00:31 lr 0.000029	 wd 0.0500	time 0.8240 (0.5652)	data time 0.0228 (0.0555)	model time 0.8012 (0.5153)	loss 0.4475 (0.5483)	grad_norm 4.4992 (3.0326)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:08:14 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][110/156]	eta 0:00:25 lr 0.000029	 wd 0.0500	time 0.7207 (0.5645)	data time 0.0211 (0.0519)	model time 0.6996 (0.5197)	loss 0.6180 (0.5471)	grad_norm 2.3125 (2.9773)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:08:19 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][120/156]	eta 0:00:20 lr 0.000029	 wd 0.0500	time 0.4254 (0.5584)	data time 0.0169 (0.0494)	model time 0.4085 (0.5125)	loss 0.6394 (0.5482)	grad_norm 2.2195 (2.9660)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:08:25 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][130/156]	eta 0:00:14 lr 0.000029	 wd 0.0500	time 0.4503 (0.5559)	data time 0.0047 (0.0471)	model time 0.4456 (0.5116)	loss 0.5308 (0.5484)	grad_norm 1.5140 (2.9080)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:08:30 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][140/156]	eta 0:00:08 lr 0.000029	 wd 0.0500	time 0.5856 (0.5540)	data time 0.0092 (0.0451)	model time 0.5764 (0.5116)	loss 0.4919 (0.5468)	grad_norm 3.1828 (2.8771)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:08:35 vssm1_tiny_0230s](training.py 201): INFO Train: [212/300][150/156]	eta 0:00:03 lr 0.000028	 wd 0.0500	time 0.4554 (0.5524)	data time 0.0007 (0.0421)	model time 0.4547 (0.5133)	loss 0.5441 (0.5457)	grad_norm 2.2402 (2.8673)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:08:38 vssm1_tiny_0230s](training.py 212): INFO EPOCH 212 training takes 0:01:26
[2024-11-09 17:08:38 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_212.pth saving......
[2024-11-09 17:08:38 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_212.pth saved !!!
[2024-11-09 17:08:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.694 (2.694)	Loss 0.1820 (0.1820)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:08:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.265 (0.444)	Loss 0.1908 (0.1841)	Acc@1 96.875 (96.733)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:08:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.153 (0.313)	Loss 0.2056 (0.1940)	Acc@1 96.875 (96.317)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:08:47 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.271)	Loss 0.2673 (0.2127)	Acc@1 91.406 (95.237)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:08:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.860 Acc@5 100.000
[2024-11-09 17:08:48 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.9%
[2024-11-09 17:08:48 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 17:08:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.363 (3.363)	Loss 0.2140 (0.2140)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:08:54 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.215 (0.552)	Loss 0.2260 (0.2257)	Acc@1 96.094 (95.170)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:08:56 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.160 (0.371)	Loss 0.2744 (0.2413)	Acc@1 93.750 (93.638)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:08:58 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.311)	Loss 0.3342 (0.2687)	Acc@1 90.625 (92.036)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:09:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.340 Acc@5 100.000
[2024-11-09 17:09:00 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 91.3%
[2024-11-09 17:09:00 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 91.34%
[2024-11-09 17:09:05 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][0/156]	eta 0:11:21 lr 0.000028	 wd 0.0500	time 4.3694 (4.3694)	data time 3.9364 (3.9364)	model time 0.0000 (0.0000)	loss 0.5617 (0.5617)	grad_norm 1.9350 (1.9350)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:09:10 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][10/156]	eta 0:02:06 lr 0.000028	 wd 0.0500	time 0.4814 (0.8675)	data time 0.0020 (0.3949)	model time 0.0000 (0.0000)	loss 0.4662 (0.5522)	grad_norm 2.6650 (2.6474)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:09:14 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][20/156]	eta 0:01:29 lr 0.000028	 wd 0.0500	time 0.4582 (0.6610)	data time 0.0023 (0.2092)	model time 0.0000 (0.0000)	loss 0.4399 (0.5606)	grad_norm 3.5214 (2.5643)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:09:19 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][30/156]	eta 0:01:16 lr 0.000028	 wd 0.0500	time 0.4816 (0.6039)	data time 0.0016 (0.1460)	model time 0.0000 (0.0000)	loss 0.6520 (0.5546)	grad_norm 3.8539 (2.6943)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:09:24 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][40/156]	eta 0:01:06 lr 0.000028	 wd 0.0500	time 0.4106 (0.5768)	data time 0.0007 (0.1135)	model time 0.0000 (0.0000)	loss 0.5641 (0.5513)	grad_norm 2.5716 (2.6799)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:09:29 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][50/156]	eta 0:00:58 lr 0.000028	 wd 0.0500	time 0.4500 (0.5538)	data time 0.0018 (0.0938)	model time 0.0000 (0.0000)	loss 0.5129 (0.5441)	grad_norm 2.3500 (2.6895)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:09:33 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][60/156]	eta 0:00:51 lr 0.000028	 wd 0.0500	time 0.5021 (0.5393)	data time 0.0035 (0.0810)	model time 0.4986 (0.4498)	loss 0.4469 (0.5457)	grad_norm 3.3099 (2.7011)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:09:38 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][70/156]	eta 0:00:45 lr 0.000028	 wd 0.0500	time 0.4752 (0.5297)	data time 0.0193 (0.0711)	model time 0.4559 (0.4552)	loss 0.6366 (0.5492)	grad_norm 2.4939 (2.7328)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:09:44 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][80/156]	eta 0:00:40 lr 0.000028	 wd 0.0500	time 0.7095 (0.5364)	data time 0.0253 (0.0664)	model time 0.6842 (0.4869)	loss 0.5154 (0.5487)	grad_norm 2.5129 (2.6957)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:09:50 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][90/156]	eta 0:00:35 lr 0.000028	 wd 0.0500	time 0.7379 (0.5402)	data time 0.0708 (0.0622)	model time 0.6672 (0.5008)	loss 0.6277 (0.5520)	grad_norm 1.5143 (2.6515)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:09:56 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][100/156]	eta 0:00:30 lr 0.000028	 wd 0.0500	time 0.4533 (0.5470)	data time 0.0048 (0.0571)	model time 0.4486 (0.5204)	loss 0.5666 (0.5529)	grad_norm 1.7533 (2.6076)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:10:02 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][110/156]	eta 0:00:25 lr 0.000028	 wd 0.0500	time 0.5418 (0.5535)	data time 0.0287 (0.0532)	model time 0.5130 (0.5345)	loss 0.6249 (0.5534)	grad_norm 3.4960 (2.6072)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:10:08 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][120/156]	eta 0:00:20 lr 0.000028	 wd 0.0500	time 0.5097 (0.5600)	data time 0.0054 (0.0503)	model time 0.5043 (0.5460)	loss 0.5348 (0.5531)	grad_norm 3.3180 (2.6304)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:10:14 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][130/156]	eta 0:00:14 lr 0.000028	 wd 0.0500	time 0.4203 (0.5617)	data time 0.0035 (0.0479)	model time 0.4168 (0.5481)	loss 0.5151 (0.5537)	grad_norm 4.3784 (2.6343)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:10:19 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][140/156]	eta 0:00:08 lr 0.000028	 wd 0.0500	time 0.4929 (0.5572)	data time 0.0008 (0.0451)	model time 0.4921 (0.5416)	loss 0.5590 (0.5509)	grad_norm 1.4621 (2.6468)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:10:24 vssm1_tiny_0230s](training.py 201): INFO Train: [213/300][150/156]	eta 0:00:03 lr 0.000028	 wd 0.0500	time 0.4517 (0.5514)	data time 0.0006 (0.0427)	model time 0.4511 (0.5335)	loss 0.5945 (0.5513)	grad_norm 2.1797 (2.6974)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:10:26 vssm1_tiny_0230s](training.py 212): INFO EPOCH 213 training takes 0:01:25
[2024-11-09 17:10:26 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_213.pth saving......
[2024-11-09 17:10:26 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_213.pth saved !!!
[2024-11-09 17:10:30 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.613 (3.613)	Loss 0.1991 (0.1991)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:10:32 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.150 (0.531)	Loss 0.2089 (0.2039)	Acc@1 95.312 (96.165)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:10:35 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.421)	Loss 0.1764 (0.2116)	Acc@1 97.656 (95.759)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:10:39 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.189 (0.411)	Loss 0.2295 (0.2132)	Acc@1 92.969 (95.413)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:10:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.280 Acc@5 100.000
[2024-11-09 17:10:42 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.3%
[2024-11-09 17:10:42 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 17:10:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.945 (2.945)	Loss 0.2136 (0.2136)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:10:47 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.155 (0.442)	Loss 0.2253 (0.2250)	Acc@1 96.094 (95.170)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:10:49 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.149 (0.340)	Loss 0.2720 (0.2405)	Acc@1 96.094 (93.787)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:10:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.203 (0.291)	Loss 0.3320 (0.2673)	Acc@1 90.625 (92.213)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:10:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.540 Acc@5 100.000
[2024-11-09 17:10:53 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 91.5%
[2024-11-09 17:10:53 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 91.54%
[2024-11-09 17:10:57 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][0/156]	eta 0:10:26 lr 0.000028	 wd 0.0500	time 4.0136 (4.0136)	data time 3.5663 (3.5663)	model time 0.0000 (0.0000)	loss 0.6175 (0.6175)	grad_norm 4.5460 (4.5460)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:03 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][10/156]	eta 0:02:03 lr 0.000028	 wd 0.0500	time 0.4374 (0.8465)	data time 0.0008 (0.3570)	model time 0.0000 (0.0000)	loss 0.4585 (0.5498)	grad_norm 3.0998 (2.7537)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:08 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][20/156]	eta 0:01:34 lr 0.000028	 wd 0.0500	time 0.4523 (0.6914)	data time 0.0079 (0.2005)	model time 0.0000 (0.0000)	loss 0.4950 (0.5439)	grad_norm 2.7701 (2.6662)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:13 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][30/156]	eta 0:01:21 lr 0.000028	 wd 0.0500	time 0.4750 (0.6456)	data time 0.0248 (0.1450)	model time 0.0000 (0.0000)	loss 0.3604 (0.5307)	grad_norm 2.4495 (2.7225)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:18 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][40/156]	eta 0:01:10 lr 0.000028	 wd 0.0500	time 0.5892 (0.6107)	data time 0.0011 (0.1121)	model time 0.0000 (0.0000)	loss 0.5176 (0.5350)	grad_norm 3.8440 (2.8047)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:24 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][50/156]	eta 0:01:03 lr 0.000028	 wd 0.0500	time 0.4695 (0.5955)	data time 0.0058 (0.0943)	model time 0.0000 (0.0000)	loss 0.5066 (0.5309)	grad_norm 4.8640 (2.8768)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:29 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][60/156]	eta 0:00:55 lr 0.000028	 wd 0.0500	time 0.4330 (0.5772)	data time 0.0008 (0.0808)	model time 0.4322 (0.4717)	loss 0.5715 (0.5318)	grad_norm 2.9738 (2.9392)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:34 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][70/156]	eta 0:00:48 lr 0.000028	 wd 0.0500	time 0.5728 (0.5662)	data time 0.0007 (0.0731)	model time 0.5721 (0.4723)	loss 0.5515 (0.5321)	grad_norm 2.5513 (2.9721)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:38 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][80/156]	eta 0:00:42 lr 0.000028	 wd 0.0500	time 0.5268 (0.5572)	data time 0.0010 (0.0663)	model time 0.5258 (0.4732)	loss 0.6368 (0.5359)	grad_norm 2.8045 (3.0026)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:43 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][90/156]	eta 0:00:36 lr 0.000028	 wd 0.0500	time 0.4391 (0.5472)	data time 0.0136 (0.0601)	model time 0.4255 (0.4692)	loss 0.6428 (0.5416)	grad_norm 2.4841 (3.0129)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:48 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][100/156]	eta 0:00:30 lr 0.000028	 wd 0.0500	time 0.4133 (0.5385)	data time 0.0011 (0.0553)	model time 0.4123 (0.4648)	loss 0.5795 (0.5460)	grad_norm 1.7102 (2.9463)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:53 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][110/156]	eta 0:00:24 lr 0.000027	 wd 0.0500	time 0.4972 (0.5334)	data time 0.0008 (0.0511)	model time 0.4964 (0.4662)	loss 0.5658 (0.5438)	grad_norm 2.7796 (2.9243)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:11:58 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][120/156]	eta 0:00:19 lr 0.000027	 wd 0.0500	time 0.5853 (0.5301)	data time 0.0010 (0.0478)	model time 0.5843 (0.4685)	loss 0.6793 (0.5478)	grad_norm 2.4540 (2.8835)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:12:03 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][130/156]	eta 0:00:13 lr 0.000027	 wd 0.0500	time 0.5023 (0.5323)	data time 0.0171 (0.0455)	model time 0.4852 (0.4776)	loss 0.5960 (0.5504)	grad_norm 2.0030 (2.8482)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:12:08 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][140/156]	eta 0:00:08 lr 0.000027	 wd 0.0500	time 0.4200 (0.5301)	data time 0.0010 (0.0437)	model time 0.4190 (0.4780)	loss 0.5613 (0.5514)	grad_norm 2.7701 (2.8231)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:12:13 vssm1_tiny_0230s](training.py 201): INFO Train: [214/300][150/156]	eta 0:00:03 lr 0.000027	 wd 0.0500	time 0.4472 (0.5275)	data time 0.0005 (0.0412)	model time 0.4467 (0.4786)	loss 0.5120 (0.5533)	grad_norm 1.9457 (2.7890)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:12:16 vssm1_tiny_0230s](training.py 212): INFO EPOCH 214 training takes 0:01:22
[2024-11-09 17:12:16 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_214.pth saving......
[2024-11-09 17:12:16 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_214.pth saved !!!
[2024-11-09 17:12:21 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.798 (4.798)	Loss 0.1976 (0.1976)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:12:23 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.203 (0.648)	Loss 0.2042 (0.1987)	Acc@1 98.438 (97.514)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:12:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.152 (0.495)	Loss 0.2286 (0.2088)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:12:29 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.143 (0.408)	Loss 0.2856 (0.2283)	Acc@1 92.188 (95.489)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:12:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.000 Acc@5 100.000
[2024-11-09 17:12:32 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 17:12:32 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.28%
[2024-11-09 17:12:36 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.582 (3.582)	Loss 0.2130 (0.2130)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:12:38 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.219 (0.506)	Loss 0.2245 (0.2242)	Acc@1 96.094 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:12:41 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.159 (0.411)	Loss 0.2695 (0.2396)	Acc@1 96.094 (93.824)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:12:44 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.161 (0.365)	Loss 0.3296 (0.2658)	Acc@1 90.625 (92.263)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:12:46 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.680 Acc@5 100.000
[2024-11-09 17:12:46 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 91.7%
[2024-11-09 17:12:46 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 91.68%
[2024-11-09 17:12:51 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][0/156]	eta 0:10:46 lr 0.000027	 wd 0.0500	time 4.1457 (4.1457)	data time 3.6672 (3.6672)	model time 0.0000 (0.0000)	loss 0.6131 (0.6131)	grad_norm 2.2939 (2.2939)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:12:56 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][10/156]	eta 0:02:11 lr 0.000027	 wd 0.0500	time 0.4136 (0.9025)	data time 0.0008 (0.3502)	model time 0.0000 (0.0000)	loss 0.5236 (0.5522)	grad_norm 4.2255 (2.9540)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:13:01 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][20/156]	eta 0:01:36 lr 0.000027	 wd 0.0500	time 0.4420 (0.7111)	data time 0.0015 (0.1915)	model time 0.0000 (0.0000)	loss 0.5223 (0.5540)	grad_norm 1.6537 (inf)	loss_scale 32768.0000 (62415.2381)	mem 13675MB
[2024-11-09 17:13:06 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][30/156]	eta 0:01:21 lr 0.000027	 wd 0.0500	time 0.6209 (0.6490)	data time 0.0239 (0.1375)	model time 0.0000 (0.0000)	loss 0.4220 (0.5447)	grad_norm 3.8976 (inf)	loss_scale 32768.0000 (52851.6129)	mem 13675MB
[2024-11-09 17:13:12 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][40/156]	eta 0:01:11 lr 0.000027	 wd 0.0500	time 0.5283 (0.6154)	data time 0.0231 (0.1082)	model time 0.0000 (0.0000)	loss 0.4936 (0.5490)	grad_norm 2.7291 (inf)	loss_scale 32768.0000 (47953.1707)	mem 13675MB
[2024-11-09 17:13:17 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][50/156]	eta 0:01:02 lr 0.000027	 wd 0.0500	time 0.4344 (0.5933)	data time 0.0015 (0.0900)	model time 0.0000 (0.0000)	loss 0.5904 (0.5498)	grad_norm 1.5155 (inf)	loss_scale 32768.0000 (44975.6863)	mem 13675MB
[2024-11-09 17:13:21 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][60/156]	eta 0:00:55 lr 0.000027	 wd 0.0500	time 0.4801 (0.5755)	data time 0.0148 (0.0777)	model time 0.4653 (0.4701)	loss 0.5350 (0.5517)	grad_norm 4.8816 (inf)	loss_scale 32768.0000 (42974.4262)	mem 13675MB
[2024-11-09 17:13:27 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][70/156]	eta 0:00:48 lr 0.000027	 wd 0.0500	time 0.4612 (0.5668)	data time 0.0007 (0.0692)	model time 0.4605 (0.4829)	loss 0.5560 (0.5529)	grad_norm 2.0625 (inf)	loss_scale 32768.0000 (41536.9014)	mem 13675MB
[2024-11-09 17:13:32 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][80/156]	eta 0:00:42 lr 0.000027	 wd 0.0500	time 0.4843 (0.5577)	data time 0.0147 (0.0638)	model time 0.4696 (0.4780)	loss 0.5140 (0.5516)	grad_norm 2.6050 (inf)	loss_scale 32768.0000 (40454.3210)	mem 13675MB
[2024-11-09 17:13:37 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][90/156]	eta 0:00:36 lr 0.000027	 wd 0.0500	time 0.5555 (0.5517)	data time 0.0044 (0.0596)	model time 0.5510 (0.4778)	loss 0.5905 (0.5552)	grad_norm 2.6856 (inf)	loss_scale 32768.0000 (39609.6703)	mem 13675MB
[2024-11-09 17:13:42 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][100/156]	eta 0:00:30 lr 0.000027	 wd 0.0500	time 0.6692 (0.5464)	data time 0.0049 (0.0549)	model time 0.6643 (0.4794)	loss 0.5960 (0.5509)	grad_norm 2.9170 (inf)	loss_scale 32768.0000 (38932.2772)	mem 13675MB
[2024-11-09 17:13:46 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][110/156]	eta 0:00:24 lr 0.000027	 wd 0.0500	time 0.4687 (0.5397)	data time 0.0014 (0.0509)	model time 0.4673 (0.4763)	loss 0.5556 (0.5460)	grad_norm 3.5194 (inf)	loss_scale 32768.0000 (38376.9369)	mem 13675MB
[2024-11-09 17:13:51 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][120/156]	eta 0:00:19 lr 0.000027	 wd 0.0500	time 0.4344 (0.5359)	data time 0.0022 (0.0477)	model time 0.4322 (0.4772)	loss 0.5090 (0.5474)	grad_norm 2.1479 (inf)	loss_scale 32768.0000 (37913.3884)	mem 13675MB
[2024-11-09 17:13:56 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][130/156]	eta 0:00:13 lr 0.000027	 wd 0.0500	time 0.4787 (0.5301)	data time 0.0007 (0.0448)	model time 0.4780 (0.4739)	loss 0.6209 (0.5460)	grad_norm 3.5523 (inf)	loss_scale 32768.0000 (37520.6107)	mem 13675MB
[2024-11-09 17:14:01 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][140/156]	eta 0:00:08 lr 0.000027	 wd 0.0500	time 0.5405 (0.5258)	data time 0.0007 (0.0426)	model time 0.5398 (0.4719)	loss 0.6136 (0.5472)	grad_norm 3.2320 (inf)	loss_scale 32768.0000 (37183.5461)	mem 13675MB
[2024-11-09 17:14:06 vssm1_tiny_0230s](training.py 201): INFO Train: [215/300][150/156]	eta 0:00:03 lr 0.000027	 wd 0.0500	time 0.4590 (0.5250)	data time 0.0004 (0.0399)	model time 0.4586 (0.4759)	loss 0.5133 (0.5457)	grad_norm 3.0583 (inf)	loss_scale 32768.0000 (36891.1258)	mem 13675MB
[2024-11-09 17:14:09 vssm1_tiny_0230s](training.py 212): INFO EPOCH 215 training takes 0:01:22
[2024-11-09 17:14:09 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_215.pth saving......
[2024-11-09 17:14:09 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_215.pth saved !!!
[2024-11-09 17:14:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.538 (3.538)	Loss 0.2257 (0.2257)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:14:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 1.127 (0.563)	Loss 0.2374 (0.2279)	Acc@1 92.188 (94.318)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:14:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.187 (0.422)	Loss 0.1696 (0.2346)	Acc@1 99.219 (94.234)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:14:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.142 (0.349)	Loss 0.2156 (0.2227)	Acc@1 95.312 (95.035)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:14:22 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.320 Acc@5 100.000
[2024-11-09 17:14:22 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.3%
[2024-11-09 17:14:22 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.32%
[2024-11-09 17:14:25 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.764 (2.764)	Loss 0.2125 (0.2125)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:14:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.350 (0.538)	Loss 0.2238 (0.2235)	Acc@1 96.094 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:14:30 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.440 (0.384)	Loss 0.2676 (0.2388)	Acc@1 96.094 (93.824)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:14:33 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.215 (0.330)	Loss 0.3276 (0.2645)	Acc@1 90.625 (92.314)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:14:35 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.800 Acc@5 100.000
[2024-11-09 17:14:35 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 91.8%
[2024-11-09 17:14:35 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 91.80%
[2024-11-09 17:14:39 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][0/156]	eta 0:10:53 lr 0.000027	 wd 0.0500	time 4.1864 (4.1864)	data time 3.7323 (3.7323)	model time 0.0000 (0.0000)	loss 0.5452 (0.5452)	grad_norm 2.2835 (2.2835)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:14:45 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][10/156]	eta 0:02:15 lr 0.000027	 wd 0.0500	time 0.5388 (0.9295)	data time 0.0262 (0.3928)	model time 0.0000 (0.0000)	loss 0.6601 (0.5431)	grad_norm 2.0563 (2.7463)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:14:50 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][20/156]	eta 0:01:36 lr 0.000027	 wd 0.0500	time 0.4247 (0.7111)	data time 0.0058 (0.2102)	model time 0.0000 (0.0000)	loss 0.6297 (0.5474)	grad_norm 2.0182 (2.8565)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:14:55 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][30/156]	eta 0:01:21 lr 0.000027	 wd 0.0500	time 0.4355 (0.6463)	data time 0.0042 (0.1489)	model time 0.0000 (0.0000)	loss 0.5553 (0.5301)	grad_norm 2.9355 (2.8696)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:00 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][40/156]	eta 0:01:11 lr 0.000027	 wd 0.0500	time 0.4726 (0.6144)	data time 0.0590 (0.1178)	model time 0.0000 (0.0000)	loss 0.5394 (0.5313)	grad_norm 2.6447 (2.9795)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:05 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][50/156]	eta 0:01:03 lr 0.000027	 wd 0.0500	time 0.4647 (0.5983)	data time 0.0006 (0.0967)	model time 0.0000 (0.0000)	loss 0.5002 (0.5414)	grad_norm 4.6552 (2.9103)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:11 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][60/156]	eta 0:00:56 lr 0.000027	 wd 0.0500	time 0.5456 (0.5882)	data time 0.0069 (0.0838)	model time 0.5387 (0.5185)	loss 0.4973 (0.5365)	grad_norm 4.4373 (2.9729)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:16 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][70/156]	eta 0:00:49 lr 0.000027	 wd 0.0500	time 0.5090 (0.5756)	data time 0.0460 (0.0744)	model time 0.4629 (0.5002)	loss 0.4563 (0.5349)	grad_norm 3.1428 (3.0516)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:21 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][80/156]	eta 0:00:43 lr 0.000026	 wd 0.0500	time 0.5457 (0.5662)	data time 0.0009 (0.0661)	model time 0.5449 (0.4975)	loss 0.6294 (0.5362)	grad_norm 3.7169 (3.0842)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:26 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][90/156]	eta 0:00:37 lr 0.000026	 wd 0.0500	time 0.5270 (0.5627)	data time 0.0007 (0.0619)	model time 0.5263 (0.4999)	loss 0.5841 (0.5336)	grad_norm 3.1844 (3.1531)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:31 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][100/156]	eta 0:00:31 lr 0.000026	 wd 0.0500	time 0.5073 (0.5597)	data time 0.0160 (0.0568)	model time 0.4913 (0.5043)	loss 0.6269 (0.5342)	grad_norm 2.0945 (3.1567)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:36 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][110/156]	eta 0:00:25 lr 0.000026	 wd 0.0500	time 0.4108 (0.5535)	data time 0.0008 (0.0532)	model time 0.4100 (0.4992)	loss 0.5842 (0.5396)	grad_norm 2.3140 (3.1398)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:41 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][120/156]	eta 0:00:19 lr 0.000026	 wd 0.0500	time 0.6029 (0.5501)	data time 0.0135 (0.0502)	model time 0.5894 (0.4987)	loss 0.5546 (0.5401)	grad_norm 2.6026 (3.0889)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:47 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][130/156]	eta 0:00:14 lr 0.000026	 wd 0.0500	time 0.5413 (0.5478)	data time 0.0235 (0.0476)	model time 0.5178 (0.4994)	loss 0.5901 (0.5410)	grad_norm 2.1847 (3.0395)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:52 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][140/156]	eta 0:00:08 lr 0.000026	 wd 0.0500	time 0.4853 (0.5453)	data time 0.0008 (0.0451)	model time 0.4845 (0.4994)	loss 0.5909 (0.5406)	grad_norm 1.5436 (3.0050)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:56 vssm1_tiny_0230s](training.py 201): INFO Train: [216/300][150/156]	eta 0:00:03 lr 0.000026	 wd 0.0500	time 0.4992 (0.5388)	data time 0.0005 (0.0422)	model time 0.4987 (0.4940)	loss 0.5753 (0.5428)	grad_norm 1.9545 (2.9650)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:15:59 vssm1_tiny_0230s](training.py 212): INFO EPOCH 216 training takes 0:01:24
[2024-11-09 17:15:59 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_216.pth saving......
[2024-11-09 17:15:59 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_216.pth saved !!!
[2024-11-09 17:16:03 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.322 (3.322)	Loss 0.2015 (0.2015)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:16:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.182 (0.495)	Loss 0.2140 (0.2061)	Acc@1 96.094 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:16:08 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.402)	Loss 0.2013 (0.2154)	Acc@1 97.656 (95.759)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:16:11 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.197 (0.369)	Loss 0.2593 (0.2231)	Acc@1 92.188 (95.212)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:16:13 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.060 Acc@5 100.000
[2024-11-09 17:16:13 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 17:16:13 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.32%
[2024-11-09 17:16:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.067 (4.067)	Loss 0.2118 (0.2118)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:16:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.200 (0.596)	Loss 0.2228 (0.2226)	Acc@1 96.094 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:16:22 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.185 (0.434)	Loss 0.2651 (0.2377)	Acc@1 96.094 (93.899)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:16:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.375)	Loss 0.3254 (0.2630)	Acc@1 90.625 (92.414)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:16:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 91.900 Acc@5 100.000
[2024-11-09 17:16:27 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 91.9%
[2024-11-09 17:16:27 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 91.90%
[2024-11-09 17:16:32 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][0/156]	eta 0:12:20 lr 0.000026	 wd 0.0500	time 4.7483 (4.7483)	data time 4.1213 (4.1213)	model time 0.0000 (0.0000)	loss 0.4999 (0.4999)	grad_norm 2.2848 (2.2848)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:16:37 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][10/156]	eta 0:02:12 lr 0.000026	 wd 0.0500	time 0.4784 (0.9096)	data time 0.0356 (0.3840)	model time 0.0000 (0.0000)	loss 0.6253 (0.5785)	grad_norm 2.5120 (2.3999)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:16:42 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][20/156]	eta 0:01:36 lr 0.000026	 wd 0.0500	time 0.5630 (0.7073)	data time 0.0010 (0.2122)	model time 0.0000 (0.0000)	loss 0.6299 (0.5810)	grad_norm 2.0938 (2.4406)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:16:47 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][30/156]	eta 0:01:20 lr 0.000026	 wd 0.0500	time 0.4803 (0.6382)	data time 0.0305 (0.1497)	model time 0.0000 (0.0000)	loss 0.4454 (0.5751)	grad_norm 3.5828 (2.6359)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:16:53 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][40/156]	eta 0:01:11 lr 0.000026	 wd 0.0500	time 0.4945 (0.6186)	data time 0.0185 (0.1162)	model time 0.0000 (0.0000)	loss 0.5023 (0.5703)	grad_norm 2.0323 (2.7635)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:16:57 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][50/156]	eta 0:01:02 lr 0.000026	 wd 0.0500	time 0.4760 (0.5915)	data time 0.0009 (0.0961)	model time 0.0000 (0.0000)	loss 0.5923 (0.5674)	grad_norm 3.8040 (2.7976)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:03 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][60/156]	eta 0:00:55 lr 0.000026	 wd 0.0500	time 0.4537 (0.5786)	data time 0.0091 (0.0823)	model time 0.4447 (0.5008)	loss 0.5725 (0.5579)	grad_norm 3.0348 (2.8695)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:07 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][70/156]	eta 0:00:48 lr 0.000026	 wd 0.0500	time 0.5177 (0.5654)	data time 0.0006 (0.0719)	model time 0.5171 (0.4886)	loss 0.4460 (0.5503)	grad_norm 4.0769 (2.9731)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:12 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][80/156]	eta 0:00:42 lr 0.000026	 wd 0.0500	time 0.4675 (0.5565)	data time 0.0009 (0.0644)	model time 0.4666 (0.4865)	loss 0.5236 (0.5522)	grad_norm 2.8985 (2.9661)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:18 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][90/156]	eta 0:00:36 lr 0.000026	 wd 0.0500	time 0.4640 (0.5526)	data time 0.0113 (0.0593)	model time 0.4527 (0.4908)	loss 0.5321 (0.5513)	grad_norm 3.0289 (2.9608)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:22 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][100/156]	eta 0:00:30 lr 0.000026	 wd 0.0500	time 0.5478 (0.5456)	data time 0.0408 (0.0551)	model time 0.5070 (0.4855)	loss 0.4478 (0.5464)	grad_norm 2.2542 (3.0329)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:27 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][110/156]	eta 0:00:24 lr 0.000026	 wd 0.0500	time 0.5739 (0.5417)	data time 0.0227 (0.0514)	model time 0.5512 (0.4860)	loss 0.5769 (0.5465)	grad_norm 2.3131 (3.0351)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:33 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][120/156]	eta 0:00:19 lr 0.000026	 wd 0.0500	time 0.4779 (0.5393)	data time 0.0032 (0.0491)	model time 0.4747 (0.4865)	loss 0.6019 (0.5467)	grad_norm 3.5158 (3.0456)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:38 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][130/156]	eta 0:00:13 lr 0.000026	 wd 0.0500	time 0.5823 (0.5362)	data time 0.0880 (0.0474)	model time 0.4944 (0.4847)	loss 0.4299 (0.5487)	grad_norm 2.7041 (3.0420)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:43 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][140/156]	eta 0:00:08 lr 0.000026	 wd 0.0500	time 0.4551 (0.5337)	data time 0.0010 (0.0451)	model time 0.4541 (0.4848)	loss 0.4396 (0.5473)	grad_norm 2.7091 (3.0036)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:48 vssm1_tiny_0230s](training.py 201): INFO Train: [217/300][150/156]	eta 0:00:03 lr 0.000026	 wd 0.0500	time 0.4154 (0.5332)	data time 0.0007 (0.0426)	model time 0.4147 (0.4881)	loss 0.5834 (0.5470)	grad_norm 3.2451 (2.9991)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:17:50 vssm1_tiny_0230s](training.py 212): INFO EPOCH 217 training takes 0:01:23
[2024-11-09 17:17:50 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_217.pth saving......
[2024-11-09 17:17:51 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_217.pth saved !!!
[2024-11-09 17:17:54 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.576 (3.576)	Loss 0.2137 (0.2137)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:17:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.148 (0.513)	Loss 0.2151 (0.2131)	Acc@1 96.094 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:17:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.239 (0.401)	Loss 0.1801 (0.2207)	Acc@1 97.656 (94.940)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:18:02 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.177 (0.351)	Loss 0.2283 (0.2186)	Acc@1 94.531 (94.960)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:18:05 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.020 Acc@5 100.000
[2024-11-09 17:18:05 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 17:18:05 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.32%
[2024-11-09 17:18:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.646 (3.646)	Loss 0.2112 (0.2112)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:18:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.494 (0.526)	Loss 0.2220 (0.2218)	Acc@1 96.094 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:18:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.392)	Loss 0.2632 (0.2369)	Acc@1 96.094 (93.899)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:18:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.176 (0.332)	Loss 0.3235 (0.2617)	Acc@1 90.625 (92.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:18:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.040 Acc@5 100.000
[2024-11-09 17:18:18 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.0%
[2024-11-09 17:18:18 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.04%
[2024-11-09 17:18:22 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][0/156]	eta 0:10:13 lr 0.000026	 wd 0.0500	time 3.9320 (3.9320)	data time 3.4215 (3.4215)	model time 0.0000 (0.0000)	loss 0.4658 (0.4658)	grad_norm 4.4913 (4.4913)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:18:26 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][10/156]	eta 0:01:55 lr 0.000026	 wd 0.0500	time 0.4933 (0.7903)	data time 0.0048 (0.3222)	model time 0.0000 (0.0000)	loss 0.5488 (0.5441)	grad_norm 4.4489 (3.5178)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:18:31 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][20/156]	eta 0:01:26 lr 0.000026	 wd 0.0500	time 0.4065 (0.6382)	data time 0.0008 (0.1752)	model time 0.0000 (0.0000)	loss 0.4703 (0.5415)	grad_norm 1.8298 (3.2211)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:18:36 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][30/156]	eta 0:01:14 lr 0.000026	 wd 0.0500	time 0.4900 (0.5908)	data time 0.0076 (0.1222)	model time 0.0000 (0.0000)	loss 0.4903 (0.5385)	grad_norm 3.6476 (3.0785)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:18:41 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][40/156]	eta 0:01:05 lr 0.000026	 wd 0.0500	time 0.4088 (0.5687)	data time 0.0008 (0.0971)	model time 0.0000 (0.0000)	loss 0.5619 (0.5400)	grad_norm 2.6501 (2.9592)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:18:47 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][50/156]	eta 0:01:00 lr 0.000025	 wd 0.0500	time 0.6022 (0.5668)	data time 0.0046 (0.0803)	model time 0.0000 (0.0000)	loss 0.5934 (0.5378)	grad_norm 2.6679 (2.9371)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:18:52 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][60/156]	eta 0:00:54 lr 0.000025	 wd 0.0500	time 0.6508 (0.5654)	data time 0.0972 (0.0715)	model time 0.5536 (0.5313)	loss 0.4413 (0.5429)	grad_norm 2.2135 (2.9264)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:18:57 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][70/156]	eta 0:00:47 lr 0.000025	 wd 0.0500	time 0.5858 (0.5578)	data time 0.0047 (0.0626)	model time 0.5811 (0.5175)	loss 0.4912 (0.5412)	grad_norm 1.9190 (2.9699)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:19:03 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][80/156]	eta 0:00:42 lr 0.000025	 wd 0.0500	time 0.5437 (0.5534)	data time 0.0140 (0.0564)	model time 0.5298 (0.5148)	loss 0.5933 (0.5396)	grad_norm 6.7349 (3.0838)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:19:08 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][90/156]	eta 0:00:36 lr 0.000025	 wd 0.0500	time 0.5503 (0.5508)	data time 0.0005 (0.0519)	model time 0.5497 (0.5149)	loss 0.6409 (0.5444)	grad_norm 4.3843 (3.0690)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:19:13 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][100/156]	eta 0:00:30 lr 0.000025	 wd 0.0500	time 0.5425 (0.5509)	data time 0.0007 (0.0484)	model time 0.5417 (0.5187)	loss 0.5288 (0.5413)	grad_norm 3.1719 (3.0510)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:19:19 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][110/156]	eta 0:00:25 lr 0.000025	 wd 0.0500	time 0.5443 (0.5488)	data time 0.0195 (0.0467)	model time 0.5249 (0.5154)	loss 0.5983 (0.5407)	grad_norm 1.8859 (3.0098)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:19:24 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][120/156]	eta 0:00:19 lr 0.000025	 wd 0.0500	time 0.6318 (0.5486)	data time 0.0051 (0.0437)	model time 0.6267 (0.5184)	loss 0.5416 (0.5420)	grad_norm 1.8899 (2.9677)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:19:29 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][130/156]	eta 0:00:14 lr 0.000025	 wd 0.0500	time 0.6622 (0.5448)	data time 0.0531 (0.0420)	model time 0.6091 (0.5133)	loss 0.6240 (0.5464)	grad_norm 2.4859 (2.9284)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:19:34 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][140/156]	eta 0:00:08 lr 0.000025	 wd 0.0500	time 0.7835 (0.5440)	data time 0.0048 (0.0402)	model time 0.7787 (0.5135)	loss 0.5214 (0.5444)	grad_norm 2.9541 (2.9219)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:19:40 vssm1_tiny_0230s](training.py 201): INFO Train: [218/300][150/156]	eta 0:00:03 lr 0.000025	 wd 0.0500	time 0.6614 (0.5432)	data time 0.0009 (0.0377)	model time 0.6605 (0.5153)	loss 0.5751 (0.5465)	grad_norm 2.2053 (2.8989)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:19:43 vssm1_tiny_0230s](training.py 212): INFO EPOCH 218 training takes 0:01:25
[2024-11-09 17:19:43 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_218.pth saving......
[2024-11-09 17:19:44 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_218.pth saved !!!
[2024-11-09 17:19:48 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.361 (4.361)	Loss 0.2234 (0.2234)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:19:51 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.146 (0.662)	Loss 0.2313 (0.2259)	Acc@1 94.531 (95.384)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:19:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.151 (0.462)	Loss 0.1816 (0.2325)	Acc@1 98.438 (94.754)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:19:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.212 (0.373)	Loss 0.2286 (0.2260)	Acc@1 94.531 (95.086)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:19:58 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.180 Acc@5 100.000
[2024-11-09 17:19:58 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.2%
[2024-11-09 17:19:58 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.32%
[2024-11-09 17:20:02 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.085 (4.085)	Loss 0.2109 (0.2109)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:20:04 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.532)	Loss 0.2216 (0.2214)	Acc@1 96.094 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:20:07 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.340 (0.432)	Loss 0.2610 (0.2363)	Acc@1 96.094 (93.824)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:20:10 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.163 (0.383)	Loss 0.3215 (0.2606)	Acc@1 90.625 (92.490)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:20:13 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.100 Acc@5 100.000
[2024-11-09 17:20:13 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.1%
[2024-11-09 17:20:13 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.10%
[2024-11-09 17:20:17 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][0/156]	eta 0:10:10 lr 0.000025	 wd 0.0500	time 3.9121 (3.9121)	data time 3.3422 (3.3422)	model time 0.0000 (0.0000)	loss 0.6157 (0.6157)	grad_norm 1.8623 (1.8623)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:20:22 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][10/156]	eta 0:02:00 lr 0.000025	 wd 0.0500	time 0.5811 (0.8272)	data time 0.1343 (0.3300)	model time 0.0000 (0.0000)	loss 0.4374 (0.5307)	grad_norm 4.0492 (3.0681)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:20:27 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][20/156]	eta 0:01:28 lr 0.000025	 wd 0.0500	time 0.4132 (0.6543)	data time 0.0100 (0.1780)	model time 0.0000 (0.0000)	loss 0.5574 (0.5366)	grad_norm 2.7001 (2.9289)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:20:32 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][30/156]	eta 0:01:17 lr 0.000025	 wd 0.0500	time 0.4351 (0.6188)	data time 0.0226 (0.1265)	model time 0.0000 (0.0000)	loss 0.4185 (0.5370)	grad_norm 4.2181 (2.9703)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:20:37 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][40/156]	eta 0:01:07 lr 0.000025	 wd 0.0500	time 0.4515 (0.5860)	data time 0.0188 (0.1005)	model time 0.0000 (0.0000)	loss 0.5229 (0.5298)	grad_norm 1.9936 (2.9946)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:20:41 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][50/156]	eta 0:00:59 lr 0.000025	 wd 0.0500	time 0.4377 (0.5595)	data time 0.0250 (0.0819)	model time 0.0000 (0.0000)	loss 0.4675 (0.5320)	grad_norm 3.6471 (3.0274)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:20:46 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][60/156]	eta 0:00:52 lr 0.000025	 wd 0.0500	time 0.4643 (0.5443)	data time 0.0032 (0.0692)	model time 0.4611 (0.4623)	loss 0.4545 (0.5304)	grad_norm 2.8288 (3.0839)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:20:51 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][70/156]	eta 0:00:46 lr 0.000025	 wd 0.0500	time 0.4302 (0.5380)	data time 0.0018 (0.0609)	model time 0.4284 (0.4758)	loss 0.6280 (0.5305)	grad_norm 2.0342 (3.0324)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:20:56 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][80/156]	eta 0:00:40 lr 0.000025	 wd 0.0500	time 0.6569 (0.5362)	data time 0.0054 (0.0555)	model time 0.6515 (0.4859)	loss 0.5635 (0.5334)	grad_norm 2.1576 (3.0044)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:21:01 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][90/156]	eta 0:00:35 lr 0.000025	 wd 0.0500	time 0.4857 (0.5343)	data time 0.0129 (0.0515)	model time 0.4728 (0.4893)	loss 0.4258 (0.5321)	grad_norm 2.3803 (2.9373)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:21:07 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][100/156]	eta 0:00:29 lr 0.000025	 wd 0.0500	time 0.5057 (0.5325)	data time 0.0402 (0.0482)	model time 0.4655 (0.4911)	loss 0.5953 (0.5352)	grad_norm 2.1570 (2.9506)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:21:12 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][110/156]	eta 0:00:24 lr 0.000025	 wd 0.0500	time 0.5623 (0.5310)	data time 0.0443 (0.0464)	model time 0.5181 (0.4906)	loss 0.5545 (0.5373)	grad_norm 2.4618 (2.9889)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:21:17 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][120/156]	eta 0:00:19 lr 0.000025	 wd 0.0500	time 0.5301 (0.5308)	data time 0.0040 (0.0443)	model time 0.5261 (0.4929)	loss 0.6325 (0.5389)	grad_norm 2.4025 (2.9611)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:21:22 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][130/156]	eta 0:00:13 lr 0.000025	 wd 0.0500	time 0.4567 (0.5281)	data time 0.0007 (0.0419)	model time 0.4559 (0.4917)	loss 0.4720 (0.5404)	grad_norm 2.1548 (2.9357)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:21:27 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][140/156]	eta 0:00:08 lr 0.000025	 wd 0.0500	time 0.5674 (0.5290)	data time 0.0008 (0.0397)	model time 0.5667 (0.4959)	loss 0.5306 (0.5408)	grad_norm 2.5921 (2.9357)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:21:33 vssm1_tiny_0230s](training.py 201): INFO Train: [219/300][150/156]	eta 0:00:03 lr 0.000025	 wd 0.0500	time 0.6143 (0.5300)	data time 0.0006 (0.0382)	model time 0.6137 (0.4990)	loss 0.5393 (0.5402)	grad_norm 2.7720 (2.9342)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:21:36 vssm1_tiny_0230s](training.py 212): INFO EPOCH 219 training takes 0:01:23
[2024-11-09 17:21:36 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_219.pth saving......
[2024-11-09 17:21:37 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_219.pth saved !!!
[2024-11-09 17:21:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.675 (3.675)	Loss 0.2035 (0.2035)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:21:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.519)	Loss 0.2098 (0.2038)	Acc@1 96.875 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:21:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.155 (0.372)	Loss 0.2023 (0.2139)	Acc@1 96.094 (95.796)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:21:47 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.313)	Loss 0.2578 (0.2214)	Acc@1 92.969 (95.161)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:21:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.820 Acc@5 100.000
[2024-11-09 17:21:49 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.8%
[2024-11-09 17:21:49 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.32%
[2024-11-09 17:21:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.336 (3.336)	Loss 0.2103 (0.2103)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:21:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.175 (0.532)	Loss 0.2208 (0.2207)	Acc@1 96.094 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:21:56 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.364)	Loss 0.2590 (0.2355)	Acc@1 96.094 (93.862)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:21:58 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.308)	Loss 0.3196 (0.2593)	Acc@1 90.625 (92.616)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:22:01 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.220 Acc@5 100.000
[2024-11-09 17:22:01 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.2%
[2024-11-09 17:22:01 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.22%
[2024-11-09 17:22:06 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][0/156]	eta 0:13:18 lr 0.000025	 wd 0.0500	time 5.1186 (5.1186)	data time 4.6657 (4.6657)	model time 0.0000 (0.0000)	loss 0.6085 (0.6085)	grad_norm 3.6484 (3.6484)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:22:11 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][10/156]	eta 0:02:10 lr 0.000025	 wd 0.0500	time 0.4294 (0.8952)	data time 0.0149 (0.4285)	model time 0.0000 (0.0000)	loss 0.5038 (0.5737)	grad_norm 2.8825 (3.0531)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:22:16 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][20/156]	eta 0:01:36 lr 0.000024	 wd 0.0500	time 0.4962 (0.7099)	data time 0.0009 (0.2265)	model time 0.0000 (0.0000)	loss 0.4843 (0.5497)	grad_norm 5.4164 (3.0565)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:22:21 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][30/156]	eta 0:01:20 lr 0.000024	 wd 0.0500	time 0.4501 (0.6424)	data time 0.0018 (0.1582)	model time 0.0000 (0.0000)	loss 0.6053 (0.5432)	grad_norm 3.3484 (3.0260)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:22:26 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][40/156]	eta 0:01:11 lr 0.000024	 wd 0.0500	time 0.4780 (0.6183)	data time 0.0128 (0.1224)	model time 0.0000 (0.0000)	loss 0.5081 (0.5565)	grad_norm 4.6821 (3.1504)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:22:31 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][50/156]	eta 0:01:02 lr 0.000024	 wd 0.0500	time 0.4573 (0.5929)	data time 0.0008 (0.1004)	model time 0.0000 (0.0000)	loss 0.5619 (0.5598)	grad_norm 1.6230 (3.0329)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:22:37 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][60/156]	eta 0:00:56 lr 0.000024	 wd 0.0500	time 0.5282 (0.5881)	data time 0.0195 (0.0862)	model time 0.5087 (0.5499)	loss 0.5741 (0.5595)	grad_norm 2.2345 (2.9392)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:22:42 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][70/156]	eta 0:00:49 lr 0.000024	 wd 0.0500	time 0.5566 (0.5787)	data time 0.0060 (0.0751)	model time 0.5506 (0.5319)	loss 0.4222 (0.5570)	grad_norm 5.4989 (2.9557)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:22:47 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][80/156]	eta 0:00:43 lr 0.000024	 wd 0.0500	time 0.4760 (0.5721)	data time 0.0288 (0.0691)	model time 0.4472 (0.5209)	loss 0.6061 (0.5555)	grad_norm 2.3281 (2.9397)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:22:53 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][90/156]	eta 0:00:37 lr 0.000024	 wd 0.0500	time 0.5083 (0.5690)	data time 0.0009 (0.0653)	model time 0.5074 (0.5179)	loss 0.5999 (0.5562)	grad_norm 2.7605 (2.9127)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:22:58 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][100/156]	eta 0:00:31 lr 0.000024	 wd 0.0500	time 0.5472 (0.5644)	data time 0.0035 (0.0600)	model time 0.5437 (0.5164)	loss 0.5903 (0.5527)	grad_norm 2.6509 (2.9067)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:23:03 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][110/156]	eta 0:00:25 lr 0.000024	 wd 0.0500	time 0.5986 (0.5602)	data time 0.0090 (0.0568)	model time 0.5895 (0.5127)	loss 0.5526 (0.5490)	grad_norm 2.5057 (2.9458)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:23:08 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][120/156]	eta 0:00:19 lr 0.000024	 wd 0.0500	time 0.5337 (0.5537)	data time 0.0546 (0.0531)	model time 0.4791 (0.5066)	loss 0.5198 (0.5484)	grad_norm 2.7211 (3.0149)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:23:13 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][130/156]	eta 0:00:14 lr 0.000024	 wd 0.0500	time 0.5321 (0.5517)	data time 0.0207 (0.0501)	model time 0.5113 (0.5075)	loss 0.6475 (0.5492)	grad_norm 1.7180 (2.9916)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:23:18 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][140/156]	eta 0:00:08 lr 0.000024	 wd 0.0500	time 0.4549 (0.5477)	data time 0.0008 (0.0470)	model time 0.4541 (0.5054)	loss 0.4257 (0.5473)	grad_norm 2.2432 (2.9503)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:23:23 vssm1_tiny_0230s](training.py 201): INFO Train: [220/300][150/156]	eta 0:00:03 lr 0.000024	 wd 0.0500	time 0.5575 (0.5446)	data time 0.0006 (0.0439)	model time 0.5568 (0.5048)	loss 0.5860 (0.5459)	grad_norm 2.1065 (2.9317)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:23:26 vssm1_tiny_0230s](training.py 212): INFO EPOCH 220 training takes 0:01:25
[2024-11-09 17:23:26 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_220.pth saving......
[2024-11-09 17:23:27 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_220.pth saved !!!
[2024-11-09 17:23:30 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.304 (3.304)	Loss 0.1737 (0.1737)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:23:33 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.218 (0.589)	Loss 0.1809 (0.1744)	Acc@1 96.875 (97.372)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:23:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.471)	Loss 0.2115 (0.1860)	Acc@1 96.875 (96.689)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:23:39 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.387)	Loss 0.2788 (0.2070)	Acc@1 91.406 (95.439)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:23:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.840 Acc@5 100.000
[2024-11-09 17:23:40 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 94.8%
[2024-11-09 17:23:40 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.32%
[2024-11-09 17:23:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.667 (3.667)	Loss 0.2096 (0.2096)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:23:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.514)	Loss 0.2200 (0.2199)	Acc@1 96.094 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:23:49 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.400)	Loss 0.2573 (0.2346)	Acc@1 96.094 (93.862)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:23:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.201 (0.341)	Loss 0.3179 (0.2581)	Acc@1 90.625 (92.641)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:23:53 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.280 Acc@5 100.000
[2024-11-09 17:23:53 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.3%
[2024-11-09 17:23:53 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.28%
[2024-11-09 17:23:57 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][0/156]	eta 0:09:47 lr 0.000024	 wd 0.0500	time 3.7683 (3.7683)	data time 3.3612 (3.3612)	model time 0.0000 (0.0000)	loss 0.5783 (0.5783)	grad_norm 4.4491 (4.4491)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:02 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][10/156]	eta 0:01:59 lr 0.000024	 wd 0.0500	time 0.4158 (0.8176)	data time 0.0008 (0.3331)	model time 0.0000 (0.0000)	loss 0.6176 (0.5710)	grad_norm 3.3860 (3.3407)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:07 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][20/156]	eta 0:01:27 lr 0.000024	 wd 0.0500	time 0.4915 (0.6446)	data time 0.0246 (0.1803)	model time 0.0000 (0.0000)	loss 0.6291 (0.5671)	grad_norm 3.6598 (3.2893)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:12 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][30/156]	eta 0:01:16 lr 0.000024	 wd 0.0500	time 0.5491 (0.6051)	data time 0.0025 (0.1278)	model time 0.0000 (0.0000)	loss 0.5301 (0.5609)	grad_norm 1.9753 (3.0460)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:18 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][40/156]	eta 0:01:08 lr 0.000024	 wd 0.0500	time 0.4846 (0.5891)	data time 0.0006 (0.1062)	model time 0.0000 (0.0000)	loss 0.5904 (0.5529)	grad_norm 2.1274 (2.9725)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:23 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][50/156]	eta 0:01:01 lr 0.000024	 wd 0.0500	time 0.4203 (0.5772)	data time 0.0007 (0.0879)	model time 0.0000 (0.0000)	loss 0.6170 (0.5537)	grad_norm 3.1115 (2.9748)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:28 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][60/156]	eta 0:00:54 lr 0.000024	 wd 0.0500	time 0.4892 (0.5681)	data time 0.0040 (0.0773)	model time 0.4851 (0.4988)	loss 0.4562 (0.5499)	grad_norm 2.1304 (3.0179)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:33 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][70/156]	eta 0:00:48 lr 0.000024	 wd 0.0500	time 0.4757 (0.5617)	data time 0.0318 (0.0691)	model time 0.4439 (0.5012)	loss 0.4360 (0.5462)	grad_norm 3.2445 (3.0096)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:39 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][80/156]	eta 0:00:42 lr 0.000024	 wd 0.0500	time 0.6116 (0.5586)	data time 0.0284 (0.0630)	model time 0.5832 (0.5063)	loss 0.4691 (0.5482)	grad_norm 2.8546 (3.0096)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:44 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][90/156]	eta 0:00:36 lr 0.000024	 wd 0.0500	time 0.5143 (0.5533)	data time 0.0237 (0.0581)	model time 0.4906 (0.5026)	loss 0.4312 (0.5493)	grad_norm 3.6872 (3.0384)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:49 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][100/156]	eta 0:00:30 lr 0.000024	 wd 0.0500	time 0.5551 (0.5512)	data time 0.0058 (0.0549)	model time 0.5493 (0.5035)	loss 0.4756 (0.5503)	grad_norm 1.6396 (3.0349)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:24:54 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][110/156]	eta 0:00:25 lr 0.000024	 wd 0.0500	time 0.4922 (0.5472)	data time 0.0268 (0.0511)	model time 0.4653 (0.5019)	loss 0.4747 (0.5503)	grad_norm 2.1986 (3.0281)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:25:00 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][120/156]	eta 0:00:19 lr 0.000024	 wd 0.0500	time 0.4536 (0.5473)	data time 0.0008 (0.0480)	model time 0.4528 (0.5066)	loss 0.5491 (0.5463)	grad_norm 2.8138 (3.0156)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:25:05 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][130/156]	eta 0:00:14 lr 0.000024	 wd 0.0500	time 0.5385 (0.5472)	data time 0.0042 (0.0460)	model time 0.5343 (0.5086)	loss 0.4732 (0.5463)	grad_norm 5.5968 (3.0530)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:25:10 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][140/156]	eta 0:00:08 lr 0.000024	 wd 0.0500	time 0.4351 (0.5433)	data time 0.0008 (0.0435)	model time 0.4342 (0.5058)	loss 0.4267 (0.5436)	grad_norm 4.3216 (3.0890)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:25:15 vssm1_tiny_0230s](training.py 201): INFO Train: [221/300][150/156]	eta 0:00:03 lr 0.000023	 wd 0.0500	time 0.4110 (0.5390)	data time 0.0005 (0.0410)	model time 0.4105 (0.5025)	loss 0.3832 (0.5418)	grad_norm 4.5932 (3.1225)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:25:17 vssm1_tiny_0230s](training.py 212): INFO EPOCH 221 training takes 0:01:24
[2024-11-09 17:25:17 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_221.pth saving......
[2024-11-09 17:25:18 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_221.pth saved !!!
[2024-11-09 17:25:21 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.069 (3.069)	Loss 0.1888 (0.1888)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:25:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.692)	Loss 0.1985 (0.1903)	Acc@1 96.094 (96.023)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:25:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.166 (0.466)	Loss 0.1696 (0.1999)	Acc@1 98.438 (95.536)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:25:30 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.387)	Loss 0.2310 (0.2002)	Acc@1 92.969 (95.539)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:25:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.600 Acc@5 100.000
[2024-11-09 17:25:32 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 17:25:32 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:25:36 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.516 (3.516)	Loss 0.2095 (0.2095)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:25:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.227 (0.467)	Loss 0.2196 (0.2194)	Acc@1 96.094 (95.241)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:25:39 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.353)	Loss 0.2551 (0.2341)	Acc@1 95.312 (93.862)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:25:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.289)	Loss 0.3159 (0.2570)	Acc@1 90.625 (92.767)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:25:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.420 Acc@5 100.000
[2024-11-09 17:25:43 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.4%
[2024-11-09 17:25:43 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.42%
[2024-11-09 17:25:49 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][0/156]	eta 0:14:13 lr 0.000023	 wd 0.0500	time 5.4725 (5.4725)	data time 4.9946 (4.9946)	model time 0.0000 (0.0000)	loss 0.5959 (0.5959)	grad_norm 2.5578 (2.5578)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:25:54 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][10/156]	eta 0:02:20 lr 0.000023	 wd 0.0500	time 0.6692 (0.9608)	data time 0.0059 (0.4659)	model time 0.0000 (0.0000)	loss 0.6639 (0.5174)	grad_norm 2.2371 (3.3634)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:25:59 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][20/156]	eta 0:01:39 lr 0.000023	 wd 0.0500	time 0.4671 (0.7284)	data time 0.0063 (0.2490)	model time 0.0000 (0.0000)	loss 0.5832 (0.5314)	grad_norm 2.4948 (3.3648)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:04 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][30/156]	eta 0:01:23 lr 0.000023	 wd 0.0500	time 0.5515 (0.6605)	data time 0.0281 (0.1752)	model time 0.0000 (0.0000)	loss 0.6424 (0.5344)	grad_norm 5.4274 (3.3584)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:09 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][40/156]	eta 0:01:11 lr 0.000023	 wd 0.0500	time 0.6142 (0.6180)	data time 0.0020 (0.1357)	model time 0.0000 (0.0000)	loss 0.5718 (0.5418)	grad_norm 2.3519 (3.3100)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:13 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][50/156]	eta 0:01:02 lr 0.000023	 wd 0.0500	time 0.5762 (0.5889)	data time 0.0108 (0.1112)	model time 0.0000 (0.0000)	loss 0.6066 (0.5403)	grad_norm 3.9935 (3.2968)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:18 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][60/156]	eta 0:00:54 lr 0.000023	 wd 0.0500	time 0.4557 (0.5711)	data time 0.0007 (0.0943)	model time 0.4550 (0.4720)	loss 0.5761 (0.5497)	grad_norm 1.5377 (3.1604)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:23 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][70/156]	eta 0:00:47 lr 0.000023	 wd 0.0500	time 0.4154 (0.5545)	data time 0.0007 (0.0826)	model time 0.4146 (0.4569)	loss 0.5556 (0.5521)	grad_norm 3.0746 (3.0833)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:28 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][80/156]	eta 0:00:41 lr 0.000023	 wd 0.0500	time 0.4330 (0.5471)	data time 0.0008 (0.0738)	model time 0.4322 (0.4657)	loss 0.5894 (0.5578)	grad_norm 2.5365 (3.0151)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:32 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][90/156]	eta 0:00:35 lr 0.000023	 wd 0.0500	time 0.4612 (0.5381)	data time 0.0010 (0.0668)	model time 0.4602 (0.4632)	loss 0.5317 (0.5556)	grad_norm 1.8583 (2.9784)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:37 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][100/156]	eta 0:00:29 lr 0.000023	 wd 0.0500	time 0.5057 (0.5315)	data time 0.0858 (0.0626)	model time 0.4199 (0.4601)	loss 0.6203 (0.5567)	grad_norm 3.4902 (2.9655)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:42 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][110/156]	eta 0:00:24 lr 0.000023	 wd 0.0500	time 0.4517 (0.5285)	data time 0.0008 (0.0581)	model time 0.4509 (0.4643)	loss 0.6416 (0.5537)	grad_norm 1.8846 (2.9902)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:47 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][120/156]	eta 0:00:18 lr 0.000023	 wd 0.0500	time 0.4123 (0.5232)	data time 0.0012 (0.0541)	model time 0.4111 (0.4629)	loss 0.6639 (0.5531)	grad_norm 4.8594 (2.9744)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:51 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][130/156]	eta 0:00:13 lr 0.000023	 wd 0.0500	time 0.4566 (0.5204)	data time 0.0012 (0.0505)	model time 0.4554 (0.4650)	loss 0.4884 (0.5527)	grad_norm 2.9154 (2.9658)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:26:56 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][140/156]	eta 0:00:08 lr 0.000023	 wd 0.0500	time 0.4515 (0.5174)	data time 0.0008 (0.0476)	model time 0.4508 (0.4654)	loss 0.5879 (0.5542)	grad_norm 2.1224 (2.9816)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:27:01 vssm1_tiny_0230s](training.py 201): INFO Train: [222/300][150/156]	eta 0:00:03 lr 0.000023	 wd 0.0500	time 0.5839 (0.5155)	data time 0.0006 (0.0445)	model time 0.5833 (0.4676)	loss 0.5578 (0.5541)	grad_norm 2.9374 (2.9553)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:27:04 vssm1_tiny_0230s](training.py 212): INFO EPOCH 222 training takes 0:01:20
[2024-11-09 17:27:04 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_222.pth saving......
[2024-11-09 17:27:04 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_222.pth saved !!!
[2024-11-09 17:27:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.061 (3.061)	Loss 0.2271 (0.2271)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:27:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.454)	Loss 0.2278 (0.2256)	Acc@1 93.750 (95.170)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:27:11 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.161 (0.355)	Loss 0.1833 (0.2318)	Acc@1 99.219 (94.940)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:27:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.314)	Loss 0.2333 (0.2262)	Acc@1 95.312 (95.413)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:27:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.520 Acc@5 100.000
[2024-11-09 17:27:16 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.5%
[2024-11-09 17:27:16 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:27:19 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.429 (3.429)	Loss 0.2089 (0.2089)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:27:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.161 (0.548)	Loss 0.2188 (0.2187)	Acc@1 96.094 (95.384)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:27:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.159 (0.379)	Loss 0.2537 (0.2333)	Acc@1 95.312 (93.936)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:27:25 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.182 (0.313)	Loss 0.3142 (0.2558)	Acc@1 90.625 (92.868)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:27:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.500 Acc@5 100.000
[2024-11-09 17:27:27 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.5%
[2024-11-09 17:27:27 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.50%
[2024-11-09 17:27:30 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][0/156]	eta 0:07:59 lr 0.000023	 wd 0.0500	time 3.0767 (3.0767)	data time 2.5942 (2.5942)	model time 0.0000 (0.0000)	loss 0.5518 (0.5518)	grad_norm 2.6446 (2.6446)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:27:35 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][10/156]	eta 0:01:47 lr 0.000023	 wd 0.0500	time 0.5406 (0.7361)	data time 0.0095 (0.2588)	model time 0.0000 (0.0000)	loss 0.4206 (0.5166)	grad_norm 5.8461 (3.3447)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:27:40 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][20/156]	eta 0:01:23 lr 0.000023	 wd 0.0500	time 0.5074 (0.6142)	data time 0.0209 (0.1416)	model time 0.0000 (0.0000)	loss 0.5789 (0.5277)	grad_norm 1.8891 (3.1672)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:27:45 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][30/156]	eta 0:01:12 lr 0.000023	 wd 0.0500	time 0.5672 (0.5790)	data time 0.0294 (0.1080)	model time 0.0000 (0.0000)	loss 0.5529 (0.5356)	grad_norm 2.8572 (3.1812)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:27:50 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][40/156]	eta 0:01:04 lr 0.000023	 wd 0.0500	time 0.4964 (0.5546)	data time 0.0089 (0.0849)	model time 0.0000 (0.0000)	loss 0.6620 (0.5390)	grad_norm 1.9398 (3.1181)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:27:55 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][50/156]	eta 0:00:57 lr 0.000023	 wd 0.0500	time 0.4217 (0.5435)	data time 0.0005 (0.0717)	model time 0.0000 (0.0000)	loss 0.4586 (0.5405)	grad_norm 3.5557 (3.0475)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:00 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][60/156]	eta 0:00:52 lr 0.000023	 wd 0.0500	time 0.5202 (0.5445)	data time 0.0186 (0.0634)	model time 0.5016 (0.5280)	loss 0.6367 (0.5418)	grad_norm 2.9441 (3.0752)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:06 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][70/156]	eta 0:00:47 lr 0.000023	 wd 0.0500	time 0.7560 (0.5506)	data time 0.0198 (0.0569)	model time 0.7362 (0.5497)	loss 0.5185 (0.5435)	grad_norm 2.8604 (2.9820)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:12 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][80/156]	eta 0:00:41 lr 0.000023	 wd 0.0500	time 0.5337 (0.5505)	data time 0.0289 (0.0532)	model time 0.5048 (0.5405)	loss 0.5291 (0.5476)	grad_norm 3.3782 (2.9554)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:17 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][90/156]	eta 0:00:35 lr 0.000023	 wd 0.0500	time 0.4922 (0.5415)	data time 0.0110 (0.0485)	model time 0.4812 (0.5199)	loss 0.6368 (0.5521)	grad_norm 3.4462 (2.8954)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:21 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][100/156]	eta 0:00:29 lr 0.000023	 wd 0.0500	time 0.5562 (0.5342)	data time 0.0106 (0.0453)	model time 0.5456 (0.5064)	loss 0.4399 (0.5486)	grad_norm 2.8415 (2.8575)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:26 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][110/156]	eta 0:00:24 lr 0.000023	 wd 0.0500	time 0.4300 (0.5308)	data time 0.0070 (0.0431)	model time 0.4230 (0.5011)	loss 0.4509 (0.5466)	grad_norm 4.5229 (2.9001)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:31 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][120/156]	eta 0:00:18 lr 0.000023	 wd 0.0500	time 0.5150 (0.5251)	data time 0.0209 (0.0404)	model time 0.4940 (0.4940)	loss 0.5964 (0.5474)	grad_norm 1.9442 (2.9011)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:35 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][130/156]	eta 0:00:13 lr 0.000023	 wd 0.0500	time 0.4229 (0.5202)	data time 0.0137 (0.0384)	model time 0.4091 (0.4882)	loss 0.6222 (0.5480)	grad_norm 3.6268 (2.9012)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:40 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][140/156]	eta 0:00:08 lr 0.000022	 wd 0.0500	time 0.4247 (0.5155)	data time 0.0010 (0.0362)	model time 0.4237 (0.4836)	loss 0.6282 (0.5492)	grad_norm 1.9789 (2.9225)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:45 vssm1_tiny_0230s](training.py 201): INFO Train: [223/300][150/156]	eta 0:00:03 lr 0.000022	 wd 0.0500	time 0.4741 (0.5123)	data time 0.0004 (0.0341)	model time 0.4737 (0.4814)	loss 0.5457 (0.5488)	grad_norm 2.3334 (2.9261)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:28:48 vssm1_tiny_0230s](training.py 212): INFO EPOCH 223 training takes 0:01:20
[2024-11-09 17:28:48 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_223.pth saving......
[2024-11-09 17:28:48 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_223.pth saved !!!
[2024-11-09 17:28:51 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.967 (2.967)	Loss 0.2207 (0.2207)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:28:53 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.421)	Loss 0.2231 (0.2191)	Acc@1 94.531 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:28:54 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.298)	Loss 0.1794 (0.2269)	Acc@1 98.438 (95.164)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:28:56 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.183 (0.274)	Loss 0.2335 (0.2226)	Acc@1 93.750 (95.338)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:28:58 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.440 Acc@5 100.000
[2024-11-09 17:28:58 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.4%
[2024-11-09 17:28:58 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:29:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.776 (1.776)	Loss 0.2085 (0.2085)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:29:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.211 (0.383)	Loss 0.2183 (0.2182)	Acc@1 96.094 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:29:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.310)	Loss 0.2515 (0.2326)	Acc@1 95.312 (93.973)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:29:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.276)	Loss 0.3123 (0.2547)	Acc@1 90.625 (92.918)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:29:09 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.580 Acc@5 100.000
[2024-11-09 17:29:09 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.6%
[2024-11-09 17:29:09 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.58%
[2024-11-09 17:29:13 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][0/156]	eta 0:11:17 lr 0.000022	 wd 0.0500	time 4.3447 (4.3447)	data time 3.8540 (3.8540)	model time 0.0000 (0.0000)	loss 0.5484 (0.5484)	grad_norm 2.3827 (2.3827)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:29:18 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][10/156]	eta 0:01:58 lr 0.000022	 wd 0.0500	time 0.4076 (0.8096)	data time 0.0007 (0.3588)	model time 0.0000 (0.0000)	loss 0.6156 (0.5872)	grad_norm 2.8229 (2.8115)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:29:23 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][20/156]	eta 0:01:29 lr 0.000022	 wd 0.0500	time 0.4617 (0.6584)	data time 0.0065 (0.1974)	model time 0.0000 (0.0000)	loss 0.6075 (0.5717)	grad_norm 2.7820 (2.7891)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:29:27 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][30/156]	eta 0:01:15 lr 0.000022	 wd 0.0500	time 0.4598 (0.5973)	data time 0.0040 (0.1371)	model time 0.0000 (0.0000)	loss 0.6072 (0.5683)	grad_norm 1.7369 (2.6477)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:29:32 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][40/156]	eta 0:01:05 lr 0.000022	 wd 0.0500	time 0.4928 (0.5646)	data time 0.0008 (0.1080)	model time 0.0000 (0.0000)	loss 0.6015 (0.5515)	grad_norm 3.4852 (2.7934)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:29:37 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][50/156]	eta 0:00:58 lr 0.000022	 wd 0.0500	time 0.4484 (0.5506)	data time 0.0006 (0.0915)	model time 0.0000 (0.0000)	loss 0.5395 (0.5459)	grad_norm 2.2658 (2.9029)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:29:42 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][60/156]	eta 0:00:51 lr 0.000022	 wd 0.0500	time 0.4650 (0.5380)	data time 0.0120 (0.0786)	model time 0.4529 (0.4602)	loss 0.5216 (0.5468)	grad_norm 1.9798 (2.9799)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:29:46 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][70/156]	eta 0:00:45 lr 0.000022	 wd 0.0500	time 0.5636 (0.5290)	data time 0.0252 (0.0689)	model time 0.5385 (0.4624)	loss 0.5869 (0.5428)	grad_norm 2.2604 (3.0256)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:29:52 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][80/156]	eta 0:00:40 lr 0.000022	 wd 0.0500	time 0.4323 (0.5271)	data time 0.0118 (0.0623)	model time 0.4205 (0.4746)	loss 0.4767 (0.5417)	grad_norm 2.0626 (3.0045)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:29:56 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][90/156]	eta 0:00:34 lr 0.000022	 wd 0.0500	time 0.4639 (0.5213)	data time 0.0067 (0.0569)	model time 0.4571 (0.4709)	loss 0.6036 (0.5411)	grad_norm 2.8337 (3.0210)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:30:01 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][100/156]	eta 0:00:28 lr 0.000022	 wd 0.0500	time 0.4149 (0.5145)	data time 0.0079 (0.0519)	model time 0.4070 (0.4662)	loss 0.4340 (0.5417)	grad_norm 3.5075 (3.0163)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:30:06 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][110/156]	eta 0:00:23 lr 0.000022	 wd 0.0500	time 0.4309 (0.5103)	data time 0.0224 (0.0483)	model time 0.4085 (0.4644)	loss 0.5780 (0.5415)	grad_norm 2.3390 (2.9929)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:30:10 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][120/156]	eta 0:00:18 lr 0.000022	 wd 0.0500	time 0.4138 (0.5062)	data time 0.0060 (0.0454)	model time 0.4078 (0.4619)	loss 0.4363 (0.5405)	grad_norm 3.1043 (3.0516)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:30:15 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][130/156]	eta 0:00:13 lr 0.000022	 wd 0.0500	time 0.4158 (0.5030)	data time 0.0007 (0.0429)	model time 0.4151 (0.4607)	loss 0.4832 (0.5426)	grad_norm 3.7329 (3.0452)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:30:19 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][140/156]	eta 0:00:07 lr 0.000022	 wd 0.0500	time 0.4122 (0.4996)	data time 0.0009 (0.0400)	model time 0.4113 (0.4598)	loss 0.4655 (0.5404)	grad_norm 3.7113 (3.0527)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:30:24 vssm1_tiny_0230s](training.py 201): INFO Train: [224/300][150/156]	eta 0:00:02 lr 0.000022	 wd 0.0500	time 0.5145 (0.4971)	data time 0.0005 (0.0374)	model time 0.5140 (0.4600)	loss 0.6081 (0.5424)	grad_norm 3.0232 (3.0410)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:30:27 vssm1_tiny_0230s](training.py 212): INFO EPOCH 224 training takes 0:01:17
[2024-11-09 17:30:27 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_224.pth saving......
[2024-11-09 17:30:27 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_224.pth saved !!!
[2024-11-09 17:30:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.147 (2.147)	Loss 0.2002 (0.2002)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:30:32 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.182 (0.407)	Loss 0.2084 (0.2048)	Acc@1 95.312 (95.881)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:30:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.315)	Loss 0.1851 (0.2128)	Acc@1 97.656 (95.387)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:30:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.290)	Loss 0.2406 (0.2161)	Acc@1 92.969 (95.237)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:30:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.160 Acc@5 100.000
[2024-11-09 17:30:38 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.2%
[2024-11-09 17:30:38 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:30:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.467 (2.467)	Loss 0.2076 (0.2076)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:30:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.310 (0.411)	Loss 0.2172 (0.2171)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:30:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.704 (0.338)	Loss 0.2505 (0.2315)	Acc@1 95.312 (94.159)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:30:47 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.288)	Loss 0.3115 (0.2535)	Acc@1 90.625 (93.044)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:30:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.740 Acc@5 100.000
[2024-11-09 17:30:49 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.7%
[2024-11-09 17:30:49 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.74%
[2024-11-09 17:30:52 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][0/156]	eta 0:08:19 lr 0.000022	 wd 0.0500	time 3.2018 (3.2018)	data time 2.6160 (2.6160)	model time 0.0000 (0.0000)	loss 0.5448 (0.5448)	grad_norm 2.4507 (2.4507)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:30:57 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][10/156]	eta 0:01:44 lr 0.000022	 wd 0.0500	time 0.4431 (0.7187)	data time 0.0089 (0.2460)	model time 0.0000 (0.0000)	loss 0.5248 (0.5317)	grad_norm 3.3296 (3.1166)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:02 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][20/156]	eta 0:01:22 lr 0.000022	 wd 0.0500	time 0.5126 (0.6059)	data time 0.0005 (0.1331)	model time 0.0000 (0.0000)	loss 0.4929 (0.5532)	grad_norm 3.4899 (3.1050)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:06 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][30/156]	eta 0:01:10 lr 0.000022	 wd 0.0500	time 0.5154 (0.5604)	data time 0.0394 (0.0936)	model time 0.0000 (0.0000)	loss 0.5352 (0.5673)	grad_norm 2.0931 (2.9571)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:11 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][40/156]	eta 0:01:02 lr 0.000022	 wd 0.0500	time 0.4616 (0.5408)	data time 0.0084 (0.0750)	model time 0.0000 (0.0000)	loss 0.5045 (0.5683)	grad_norm 2.2962 (2.8904)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:16 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][50/156]	eta 0:00:55 lr 0.000022	 wd 0.0500	time 0.4711 (0.5251)	data time 0.0007 (0.0608)	model time 0.0000 (0.0000)	loss 0.4858 (0.5575)	grad_norm 2.4886 (2.8741)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:20 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][60/156]	eta 0:00:49 lr 0.000022	 wd 0.0500	time 0.4896 (0.5143)	data time 0.0120 (0.0528)	model time 0.4777 (0.4477)	loss 0.5914 (0.5595)	grad_norm 2.4055 (2.8387)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:25 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][70/156]	eta 0:00:43 lr 0.000022	 wd 0.0500	time 0.4966 (0.5096)	data time 0.0008 (0.0470)	model time 0.4959 (0.4581)	loss 0.5979 (0.5588)	grad_norm 1.8265 (2.8186)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:30 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][80/156]	eta 0:00:38 lr 0.000022	 wd 0.0500	time 0.4094 (0.5057)	data time 0.0009 (0.0422)	model time 0.4085 (0.4623)	loss 0.6476 (0.5600)	grad_norm 2.2476 (2.7967)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:35 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][90/156]	eta 0:00:33 lr 0.000022	 wd 0.0500	time 0.4234 (0.5031)	data time 0.0006 (0.0385)	model time 0.4227 (0.4650)	loss 0.5406 (0.5620)	grad_norm 2.8354 (2.7807)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:39 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][100/156]	eta 0:00:27 lr 0.000022	 wd 0.0500	time 0.4177 (0.4975)	data time 0.0006 (0.0360)	model time 0.4172 (0.4586)	loss 0.6018 (0.5631)	grad_norm 3.9422 (2.8183)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:44 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][110/156]	eta 0:00:22 lr 0.000022	 wd 0.0500	time 0.5183 (0.4972)	data time 0.0205 (0.0341)	model time 0.4978 (0.4622)	loss 0.6217 (0.5634)	grad_norm 3.3180 (2.8070)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:49 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][120/156]	eta 0:00:17 lr 0.000021	 wd 0.0500	time 0.4297 (0.4946)	data time 0.0094 (0.0321)	model time 0.4203 (0.4612)	loss 0.4864 (0.5625)	grad_norm 4.1067 (2.8456)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:53 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][130/156]	eta 0:00:12 lr 0.000021	 wd 0.0500	time 0.4565 (0.4922)	data time 0.0009 (0.0301)	model time 0.4556 (0.4607)	loss 0.5401 (0.5624)	grad_norm 2.3857 (2.8759)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:31:58 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][140/156]	eta 0:00:07 lr 0.000021	 wd 0.0500	time 0.4558 (0.4912)	data time 0.0008 (0.0286)	model time 0.4550 (0.4617)	loss 0.5866 (0.5618)	grad_norm 3.0429 (2.8918)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:32:03 vssm1_tiny_0230s](training.py 201): INFO Train: [225/300][150/156]	eta 0:00:02 lr 0.000021	 wd 0.0500	time 0.4730 (0.4896)	data time 0.0007 (0.0268)	model time 0.4723 (0.4620)	loss 0.5960 (0.5640)	grad_norm 2.8945 (2.9329)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:32:06 vssm1_tiny_0230s](training.py 212): INFO EPOCH 225 training takes 0:01:16
[2024-11-09 17:32:06 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_225.pth saving......
[2024-11-09 17:32:06 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_225.pth saved !!!
[2024-11-09 17:32:09 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.476 (2.476)	Loss 0.2491 (0.2491)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:32:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.214 (0.401)	Loss 0.2573 (0.2526)	Acc@1 94.531 (94.673)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:32:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.317)	Loss 0.1730 (0.2567)	Acc@1 99.219 (94.382)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:32:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.286)	Loss 0.2183 (0.2388)	Acc@1 94.531 (95.086)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:32:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.440 Acc@5 100.000
[2024-11-09 17:32:17 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.4%
[2024-11-09 17:32:17 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:32:20 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.777 (2.777)	Loss 0.2074 (0.2074)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:32:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.455)	Loss 0.2168 (0.2168)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:32:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.337)	Loss 0.2485 (0.2311)	Acc@1 95.312 (94.122)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:32:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.290)	Loss 0.3096 (0.2526)	Acc@1 91.406 (93.070)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:32:29 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.760 Acc@5 100.000
[2024-11-09 17:32:29 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.8%
[2024-11-09 17:32:29 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.76%
[2024-11-09 17:32:32 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][0/156]	eta 0:09:10 lr 0.000021	 wd 0.0500	time 3.5264 (3.5264)	data time 3.0458 (3.0458)	model time 0.0000 (0.0000)	loss 0.6090 (0.6090)	grad_norm 3.7371 (3.7371)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:32:37 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][10/156]	eta 0:01:47 lr 0.000021	 wd 0.0500	time 0.4345 (0.7373)	data time 0.0007 (0.2812)	model time 0.0000 (0.0000)	loss 0.5981 (0.5420)	grad_norm 4.1514 (2.9551)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:32:41 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][20/156]	eta 0:01:23 lr 0.000021	 wd 0.0500	time 0.4240 (0.6109)	data time 0.0006 (0.1546)	model time 0.0000 (0.0000)	loss 0.4940 (0.5363)	grad_norm 6.3442 (3.2772)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:32:46 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][30/156]	eta 0:01:10 lr 0.000021	 wd 0.0500	time 0.4661 (0.5611)	data time 0.0313 (0.1079)	model time 0.0000 (0.0000)	loss 0.4813 (0.5347)	grad_norm 1.8526 (3.3107)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:32:51 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][40/156]	eta 0:01:02 lr 0.000021	 wd 0.0500	time 0.4380 (0.5394)	data time 0.0073 (0.0835)	model time 0.0000 (0.0000)	loss 0.5489 (0.5312)	grad_norm 3.4079 (3.3866)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:32:55 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][50/156]	eta 0:00:55 lr 0.000021	 wd 0.0500	time 0.4861 (0.5254)	data time 0.0005 (0.0689)	model time 0.0000 (0.0000)	loss 0.4341 (0.5299)	grad_norm 4.1027 (3.4590)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:00 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][60/156]	eta 0:00:49 lr 0.000021	 wd 0.0500	time 0.4301 (0.5173)	data time 0.0036 (0.0597)	model time 0.4265 (0.4634)	loss 0.5758 (0.5352)	grad_norm 2.4178 (3.4619)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:05 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][70/156]	eta 0:00:43 lr 0.000021	 wd 0.0500	time 0.4784 (0.5112)	data time 0.0402 (0.0542)	model time 0.4383 (0.4581)	loss 0.5198 (0.5342)	grad_norm 2.9375 (3.4490)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:10 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][80/156]	eta 0:00:38 lr 0.000021	 wd 0.0500	time 0.4156 (0.5064)	data time 0.0098 (0.0491)	model time 0.4057 (0.4588)	loss 0.4607 (0.5353)	grad_norm 2.4825 (3.4082)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:14 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][90/156]	eta 0:00:33 lr 0.000021	 wd 0.0500	time 0.4563 (0.5006)	data time 0.0007 (0.0448)	model time 0.4556 (0.4548)	loss 0.5350 (0.5355)	grad_norm 2.3837 (3.3110)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:19 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][100/156]	eta 0:00:27 lr 0.000021	 wd 0.0500	time 0.4476 (0.4967)	data time 0.0034 (0.0410)	model time 0.4443 (0.4549)	loss 0.4408 (0.5353)	grad_norm 4.3928 (3.3078)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:23 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][110/156]	eta 0:00:22 lr 0.000021	 wd 0.0500	time 0.4815 (0.4945)	data time 0.0013 (0.0383)	model time 0.4803 (0.4561)	loss 0.5914 (0.5339)	grad_norm 2.4265 (3.2496)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:28 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][120/156]	eta 0:00:17 lr 0.000021	 wd 0.0500	time 0.4762 (0.4930)	data time 0.0657 (0.0359)	model time 0.4105 (0.4576)	loss 0.5439 (0.5345)	grad_norm 3.5276 (3.2408)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:33 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][130/156]	eta 0:00:12 lr 0.000021	 wd 0.0500	time 0.4142 (0.4947)	data time 0.0072 (0.0346)	model time 0.4070 (0.4625)	loss 0.6380 (0.5350)	grad_norm 2.8581 (3.2254)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:38 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][140/156]	eta 0:00:07 lr 0.000021	 wd 0.0500	time 0.4690 (0.4944)	data time 0.0046 (0.0327)	model time 0.4643 (0.4646)	loss 0.3750 (0.5312)	grad_norm 4.6174 (3.2928)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:43 vssm1_tiny_0230s](training.py 201): INFO Train: [226/300][150/156]	eta 0:00:02 lr 0.000021	 wd 0.0500	time 0.5149 (0.4919)	data time 0.0005 (0.0306)	model time 0.5144 (0.4639)	loss 0.3965 (0.5323)	grad_norm 2.9585 (3.2458)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:33:45 vssm1_tiny_0230s](training.py 212): INFO EPOCH 226 training takes 0:01:16
[2024-11-09 17:33:45 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_226.pth saving......
[2024-11-09 17:33:46 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_226.pth saved !!!
[2024-11-09 17:33:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.899 (2.899)	Loss 0.1895 (0.1895)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:33:51 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.414)	Loss 0.1943 (0.1901)	Acc@1 95.312 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:33:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.328)	Loss 0.1775 (0.1994)	Acc@1 97.656 (95.722)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:33:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.284)	Loss 0.2341 (0.2036)	Acc@1 92.969 (95.539)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:33:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.500 Acc@5 100.000
[2024-11-09 17:33:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.5%
[2024-11-09 17:33:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:34:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.887 (2.887)	Loss 0.2068 (0.2068)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:34:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.155 (0.436)	Loss 0.2161 (0.2160)	Acc@1 96.094 (95.526)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:34:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.311)	Loss 0.2472 (0.2303)	Acc@1 95.312 (94.122)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:34:05 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.262)	Loss 0.3083 (0.2515)	Acc@1 91.406 (93.095)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:34:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.780 Acc@5 100.000
[2024-11-09 17:34:08 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.8%
[2024-11-09 17:34:08 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.78%
[2024-11-09 17:34:11 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][0/156]	eta 0:08:35 lr 0.000021	 wd 0.0500	time 3.3065 (3.3065)	data time 2.7662 (2.7662)	model time 0.0000 (0.0000)	loss 0.4651 (0.4651)	grad_norm 3.2129 (3.2129)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:34:16 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][10/156]	eta 0:01:48 lr 0.000021	 wd 0.0500	time 0.4227 (0.7421)	data time 0.0017 (0.2666)	model time 0.0000 (0.0000)	loss 0.6148 (0.5413)	grad_norm 4.5909 (3.5160)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:34:21 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][20/156]	eta 0:01:25 lr 0.000021	 wd 0.0500	time 0.4291 (0.6264)	data time 0.0028 (0.1505)	model time 0.0000 (0.0000)	loss 0.5311 (0.5575)	grad_norm 3.0121 (3.4166)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:34:26 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][30/156]	eta 0:01:13 lr 0.000021	 wd 0.0500	time 0.4545 (0.5835)	data time 0.0198 (0.1107)	model time 0.0000 (0.0000)	loss 0.4326 (0.5499)	grad_norm 3.7283 (3.2947)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:34:31 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][40/156]	eta 0:01:04 lr 0.000021	 wd 0.0500	time 0.4745 (0.5556)	data time 0.0286 (0.0865)	model time 0.0000 (0.0000)	loss 0.4557 (0.5426)	grad_norm 2.8912 (3.2892)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:34:36 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][50/156]	eta 0:00:57 lr 0.000021	 wd 0.0500	time 0.4669 (0.5452)	data time 0.0178 (0.0730)	model time 0.0000 (0.0000)	loss 0.5782 (0.5406)	grad_norm 3.2530 (3.2554)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:34:40 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][60/156]	eta 0:00:50 lr 0.000021	 wd 0.0500	time 0.4116 (0.5288)	data time 0.0008 (0.0618)	model time 0.4108 (0.4407)	loss 0.4650 (0.5440)	grad_norm 4.5631 (3.2434)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:34:45 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][70/156]	eta 0:00:44 lr 0.000021	 wd 0.0500	time 0.4779 (0.5193)	data time 0.0067 (0.0538)	model time 0.4712 (0.4486)	loss 0.6768 (0.5490)	grad_norm 3.5167 (3.1923)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:34:50 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][80/156]	eta 0:00:39 lr 0.000021	 wd 0.0500	time 0.5150 (0.5135)	data time 0.0235 (0.0477)	model time 0.4915 (0.4548)	loss 0.6052 (0.5474)	grad_norm 1.8219 (3.1432)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:34:54 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][90/156]	eta 0:00:33 lr 0.000021	 wd 0.0500	time 0.5030 (0.5067)	data time 0.0249 (0.0433)	model time 0.4780 (0.4521)	loss 0.5856 (0.5475)	grad_norm 2.2530 (3.1344)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:34:58 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][100/156]	eta 0:00:27 lr 0.000021	 wd 0.0500	time 0.4396 (0.4999)	data time 0.0012 (0.0398)	model time 0.4384 (0.4477)	loss 0.4488 (0.5451)	grad_norm 3.4683 (3.0929)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:35:03 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][110/156]	eta 0:00:22 lr 0.000021	 wd 0.0500	time 0.4912 (0.4988)	data time 0.0223 (0.0373)	model time 0.4689 (0.4525)	loss 0.5239 (0.5441)	grad_norm 2.2619 (3.0741)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:35:08 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][120/156]	eta 0:00:17 lr 0.000020	 wd 0.0500	time 0.4503 (0.4971)	data time 0.0007 (0.0349)	model time 0.4496 (0.4550)	loss 0.6113 (0.5416)	grad_norm 4.6241 (3.1219)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:35:13 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][130/156]	eta 0:00:12 lr 0.000020	 wd 0.0500	time 0.4620 (0.4960)	data time 0.0221 (0.0334)	model time 0.4400 (0.4566)	loss 0.6452 (0.5396)	grad_norm 3.4197 (3.1234)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:35:18 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][140/156]	eta 0:00:07 lr 0.000020	 wd 0.0500	time 0.5122 (0.4959)	data time 0.0009 (0.0319)	model time 0.5112 (0.4595)	loss 0.4326 (0.5389)	grad_norm 2.3715 (3.1481)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:35:23 vssm1_tiny_0230s](training.py 201): INFO Train: [227/300][150/156]	eta 0:00:02 lr 0.000020	 wd 0.0500	time 0.4193 (0.4938)	data time 0.0006 (0.0298)	model time 0.4187 (0.4598)	loss 0.4739 (0.5397)	grad_norm 3.8431 (3.1743)	loss_scale 65536.0000 (33636.0265)	mem 13675MB
[2024-11-09 17:35:25 vssm1_tiny_0230s](training.py 212): INFO EPOCH 227 training takes 0:01:17
[2024-11-09 17:35:25 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_227.pth saving......
[2024-11-09 17:35:26 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_227.pth saved !!!
[2024-11-09 17:35:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.289 (3.289)	Loss 0.1902 (0.1902)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:35:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.139 (0.472)	Loss 0.1941 (0.1923)	Acc@1 96.875 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:35:33 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.252 (0.364)	Loss 0.1818 (0.2004)	Acc@1 97.656 (95.871)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:35:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.195 (0.309)	Loss 0.2446 (0.2061)	Acc@1 92.188 (95.489)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:35:37 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.420 Acc@5 100.000
[2024-11-09 17:35:37 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.4%
[2024-11-09 17:35:37 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:35:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.075 (3.075)	Loss 0.2065 (0.2065)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:35:42 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.423)	Loss 0.2157 (0.2155)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:35:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.175 (0.302)	Loss 0.2452 (0.2297)	Acc@1 95.312 (94.122)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:35:45 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.154 (0.269)	Loss 0.3064 (0.2504)	Acc@1 91.406 (93.145)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:35:47 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.860 Acc@5 100.000
[2024-11-09 17:35:47 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.9%
[2024-11-09 17:35:47 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.86%
[2024-11-09 17:35:51 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][0/156]	eta 0:08:55 lr 0.000020	 wd 0.0500	time 3.4350 (3.4350)	data time 3.0193 (3.0193)	model time 0.0000 (0.0000)	loss 0.4894 (0.4894)	grad_norm 3.7838 (3.7838)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:35:56 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][10/156]	eta 0:01:51 lr 0.000020	 wd 0.0500	time 0.5475 (0.7635)	data time 0.0006 (0.2999)	model time 0.0000 (0.0000)	loss 0.5923 (0.5590)	grad_norm 3.5263 (3.4084)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:00 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][20/156]	eta 0:01:24 lr 0.000020	 wd 0.0500	time 0.4378 (0.6202)	data time 0.0008 (0.1635)	model time 0.0000 (0.0000)	loss 0.4951 (0.5491)	grad_norm 2.8289 (3.4677)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:05 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][30/156]	eta 0:01:11 lr 0.000020	 wd 0.0500	time 0.5406 (0.5684)	data time 0.0148 (0.1128)	model time 0.0000 (0.0000)	loss 0.6246 (0.5575)	grad_norm 3.2162 (3.4262)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:10 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][40/156]	eta 0:01:03 lr 0.000020	 wd 0.0500	time 0.4162 (0.5501)	data time 0.0109 (0.0910)	model time 0.0000 (0.0000)	loss 0.5905 (0.5625)	grad_norm 2.1605 (3.2065)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:15 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][50/156]	eta 0:00:57 lr 0.000020	 wd 0.0500	time 0.5035 (0.5397)	data time 0.0138 (0.0753)	model time 0.0000 (0.0000)	loss 0.5481 (0.5574)	grad_norm 2.3936 (3.2365)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:20 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][60/156]	eta 0:00:50 lr 0.000020	 wd 0.0500	time 0.4597 (0.5300)	data time 0.0043 (0.0669)	model time 0.4554 (0.4560)	loss 0.6186 (0.5624)	grad_norm 2.3260 (3.2021)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:24 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][70/156]	eta 0:00:44 lr 0.000020	 wd 0.0500	time 0.4772 (0.5214)	data time 0.0623 (0.0600)	model time 0.4149 (0.4533)	loss 0.5599 (0.5579)	grad_norm 2.2279 (3.2513)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:29 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][80/156]	eta 0:00:39 lr 0.000020	 wd 0.0500	time 0.4175 (0.5159)	data time 0.0104 (0.0539)	model time 0.4071 (0.4577)	loss 0.6036 (0.5506)	grad_norm 3.4426 (3.3787)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:34 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][90/156]	eta 0:00:33 lr 0.000020	 wd 0.0500	time 0.4467 (0.5121)	data time 0.0006 (0.0490)	model time 0.4461 (0.4614)	loss 0.5922 (0.5529)	grad_norm 4.5380 (3.3811)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:39 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][100/156]	eta 0:00:28 lr 0.000020	 wd 0.0500	time 0.4619 (0.5065)	data time 0.0080 (0.0446)	model time 0.4539 (0.4594)	loss 0.4474 (0.5491)	grad_norm 4.0548 (3.3896)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:43 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][110/156]	eta 0:00:23 lr 0.000020	 wd 0.0500	time 0.4249 (0.5022)	data time 0.0030 (0.0414)	model time 0.4219 (0.4577)	loss 0.4812 (0.5478)	grad_norm 4.6155 (3.4370)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:48 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][120/156]	eta 0:00:17 lr 0.000020	 wd 0.0500	time 0.5184 (0.4991)	data time 0.0260 (0.0388)	model time 0.4924 (0.4573)	loss 0.4194 (0.5482)	grad_norm 3.7156 (3.4368)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:52 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][130/156]	eta 0:00:12 lr 0.000020	 wd 0.0500	time 0.5074 (0.4962)	data time 0.0062 (0.0364)	model time 0.5012 (0.4568)	loss 0.4703 (0.5458)	grad_norm 3.9308 (3.3952)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:36:57 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][140/156]	eta 0:00:07 lr 0.000020	 wd 0.0500	time 0.4121 (0.4928)	data time 0.0010 (0.0341)	model time 0.4111 (0.4555)	loss 0.6180 (0.5454)	grad_norm 5.4063 (3.4367)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:37:01 vssm1_tiny_0230s](training.py 201): INFO Train: [228/300][150/156]	eta 0:00:02 lr 0.000020	 wd 0.0500	time 0.4311 (0.4895)	data time 0.0163 (0.0319)	model time 0.4148 (0.4541)	loss 0.4131 (0.5407)	grad_norm 3.6216 (3.4609)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:37:04 vssm1_tiny_0230s](training.py 212): INFO EPOCH 228 training takes 0:01:16
[2024-11-09 17:37:04 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_228.pth saving......
[2024-11-09 17:37:04 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_228.pth saved !!!
[2024-11-09 17:37:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.119 (2.119)	Loss 0.1766 (0.1766)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:37:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.186 (0.452)	Loss 0.1830 (0.1797)	Acc@1 96.094 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:37:11 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.323)	Loss 0.1879 (0.1904)	Acc@1 97.656 (96.057)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:37:13 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.283)	Loss 0.2438 (0.2011)	Acc@1 92.188 (95.514)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:37:15 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.480 Acc@5 100.000
[2024-11-09 17:37:15 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.5%
[2024-11-09 17:37:15 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:37:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.570 (2.570)	Loss 0.2059 (0.2059)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:37:19 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.397)	Loss 0.2148 (0.2148)	Acc@1 96.094 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:37:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.288)	Loss 0.2439 (0.2289)	Acc@1 95.312 (94.085)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:37:23 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.259)	Loss 0.3052 (0.2494)	Acc@1 91.406 (93.145)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:37:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.880 Acc@5 100.000
[2024-11-09 17:37:25 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.9%
[2024-11-09 17:37:25 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.88%
[2024-11-09 17:37:28 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][0/156]	eta 0:08:02 lr 0.000020	 wd 0.0500	time 3.0935 (3.0935)	data time 2.6079 (2.6079)	model time 0.0000 (0.0000)	loss 0.4951 (0.4951)	grad_norm 3.5608 (3.5608)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:37:33 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][10/156]	eta 0:01:43 lr 0.000020	 wd 0.0500	time 0.5206 (0.7074)	data time 0.0224 (0.2470)	model time 0.0000 (0.0000)	loss 0.4476 (0.5467)	grad_norm 3.1186 (3.6973)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:37:38 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][20/156]	eta 0:01:21 lr 0.000020	 wd 0.0500	time 0.5186 (0.5974)	data time 0.0151 (0.1332)	model time 0.0000 (0.0000)	loss 0.6774 (0.5458)	grad_norm 2.4508 (3.4236)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:37:43 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][30/156]	eta 0:01:09 lr 0.000020	 wd 0.0500	time 0.4486 (0.5529)	data time 0.0055 (0.0927)	model time 0.0000 (0.0000)	loss 0.6183 (0.5565)	grad_norm 2.0698 (3.2933)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:37:47 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][40/156]	eta 0:01:02 lr 0.000020	 wd 0.0500	time 0.5199 (0.5373)	data time 0.0017 (0.0735)	model time 0.0000 (0.0000)	loss 0.3837 (0.5479)	grad_norm 4.1536 (3.4265)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:37:52 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][50/156]	eta 0:00:55 lr 0.000020	 wd 0.0500	time 0.4439 (0.5256)	data time 0.0065 (0.0609)	model time 0.0000 (0.0000)	loss 0.3993 (0.5422)	grad_norm 4.1476 (3.3616)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:37:57 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][60/156]	eta 0:00:49 lr 0.000020	 wd 0.0500	time 0.4336 (0.5162)	data time 0.0020 (0.0537)	model time 0.4316 (0.4519)	loss 0.5347 (0.5398)	grad_norm 3.5624 (3.3305)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:38:02 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][70/156]	eta 0:00:43 lr 0.000020	 wd 0.0500	time 0.4643 (0.5092)	data time 0.0397 (0.0485)	model time 0.4246 (0.4505)	loss 0.5517 (0.5378)	grad_norm 3.0477 (3.2435)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:38:06 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][80/156]	eta 0:00:38 lr 0.000020	 wd 0.0500	time 0.5061 (0.5066)	data time 0.0636 (0.0448)	model time 0.4425 (0.4568)	loss 0.5677 (0.5419)	grad_norm 3.1771 (3.1677)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:38:11 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][90/156]	eta 0:00:33 lr 0.000020	 wd 0.0500	time 0.4409 (0.5053)	data time 0.0032 (0.0421)	model time 0.4376 (0.4613)	loss 0.6256 (0.5385)	grad_norm 2.7223 (3.1354)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:38:16 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][100/156]	eta 0:00:28 lr 0.000020	 wd 0.0500	time 0.4625 (0.5023)	data time 0.0114 (0.0396)	model time 0.4511 (0.4607)	loss 0.6317 (0.5391)	grad_norm 3.2057 (3.1314)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:38:21 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][110/156]	eta 0:00:23 lr 0.000020	 wd 0.0500	time 0.4166 (0.5004)	data time 0.0072 (0.0374)	model time 0.4094 (0.4616)	loss 0.5704 (0.5405)	grad_norm 3.3871 (3.1507)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:38:26 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][120/156]	eta 0:00:17 lr 0.000019	 wd 0.0500	time 0.4628 (0.4973)	data time 0.0014 (0.0356)	model time 0.4614 (0.4596)	loss 0.6173 (0.5439)	grad_norm 2.7601 (3.1433)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:38:30 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][130/156]	eta 0:00:12 lr 0.000019	 wd 0.0500	time 0.4372 (0.4961)	data time 0.0205 (0.0334)	model time 0.4166 (0.4615)	loss 0.5844 (0.5422)	grad_norm 1.7135 (3.1388)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:38:35 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][140/156]	eta 0:00:07 lr 0.000019	 wd 0.0500	time 0.5293 (0.4942)	data time 0.0009 (0.0316)	model time 0.5284 (0.4614)	loss 0.5304 (0.5413)	grad_norm 2.7615 (3.0916)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:38:40 vssm1_tiny_0230s](training.py 201): INFO Train: [229/300][150/156]	eta 0:00:02 lr 0.000019	 wd 0.0500	time 0.5247 (0.4939)	data time 0.0007 (0.0296)	model time 0.5240 (0.4642)	loss 0.6409 (0.5405)	grad_norm 2.1644 (3.0863)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:38:43 vssm1_tiny_0230s](training.py 212): INFO EPOCH 229 training takes 0:01:17
[2024-11-09 17:38:43 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_229.pth saving......
[2024-11-09 17:38:43 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_229.pth saved !!!
[2024-11-09 17:38:46 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.841 (2.841)	Loss 0.1998 (0.1998)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:38:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.160 (0.449)	Loss 0.2090 (0.2038)	Acc@1 94.531 (95.455)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:38:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.337)	Loss 0.1772 (0.2125)	Acc@1 98.438 (95.201)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:38:52 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.292)	Loss 0.2290 (0.2112)	Acc@1 93.750 (95.262)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:38:54 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.300 Acc@5 100.000
[2024-11-09 17:38:54 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.3%
[2024-11-09 17:38:54 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:38:57 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.443 (2.443)	Loss 0.2053 (0.2053)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:38:59 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.435)	Loss 0.2142 (0.2140)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:39:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.159 (0.313)	Loss 0.2422 (0.2281)	Acc@1 95.312 (94.122)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:39:03 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.163 (0.276)	Loss 0.3035 (0.2482)	Acc@1 91.406 (93.170)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:39:04 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 92.920 Acc@5 100.000
[2024-11-09 17:39:04 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 92.9%
[2024-11-09 17:39:04 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 92.92%
[2024-11-09 17:39:09 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][0/156]	eta 0:11:07 lr 0.000019	 wd 0.0500	time 4.2819 (4.2819)	data time 3.8363 (3.8363)	model time 0.0000 (0.0000)	loss 0.4853 (0.4853)	grad_norm 2.6373 (2.6373)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:39:14 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][10/156]	eta 0:02:01 lr 0.000019	 wd 0.0500	time 0.4575 (0.8293)	data time 0.0268 (0.3575)	model time 0.0000 (0.0000)	loss 0.3936 (0.5048)	grad_norm 3.1815 (3.1975)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:39:18 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][20/156]	eta 0:01:30 lr 0.000019	 wd 0.0500	time 0.5370 (0.6663)	data time 0.0491 (0.2003)	model time 0.0000 (0.0000)	loss 0.5480 (0.5173)	grad_norm 2.4219 (3.1413)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:39:23 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][30/156]	eta 0:01:16 lr 0.000019	 wd 0.0500	time 0.5231 (0.6053)	data time 0.0015 (0.1392)	model time 0.0000 (0.0000)	loss 0.5740 (0.5314)	grad_norm 4.6698 (3.3107)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:39:28 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][40/156]	eta 0:01:05 lr 0.000019	 wd 0.0500	time 0.4319 (0.5682)	data time 0.0052 (0.1068)	model time 0.0000 (0.0000)	loss 0.6170 (0.5345)	grad_norm 4.3345 (3.3087)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:39:32 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][50/156]	eta 0:00:57 lr 0.000019	 wd 0.0500	time 0.4375 (0.5457)	data time 0.0022 (0.0872)	model time 0.0000 (0.0000)	loss 0.4678 (0.5342)	grad_norm 4.5226 (3.3031)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:39:37 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][60/156]	eta 0:00:51 lr 0.000019	 wd 0.0500	time 0.4526 (0.5313)	data time 0.0318 (0.0746)	model time 0.4208 (0.4476)	loss 0.6261 (0.5386)	grad_norm 2.0129 (3.2269)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:39:42 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][70/156]	eta 0:00:45 lr 0.000019	 wd 0.0500	time 0.4131 (0.5268)	data time 0.0093 (0.0667)	model time 0.4038 (0.4644)	loss 0.4517 (0.5407)	grad_norm 2.7243 (3.2011)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:39:47 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][80/156]	eta 0:00:40 lr 0.000019	 wd 0.0500	time 0.4767 (0.5298)	data time 0.0322 (0.0633)	model time 0.4445 (0.4800)	loss 0.6073 (0.5457)	grad_norm 2.9974 (3.1859)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:39:52 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][90/156]	eta 0:00:34 lr 0.000019	 wd 0.0500	time 0.5207 (0.5260)	data time 0.0407 (0.0579)	model time 0.4800 (0.4803)	loss 0.4409 (0.5425)	grad_norm 2.5784 (3.1283)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:39:57 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][100/156]	eta 0:00:29 lr 0.000019	 wd 0.0500	time 0.5468 (0.5228)	data time 0.0068 (0.0540)	model time 0.5399 (0.4793)	loss 0.5219 (0.5371)	grad_norm 3.9190 (3.1916)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:40:02 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][110/156]	eta 0:00:24 lr 0.000019	 wd 0.0500	time 0.5110 (0.5218)	data time 0.0036 (0.0516)	model time 0.5075 (0.4801)	loss 0.5763 (0.5391)	grad_norm 3.3394 (3.1837)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:40:07 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][120/156]	eta 0:00:18 lr 0.000019	 wd 0.0500	time 0.5499 (0.5203)	data time 0.0824 (0.0488)	model time 0.4675 (0.4810)	loss 0.4202 (0.5362)	grad_norm 5.1669 (3.2306)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:40:13 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][130/156]	eta 0:00:13 lr 0.000019	 wd 0.0500	time 0.7288 (0.5216)	data time 0.0236 (0.0467)	model time 0.7052 (0.4853)	loss 0.5435 (0.5358)	grad_norm 4.1880 (3.2536)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 17:40:18 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][140/156]	eta 0:00:08 lr 0.000019	 wd 0.0500	time 0.6406 (0.5242)	data time 0.0008 (0.0441)	model time 0.6397 (0.4922)	loss 0.4267 (0.5346)	grad_norm 5.9392 (inf)	loss_scale 32768.0000 (65071.2057)	mem 13675MB
[2024-11-09 17:40:23 vssm1_tiny_0230s](training.py 201): INFO Train: [230/300][150/156]	eta 0:00:03 lr 0.000019	 wd 0.0500	time 0.4319 (0.5214)	data time 0.0004 (0.0415)	model time 0.4315 (0.4909)	loss 0.5674 (0.5366)	grad_norm 3.8335 (inf)	loss_scale 32768.0000 (62931.9205)	mem 13675MB
[2024-11-09 17:40:26 vssm1_tiny_0230s](training.py 212): INFO EPOCH 230 training takes 0:01:21
[2024-11-09 17:40:26 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_230.pth saving......
[2024-11-09 17:40:26 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_230.pth saved !!!
[2024-11-09 17:40:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.069 (3.069)	Loss 0.2135 (0.2135)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:40:32 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.194 (0.490)	Loss 0.2263 (0.2158)	Acc@1 93.750 (95.384)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:40:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.161 (0.353)	Loss 0.1708 (0.2223)	Acc@1 97.656 (94.903)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:40:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.308)	Loss 0.2178 (0.2138)	Acc@1 93.750 (95.338)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:40:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.480 Acc@5 100.000
[2024-11-09 17:40:38 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.5%
[2024-11-09 17:40:38 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:40:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.382 (2.382)	Loss 0.2048 (0.2048)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:40:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.147 (0.453)	Loss 0.2135 (0.2134)	Acc@1 96.094 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:40:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.470 (0.322)	Loss 0.2408 (0.2274)	Acc@1 95.312 (94.159)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:40:47 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.212 (0.296)	Loss 0.3020 (0.2472)	Acc@1 91.406 (93.271)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:40:50 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.020 Acc@5 100.000
[2024-11-09 17:40:50 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.0%
[2024-11-09 17:40:50 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.02%
[2024-11-09 17:40:53 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][0/156]	eta 0:09:54 lr 0.000019	 wd 0.0500	time 3.8088 (3.8088)	data time 3.3726 (3.3726)	model time 0.0000 (0.0000)	loss 0.4064 (0.4064)	grad_norm 3.2859 (3.2859)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:40:58 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][10/156]	eta 0:01:52 lr 0.000019	 wd 0.0500	time 0.5238 (0.7696)	data time 0.0294 (0.3139)	model time 0.0000 (0.0000)	loss 0.6462 (0.5543)	grad_norm 1.6175 (2.9821)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:03 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][20/156]	eta 0:01:25 lr 0.000019	 wd 0.0500	time 0.4576 (0.6263)	data time 0.0112 (0.1667)	model time 0.0000 (0.0000)	loss 0.5491 (0.5433)	grad_norm 2.5310 (2.8868)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:07 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][30/156]	eta 0:01:11 lr 0.000019	 wd 0.0500	time 0.4442 (0.5681)	data time 0.0007 (0.1142)	model time 0.0000 (0.0000)	loss 0.4545 (0.5537)	grad_norm 4.2116 (2.8463)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:12 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][40/156]	eta 0:01:02 lr 0.000019	 wd 0.0500	time 0.5418 (0.5409)	data time 0.0097 (0.0879)	model time 0.0000 (0.0000)	loss 0.6256 (0.5478)	grad_norm 2.4825 (2.9979)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:17 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][50/156]	eta 0:00:56 lr 0.000019	 wd 0.0500	time 0.5321 (0.5285)	data time 0.0178 (0.0731)	model time 0.0000 (0.0000)	loss 0.5292 (0.5441)	grad_norm 4.1761 (3.0132)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:21 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][60/156]	eta 0:00:49 lr 0.000019	 wd 0.0500	time 0.4307 (0.5197)	data time 0.0041 (0.0627)	model time 0.4266 (0.4648)	loss 0.4811 (0.5474)	grad_norm 3.6942 (3.0137)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:26 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][70/156]	eta 0:00:44 lr 0.000019	 wd 0.0500	time 0.5046 (0.5169)	data time 0.0989 (0.0563)	model time 0.4056 (0.4737)	loss 0.4740 (0.5399)	grad_norm 2.7436 (3.0094)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:31 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][80/156]	eta 0:00:38 lr 0.000019	 wd 0.0500	time 0.4557 (0.5118)	data time 0.0008 (0.0501)	model time 0.4549 (0.4723)	loss 0.5453 (0.5391)	grad_norm 3.7269 (2.9891)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:36 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][90/156]	eta 0:00:33 lr 0.000019	 wd 0.0500	time 0.4831 (0.5059)	data time 0.0031 (0.0453)	model time 0.4800 (0.4672)	loss 0.4288 (0.5390)	grad_norm 4.5267 (3.0662)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:41 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][100/156]	eta 0:00:28 lr 0.000019	 wd 0.0500	time 0.4274 (0.5037)	data time 0.0008 (0.0425)	model time 0.4266 (0.4671)	loss 0.5347 (0.5373)	grad_norm 4.9394 (3.1210)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:45 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][110/156]	eta 0:00:23 lr 0.000019	 wd 0.0500	time 0.4809 (0.5008)	data time 0.0266 (0.0395)	model time 0.4543 (0.4664)	loss 0.5848 (0.5372)	grad_norm 2.5231 (3.1377)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:50 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][120/156]	eta 0:00:17 lr 0.000019	 wd 0.0500	time 0.4074 (0.4963)	data time 0.0010 (0.0368)	model time 0.4065 (0.4623)	loss 0.6123 (0.5395)	grad_norm 2.9940 (3.1039)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:54 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][130/156]	eta 0:00:12 lr 0.000018	 wd 0.0500	time 0.4983 (0.4930)	data time 0.0404 (0.0348)	model time 0.4578 (0.4599)	loss 0.5635 (0.5406)	grad_norm 3.2276 (3.1287)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:41:59 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][140/156]	eta 0:00:07 lr 0.000018	 wd 0.0500	time 0.5112 (0.4929)	data time 0.0008 (0.0328)	model time 0.5103 (0.4627)	loss 0.5087 (0.5395)	grad_norm 2.5236 (3.1228)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:42:04 vssm1_tiny_0230s](training.py 201): INFO Train: [231/300][150/156]	eta 0:00:02 lr 0.000018	 wd 0.0500	time 0.4082 (0.4922)	data time 0.0005 (0.0309)	model time 0.4077 (0.4643)	loss 0.6529 (0.5401)	grad_norm 2.7918 (3.1500)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:42:06 vssm1_tiny_0230s](training.py 212): INFO EPOCH 231 training takes 0:01:16
[2024-11-09 17:42:06 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_231.pth saving......
[2024-11-09 17:42:07 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_231.pth saved !!!
[2024-11-09 17:42:10 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.261 (3.261)	Loss 0.2045 (0.2045)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:42:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.146 (0.676)	Loss 0.2136 (0.2037)	Acc@1 96.875 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:42:17 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.467)	Loss 0.1813 (0.2112)	Acc@1 97.656 (95.647)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:42:19 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.152 (0.402)	Loss 0.2357 (0.2113)	Acc@1 93.750 (95.565)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:42:22 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.500 Acc@5 100.000
[2024-11-09 17:42:22 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.5%
[2024-11-09 17:42:22 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:42:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.061 (4.061)	Loss 0.2047 (0.2047)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:42:28 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.186 (0.519)	Loss 0.2134 (0.2132)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:42:30 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.353)	Loss 0.2388 (0.2270)	Acc@1 95.312 (94.122)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:42:31 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.142 (0.293)	Loss 0.3000 (0.2462)	Acc@1 92.188 (93.271)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:42:33 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.080 Acc@5 100.000
[2024-11-09 17:42:33 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.1%
[2024-11-09 17:42:33 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.08%
[2024-11-09 17:42:37 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][0/156]	eta 0:09:57 lr 0.000018	 wd 0.0500	time 3.8302 (3.8302)	data time 3.3751 (3.3751)	model time 0.0000 (0.0000)	loss 0.5405 (0.5405)	grad_norm 2.6046 (2.6046)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:42:42 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][10/156]	eta 0:01:56 lr 0.000018	 wd 0.0500	time 0.5043 (0.7956)	data time 0.0061 (0.3175)	model time 0.0000 (0.0000)	loss 0.5481 (0.5302)	grad_norm 4.0800 (3.5213)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:42:47 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][20/156]	eta 0:01:27 lr 0.000018	 wd 0.0500	time 0.5598 (0.6445)	data time 0.0018 (0.1709)	model time 0.0000 (0.0000)	loss 0.6311 (0.5382)	grad_norm 1.8513 (3.4270)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:42:52 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][30/156]	eta 0:01:13 lr 0.000018	 wd 0.0500	time 0.4818 (0.5864)	data time 0.0137 (0.1190)	model time 0.0000 (0.0000)	loss 0.5947 (0.5433)	grad_norm 2.9263 (3.2623)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:42:56 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][40/156]	eta 0:01:04 lr 0.000018	 wd 0.0500	time 0.4921 (0.5596)	data time 0.0009 (0.0933)	model time 0.0000 (0.0000)	loss 0.5337 (0.5371)	grad_norm 3.3560 (3.1583)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:01 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][50/156]	eta 0:00:57 lr 0.000018	 wd 0.0500	time 0.5197 (0.5446)	data time 0.0068 (0.0795)	model time 0.0000 (0.0000)	loss 0.4170 (0.5407)	grad_norm 3.2078 (3.1298)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:06 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][60/156]	eta 0:00:50 lr 0.000018	 wd 0.0500	time 0.4113 (0.5308)	data time 0.0059 (0.0678)	model time 0.4053 (0.4523)	loss 0.5149 (0.5404)	grad_norm 2.3053 (3.0873)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:11 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][70/156]	eta 0:00:45 lr 0.000018	 wd 0.0500	time 0.5042 (0.5254)	data time 0.0015 (0.0594)	model time 0.5027 (0.4683)	loss 0.5170 (0.5443)	grad_norm 2.6163 (3.0500)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:15 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][80/156]	eta 0:00:39 lr 0.000018	 wd 0.0500	time 0.4587 (0.5173)	data time 0.0241 (0.0536)	model time 0.4346 (0.4614)	loss 0.6074 (0.5459)	grad_norm 2.6698 (3.0353)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:20 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][90/156]	eta 0:00:34 lr 0.000018	 wd 0.0500	time 0.5971 (0.5153)	data time 0.1146 (0.0504)	model time 0.4825 (0.4646)	loss 0.5133 (0.5484)	grad_norm 3.7417 (3.0300)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:25 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][100/156]	eta 0:00:28 lr 0.000018	 wd 0.0500	time 0.4427 (0.5094)	data time 0.0005 (0.0469)	model time 0.4422 (0.4600)	loss 0.4084 (0.5468)	grad_norm 2.5993 (3.0522)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:30 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][110/156]	eta 0:00:23 lr 0.000018	 wd 0.0500	time 0.4109 (0.5058)	data time 0.0032 (0.0432)	model time 0.4076 (0.4604)	loss 0.6215 (0.5478)	grad_norm 1.8561 (3.0582)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:35 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][120/156]	eta 0:00:18 lr 0.000018	 wd 0.0500	time 0.4587 (0.5074)	data time 0.0212 (0.0408)	model time 0.4375 (0.4678)	loss 0.5008 (0.5436)	grad_norm 3.3852 (3.0806)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:39 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][130/156]	eta 0:00:13 lr 0.000018	 wd 0.0500	time 0.4709 (0.5041)	data time 0.0010 (0.0388)	model time 0.4699 (0.4654)	loss 0.5883 (0.5415)	grad_norm 3.2295 (3.0991)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:44 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][140/156]	eta 0:00:08 lr 0.000018	 wd 0.0500	time 0.4090 (0.5025)	data time 0.0008 (0.0365)	model time 0.4082 (0.4665)	loss 0.4411 (0.5408)	grad_norm 3.4714 (3.0955)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:49 vssm1_tiny_0230s](training.py 201): INFO Train: [232/300][150/156]	eta 0:00:02 lr 0.000018	 wd 0.0500	time 0.4231 (0.4990)	data time 0.0007 (0.0341)	model time 0.4224 (0.4648)	loss 0.5149 (0.5371)	grad_norm 3.3158 (3.1071)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:43:52 vssm1_tiny_0230s](training.py 212): INFO EPOCH 232 training takes 0:01:18
[2024-11-09 17:43:52 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_232.pth saving......
[2024-11-09 17:43:52 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_232.pth saved !!!
[2024-11-09 17:43:54 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.617 (2.617)	Loss 0.1783 (0.1783)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:43:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.428)	Loss 0.1897 (0.1811)	Acc@1 96.094 (96.662)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:43:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.169 (0.315)	Loss 0.1683 (0.1900)	Acc@1 97.656 (96.019)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:44:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.147 (0.281)	Loss 0.2323 (0.1950)	Acc@1 93.750 (95.590)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:44:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.500 Acc@5 100.000
[2024-11-09 17:44:03 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.5%
[2024-11-09 17:44:03 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.60%
[2024-11-09 17:44:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.267 (3.267)	Loss 0.2043 (0.2043)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:44:08 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.475)	Loss 0.2129 (0.2127)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:44:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.350)	Loss 0.2373 (0.2264)	Acc@1 95.312 (94.159)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:44:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.289)	Loss 0.2986 (0.2452)	Acc@1 92.188 (93.372)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:44:13 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.180 Acc@5 100.000
[2024-11-09 17:44:13 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.2%
[2024-11-09 17:44:13 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.18%
[2024-11-09 17:44:17 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][0/156]	eta 0:08:11 lr 0.000018	 wd 0.0500	time 3.1500 (3.1500)	data time 2.6867 (2.6867)	model time 0.0000 (0.0000)	loss 0.5986 (0.5986)	grad_norm 3.2126 (3.2126)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:44:21 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][10/156]	eta 0:01:45 lr 0.000018	 wd 0.0500	time 0.5171 (0.7214)	data time 0.0092 (0.2536)	model time 0.0000 (0.0000)	loss 0.5294 (0.5595)	grad_norm 4.5886 (3.3606)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:44:26 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][20/156]	eta 0:01:19 lr 0.000018	 wd 0.0500	time 0.4508 (0.5848)	data time 0.0182 (0.1373)	model time 0.0000 (0.0000)	loss 0.4311 (0.5569)	grad_norm 3.2227 (3.1020)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:44:30 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][30/156]	eta 0:01:08 lr 0.000018	 wd 0.0500	time 0.4559 (0.5413)	data time 0.0070 (0.0957)	model time 0.0000 (0.0000)	loss 0.6201 (0.5542)	grad_norm 3.6844 (3.3274)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:44:35 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][40/156]	eta 0:01:00 lr 0.000018	 wd 0.0500	time 0.5482 (0.5213)	data time 0.0007 (0.0752)	model time 0.0000 (0.0000)	loss 0.3939 (0.5449)	grad_norm 2.7053 (3.2222)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:44:40 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][50/156]	eta 0:00:54 lr 0.000018	 wd 0.0500	time 0.4715 (0.5153)	data time 0.0042 (0.0628)	model time 0.0000 (0.0000)	loss 0.5829 (0.5486)	grad_norm 2.0054 (3.2225)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:44:45 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][60/156]	eta 0:00:49 lr 0.000018	 wd 0.0500	time 0.6580 (0.5127)	data time 0.0009 (0.0539)	model time 0.6571 (0.4910)	loss 0.5961 (0.5507)	grad_norm 2.1128 (3.2066)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:44:49 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][70/156]	eta 0:00:43 lr 0.000018	 wd 0.0500	time 0.4227 (0.5078)	data time 0.0008 (0.0471)	model time 0.4219 (0.4816)	loss 0.6078 (0.5462)	grad_norm 4.0656 (3.1740)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:44:54 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][80/156]	eta 0:00:38 lr 0.000018	 wd 0.0500	time 0.4936 (0.5031)	data time 0.0384 (0.0441)	model time 0.4553 (0.4701)	loss 0.5974 (0.5443)	grad_norm 2.5849 (3.1640)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:44:59 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][90/156]	eta 0:00:33 lr 0.000018	 wd 0.0500	time 0.5265 (0.5009)	data time 0.0077 (0.0408)	model time 0.5189 (0.4698)	loss 0.6052 (0.5481)	grad_norm 3.2055 (3.1171)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:45:04 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][100/156]	eta 0:00:27 lr 0.000018	 wd 0.0500	time 0.4963 (0.4978)	data time 0.0197 (0.0380)	model time 0.4766 (0.4673)	loss 0.5990 (0.5497)	grad_norm 2.3887 (3.0835)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:45:08 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][110/156]	eta 0:00:22 lr 0.000018	 wd 0.0500	time 0.4146 (0.4950)	data time 0.0057 (0.0355)	model time 0.4089 (0.4655)	loss 0.4720 (0.5492)	grad_norm 3.4013 (3.0953)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:45:13 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][120/156]	eta 0:00:17 lr 0.000018	 wd 0.0500	time 0.4188 (0.4909)	data time 0.0005 (0.0331)	model time 0.4183 (0.4617)	loss 0.4398 (0.5456)	grad_norm 5.0659 (3.1710)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:45:18 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][130/156]	eta 0:00:12 lr 0.000018	 wd 0.0500	time 0.4978 (0.4915)	data time 0.0042 (0.0318)	model time 0.4935 (0.4644)	loss 0.5302 (0.5437)	grad_norm 2.4593 (3.1545)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:45:23 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][140/156]	eta 0:00:07 lr 0.000018	 wd 0.0500	time 0.4842 (0.4913)	data time 0.0011 (0.0306)	model time 0.4830 (0.4654)	loss 0.6860 (0.5453)	grad_norm 6.0205 (3.1855)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:45:28 vssm1_tiny_0230s](training.py 201): INFO Train: [233/300][150/156]	eta 0:00:02 lr 0.000017	 wd 0.0500	time 0.4158 (0.4914)	data time 0.0005 (0.0288)	model time 0.4153 (0.4679)	loss 0.6117 (0.5453)	grad_norm 2.3736 (3.1985)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:45:30 vssm1_tiny_0230s](training.py 212): INFO EPOCH 233 training takes 0:01:16
[2024-11-09 17:45:30 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_233.pth saving......
[2024-11-09 17:45:31 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_233.pth saved !!!
[2024-11-09 17:45:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.036 (3.036)	Loss 0.2047 (0.2047)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:45:36 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.455)	Loss 0.2152 (0.2040)	Acc@1 95.312 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:45:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.156 (0.320)	Loss 0.1761 (0.2110)	Acc@1 97.656 (95.796)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:45:39 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.279)	Loss 0.2325 (0.2099)	Acc@1 92.969 (95.665)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:45:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.660 Acc@5 100.000
[2024-11-09 17:45:42 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 17:45:42 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.66%
[2024-11-09 17:45:46 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.931 (3.931)	Loss 0.2042 (0.2042)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:45:47 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.150 (0.511)	Loss 0.2126 (0.2124)	Acc@1 96.094 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:45:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.387)	Loss 0.2360 (0.2261)	Acc@1 95.312 (94.196)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:45:52 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.201 (0.326)	Loss 0.2974 (0.2444)	Acc@1 92.188 (93.397)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:45:54 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.220 Acc@5 100.000
[2024-11-09 17:45:54 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.2%
[2024-11-09 17:45:54 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.22%
[2024-11-09 17:45:58 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][0/156]	eta 0:10:04 lr 0.000017	 wd 0.0500	time 3.8778 (3.8778)	data time 3.4102 (3.4102)	model time 0.0000 (0.0000)	loss 0.6295 (0.6295)	grad_norm 2.4887 (2.4887)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:02 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][10/156]	eta 0:01:56 lr 0.000017	 wd 0.0500	time 0.4584 (0.8007)	data time 0.0024 (0.3284)	model time 0.0000 (0.0000)	loss 0.4209 (0.5527)	grad_norm 2.9717 (3.2654)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:08 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][20/156]	eta 0:01:35 lr 0.000017	 wd 0.0500	time 0.5652 (0.7032)	data time 0.0007 (0.1912)	model time 0.0000 (0.0000)	loss 0.4562 (0.5555)	grad_norm 3.3498 (3.0996)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:14 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][30/156]	eta 0:01:21 lr 0.000017	 wd 0.0500	time 0.7193 (0.6481)	data time 0.0034 (0.1340)	model time 0.0000 (0.0000)	loss 0.3740 (0.5447)	grad_norm 4.8738 (3.2184)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:19 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][40/156]	eta 0:01:10 lr 0.000017	 wd 0.0500	time 0.4406 (0.6089)	data time 0.0177 (0.1056)	model time 0.0000 (0.0000)	loss 0.5797 (0.5441)	grad_norm 3.5850 (3.1727)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:23 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][50/156]	eta 0:01:02 lr 0.000017	 wd 0.0500	time 0.4249 (0.5850)	data time 0.0084 (0.0878)	model time 0.0000 (0.0000)	loss 0.5559 (0.5386)	grad_norm 3.9248 (3.2685)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:28 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][60/156]	eta 0:00:54 lr 0.000017	 wd 0.0500	time 0.4138 (0.5652)	data time 0.0055 (0.0745)	model time 0.4083 (0.4583)	loss 0.6392 (0.5384)	grad_norm 2.9950 (3.3219)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:33 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][70/156]	eta 0:00:47 lr 0.000017	 wd 0.0500	time 0.4168 (0.5509)	data time 0.0028 (0.0657)	model time 0.4140 (0.4547)	loss 0.6397 (0.5423)	grad_norm 2.5945 (3.2489)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:38 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][80/156]	eta 0:00:41 lr 0.000017	 wd 0.0500	time 0.5052 (0.5461)	data time 0.0007 (0.0591)	model time 0.5045 (0.4698)	loss 0.5281 (0.5407)	grad_norm 1.5531 (3.2374)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:43 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][90/156]	eta 0:00:35 lr 0.000017	 wd 0.0500	time 0.4365 (0.5389)	data time 0.0083 (0.0534)	model time 0.4283 (0.4706)	loss 0.5513 (0.5445)	grad_norm 1.8450 (3.2117)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:47 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][100/156]	eta 0:00:29 lr 0.000017	 wd 0.0500	time 0.4221 (0.5312)	data time 0.0158 (0.0491)	model time 0.4063 (0.4667)	loss 0.6366 (0.5471)	grad_norm 2.3217 (3.1771)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:52 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][110/156]	eta 0:00:24 lr 0.000017	 wd 0.0500	time 0.4566 (0.5249)	data time 0.0057 (0.0464)	model time 0.4509 (0.4627)	loss 0.6145 (0.5467)	grad_norm 2.9912 (3.1549)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:46:57 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][120/156]	eta 0:00:18 lr 0.000017	 wd 0.0500	time 0.4930 (0.5233)	data time 0.0032 (0.0444)	model time 0.4899 (0.4656)	loss 0.5475 (0.5463)	grad_norm 2.5181 (3.1241)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:47:02 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][130/156]	eta 0:00:13 lr 0.000017	 wd 0.0500	time 0.5110 (0.5191)	data time 0.0045 (0.0416)	model time 0.5065 (0.4650)	loss 0.5677 (0.5438)	grad_norm 2.4061 (3.1251)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:47:07 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][140/156]	eta 0:00:08 lr 0.000017	 wd 0.0500	time 0.4857 (0.5169)	data time 0.0010 (0.0397)	model time 0.4847 (0.4660)	loss 0.4887 (0.5434)	grad_norm 3.7057 (3.1143)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:47:11 vssm1_tiny_0230s](training.py 201): INFO Train: [234/300][150/156]	eta 0:00:03 lr 0.000017	 wd 0.0500	time 0.4075 (0.5121)	data time 0.0007 (0.0371)	model time 0.4068 (0.4637)	loss 0.6040 (0.5449)	grad_norm 2.2118 (3.1024)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:47:14 vssm1_tiny_0230s](training.py 212): INFO EPOCH 234 training takes 0:01:19
[2024-11-09 17:47:14 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_234.pth saving......
[2024-11-09 17:47:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_234.pth saved !!!
[2024-11-09 17:47:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.036 (3.036)	Loss 0.2021 (0.2021)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:47:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.190 (0.478)	Loss 0.2078 (0.2027)	Acc@1 96.094 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:47:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.326)	Loss 0.1874 (0.2119)	Acc@1 97.656 (95.945)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:47:24 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.299)	Loss 0.2426 (0.2159)	Acc@1 91.406 (95.514)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:47:26 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.480 Acc@5 100.000
[2024-11-09 17:47:26 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.5%
[2024-11-09 17:47:26 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.66%
[2024-11-09 17:47:28 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.800 (2.800)	Loss 0.2036 (0.2036)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:47:30 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.196 (0.415)	Loss 0.2118 (0.2115)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:47:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.171 (0.325)	Loss 0.2347 (0.2252)	Acc@1 95.312 (94.159)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:47:34 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.162 (0.281)	Loss 0.2961 (0.2434)	Acc@1 92.188 (93.397)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:47:36 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.240 Acc@5 100.000
[2024-11-09 17:47:36 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.2%
[2024-11-09 17:47:36 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.24%
[2024-11-09 17:47:40 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][0/156]	eta 0:10:58 lr 0.000017	 wd 0.0500	time 4.2191 (4.2191)	data time 3.8048 (3.8048)	model time 0.0000 (0.0000)	loss 0.5962 (0.5962)	grad_norm 2.0451 (2.0451)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:47:45 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][10/156]	eta 0:01:59 lr 0.000017	 wd 0.0500	time 0.4683 (0.8190)	data time 0.0050 (0.3506)	model time 0.0000 (0.0000)	loss 0.4831 (0.5537)	grad_norm 3.8503 (3.0652)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:47:50 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][20/156]	eta 0:01:30 lr 0.000017	 wd 0.0500	time 0.4768 (0.6682)	data time 0.0015 (0.1890)	model time 0.0000 (0.0000)	loss 0.6305 (0.5405)	grad_norm 2.0768 (3.0103)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:47:55 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][30/156]	eta 0:01:17 lr 0.000017	 wd 0.0500	time 0.6967 (0.6135)	data time 0.0995 (0.1367)	model time 0.0000 (0.0000)	loss 0.5840 (0.5360)	grad_norm 3.2658 (3.1666)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:47:59 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][40/156]	eta 0:01:06 lr 0.000017	 wd 0.0500	time 0.4677 (0.5755)	data time 0.0006 (0.1047)	model time 0.0000 (0.0000)	loss 0.5317 (0.5311)	grad_norm 1.8897 (3.1429)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:04 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][50/156]	eta 0:00:58 lr 0.000017	 wd 0.0500	time 0.4836 (0.5563)	data time 0.0008 (0.0872)	model time 0.0000 (0.0000)	loss 0.4988 (0.5334)	grad_norm 2.6841 (3.2533)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:09 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][60/156]	eta 0:00:52 lr 0.000017	 wd 0.0500	time 0.5714 (0.5418)	data time 0.0249 (0.0763)	model time 0.5465 (0.4476)	loss 0.6558 (0.5317)	grad_norm 3.1057 (3.3346)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:14 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][70/156]	eta 0:00:45 lr 0.000017	 wd 0.0500	time 0.4774 (0.5327)	data time 0.0112 (0.0688)	model time 0.4662 (0.4507)	loss 0.4495 (0.5317)	grad_norm 4.2340 (3.3165)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:18 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][80/156]	eta 0:00:39 lr 0.000017	 wd 0.0500	time 0.4368 (0.5260)	data time 0.0006 (0.0618)	model time 0.4362 (0.4559)	loss 0.4262 (0.5318)	grad_norm 2.6842 (3.3236)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:23 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][90/156]	eta 0:00:34 lr 0.000017	 wd 0.0500	time 0.5780 (0.5208)	data time 0.0053 (0.0558)	model time 0.5726 (0.4599)	loss 0.5488 (0.5338)	grad_norm 2.6930 (3.2620)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:28 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][100/156]	eta 0:00:29 lr 0.000017	 wd 0.0500	time 0.4501 (0.5191)	data time 0.0107 (0.0515)	model time 0.4394 (0.4661)	loss 0.5850 (0.5391)	grad_norm 4.1446 (3.2096)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:33 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][110/156]	eta 0:00:23 lr 0.000017	 wd 0.0500	time 0.4158 (0.5185)	data time 0.0006 (0.0478)	model time 0.4153 (0.4720)	loss 0.4465 (0.5388)	grad_norm 3.1963 (3.1635)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:39 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][120/156]	eta 0:00:18 lr 0.000017	 wd 0.0500	time 0.4588 (0.5229)	data time 0.0180 (0.0452)	model time 0.4408 (0.4840)	loss 0.5719 (0.5378)	grad_norm 3.6134 (3.1653)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:45 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][130/156]	eta 0:00:13 lr 0.000017	 wd 0.0500	time 0.6181 (0.5266)	data time 0.0538 (0.0444)	model time 0.5643 (0.4905)	loss 0.6449 (0.5384)	grad_norm 4.3226 (3.2251)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:50 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][140/156]	eta 0:00:08 lr 0.000017	 wd 0.0500	time 0.4359 (0.5252)	data time 0.0008 (0.0423)	model time 0.4351 (0.4907)	loss 0.4730 (0.5360)	grad_norm 2.6062 (3.2012)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:54 vssm1_tiny_0230s](training.py 201): INFO Train: [235/300][150/156]	eta 0:00:03 lr 0.000017	 wd 0.0500	time 0.4088 (0.5201)	data time 0.0005 (0.0398)	model time 0.4083 (0.4860)	loss 0.5648 (0.5358)	grad_norm 2.7458 (3.2329)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:48:57 vssm1_tiny_0230s](training.py 212): INFO EPOCH 235 training takes 0:01:21
[2024-11-09 17:48:57 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_235.pth saving......
[2024-11-09 17:48:57 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_235.pth saved !!!
[2024-11-09 17:48:59 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.620 (1.620)	Loss 0.1904 (0.1904)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:49:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.306)	Loss 0.2063 (0.1944)	Acc@1 93.750 (95.881)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:49:03 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.255)	Loss 0.1588 (0.2021)	Acc@1 98.438 (95.461)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:49:05 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.239)	Loss 0.2205 (0.1994)	Acc@1 93.750 (95.615)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:49:07 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.660 Acc@5 100.000
[2024-11-09 17:49:07 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 17:49:07 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.66%
[2024-11-09 17:49:09 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.240 (2.240)	Loss 0.2032 (0.2032)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:49:12 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.531 (0.455)	Loss 0.2114 (0.2111)	Acc@1 96.094 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:49:14 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.330)	Loss 0.2339 (0.2246)	Acc@1 95.312 (94.234)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:49:16 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.288)	Loss 0.2954 (0.2426)	Acc@1 92.188 (93.448)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:49:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.300 Acc@5 100.000
[2024-11-09 17:49:17 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.3%
[2024-11-09 17:49:17 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.30%
[2024-11-09 17:49:21 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][0/156]	eta 0:10:27 lr 0.000017	 wd 0.0500	time 4.0238 (4.0238)	data time 3.5942 (3.5942)	model time 0.0000 (0.0000)	loss 0.6218 (0.6218)	grad_norm 3.8342 (3.8342)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:49:26 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][10/156]	eta 0:01:54 lr 0.000016	 wd 0.0500	time 0.4569 (0.7811)	data time 0.0059 (0.3321)	model time 0.0000 (0.0000)	loss 0.5853 (0.5551)	grad_norm 1.7538 (2.9285)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:49:31 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][20/156]	eta 0:01:25 lr 0.000016	 wd 0.0500	time 0.5139 (0.6318)	data time 0.0113 (0.1774)	model time 0.0000 (0.0000)	loss 0.5768 (0.5354)	grad_norm 4.1732 (3.5452)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:49:36 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][30/156]	eta 0:01:13 lr 0.000016	 wd 0.0500	time 0.4412 (0.5836)	data time 0.0010 (0.1265)	model time 0.0000 (0.0000)	loss 0.4116 (0.5439)	grad_norm 3.4167 (3.3214)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:49:40 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][40/156]	eta 0:01:04 lr 0.000016	 wd 0.0500	time 0.5554 (0.5540)	data time 0.0090 (0.0983)	model time 0.0000 (0.0000)	loss 0.6080 (0.5370)	grad_norm 3.2028 (3.2432)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:49:45 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][50/156]	eta 0:00:56 lr 0.000016	 wd 0.0500	time 0.4284 (0.5370)	data time 0.0204 (0.0807)	model time 0.0000 (0.0000)	loss 0.4907 (0.5393)	grad_norm 2.3476 (3.1427)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:49:49 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][60/156]	eta 0:00:50 lr 0.000016	 wd 0.0500	time 0.4219 (0.5219)	data time 0.0168 (0.0698)	model time 0.4050 (0.4303)	loss 0.5346 (0.5405)	grad_norm 3.3361 (3.0689)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:49:53 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][70/156]	eta 0:00:43 lr 0.000016	 wd 0.0500	time 0.4074 (0.5081)	data time 0.0005 (0.0603)	model time 0.4069 (0.4261)	loss 0.5452 (0.5422)	grad_norm 1.5465 (3.0260)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:49:58 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][80/156]	eta 0:00:37 lr 0.000016	 wd 0.0500	time 0.4080 (0.4955)	data time 0.0005 (0.0529)	model time 0.4074 (0.4191)	loss 0.5451 (0.5448)	grad_norm 3.2781 (3.0703)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:50:02 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][90/156]	eta 0:00:32 lr 0.000016	 wd 0.0500	time 0.4291 (0.4888)	data time 0.0023 (0.0474)	model time 0.4268 (0.4224)	loss 0.4248 (0.5448)	grad_norm 2.8715 (3.1053)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:50:07 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][100/156]	eta 0:00:27 lr 0.000016	 wd 0.0500	time 0.5278 (0.4886)	data time 0.0031 (0.0443)	model time 0.5246 (0.4322)	loss 0.6191 (0.5484)	grad_norm 2.3937 (3.1062)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:50:12 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][110/156]	eta 0:00:22 lr 0.000016	 wd 0.0500	time 0.6066 (0.4883)	data time 0.0007 (0.0410)	model time 0.6059 (0.4396)	loss 0.4622 (0.5444)	grad_norm 3.2461 (3.0882)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:50:17 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][120/156]	eta 0:00:17 lr 0.000016	 wd 0.0500	time 0.4095 (0.4886)	data time 0.0017 (0.0384)	model time 0.4078 (0.4457)	loss 0.5679 (0.5473)	grad_norm 1.8147 (3.0421)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:50:21 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][130/156]	eta 0:00:12 lr 0.000016	 wd 0.0500	time 0.4372 (0.4869)	data time 0.0207 (0.0366)	model time 0.4165 (0.4466)	loss 0.5508 (0.5458)	grad_norm 2.6215 (3.0665)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:50:26 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][140/156]	eta 0:00:07 lr 0.000016	 wd 0.0500	time 0.5455 (0.4874)	data time 0.0009 (0.0347)	model time 0.5447 (0.4506)	loss 0.5588 (0.5453)	grad_norm 2.6756 (3.0702)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:50:31 vssm1_tiny_0230s](training.py 201): INFO Train: [236/300][150/156]	eta 0:00:02 lr 0.000016	 wd 0.0500	time 0.4947 (0.4852)	data time 0.0007 (0.0325)	model time 0.4940 (0.4510)	loss 0.5916 (0.5477)	grad_norm 2.1302 (3.0757)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:50:34 vssm1_tiny_0230s](training.py 212): INFO EPOCH 236 training takes 0:01:16
[2024-11-09 17:50:34 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_236.pth saving......
[2024-11-09 17:50:34 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_236.pth saved !!!
[2024-11-09 17:50:37 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.976 (2.976)	Loss 0.2084 (0.2084)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:50:39 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.412)	Loss 0.2181 (0.2096)	Acc@1 94.531 (96.165)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:50:41 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.317)	Loss 0.1952 (0.2170)	Acc@1 97.656 (95.982)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:50:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.225 (0.280)	Loss 0.2524 (0.2198)	Acc@1 91.406 (95.539)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:50:46 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.360 Acc@5 100.000
[2024-11-09 17:50:46 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.4%
[2024-11-09 17:50:46 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.66%
[2024-11-09 17:50:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.447 (3.447)	Loss 0.2029 (0.2029)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:50:51 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.152 (0.456)	Loss 0.2111 (0.2107)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:50:52 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.314)	Loss 0.2319 (0.2242)	Acc@1 95.312 (94.271)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:50:54 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.284)	Loss 0.2932 (0.2416)	Acc@1 92.188 (93.523)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:50:56 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.360 Acc@5 100.000
[2024-11-09 17:50:56 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.4%
[2024-11-09 17:50:56 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.36%
[2024-11-09 17:51:01 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][0/156]	eta 0:10:45 lr 0.000016	 wd 0.0500	time 4.1373 (4.1373)	data time 3.6279 (3.6279)	model time 0.0000 (0.0000)	loss 0.4442 (0.4442)	grad_norm 4.7413 (4.7413)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:05 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][10/156]	eta 0:01:59 lr 0.000016	 wd 0.0500	time 0.4856 (0.8193)	data time 0.0225 (0.3472)	model time 0.0000 (0.0000)	loss 0.6064 (0.5394)	grad_norm 3.8850 (3.5310)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:10 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][20/156]	eta 0:01:29 lr 0.000016	 wd 0.0500	time 0.5160 (0.6601)	data time 0.0019 (0.1843)	model time 0.0000 (0.0000)	loss 0.5587 (0.5534)	grad_norm 3.7560 (3.2226)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:15 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][30/156]	eta 0:01:15 lr 0.000016	 wd 0.0500	time 0.4486 (0.5987)	data time 0.0005 (0.1270)	model time 0.0000 (0.0000)	loss 0.5037 (0.5557)	grad_norm 1.4564 (3.0202)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:20 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][40/156]	eta 0:01:07 lr 0.000016	 wd 0.0500	time 0.6108 (0.5803)	data time 0.0049 (0.0982)	model time 0.0000 (0.0000)	loss 0.5120 (0.5498)	grad_norm 1.9950 (3.0268)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:26 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][50/156]	eta 0:01:00 lr 0.000016	 wd 0.0500	time 0.5081 (0.5739)	data time 0.0293 (0.0840)	model time 0.0000 (0.0000)	loss 0.5278 (0.5504)	grad_norm 4.9859 (3.0304)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:31 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][60/156]	eta 0:00:54 lr 0.000016	 wd 0.0500	time 0.5476 (0.5694)	data time 0.0237 (0.0751)	model time 0.5239 (0.5166)	loss 0.5855 (0.5493)	grad_norm 2.1125 (2.9844)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:36 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][70/156]	eta 0:00:48 lr 0.000016	 wd 0.0500	time 0.5526 (0.5591)	data time 0.0104 (0.0664)	model time 0.5422 (0.4997)	loss 0.6254 (0.5464)	grad_norm 2.8819 (3.0306)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:41 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][80/156]	eta 0:00:41 lr 0.000016	 wd 0.0500	time 0.5524 (0.5475)	data time 0.0334 (0.0594)	model time 0.5190 (0.4849)	loss 0.4881 (0.5407)	grad_norm 2.5307 (3.0652)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:46 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][90/156]	eta 0:00:35 lr 0.000016	 wd 0.0500	time 0.4919 (0.5409)	data time 0.0045 (0.0540)	model time 0.4874 (0.4832)	loss 0.5971 (0.5421)	grad_norm 3.6754 (3.1170)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:50 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][100/156]	eta 0:00:29 lr 0.000016	 wd 0.0500	time 0.4605 (0.5319)	data time 0.0111 (0.0497)	model time 0.4494 (0.4743)	loss 0.6259 (0.5404)	grad_norm 3.4961 (3.1313)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:55 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][110/156]	eta 0:00:24 lr 0.000016	 wd 0.0500	time 0.6334 (0.5273)	data time 0.0009 (0.0461)	model time 0.6324 (0.4737)	loss 0.4921 (0.5418)	grad_norm 3.6155 (3.0952)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:51:59 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][120/156]	eta 0:00:18 lr 0.000016	 wd 0.0500	time 0.4132 (0.5202)	data time 0.0007 (0.0427)	model time 0.4125 (0.4683)	loss 0.4219 (0.5390)	grad_norm 4.3902 (3.0835)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:52:04 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][130/156]	eta 0:00:13 lr 0.000016	 wd 0.0500	time 0.6319 (0.5155)	data time 0.0007 (0.0400)	model time 0.6312 (0.4663)	loss 0.3903 (0.5389)	grad_norm 3.4519 (3.1092)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:52:08 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][140/156]	eta 0:00:08 lr 0.000016	 wd 0.0500	time 0.4126 (0.5109)	data time 0.0008 (0.0379)	model time 0.4119 (0.4634)	loss 0.6673 (0.5406)	grad_norm 5.7347 (3.1630)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:52:13 vssm1_tiny_0230s](training.py 201): INFO Train: [237/300][150/156]	eta 0:00:03 lr 0.000016	 wd 0.0500	time 0.4167 (0.5090)	data time 0.0006 (0.0357)	model time 0.4161 (0.4647)	loss 0.5488 (0.5389)	grad_norm 3.4031 (3.2018)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:52:16 vssm1_tiny_0230s](training.py 212): INFO EPOCH 237 training takes 0:01:19
[2024-11-09 17:52:16 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_237.pth saving......
[2024-11-09 17:52:16 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_237.pth saved !!!
[2024-11-09 17:52:19 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.243 (3.243)	Loss 0.1930 (0.1930)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:52:21 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.172 (0.464)	Loss 0.1974 (0.1903)	Acc@1 96.875 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:52:23 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.315)	Loss 0.1877 (0.1995)	Acc@1 97.656 (96.243)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:52:24 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.267)	Loss 0.2426 (0.2081)	Acc@1 92.188 (95.691)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:52:27 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.400 Acc@5 100.000
[2024-11-09 17:52:27 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.4%
[2024-11-09 17:52:27 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.66%
[2024-11-09 17:52:30 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.989 (2.989)	Loss 0.2025 (0.2025)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:52:32 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.448)	Loss 0.2107 (0.2101)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:52:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.329)	Loss 0.2310 (0.2236)	Acc@1 95.312 (94.271)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:52:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.197 (0.285)	Loss 0.2922 (0.2408)	Acc@1 92.188 (93.548)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:52:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.400 Acc@5 100.000
[2024-11-09 17:52:38 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.4%
[2024-11-09 17:52:38 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.40%
[2024-11-09 17:52:42 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][0/156]	eta 0:10:25 lr 0.000016	 wd 0.0500	time 4.0068 (4.0068)	data time 3.2778 (3.2778)	model time 0.0000 (0.0000)	loss 0.6348 (0.6348)	grad_norm 4.3483 (4.3483)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:52:46 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][10/156]	eta 0:01:55 lr 0.000016	 wd 0.0500	time 0.4402 (0.7884)	data time 0.0043 (0.3116)	model time 0.0000 (0.0000)	loss 0.5831 (0.5650)	grad_norm 3.4001 (3.6546)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:52:51 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][20/156]	eta 0:01:27 lr 0.000016	 wd 0.0500	time 0.5263 (0.6424)	data time 0.0205 (0.1684)	model time 0.0000 (0.0000)	loss 0.5297 (0.5420)	grad_norm 2.8519 (3.3685)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:52:56 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][30/156]	eta 0:01:15 lr 0.000016	 wd 0.0500	time 0.4782 (0.5986)	data time 0.0006 (0.1198)	model time 0.0000 (0.0000)	loss 0.5440 (0.5485)	grad_norm 3.1047 (3.3329)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:01 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][40/156]	eta 0:01:06 lr 0.000016	 wd 0.0500	time 0.4506 (0.5740)	data time 0.0423 (0.0937)	model time 0.0000 (0.0000)	loss 0.4450 (0.5441)	grad_norm 2.9621 (3.2500)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:06 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][50/156]	eta 0:00:58 lr 0.000015	 wd 0.0500	time 0.5922 (0.5551)	data time 0.1076 (0.0799)	model time 0.0000 (0.0000)	loss 0.4829 (0.5496)	grad_norm 4.2723 (3.2806)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:11 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][60/156]	eta 0:00:51 lr 0.000015	 wd 0.0500	time 0.5068 (0.5411)	data time 0.0263 (0.0694)	model time 0.4805 (0.4535)	loss 0.4477 (0.5494)	grad_norm 3.1886 (3.2622)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:16 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][70/156]	eta 0:00:45 lr 0.000015	 wd 0.0500	time 0.4152 (0.5333)	data time 0.0010 (0.0609)	model time 0.4143 (0.4653)	loss 0.5710 (0.5419)	grad_norm 2.2951 (3.2759)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:20 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][80/156]	eta 0:00:39 lr 0.000015	 wd 0.0500	time 0.5121 (0.5221)	data time 0.0152 (0.0546)	model time 0.4970 (0.4545)	loss 0.5757 (0.5380)	grad_norm 3.4801 (3.3429)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:25 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][90/156]	eta 0:00:34 lr 0.000015	 wd 0.0500	time 0.4993 (0.5206)	data time 0.0010 (0.0505)	model time 0.4983 (0.4635)	loss 0.6833 (0.5398)	grad_norm 2.3743 (3.2644)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:30 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][100/156]	eta 0:00:28 lr 0.000015	 wd 0.0500	time 0.4837 (0.5155)	data time 0.0066 (0.0465)	model time 0.4771 (0.4627)	loss 0.4877 (0.5392)	grad_norm 1.9427 (3.2362)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:34 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][110/156]	eta 0:00:23 lr 0.000015	 wd 0.0500	time 0.4229 (0.5067)	data time 0.0005 (0.0427)	model time 0.4224 (0.4545)	loss 0.5143 (0.5402)	grad_norm 2.5757 (3.2373)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:38 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][120/156]	eta 0:00:18 lr 0.000015	 wd 0.0500	time 0.5618 (0.5019)	data time 0.1007 (0.0407)	model time 0.4612 (0.4510)	loss 0.5581 (0.5385)	grad_norm 1.6906 (3.2206)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:43 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][130/156]	eta 0:00:12 lr 0.000015	 wd 0.0500	time 0.4117 (0.4999)	data time 0.0060 (0.0382)	model time 0.4057 (0.4531)	loss 0.5979 (0.5382)	grad_norm 2.0977 (3.2395)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:48 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][140/156]	eta 0:00:07 lr 0.000015	 wd 0.0500	time 0.4947 (0.4979)	data time 0.0010 (0.0361)	model time 0.4937 (0.4542)	loss 0.4995 (0.5392)	grad_norm 2.1003 (3.2188)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:52 vssm1_tiny_0230s](training.py 201): INFO Train: [238/300][150/156]	eta 0:00:02 lr 0.000015	 wd 0.0500	time 0.4497 (0.4942)	data time 0.0005 (0.0337)	model time 0.4492 (0.4530)	loss 0.4950 (0.5393)	grad_norm 3.9690 (3.2442)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:53:55 vssm1_tiny_0230s](training.py 212): INFO EPOCH 238 training takes 0:01:17
[2024-11-09 17:53:55 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_238.pth saving......
[2024-11-09 17:53:55 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_238.pth saved !!!
[2024-11-09 17:53:57 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.881 (1.881)	Loss 0.2153 (0.2153)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:54:01 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.159 (0.473)	Loss 0.2251 (0.2156)	Acc@1 93.750 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:54:03 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.184 (0.384)	Loss 0.1764 (0.2235)	Acc@1 99.219 (94.978)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:54:05 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.152 (0.322)	Loss 0.2318 (0.2180)	Acc@1 92.969 (95.489)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:54:07 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.580 Acc@5 100.000
[2024-11-09 17:54:07 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 17:54:07 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.66%
[2024-11-09 17:54:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.733 (3.733)	Loss 0.2021 (0.2021)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:54:13 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.155 (0.545)	Loss 0.2102 (0.2097)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:54:15 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.358)	Loss 0.2300 (0.2230)	Acc@1 95.312 (94.271)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:54:16 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.215 (0.292)	Loss 0.2913 (0.2400)	Acc@1 92.188 (93.599)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:54:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.440 Acc@5 100.000
[2024-11-09 17:54:18 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.4%
[2024-11-09 17:54:18 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.44%
[2024-11-09 17:54:22 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][0/156]	eta 0:10:03 lr 0.000015	 wd 0.0500	time 3.8707 (3.8707)	data time 3.2392 (3.2392)	model time 0.0000 (0.0000)	loss 0.5415 (0.5415)	grad_norm 2.5439 (2.5439)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:54:27 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][10/156]	eta 0:01:58 lr 0.000015	 wd 0.0500	time 0.4515 (0.8125)	data time 0.0009 (0.3111)	model time 0.0000 (0.0000)	loss 0.6053 (0.5501)	grad_norm 2.7058 (3.3552)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:54:31 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][20/156]	eta 0:01:28 lr 0.000015	 wd 0.0500	time 0.4294 (0.6523)	data time 0.0118 (0.1681)	model time 0.0000 (0.0000)	loss 0.5924 (0.5405)	grad_norm 3.0333 (3.1626)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:54:36 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][30/156]	eta 0:01:15 lr 0.000015	 wd 0.0500	time 0.6169 (0.5958)	data time 0.1137 (0.1193)	model time 0.0000 (0.0000)	loss 0.5902 (0.5467)	grad_norm 3.9103 (2.9632)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:54:41 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][40/156]	eta 0:01:06 lr 0.000015	 wd 0.0500	time 0.5467 (0.5705)	data time 0.0250 (0.0933)	model time 0.0000 (0.0000)	loss 0.6308 (0.5493)	grad_norm 2.8455 (2.9383)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:54:46 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][50/156]	eta 0:00:58 lr 0.000015	 wd 0.0500	time 0.4608 (0.5548)	data time 0.0010 (0.0790)	model time 0.0000 (0.0000)	loss 0.4653 (0.5498)	grad_norm 3.3044 (2.9851)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:54:51 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][60/156]	eta 0:00:52 lr 0.000015	 wd 0.0500	time 0.4635 (0.5422)	data time 0.0105 (0.0678)	model time 0.4530 (0.4673)	loss 0.6253 (0.5472)	grad_norm 3.6814 (3.0325)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:54:56 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][70/156]	eta 0:00:45 lr 0.000015	 wd 0.0500	time 0.6635 (0.5329)	data time 0.0201 (0.0602)	model time 0.6434 (0.4649)	loss 0.5516 (0.5469)	grad_norm 4.0559 (3.0216)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:55:00 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][80/156]	eta 0:00:39 lr 0.000015	 wd 0.0500	time 0.5202 (0.5252)	data time 0.0007 (0.0539)	model time 0.5195 (0.4636)	loss 0.6334 (0.5501)	grad_norm 2.3897 (2.9748)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:55:05 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][90/156]	eta 0:00:34 lr 0.000015	 wd 0.0500	time 0.4156 (0.5160)	data time 0.0005 (0.0493)	model time 0.4150 (0.4550)	loss 0.5080 (0.5458)	grad_norm 3.1403 (2.9668)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:55:10 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][100/156]	eta 0:00:28 lr 0.000015	 wd 0.0500	time 0.4452 (0.5177)	data time 0.0091 (0.0458)	model time 0.4361 (0.4678)	loss 0.5349 (0.5460)	grad_norm 2.5004 (2.9256)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:55:15 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][110/156]	eta 0:00:23 lr 0.000015	 wd 0.0500	time 0.4726 (0.5122)	data time 0.0258 (0.0424)	model time 0.4468 (0.4647)	loss 0.5641 (0.5473)	grad_norm 1.7122 (2.9248)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:55:19 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][120/156]	eta 0:00:18 lr 0.000015	 wd 0.0500	time 0.6089 (0.5094)	data time 0.0189 (0.0397)	model time 0.5900 (0.4653)	loss 0.4782 (0.5444)	grad_norm 3.0746 (2.9496)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:55:25 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][130/156]	eta 0:00:13 lr 0.000015	 wd 0.0500	time 0.7405 (0.5121)	data time 0.0379 (0.0376)	model time 0.7025 (0.4737)	loss 0.4841 (0.5446)	grad_norm 2.5495 (2.9460)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:55:30 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][140/156]	eta 0:00:08 lr 0.000015	 wd 0.0500	time 0.5661 (0.5142)	data time 0.0008 (0.0372)	model time 0.5653 (0.4777)	loss 0.4611 (0.5462)	grad_norm 3.6285 (2.9769)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:55:35 vssm1_tiny_0230s](training.py 201): INFO Train: [239/300][150/156]	eta 0:00:03 lr 0.000015	 wd 0.0500	time 0.4946 (0.5119)	data time 0.0005 (0.0348)	model time 0.4940 (0.4778)	loss 0.5751 (0.5450)	grad_norm 3.4810 (3.0367)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:55:38 vssm1_tiny_0230s](training.py 212): INFO EPOCH 239 training takes 0:01:20
[2024-11-09 17:55:38 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_239.pth saving......
[2024-11-09 17:55:38 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_239.pth saved !!!
[2024-11-09 17:55:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.859 (2.859)	Loss 0.1890 (0.1890)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:55:44 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.141 (0.461)	Loss 0.1975 (0.1937)	Acc@1 96.094 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:55:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.328)	Loss 0.1884 (0.2027)	Acc@1 97.656 (95.685)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:55:47 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.316 (0.286)	Loss 0.2456 (0.2102)	Acc@1 92.188 (95.439)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:55:50 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.320 Acc@5 100.000
[2024-11-09 17:55:50 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.3%
[2024-11-09 17:55:50 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.66%
[2024-11-09 17:55:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.323 (2.323)	Loss 0.2019 (0.2019)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:55:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.260 (0.444)	Loss 0.2098 (0.2092)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:55:57 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.177 (0.339)	Loss 0.2285 (0.2225)	Acc@1 96.094 (94.345)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:55:59 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.159 (0.286)	Loss 0.2898 (0.2391)	Acc@1 92.188 (93.649)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:56:01 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.500 Acc@5 100.000
[2024-11-09 17:56:01 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.5%
[2024-11-09 17:56:01 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.50%
[2024-11-09 17:56:04 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][0/156]	eta 0:09:00 lr 0.000015	 wd 0.0500	time 3.4647 (3.4647)	data time 2.8805 (2.8805)	model time 0.0000 (0.0000)	loss 0.5828 (0.5828)	grad_norm 2.0388 (2.0388)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:09 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][10/156]	eta 0:01:51 lr 0.000015	 wd 0.0500	time 0.4448 (0.7666)	data time 0.0122 (0.2754)	model time 0.0000 (0.0000)	loss 0.5393 (0.5279)	grad_norm 3.3573 (3.2815)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:14 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][20/156]	eta 0:01:26 lr 0.000015	 wd 0.0500	time 0.5369 (0.6335)	data time 0.0022 (0.1483)	model time 0.0000 (0.0000)	loss 0.6182 (0.5310)	grad_norm 3.5743 (3.1403)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:19 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][30/156]	eta 0:01:15 lr 0.000015	 wd 0.0500	time 0.5959 (0.5984)	data time 0.0480 (0.1075)	model time 0.0000 (0.0000)	loss 0.4362 (0.5298)	grad_norm 3.6829 (3.1823)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:24 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][40/156]	eta 0:01:05 lr 0.000015	 wd 0.0500	time 0.4473 (0.5678)	data time 0.0270 (0.0858)	model time 0.0000 (0.0000)	loss 0.5506 (0.5327)	grad_norm 2.1671 (3.0820)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:28 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][50/156]	eta 0:00:57 lr 0.000015	 wd 0.0500	time 0.4209 (0.5460)	data time 0.0005 (0.0705)	model time 0.0000 (0.0000)	loss 0.5236 (0.5311)	grad_norm 2.5950 (3.0985)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:33 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][60/156]	eta 0:00:51 lr 0.000015	 wd 0.0500	time 0.4467 (0.5366)	data time 0.0404 (0.0629)	model time 0.4063 (0.4642)	loss 0.5529 (0.5273)	grad_norm 2.2363 (3.1442)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:38 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][70/156]	eta 0:00:45 lr 0.000015	 wd 0.0500	time 0.4640 (0.5261)	data time 0.0179 (0.0555)	model time 0.4461 (0.4578)	loss 0.6570 (0.5291)	grad_norm 3.6353 (3.1513)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:43 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][80/156]	eta 0:00:39 lr 0.000015	 wd 0.0500	time 0.5182 (0.5228)	data time 0.0236 (0.0507)	model time 0.4945 (0.4664)	loss 0.6132 (0.5283)	grad_norm 2.5423 (3.2041)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:48 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][90/156]	eta 0:00:34 lr 0.000015	 wd 0.0500	time 0.5165 (0.5203)	data time 0.0132 (0.0460)	model time 0.5034 (0.4727)	loss 0.5074 (0.5293)	grad_norm 1.7054 (3.2038)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:53 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][100/156]	eta 0:00:28 lr 0.000014	 wd 0.0500	time 0.4206 (0.5151)	data time 0.0088 (0.0424)	model time 0.4118 (0.4697)	loss 0.6215 (0.5315)	grad_norm 3.0962 (3.2008)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:56:58 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][110/156]	eta 0:00:23 lr 0.000014	 wd 0.0500	time 0.4748 (0.5142)	data time 0.0012 (0.0393)	model time 0.4736 (0.4743)	loss 0.6884 (0.5327)	grad_norm 3.1630 (3.2315)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:57:03 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][120/156]	eta 0:00:18 lr 0.000014	 wd 0.0500	time 0.4589 (0.5122)	data time 0.0013 (0.0371)	model time 0.4576 (0.4748)	loss 0.5243 (0.5344)	grad_norm 2.4479 (3.2561)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:57:07 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][130/156]	eta 0:00:13 lr 0.000014	 wd 0.0500	time 0.5838 (0.5103)	data time 0.0034 (0.0356)	model time 0.5804 (0.4743)	loss 0.4625 (0.5345)	grad_norm 3.6095 (3.2699)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:57:12 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][140/156]	eta 0:00:08 lr 0.000014	 wd 0.0500	time 0.4197 (0.5072)	data time 0.0008 (0.0339)	model time 0.4190 (0.4720)	loss 0.5789 (0.5360)	grad_norm 2.2856 (3.2377)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:57:17 vssm1_tiny_0230s](training.py 201): INFO Train: [240/300][150/156]	eta 0:00:03 lr 0.000014	 wd 0.0500	time 0.4131 (0.5043)	data time 0.0057 (0.0320)	model time 0.4074 (0.4707)	loss 0.5881 (0.5371)	grad_norm 2.2650 (3.2211)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:57:19 vssm1_tiny_0230s](training.py 212): INFO EPOCH 240 training takes 0:01:18
[2024-11-09 17:57:19 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_240.pth saving......
[2024-11-09 17:57:20 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_240.pth saved !!!
[2024-11-09 17:57:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.972 (2.972)	Loss 0.2014 (0.2014)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:57:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.159 (0.507)	Loss 0.2124 (0.2014)	Acc@1 95.312 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:57:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.154 (0.360)	Loss 0.1918 (0.2095)	Acc@1 96.875 (95.945)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:57:29 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.289)	Loss 0.2427 (0.2141)	Acc@1 92.969 (95.766)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:57:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.680 Acc@5 100.000
[2024-11-09 17:57:31 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 17:57:31 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.68%
[2024-11-09 17:57:35 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.462 (3.462)	Loss 0.2015 (0.2015)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:57:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.533)	Loss 0.2095 (0.2088)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:57:39 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.154 (0.385)	Loss 0.2275 (0.2220)	Acc@1 96.094 (94.345)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:57:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.144 (0.319)	Loss 0.2888 (0.2383)	Acc@1 92.188 (93.649)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:57:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.520 Acc@5 100.000
[2024-11-09 17:57:43 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.5%
[2024-11-09 17:57:43 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.52%
[2024-11-09 17:57:48 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][0/156]	eta 0:12:28 lr 0.000014	 wd 0.0500	time 4.7998 (4.7998)	data time 4.3448 (4.3448)	model time 0.0000 (0.0000)	loss 0.5901 (0.5901)	grad_norm 4.6233 (4.6233)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:57:53 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][10/156]	eta 0:02:10 lr 0.000014	 wd 0.0500	time 0.4383 (0.8941)	data time 0.0172 (0.4257)	model time 0.0000 (0.0000)	loss 0.5789 (0.5345)	grad_norm 2.5242 (3.5225)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:57:58 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][20/156]	eta 0:01:35 lr 0.000014	 wd 0.0500	time 0.4257 (0.7013)	data time 0.0007 (0.2260)	model time 0.0000 (0.0000)	loss 0.4962 (0.5262)	grad_norm 3.3735 (3.5639)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:03 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][30/156]	eta 0:01:19 lr 0.000014	 wd 0.0500	time 0.4317 (0.6346)	data time 0.0115 (0.1582)	model time 0.0000 (0.0000)	loss 0.4534 (0.5274)	grad_norm 3.6317 (3.4662)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:07 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][40/156]	eta 0:01:08 lr 0.000014	 wd 0.0500	time 0.4338 (0.5907)	data time 0.0015 (0.1220)	model time 0.0000 (0.0000)	loss 0.5931 (0.5354)	grad_norm 2.5809 (3.2662)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:12 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][50/156]	eta 0:00:59 lr 0.000014	 wd 0.0500	time 0.4858 (0.5615)	data time 0.0239 (0.1013)	model time 0.0000 (0.0000)	loss 0.5383 (0.5404)	grad_norm 2.4071 (3.2096)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:16 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][60/156]	eta 0:00:52 lr 0.000014	 wd 0.0500	time 0.5419 (0.5450)	data time 0.0007 (0.0859)	model time 0.5413 (0.4532)	loss 0.4507 (0.5433)	grad_norm 6.9450 (3.2418)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:21 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][70/156]	eta 0:00:45 lr 0.000014	 wd 0.0500	time 0.4639 (0.5322)	data time 0.0008 (0.0749)	model time 0.4631 (0.4499)	loss 0.5419 (0.5423)	grad_norm 3.5593 (3.2874)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:26 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][80/156]	eta 0:00:39 lr 0.000014	 wd 0.0500	time 0.5178 (0.5255)	data time 0.0050 (0.0667)	model time 0.5128 (0.4564)	loss 0.5008 (0.5377)	grad_norm 3.1659 (3.3087)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:31 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][90/156]	eta 0:00:34 lr 0.000014	 wd 0.0500	time 0.5423 (0.5219)	data time 0.0037 (0.0602)	model time 0.5387 (0.4635)	loss 0.4943 (0.5373)	grad_norm 3.0511 (3.2703)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:36 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][100/156]	eta 0:00:29 lr 0.000014	 wd 0.0500	time 0.4371 (0.5197)	data time 0.0016 (0.0559)	model time 0.4355 (0.4675)	loss 0.5084 (0.5377)	grad_norm 2.1305 (3.2459)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:40 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][110/156]	eta 0:00:23 lr 0.000014	 wd 0.0500	time 0.4274 (0.5120)	data time 0.0008 (0.0514)	model time 0.4266 (0.4608)	loss 0.4713 (0.5418)	grad_norm 2.8671 (3.2311)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:44 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][120/156]	eta 0:00:18 lr 0.000014	 wd 0.0500	time 0.4394 (0.5060)	data time 0.0007 (0.0480)	model time 0.4387 (0.4565)	loss 0.6167 (0.5419)	grad_norm 3.6650 (3.2095)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:49 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][130/156]	eta 0:00:13 lr 0.000014	 wd 0.0500	time 0.4469 (0.5033)	data time 0.0012 (0.0454)	model time 0.4457 (0.4564)	loss 0.5727 (0.5414)	grad_norm 2.2466 (3.1885)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:54 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][140/156]	eta 0:00:08 lr 0.000014	 wd 0.0500	time 0.4847 (0.5027)	data time 0.0091 (0.0438)	model time 0.4756 (0.4582)	loss 0.5197 (0.5422)	grad_norm 4.4737 (3.1642)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:58:59 vssm1_tiny_0230s](training.py 201): INFO Train: [241/300][150/156]	eta 0:00:03 lr 0.000014	 wd 0.0500	time 0.4416 (0.5024)	data time 0.0007 (0.0412)	model time 0.4408 (0.4616)	loss 0.5128 (0.5385)	grad_norm 3.6370 (3.1862)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:59:01 vssm1_tiny_0230s](training.py 212): INFO EPOCH 241 training takes 0:01:18
[2024-11-09 17:59:01 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_241.pth saving......
[2024-11-09 17:59:02 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_241.pth saved !!!
[2024-11-09 17:59:05 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.187 (3.187)	Loss 0.2015 (0.2015)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:59:07 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.296 (0.487)	Loss 0.2065 (0.2004)	Acc@1 95.312 (96.662)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:59:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.187 (0.373)	Loss 0.1703 (0.2078)	Acc@1 98.438 (96.019)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:59:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.152 (0.333)	Loss 0.2322 (0.2077)	Acc@1 91.406 (95.766)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:59:14 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.580 Acc@5 100.000
[2024-11-09 17:59:14 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 17:59:14 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.68%
[2024-11-09 17:59:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.936 (1.936)	Loss 0.2017 (0.2017)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:59:19 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.398)	Loss 0.2094 (0.2086)	Acc@1 96.094 (95.810)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:59:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.298)	Loss 0.2263 (0.2217)	Acc@1 96.094 (94.420)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:59:23 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.277)	Loss 0.2876 (0.2377)	Acc@1 92.188 (93.700)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 17:59:26 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.560 Acc@5 100.000
[2024-11-09 17:59:26 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.6%
[2024-11-09 17:59:26 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.56%
[2024-11-09 17:59:31 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][0/156]	eta 0:13:33 lr 0.000014	 wd 0.0500	time 5.2170 (5.2170)	data time 4.6093 (4.6093)	model time 0.0000 (0.0000)	loss 0.5006 (0.5006)	grad_norm 4.4818 (4.4818)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:59:38 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][10/156]	eta 0:02:43 lr 0.000014	 wd 0.0500	time 0.5348 (1.1196)	data time 0.0093 (0.4551)	model time 0.0000 (0.0000)	loss 0.6357 (0.5568)	grad_norm 3.5440 (4.2064)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:59:43 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][20/156]	eta 0:01:51 lr 0.000014	 wd 0.0500	time 0.4965 (0.8196)	data time 0.0250 (0.2429)	model time 0.0000 (0.0000)	loss 0.6087 (0.5503)	grad_norm 3.9498 (4.6541)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:59:47 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][30/156]	eta 0:01:28 lr 0.000014	 wd 0.0500	time 0.4675 (0.7027)	data time 0.0250 (0.1682)	model time 0.0000 (0.0000)	loss 0.5938 (0.5430)	grad_norm 2.8022 (4.4485)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:59:52 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][40/156]	eta 0:01:14 lr 0.000014	 wd 0.0500	time 0.4460 (0.6397)	data time 0.0007 (0.1282)	model time 0.0000 (0.0000)	loss 0.5613 (0.5405)	grad_norm 3.3319 (4.3922)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 17:59:56 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][50/156]	eta 0:01:04 lr 0.000014	 wd 0.0500	time 0.4686 (0.6054)	data time 0.0011 (0.1050)	model time 0.0000 (0.0000)	loss 0.4609 (0.5408)	grad_norm 2.4769 (4.1145)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:01 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][60/156]	eta 0:00:56 lr 0.000014	 wd 0.0500	time 0.4405 (0.5860)	data time 0.0184 (0.0923)	model time 0.4220 (0.4589)	loss 0.4342 (0.5353)	grad_norm 5.3239 (4.0228)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:06 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][70/156]	eta 0:00:48 lr 0.000014	 wd 0.0500	time 0.4346 (0.5641)	data time 0.0015 (0.0796)	model time 0.4331 (0.4441)	loss 0.5364 (0.5356)	grad_norm 2.4660 (3.9421)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:10 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][80/156]	eta 0:00:41 lr 0.000014	 wd 0.0500	time 0.4337 (0.5493)	data time 0.0012 (0.0707)	model time 0.4325 (0.4415)	loss 0.5954 (0.5338)	grad_norm 2.7279 (4.0030)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:15 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][90/156]	eta 0:00:35 lr 0.000014	 wd 0.0500	time 0.4174 (0.5410)	data time 0.0095 (0.0642)	model time 0.4079 (0.4467)	loss 0.4122 (0.5319)	grad_norm 3.9226 (3.9291)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:19 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][100/156]	eta 0:00:29 lr 0.000014	 wd 0.0500	time 0.5031 (0.5334)	data time 0.0210 (0.0592)	model time 0.4821 (0.4475)	loss 0.5735 (0.5350)	grad_norm 1.7900 (3.8886)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:24 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][110/156]	eta 0:00:24 lr 0.000014	 wd 0.0500	time 0.4212 (0.5291)	data time 0.0006 (0.0558)	model time 0.4206 (0.4503)	loss 0.4206 (0.5346)	grad_norm 2.4105 (3.8493)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:29 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][120/156]	eta 0:00:18 lr 0.000014	 wd 0.0500	time 0.4495 (0.5238)	data time 0.0008 (0.0524)	model time 0.4486 (0.4502)	loss 0.5797 (0.5369)	grad_norm 1.5710 (3.7738)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:34 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][130/156]	eta 0:00:13 lr 0.000014	 wd 0.0500	time 0.4389 (0.5215)	data time 0.0127 (0.0488)	model time 0.4263 (0.4551)	loss 0.5607 (0.5397)	grad_norm 2.7252 (3.7002)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:39 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][140/156]	eta 0:00:08 lr 0.000014	 wd 0.0500	time 0.4090 (0.5186)	data time 0.0007 (0.0464)	model time 0.4083 (0.4562)	loss 0.6112 (0.5395)	grad_norm 3.2648 (3.6855)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:43 vssm1_tiny_0230s](training.py 201): INFO Train: [242/300][150/156]	eta 0:00:03 lr 0.000013	 wd 0.0500	time 0.4205 (0.5146)	data time 0.0006 (0.0433)	model time 0.4199 (0.4563)	loss 0.6732 (0.5397)	grad_norm 2.3404 (3.6183)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:00:46 vssm1_tiny_0230s](training.py 212): INFO EPOCH 242 training takes 0:01:20
[2024-11-09 18:00:46 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_242.pth saving......
[2024-11-09 18:00:46 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_242.pth saved !!!
[2024-11-09 18:00:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.781 (2.781)	Loss 0.2017 (0.2017)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:00:51 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.142 (0.439)	Loss 0.2092 (0.2009)	Acc@1 96.875 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:00:54 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.195 (0.336)	Loss 0.1937 (0.2095)	Acc@1 96.875 (95.945)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:00:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.285)	Loss 0.2522 (0.2158)	Acc@1 91.406 (95.565)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:00:58 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.400 Acc@5 100.000
[2024-11-09 18:00:58 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.4%
[2024-11-09 18:00:58 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.68%
[2024-11-09 18:01:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.573 (2.573)	Loss 0.2012 (0.2012)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:01:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.403)	Loss 0.2089 (0.2081)	Acc@1 96.094 (95.810)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:01:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.321)	Loss 0.2251 (0.2211)	Acc@1 96.094 (94.457)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:01:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.200 (0.287)	Loss 0.2864 (0.2367)	Acc@1 92.188 (93.750)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:01:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.620 Acc@5 100.000
[2024-11-09 18:01:08 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.6%
[2024-11-09 18:01:08 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.62%
[2024-11-09 18:01:12 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][0/156]	eta 0:10:06 lr 0.000013	 wd 0.0500	time 3.8869 (3.8869)	data time 3.4350 (3.4350)	model time 0.0000 (0.0000)	loss 0.4804 (0.4804)	grad_norm 2.2937 (2.2937)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:01:17 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][10/156]	eta 0:01:54 lr 0.000013	 wd 0.0500	time 0.5142 (0.7864)	data time 0.0008 (0.3200)	model time 0.0000 (0.0000)	loss 0.6325 (0.5455)	grad_norm 4.4955 (3.4724)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:01:22 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][20/156]	eta 0:01:28 lr 0.000013	 wd 0.0500	time 0.5262 (0.6473)	data time 0.0006 (0.1731)	model time 0.0000 (0.0000)	loss 0.6709 (0.5506)	grad_norm 2.5717 (3.0371)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:01:27 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][30/156]	eta 0:01:15 lr 0.000013	 wd 0.0500	time 0.4452 (0.6002)	data time 0.0023 (0.1223)	model time 0.0000 (0.0000)	loss 0.4203 (0.5420)	grad_norm 3.1102 (3.1271)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:01:32 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][40/156]	eta 0:01:07 lr 0.000013	 wd 0.0500	time 0.4302 (0.5800)	data time 0.0009 (0.0950)	model time 0.0000 (0.0000)	loss 0.4674 (0.5351)	grad_norm 3.0126 (3.2293)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:01:38 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][50/156]	eta 0:01:00 lr 0.000013	 wd 0.0500	time 0.5668 (0.5730)	data time 0.0329 (0.0793)	model time 0.0000 (0.0000)	loss 0.5856 (0.5319)	grad_norm 2.9840 (3.2919)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:01:43 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][60/156]	eta 0:00:53 lr 0.000013	 wd 0.0500	time 0.4148 (0.5619)	data time 0.0015 (0.0677)	model time 0.4133 (0.4968)	loss 0.6465 (0.5336)	grad_norm 2.2475 (3.2815)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:01:48 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][70/156]	eta 0:00:47 lr 0.000013	 wd 0.0500	time 0.5782 (0.5539)	data time 0.0024 (0.0588)	model time 0.5758 (0.4988)	loss 0.4630 (0.5355)	grad_norm 2.5411 (3.2476)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:01:53 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][80/156]	eta 0:00:41 lr 0.000013	 wd 0.0500	time 0.4793 (0.5484)	data time 0.0050 (0.0533)	model time 0.4743 (0.4976)	loss 0.4636 (0.5306)	grad_norm 1.7443 (3.1990)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:01:57 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][90/156]	eta 0:00:35 lr 0.000013	 wd 0.0500	time 0.5099 (0.5391)	data time 0.0257 (0.0488)	model time 0.4842 (0.4860)	loss 0.6319 (0.5332)	grad_norm 3.3954 (3.1743)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:02:02 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][100/156]	eta 0:00:29 lr 0.000013	 wd 0.0500	time 0.4471 (0.5325)	data time 0.0012 (0.0451)	model time 0.4459 (0.4811)	loss 0.4291 (0.5316)	grad_norm 2.7657 (3.1776)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:02:07 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][110/156]	eta 0:00:24 lr 0.000013	 wd 0.0500	time 0.4749 (0.5288)	data time 0.0058 (0.0419)	model time 0.4691 (0.4812)	loss 0.5898 (0.5302)	grad_norm 4.8152 (3.2321)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:02:12 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][120/156]	eta 0:00:18 lr 0.000013	 wd 0.0500	time 0.4134 (0.5221)	data time 0.0035 (0.0394)	model time 0.4100 (0.4748)	loss 0.6472 (0.5310)	grad_norm 3.1711 (3.2871)	loss_scale 65536.0000 (35476.0992)	mem 13675MB
[2024-11-09 18:02:16 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][130/156]	eta 0:00:13 lr 0.000013	 wd 0.0500	time 0.4732 (0.5166)	data time 0.0272 (0.0376)	model time 0.4459 (0.4697)	loss 0.4189 (0.5307)	grad_norm 5.4487 (3.3304)	loss_scale 65536.0000 (37770.7481)	mem 13675MB
[2024-11-09 18:02:21 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][140/156]	eta 0:00:08 lr 0.000013	 wd 0.0500	time 0.4174 (0.5131)	data time 0.0008 (0.0356)	model time 0.4165 (0.4683)	loss 0.5818 (0.5325)	grad_norm 2.5233 (3.3476)	loss_scale 65536.0000 (39739.9149)	mem 13675MB
[2024-11-09 18:02:25 vssm1_tiny_0230s](training.py 201): INFO Train: [243/300][150/156]	eta 0:00:03 lr 0.000013	 wd 0.0500	time 0.4115 (0.5087)	data time 0.0006 (0.0334)	model time 0.4110 (0.4659)	loss 0.5241 (0.5322)	grad_norm 2.8606 (3.3268)	loss_scale 65536.0000 (41448.2649)	mem 13675MB
[2024-11-09 18:02:28 vssm1_tiny_0230s](training.py 212): INFO EPOCH 243 training takes 0:01:19
[2024-11-09 18:02:28 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_243.pth saving......
[2024-11-09 18:02:28 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_243.pth saved !!!
[2024-11-09 18:02:32 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.172 (4.172)	Loss 0.2133 (0.2133)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:02:34 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.439 (0.549)	Loss 0.2177 (0.2106)	Acc@1 94.531 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:02:36 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.394)	Loss 0.1714 (0.2172)	Acc@1 98.438 (95.461)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:02:38 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.164 (0.315)	Loss 0.2261 (0.2141)	Acc@1 92.969 (95.565)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:02:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.520 Acc@5 100.000
[2024-11-09 18:02:40 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.5%
[2024-11-09 18:02:40 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.68%
[2024-11-09 18:02:43 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.637 (2.637)	Loss 0.2009 (0.2009)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:02:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.153 (0.427)	Loss 0.2085 (0.2077)	Acc@1 96.094 (95.810)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:02:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.332)	Loss 0.2240 (0.2206)	Acc@1 96.094 (94.494)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:02:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.293)	Loss 0.2852 (0.2360)	Acc@1 92.188 (93.851)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:02:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.760 Acc@5 100.000
[2024-11-09 18:02:51 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.8%
[2024-11-09 18:02:51 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.76%
[2024-11-09 18:02:53 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][0/156]	eta 0:06:00 lr 0.000013	 wd 0.0500	time 2.3113 (2.3113)	data time 1.9061 (1.9061)	model time 0.0000 (0.0000)	loss 0.5755 (0.5755)	grad_norm 2.0873 (2.0873)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:02:58 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][10/156]	eta 0:01:37 lr 0.000013	 wd 0.0500	time 0.4903 (0.6681)	data time 0.0071 (0.1976)	model time 0.0000 (0.0000)	loss 0.5596 (0.5299)	grad_norm 2.9564 (3.5062)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:03 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][20/156]	eta 0:01:17 lr 0.000013	 wd 0.0500	time 0.4238 (0.5698)	data time 0.0008 (0.1085)	model time 0.0000 (0.0000)	loss 0.5306 (0.5280)	grad_norm 2.8598 (3.4093)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:08 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][30/156]	eta 0:01:07 lr 0.000013	 wd 0.0500	time 0.4692 (0.5368)	data time 0.0084 (0.0751)	model time 0.0000 (0.0000)	loss 0.6617 (0.5367)	grad_norm 3.2559 (3.3153)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:12 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][40/156]	eta 0:00:59 lr 0.000013	 wd 0.0500	time 0.4133 (0.5165)	data time 0.0047 (0.0592)	model time 0.0000 (0.0000)	loss 0.5774 (0.5508)	grad_norm 4.5359 (3.3313)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:17 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][50/156]	eta 0:00:53 lr 0.000013	 wd 0.0500	time 0.4447 (0.5072)	data time 0.0144 (0.0503)	model time 0.0000 (0.0000)	loss 0.6313 (0.5495)	grad_norm 2.1524 (3.2828)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:21 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][60/156]	eta 0:00:47 lr 0.000013	 wd 0.0500	time 0.4907 (0.4983)	data time 0.0014 (0.0427)	model time 0.4892 (0.4489)	loss 0.6040 (0.5497)	grad_norm 2.1315 (3.2467)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:26 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][70/156]	eta 0:00:42 lr 0.000013	 wd 0.0500	time 0.4179 (0.4964)	data time 0.0069 (0.0392)	model time 0.4110 (0.4579)	loss 0.4287 (0.5496)	grad_norm 3.8954 (3.2600)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:31 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][80/156]	eta 0:00:37 lr 0.000013	 wd 0.0500	time 0.4411 (0.4908)	data time 0.0007 (0.0358)	model time 0.4404 (0.4517)	loss 0.6023 (0.5491)	grad_norm 1.8499 (3.2291)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:35 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][90/156]	eta 0:00:32 lr 0.000013	 wd 0.0500	time 0.4260 (0.4877)	data time 0.0181 (0.0324)	model time 0.4079 (0.4532)	loss 0.5550 (0.5521)	grad_norm 2.7191 (3.1943)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:40 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][100/156]	eta 0:00:27 lr 0.000013	 wd 0.0500	time 0.4508 (0.4853)	data time 0.0009 (0.0306)	model time 0.4500 (0.4524)	loss 0.5723 (0.5518)	grad_norm 2.4827 (3.2007)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:45 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][110/156]	eta 0:00:22 lr 0.000013	 wd 0.0500	time 0.4272 (0.4834)	data time 0.0006 (0.0291)	model time 0.4265 (0.4522)	loss 0.6004 (0.5510)	grad_norm 2.0419 (3.1749)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:49 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][120/156]	eta 0:00:17 lr 0.000013	 wd 0.0500	time 0.4280 (0.4836)	data time 0.0011 (0.0276)	model time 0.4268 (0.4553)	loss 0.5984 (0.5481)	grad_norm 3.5845 (3.1701)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:54 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][130/156]	eta 0:00:12 lr 0.000013	 wd 0.0500	time 0.5709 (0.4817)	data time 0.0008 (0.0260)	model time 0.5701 (0.4549)	loss 0.4323 (0.5480)	grad_norm 3.0313 (3.1638)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:03:59 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][140/156]	eta 0:00:07 lr 0.000013	 wd 0.0500	time 0.5172 (0.4809)	data time 0.0011 (0.0247)	model time 0.5161 (0.4558)	loss 0.6335 (0.5492)	grad_norm 2.7034 (3.1343)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:04:03 vssm1_tiny_0230s](training.py 201): INFO Train: [244/300][150/156]	eta 0:00:02 lr 0.000013	 wd 0.0500	time 0.5402 (0.4782)	data time 0.0006 (0.0232)	model time 0.5396 (0.4541)	loss 0.5826 (0.5517)	grad_norm 2.8175 (3.1353)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:04:06 vssm1_tiny_0230s](training.py 212): INFO EPOCH 244 training takes 0:01:15
[2024-11-09 18:04:06 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_244.pth saving......
[2024-11-09 18:04:07 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_244.pth saved !!!
[2024-11-09 18:04:10 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.769 (2.769)	Loss 0.2151 (0.2151)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:04:12 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.560 (0.502)	Loss 0.2227 (0.2137)	Acc@1 94.531 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:04:14 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.249 (0.350)	Loss 0.1814 (0.2218)	Acc@1 99.219 (95.685)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:04:17 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.155 (0.336)	Loss 0.2367 (0.2203)	Acc@1 93.750 (95.691)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:04:20 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.740 Acc@5 100.000
[2024-11-09 18:04:20 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:04:20 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:04:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.834 (2.834)	Loss 0.2004 (0.2004)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:04:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.432)	Loss 0.2080 (0.2072)	Acc@1 96.094 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:04:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.321)	Loss 0.2230 (0.2201)	Acc@1 96.094 (94.457)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:04:29 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.301)	Loss 0.2844 (0.2353)	Acc@1 92.188 (93.826)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:04:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.760 Acc@5 100.000
[2024-11-09 18:04:31 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.8%
[2024-11-09 18:04:31 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.76%
[2024-11-09 18:04:35 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][0/156]	eta 0:10:12 lr 0.000013	 wd 0.0500	time 3.9271 (3.9271)	data time 3.5128 (3.5128)	model time 0.0000 (0.0000)	loss 0.5458 (0.5458)	grad_norm 1.9584 (1.9584)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:04:40 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][10/156]	eta 0:01:49 lr 0.000013	 wd 0.0500	time 0.5400 (0.7526)	data time 0.0209 (0.3266)	model time 0.0000 (0.0000)	loss 0.4682 (0.5274)	grad_norm 2.9951 (3.0079)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:04:44 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][20/156]	eta 0:01:23 lr 0.000013	 wd 0.0500	time 0.5237 (0.6169)	data time 0.0038 (0.1762)	model time 0.0000 (0.0000)	loss 0.5218 (0.5460)	grad_norm 3.0288 (2.9649)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:04:49 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][30/156]	eta 0:01:11 lr 0.000013	 wd 0.0500	time 0.5735 (0.5713)	data time 0.0094 (0.1232)	model time 0.0000 (0.0000)	loss 0.4935 (0.5397)	grad_norm 2.6375 (2.9983)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:04:54 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][40/156]	eta 0:01:04 lr 0.000013	 wd 0.0500	time 0.4496 (0.5518)	data time 0.0306 (0.0989)	model time 0.0000 (0.0000)	loss 0.5043 (0.5490)	grad_norm 3.6137 (2.9579)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 18:04:59 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][50/156]	eta 0:00:57 lr 0.000013	 wd 0.0500	time 0.5293 (0.5416)	data time 0.0006 (0.0833)	model time 0.0000 (0.0000)	loss 0.6503 (0.5513)	grad_norm 2.1330 (inf)	loss_scale 32768.0000 (63608.4706)	mem 13675MB
[2024-11-09 18:05:04 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][60/156]	eta 0:00:51 lr 0.000013	 wd 0.0500	time 0.4537 (0.5379)	data time 0.0040 (0.0717)	model time 0.4497 (0.5058)	loss 0.4970 (0.5508)	grad_norm 2.2268 (inf)	loss_scale 32768.0000 (58552.6557)	mem 13675MB
[2024-11-09 18:05:09 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][70/156]	eta 0:00:45 lr 0.000012	 wd 0.0500	time 0.5360 (0.5313)	data time 0.0007 (0.0635)	model time 0.5353 (0.4919)	loss 0.4734 (0.5492)	grad_norm 3.6416 (inf)	loss_scale 32768.0000 (54921.0141)	mem 13675MB
[2024-11-09 18:05:13 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][80/156]	eta 0:00:39 lr 0.000012	 wd 0.0500	time 0.4383 (0.5209)	data time 0.0005 (0.0568)	model time 0.4378 (0.4741)	loss 0.5764 (0.5452)	grad_norm 2.9731 (inf)	loss_scale 32768.0000 (52186.0741)	mem 13675MB
[2024-11-09 18:05:18 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][90/156]	eta 0:00:33 lr 0.000012	 wd 0.0500	time 0.4189 (0.5126)	data time 0.0076 (0.0518)	model time 0.4113 (0.4639)	loss 0.5222 (0.5397)	grad_norm 2.9443 (inf)	loss_scale 32768.0000 (50052.2198)	mem 13675MB
[2024-11-09 18:05:22 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][100/156]	eta 0:00:28 lr 0.000012	 wd 0.0500	time 0.4358 (0.5056)	data time 0.0017 (0.0475)	model time 0.4341 (0.4579)	loss 0.4850 (0.5386)	grad_norm 4.9544 (inf)	loss_scale 32768.0000 (48340.9109)	mem 13675MB
[2024-11-09 18:05:27 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][110/156]	eta 0:00:23 lr 0.000012	 wd 0.0500	time 0.5116 (0.5009)	data time 0.0085 (0.0440)	model time 0.5031 (0.4555)	loss 0.5217 (0.5370)	grad_norm 3.8939 (inf)	loss_scale 32768.0000 (46937.9459)	mem 13675MB
[2024-11-09 18:05:32 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][120/156]	eta 0:00:18 lr 0.000012	 wd 0.0500	time 0.4286 (0.5012)	data time 0.0009 (0.0411)	model time 0.4277 (0.4612)	loss 0.4164 (0.5367)	grad_norm 6.5938 (inf)	loss_scale 32768.0000 (45766.8760)	mem 13675MB
[2024-11-09 18:05:36 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][130/156]	eta 0:00:12 lr 0.000012	 wd 0.0500	time 0.4178 (0.4979)	data time 0.0098 (0.0393)	model time 0.4080 (0.4588)	loss 0.5068 (0.5364)	grad_norm 3.2849 (inf)	loss_scale 32768.0000 (44774.5954)	mem 13675MB
[2024-11-09 18:05:41 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][140/156]	eta 0:00:07 lr 0.000012	 wd 0.0500	time 0.4098 (0.4939)	data time 0.0010 (0.0369)	model time 0.4088 (0.4563)	loss 0.5216 (0.5362)	grad_norm 3.6104 (inf)	loss_scale 32768.0000 (43923.0638)	mem 13675MB
[2024-11-09 18:05:45 vssm1_tiny_0230s](training.py 201): INFO Train: [245/300][150/156]	eta 0:00:02 lr 0.000012	 wd 0.0500	time 0.4514 (0.4901)	data time 0.0005 (0.0345)	model time 0.4508 (0.4543)	loss 0.4973 (0.5361)	grad_norm 3.9230 (inf)	loss_scale 32768.0000 (43184.3179)	mem 13675MB
[2024-11-09 18:05:48 vssm1_tiny_0230s](training.py 212): INFO EPOCH 245 training takes 0:01:16
[2024-11-09 18:05:48 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_245.pth saving......
[2024-11-09 18:05:48 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_245.pth saved !!!
[2024-11-09 18:05:51 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.104 (3.104)	Loss 0.2089 (0.2089)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:05:53 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.444)	Loss 0.2159 (0.2059)	Acc@1 95.312 (95.952)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:05:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.564 (0.338)	Loss 0.1659 (0.2132)	Acc@1 98.438 (95.610)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:05:58 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.186 (0.316)	Loss 0.2251 (0.2083)	Acc@1 92.188 (95.691)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:06:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.700 Acc@5 100.000
[2024-11-09 18:06:00 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:06:00 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:06:03 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.196 (3.196)	Loss 0.2002 (0.2002)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:06:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.215 (0.497)	Loss 0.2078 (0.2068)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:06:07 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.144 (0.343)	Loss 0.2224 (0.2196)	Acc@1 96.094 (94.457)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:06:09 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.301)	Loss 0.2837 (0.2347)	Acc@1 92.188 (93.826)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:06:11 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.780 Acc@5 100.000
[2024-11-09 18:06:11 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.8%
[2024-11-09 18:06:11 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.78%
[2024-11-09 18:06:15 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][0/156]	eta 0:08:33 lr 0.000012	 wd 0.0500	time 3.2934 (3.2934)	data time 2.8695 (2.8695)	model time 0.0000 (0.0000)	loss 0.5610 (0.5610)	grad_norm 4.5448 (4.5448)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:06:19 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][10/156]	eta 0:01:47 lr 0.000012	 wd 0.0500	time 0.4528 (0.7385)	data time 0.0010 (0.2739)	model time 0.0000 (0.0000)	loss 0.6187 (0.5494)	grad_norm 3.9218 (3.2936)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:06:24 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][20/156]	eta 0:01:25 lr 0.000012	 wd 0.0500	time 0.4305 (0.6270)	data time 0.0262 (0.1509)	model time 0.0000 (0.0000)	loss 0.5456 (0.5480)	grad_norm 2.9541 (3.1477)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:06:29 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][30/156]	eta 0:01:12 lr 0.000012	 wd 0.0500	time 0.5377 (0.5763)	data time 0.0066 (0.1052)	model time 0.0000 (0.0000)	loss 0.4821 (0.5346)	grad_norm 1.6523 (3.3386)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:06:34 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][40/156]	eta 0:01:03 lr 0.000012	 wd 0.0500	time 0.4608 (0.5471)	data time 0.0252 (0.0818)	model time 0.0000 (0.0000)	loss 0.5605 (0.5336)	grad_norm 6.1413 (3.4048)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:06:38 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][50/156]	eta 0:00:56 lr 0.000012	 wd 0.0500	time 0.4503 (0.5295)	data time 0.0258 (0.0673)	model time 0.0000 (0.0000)	loss 0.5667 (0.5366)	grad_norm 2.7230 (3.3432)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:06:43 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][60/156]	eta 0:00:49 lr 0.000012	 wd 0.0500	time 0.4166 (0.5205)	data time 0.0106 (0.0578)	model time 0.4060 (0.4648)	loss 0.6940 (0.5417)	grad_norm 2.6636 (3.2528)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:06:48 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][70/156]	eta 0:00:44 lr 0.000012	 wd 0.0500	time 0.4766 (0.5132)	data time 0.0177 (0.0504)	model time 0.4589 (0.4644)	loss 0.4405 (0.5384)	grad_norm 3.1353 (3.2592)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:06:52 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][80/156]	eta 0:00:38 lr 0.000012	 wd 0.0500	time 0.5554 (0.5093)	data time 0.0256 (0.0457)	model time 0.5297 (0.4659)	loss 0.5464 (0.5378)	grad_norm 2.3950 (3.2477)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:06:57 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][90/156]	eta 0:00:33 lr 0.000012	 wd 0.0500	time 0.4242 (0.5045)	data time 0.0056 (0.0418)	model time 0.4187 (0.4634)	loss 0.4734 (0.5367)	grad_norm 5.0531 (3.2598)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:07:02 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][100/156]	eta 0:00:28 lr 0.000012	 wd 0.0500	time 0.5623 (0.5014)	data time 0.0156 (0.0385)	model time 0.5467 (0.4635)	loss 0.4920 (0.5388)	grad_norm 2.7197 (3.2918)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:07:06 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][110/156]	eta 0:00:22 lr 0.000012	 wd 0.0500	time 0.5014 (0.4971)	data time 0.0050 (0.0355)	model time 0.4965 (0.4610)	loss 0.6076 (0.5371)	grad_norm 3.3617 (3.3890)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:07:11 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][120/156]	eta 0:00:17 lr 0.000012	 wd 0.0500	time 0.4314 (0.4935)	data time 0.0007 (0.0330)	model time 0.4307 (0.4592)	loss 0.5177 (0.5375)	grad_norm 4.5123 (3.3557)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:07:16 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][130/156]	eta 0:00:12 lr 0.000012	 wd 0.0500	time 0.4550 (0.4917)	data time 0.0006 (0.0309)	model time 0.4545 (0.4599)	loss 0.5999 (0.5392)	grad_norm 3.1274 (3.4204)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:07:21 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][140/156]	eta 0:00:07 lr 0.000012	 wd 0.0500	time 0.4512 (0.4927)	data time 0.0008 (0.0295)	model time 0.4504 (0.4637)	loss 0.6166 (0.5414)	grad_norm 2.3933 (3.3839)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:07:25 vssm1_tiny_0230s](training.py 201): INFO Train: [246/300][150/156]	eta 0:00:02 lr 0.000012	 wd 0.0500	time 0.5038 (0.4895)	data time 0.0006 (0.0276)	model time 0.5032 (0.4617)	loss 0.5822 (0.5416)	grad_norm 4.9456 (3.4121)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:07:28 vssm1_tiny_0230s](training.py 212): INFO EPOCH 246 training takes 0:01:16
[2024-11-09 18:07:28 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_246.pth saving......
[2024-11-09 18:07:28 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_246.pth saved !!!
[2024-11-09 18:07:30 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.510 (2.510)	Loss 0.2048 (0.2048)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:07:33 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.427)	Loss 0.2147 (0.2057)	Acc@1 96.094 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:07:35 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.179 (0.329)	Loss 0.1879 (0.2135)	Acc@1 97.656 (96.205)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:07:37 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.293)	Loss 0.2451 (0.2176)	Acc@1 92.188 (95.842)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:07:39 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.680 Acc@5 100.000
[2024-11-09 18:07:39 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:07:39 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:07:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.938 (2.938)	Loss 0.2001 (0.2001)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:07:44 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.148 (0.430)	Loss 0.2075 (0.2065)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:07:46 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.319)	Loss 0.2212 (0.2192)	Acc@1 96.094 (94.568)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:07:48 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.164 (0.287)	Loss 0.2827 (0.2340)	Acc@1 92.188 (93.901)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:07:50 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.860 Acc@5 100.000
[2024-11-09 18:07:50 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.9%
[2024-11-09 18:07:50 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.86%
[2024-11-09 18:07:54 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][0/156]	eta 0:10:01 lr 0.000012	 wd 0.0500	time 3.8588 (3.8588)	data time 3.4349 (3.4349)	model time 0.0000 (0.0000)	loss 0.5183 (0.5183)	grad_norm 3.0863 (3.0863)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:07:59 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][10/156]	eta 0:01:56 lr 0.000012	 wd 0.0500	time 0.5035 (0.7975)	data time 0.0008 (0.3190)	model time 0.0000 (0.0000)	loss 0.6090 (0.5251)	grad_norm 5.0978 (3.2029)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:04 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][20/156]	eta 0:01:27 lr 0.000012	 wd 0.0500	time 0.4873 (0.6460)	data time 0.0580 (0.1754)	model time 0.0000 (0.0000)	loss 0.4855 (0.5075)	grad_norm 1.8482 (3.7853)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:09 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][30/156]	eta 0:01:15 lr 0.000012	 wd 0.0500	time 0.5243 (0.6010)	data time 0.0271 (0.1237)	model time 0.0000 (0.0000)	loss 0.5133 (0.5157)	grad_norm 3.1643 (3.6834)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:14 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][40/156]	eta 0:01:08 lr 0.000012	 wd 0.0500	time 0.5419 (0.5876)	data time 0.0008 (0.0982)	model time 0.0000 (0.0000)	loss 0.6060 (0.5223)	grad_norm 4.0618 (3.4560)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:20 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][50/156]	eta 0:01:01 lr 0.000012	 wd 0.0500	time 0.5367 (0.5778)	data time 0.0747 (0.0849)	model time 0.0000 (0.0000)	loss 0.6319 (0.5302)	grad_norm 1.8409 (3.4077)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:25 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][60/156]	eta 0:00:54 lr 0.000012	 wd 0.0500	time 0.5235 (0.5636)	data time 0.0008 (0.0735)	model time 0.5227 (0.4757)	loss 0.4277 (0.5277)	grad_norm 4.1670 (3.4092)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:29 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][70/156]	eta 0:00:46 lr 0.000012	 wd 0.0500	time 0.4758 (0.5462)	data time 0.0054 (0.0656)	model time 0.4704 (0.4494)	loss 0.5401 (0.5311)	grad_norm 2.2037 (3.3016)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:34 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][80/156]	eta 0:00:41 lr 0.000012	 wd 0.0500	time 0.4279 (0.5400)	data time 0.0036 (0.0595)	model time 0.4243 (0.4595)	loss 0.5550 (0.5306)	grad_norm 2.5632 (3.2265)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:39 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][90/156]	eta 0:00:35 lr 0.000012	 wd 0.0500	time 0.4456 (0.5359)	data time 0.0213 (0.0550)	model time 0.4243 (0.4656)	loss 0.4482 (0.5313)	grad_norm 2.3986 (3.1984)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:44 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][100/156]	eta 0:00:29 lr 0.000012	 wd 0.0500	time 0.5142 (0.5287)	data time 0.0144 (0.0503)	model time 0.4998 (0.4636)	loss 0.6013 (0.5299)	grad_norm 3.7854 (3.1747)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:48 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][110/156]	eta 0:00:24 lr 0.000012	 wd 0.0500	time 0.4646 (0.5237)	data time 0.0160 (0.0468)	model time 0.4486 (0.4634)	loss 0.5396 (0.5296)	grad_norm 4.3509 (3.1923)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:53 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][120/156]	eta 0:00:18 lr 0.000012	 wd 0.0500	time 0.5470 (0.5195)	data time 0.0240 (0.0438)	model time 0.5230 (0.4631)	loss 0.5758 (0.5298)	grad_norm 4.7215 (3.2380)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:08:58 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][130/156]	eta 0:00:13 lr 0.000012	 wd 0.0500	time 0.5696 (0.5152)	data time 0.0082 (0.0411)	model time 0.5614 (0.4621)	loss 0.5885 (0.5300)	grad_norm 2.8163 (3.2493)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:09:02 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][140/156]	eta 0:00:08 lr 0.000012	 wd 0.0500	time 0.4696 (0.5102)	data time 0.0009 (0.0389)	model time 0.4687 (0.4591)	loss 0.6131 (0.5302)	grad_norm 2.4306 (3.2118)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:09:07 vssm1_tiny_0230s](training.py 201): INFO Train: [247/300][150/156]	eta 0:00:03 lr 0.000012	 wd 0.0500	time 0.4610 (0.5086)	data time 0.0005 (0.0364)	model time 0.4605 (0.4618)	loss 0.5211 (0.5308)	grad_norm 2.5868 (3.2297)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:09:10 vssm1_tiny_0230s](training.py 212): INFO EPOCH 247 training takes 0:01:19
[2024-11-09 18:09:10 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_247.pth saving......
[2024-11-09 18:09:10 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_247.pth saved !!!
[2024-11-09 18:09:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.026 (3.026)	Loss 0.2018 (0.2018)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:09:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.451)	Loss 0.2147 (0.2045)	Acc@1 95.312 (95.881)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:09:17 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.321)	Loss 0.1705 (0.2122)	Acc@1 98.438 (95.536)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:09:19 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.282)	Loss 0.2247 (0.2093)	Acc@1 93.750 (95.691)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:09:21 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.660 Acc@5 100.000
[2024-11-09 18:09:21 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:09:21 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:09:24 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.728 (2.728)	Loss 0.1998 (0.1998)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:09:26 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.150 (0.427)	Loss 0.2074 (0.2063)	Acc@1 96.094 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:09:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.170 (0.294)	Loss 0.2200 (0.2189)	Acc@1 96.094 (94.606)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:09:29 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.269)	Loss 0.2815 (0.2333)	Acc@1 92.188 (93.926)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:09:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.880 Acc@5 100.000
[2024-11-09 18:09:31 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.9%
[2024-11-09 18:09:31 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.88%
[2024-11-09 18:09:35 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][0/156]	eta 0:10:34 lr 0.000011	 wd 0.0500	time 4.0666 (4.0666)	data time 3.5317 (3.5317)	model time 0.0000 (0.0000)	loss 0.3998 (0.3998)	grad_norm 4.4943 (4.4943)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:09:41 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][10/156]	eta 0:02:05 lr 0.000011	 wd 0.0500	time 0.4254 (0.8568)	data time 0.0007 (0.3385)	model time 0.0000 (0.0000)	loss 0.5836 (0.5372)	grad_norm 2.5153 (3.5995)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:09:46 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][20/156]	eta 0:01:34 lr 0.000011	 wd 0.0500	time 0.4533 (0.6913)	data time 0.0102 (0.1875)	model time 0.0000 (0.0000)	loss 0.5054 (0.5346)	grad_norm 4.4705 (3.4569)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:09:51 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][30/156]	eta 0:01:18 lr 0.000011	 wd 0.0500	time 0.4935 (0.6235)	data time 0.0319 (0.1322)	model time 0.0000 (0.0000)	loss 0.6534 (0.5375)	grad_norm 3.2451 (3.3862)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:09:55 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][40/156]	eta 0:01:08 lr 0.000011	 wd 0.0500	time 0.4286 (0.5905)	data time 0.0220 (0.1049)	model time 0.0000 (0.0000)	loss 0.4458 (0.5358)	grad_norm 2.8929 (3.2753)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:00 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][50/156]	eta 0:01:00 lr 0.000011	 wd 0.0500	time 0.4184 (0.5717)	data time 0.0049 (0.0854)	model time 0.0000 (0.0000)	loss 0.4824 (0.5450)	grad_norm 5.0730 (3.1700)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:05 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][60/156]	eta 0:00:53 lr 0.000011	 wd 0.0500	time 0.5984 (0.5539)	data time 0.0204 (0.0731)	model time 0.5780 (0.4529)	loss 0.5746 (0.5428)	grad_norm 2.8169 (3.1508)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:09 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][70/156]	eta 0:00:46 lr 0.000011	 wd 0.0500	time 0.4159 (0.5393)	data time 0.0048 (0.0640)	model time 0.4110 (0.4472)	loss 0.4367 (0.5410)	grad_norm 3.9687 (3.2025)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:14 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][80/156]	eta 0:00:40 lr 0.000011	 wd 0.0500	time 0.4164 (0.5271)	data time 0.0022 (0.0570)	model time 0.4141 (0.4426)	loss 0.4102 (0.5367)	grad_norm 3.4411 (3.2338)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:18 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][90/156]	eta 0:00:34 lr 0.000011	 wd 0.0500	time 0.4263 (0.5175)	data time 0.0160 (0.0516)	model time 0.4103 (0.4399)	loss 0.6255 (0.5374)	grad_norm 2.5753 (3.1999)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:23 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][100/156]	eta 0:00:28 lr 0.000011	 wd 0.0500	time 0.4743 (0.5136)	data time 0.0132 (0.0473)	model time 0.4611 (0.4460)	loss 0.6018 (0.5366)	grad_norm 3.1867 (3.1801)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:28 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][110/156]	eta 0:00:23 lr 0.000011	 wd 0.0500	time 0.5903 (0.5127)	data time 0.0106 (0.0445)	model time 0.5798 (0.4528)	loss 0.5551 (0.5384)	grad_norm 2.0326 (3.1679)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:33 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][120/156]	eta 0:00:18 lr 0.000011	 wd 0.0500	time 0.5906 (0.5137)	data time 0.0013 (0.0419)	model time 0.5893 (0.4612)	loss 0.5793 (0.5377)	grad_norm 3.6651 (3.1428)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:38 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][130/156]	eta 0:00:13 lr 0.000011	 wd 0.0500	time 0.5845 (0.5103)	data time 0.0283 (0.0401)	model time 0.5562 (0.4600)	loss 0.5092 (0.5351)	grad_norm 4.2031 (3.1872)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:43 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][140/156]	eta 0:00:08 lr 0.000011	 wd 0.0500	time 0.4246 (0.5078)	data time 0.0010 (0.0378)	model time 0.4236 (0.4607)	loss 0.5042 (0.5323)	grad_norm 3.0498 (3.2258)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:47 vssm1_tiny_0230s](training.py 201): INFO Train: [248/300][150/156]	eta 0:00:03 lr 0.000011	 wd 0.0500	time 0.4600 (0.5041)	data time 0.0006 (0.0354)	model time 0.4594 (0.4597)	loss 0.5535 (0.5318)	grad_norm 2.9395 (3.2634)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:10:50 vssm1_tiny_0230s](training.py 212): INFO EPOCH 248 training takes 0:01:19
[2024-11-09 18:10:50 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_248.pth saving......
[2024-11-09 18:10:51 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_248.pth saved !!!
[2024-11-09 18:10:54 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.634 (2.634)	Loss 0.1969 (0.1969)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:10:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.817 (0.543)	Loss 0.2063 (0.1963)	Acc@1 96.094 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:10:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.374)	Loss 0.1638 (0.2049)	Acc@1 99.219 (95.350)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:11:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.159 (0.328)	Loss 0.2191 (0.2026)	Acc@1 93.750 (95.489)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:11:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.500 Acc@5 100.000
[2024-11-09 18:11:03 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.5%
[2024-11-09 18:11:03 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:11:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.233 (3.233)	Loss 0.1996 (0.1996)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:11:08 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.155 (0.458)	Loss 0.2072 (0.2058)	Acc@1 96.094 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:11:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.214 (0.333)	Loss 0.2192 (0.2184)	Acc@1 96.094 (94.680)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:11:13 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.299)	Loss 0.2805 (0.2326)	Acc@1 92.188 (93.977)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:11:15 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.920 Acc@5 100.000
[2024-11-09 18:11:15 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.9%
[2024-11-09 18:11:15 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.92%
[2024-11-09 18:11:18 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][0/156]	eta 0:09:00 lr 0.000011	 wd 0.0500	time 3.4664 (3.4664)	data time 2.8853 (2.8853)	model time 0.0000 (0.0000)	loss 0.5492 (0.5492)	grad_norm 3.7590 (3.7590)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:11:23 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][10/156]	eta 0:01:50 lr 0.000011	 wd 0.0500	time 0.5130 (0.7551)	data time 0.0127 (0.2695)	model time 0.0000 (0.0000)	loss 0.4565 (0.5090)	grad_norm 4.7043 (3.9499)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:11:28 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][20/156]	eta 0:01:27 lr 0.000011	 wd 0.0500	time 0.4153 (0.6406)	data time 0.0097 (0.1489)	model time 0.0000 (0.0000)	loss 0.6257 (0.5338)	grad_norm 2.3768 (3.6565)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:11:33 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][30/156]	eta 0:01:14 lr 0.000011	 wd 0.0500	time 0.4799 (0.5936)	data time 0.0034 (0.1043)	model time 0.0000 (0.0000)	loss 0.6027 (0.5438)	grad_norm 2.6303 (3.4319)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:11:38 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][40/156]	eta 0:01:04 lr 0.000011	 wd 0.0500	time 0.4665 (0.5579)	data time 0.0247 (0.0814)	model time 0.0000 (0.0000)	loss 0.5160 (0.5446)	grad_norm 3.8441 (3.3037)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:11:42 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][50/156]	eta 0:00:56 lr 0.000011	 wd 0.0500	time 0.4128 (0.5372)	data time 0.0077 (0.0678)	model time 0.0000 (0.0000)	loss 0.5370 (0.5511)	grad_norm 3.4995 (3.2461)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:11:47 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][60/156]	eta 0:00:50 lr 0.000011	 wd 0.0500	time 0.4125 (0.5290)	data time 0.0007 (0.0587)	model time 0.4117 (0.4755)	loss 0.5906 (0.5510)	grad_norm 3.3645 (3.2868)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:11:52 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][70/156]	eta 0:00:44 lr 0.000011	 wd 0.0500	time 0.4151 (0.5195)	data time 0.0008 (0.0514)	model time 0.4143 (0.4647)	loss 0.5852 (0.5520)	grad_norm 2.5133 (3.2505)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:11:56 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][80/156]	eta 0:00:39 lr 0.000011	 wd 0.0500	time 0.4477 (0.5139)	data time 0.0007 (0.0465)	model time 0.4469 (0.4640)	loss 0.3982 (0.5455)	grad_norm 3.7982 (3.3084)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:12:01 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][90/156]	eta 0:00:33 lr 0.000011	 wd 0.0500	time 0.5178 (0.5087)	data time 0.0267 (0.0422)	model time 0.4912 (0.4628)	loss 0.5379 (0.5472)	grad_norm 1.5606 (3.2695)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:12:06 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][100/156]	eta 0:00:28 lr 0.000011	 wd 0.0500	time 0.5489 (0.5027)	data time 0.0135 (0.0386)	model time 0.5354 (0.4588)	loss 0.5757 (0.5446)	grad_norm 5.3453 (3.2811)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:12:10 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][110/156]	eta 0:00:22 lr 0.000011	 wd 0.0500	time 0.4108 (0.4973)	data time 0.0036 (0.0360)	model time 0.4072 (0.4543)	loss 0.5939 (0.5459)	grad_norm 2.4247 (3.2889)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:12:15 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][120/156]	eta 0:00:17 lr 0.000011	 wd 0.0500	time 0.4584 (0.4952)	data time 0.0179 (0.0346)	model time 0.4404 (0.4541)	loss 0.5376 (0.5450)	grad_norm 1.7356 (3.2838)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:12:19 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][130/156]	eta 0:00:12 lr 0.000011	 wd 0.0500	time 0.4244 (0.4937)	data time 0.0021 (0.0332)	model time 0.4223 (0.4547)	loss 0.5776 (0.5427)	grad_norm 2.3356 (3.2698)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:12:24 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][140/156]	eta 0:00:07 lr 0.000011	 wd 0.0500	time 0.4513 (0.4917)	data time 0.0010 (0.0320)	model time 0.4503 (0.4543)	loss 0.6217 (0.5440)	grad_norm 3.2725 (3.2315)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:12:28 vssm1_tiny_0230s](training.py 201): INFO Train: [249/300][150/156]	eta 0:00:02 lr 0.000011	 wd 0.0500	time 0.4571 (0.4881)	data time 0.0005 (0.0299)	model time 0.4566 (0.4525)	loss 0.4809 (0.5438)	grad_norm 2.7716 (3.2223)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:12:31 vssm1_tiny_0230s](training.py 212): INFO EPOCH 249 training takes 0:01:16
[2024-11-09 18:12:31 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_249.pth saving......
[2024-11-09 18:12:32 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_249.pth saved !!!
[2024-11-09 18:12:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.219 (2.219)	Loss 0.1882 (0.1882)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:12:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.159 (0.471)	Loss 0.1975 (0.1894)	Acc@1 96.875 (96.946)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:12:39 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.355)	Loss 0.1995 (0.1988)	Acc@1 96.875 (96.354)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:12:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.153 (0.297)	Loss 0.2610 (0.2114)	Acc@1 92.188 (95.665)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:12:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.340 Acc@5 100.000
[2024-11-09 18:12:43 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.3%
[2024-11-09 18:12:43 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:12:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.444 (2.444)	Loss 0.1993 (0.1993)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:12:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.445)	Loss 0.2069 (0.2055)	Acc@1 95.312 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:12:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.309)	Loss 0.2185 (0.2181)	Acc@1 96.094 (94.643)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:12:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.162 (0.268)	Loss 0.2798 (0.2321)	Acc@1 92.188 (93.977)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:12:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.920 Acc@5 100.000
[2024-11-09 18:12:55 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 93.9%
[2024-11-09 18:12:55 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.92%
[2024-11-09 18:13:00 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][0/156]	eta 0:14:33 lr 0.000011	 wd 0.0500	time 5.5978 (5.5978)	data time 4.9996 (4.9996)	model time 0.0000 (0.0000)	loss 0.5439 (0.5439)	grad_norm 2.8479 (2.8479)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:05 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][10/156]	eta 0:02:22 lr 0.000011	 wd 0.0500	time 0.4124 (0.9732)	data time 0.0037 (0.4666)	model time 0.0000 (0.0000)	loss 0.5735 (0.5052)	grad_norm 1.9341 (2.7729)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:11 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][20/156]	eta 0:01:44 lr 0.000011	 wd 0.0500	time 0.4143 (0.7666)	data time 0.0027 (0.2497)	model time 0.0000 (0.0000)	loss 0.4842 (0.5034)	grad_norm 3.5997 (3.2529)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:15 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][30/156]	eta 0:01:24 lr 0.000011	 wd 0.0500	time 0.4465 (0.6719)	data time 0.0233 (0.1725)	model time 0.0000 (0.0000)	loss 0.6283 (0.5177)	grad_norm 2.9182 (3.2543)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:21 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][40/156]	eta 0:01:13 lr 0.000011	 wd 0.0500	time 0.5136 (0.6318)	data time 0.0048 (0.1336)	model time 0.0000 (0.0000)	loss 0.4387 (0.5214)	grad_norm 4.2670 (3.2152)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:25 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][50/156]	eta 0:01:03 lr 0.000011	 wd 0.0500	time 0.7148 (0.6021)	data time 0.0027 (0.1095)	model time 0.0000 (0.0000)	loss 0.4977 (0.5341)	grad_norm 4.0227 (3.2336)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:31 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][60/156]	eta 0:00:56 lr 0.000011	 wd 0.0500	time 0.5142 (0.5910)	data time 0.0012 (0.0942)	model time 0.5130 (0.5183)	loss 0.5917 (0.5339)	grad_norm 5.2284 (3.3694)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:36 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][70/156]	eta 0:00:49 lr 0.000011	 wd 0.0500	time 0.4827 (0.5760)	data time 0.0006 (0.0824)	model time 0.4821 (0.4963)	loss 0.4928 (0.5382)	grad_norm 4.3037 (3.3308)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:41 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][80/156]	eta 0:00:43 lr 0.000011	 wd 0.0500	time 0.6245 (0.5680)	data time 0.0412 (0.0742)	model time 0.5833 (0.4960)	loss 0.5262 (0.5407)	grad_norm 2.7607 (3.2710)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:46 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][90/156]	eta 0:00:36 lr 0.000011	 wd 0.0500	time 0.4891 (0.5605)	data time 0.0023 (0.0676)	model time 0.4868 (0.4932)	loss 0.5668 (0.5406)	grad_norm 3.3374 (3.2693)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:50 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][100/156]	eta 0:00:30 lr 0.000010	 wd 0.0500	time 0.4185 (0.5493)	data time 0.0010 (0.0614)	model time 0.4174 (0.4832)	loss 0.4717 (0.5386)	grad_norm 3.0207 (3.2313)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:13:55 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][110/156]	eta 0:00:24 lr 0.000010	 wd 0.0500	time 0.5424 (0.5424)	data time 0.0006 (0.0571)	model time 0.5419 (0.4791)	loss 0.6203 (0.5404)	grad_norm 2.3200 (3.1747)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:14:00 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][120/156]	eta 0:00:19 lr 0.000010	 wd 0.0500	time 0.4497 (0.5379)	data time 0.0070 (0.0531)	model time 0.4427 (0.4791)	loss 0.4292 (0.5412)	grad_norm 3.2658 (3.2107)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:14:05 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][130/156]	eta 0:00:13 lr 0.000010	 wd 0.0500	time 0.4821 (0.5365)	data time 0.0187 (0.0501)	model time 0.4634 (0.4824)	loss 0.4415 (0.5406)	grad_norm 4.6942 (3.2123)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:14:10 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][140/156]	eta 0:00:08 lr 0.000010	 wd 0.0500	time 0.4465 (0.5337)	data time 0.0009 (0.0473)	model time 0.4456 (0.4830)	loss 0.6016 (0.5391)	grad_norm 3.5513 (3.2085)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:14:14 vssm1_tiny_0230s](training.py 201): INFO Train: [250/300][150/156]	eta 0:00:03 lr 0.000010	 wd 0.0500	time 0.4820 (0.5283)	data time 0.0006 (0.0443)	model time 0.4814 (0.4797)	loss 0.6249 (0.5384)	grad_norm 3.1530 (3.2293)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:14:17 vssm1_tiny_0230s](training.py 212): INFO EPOCH 250 training takes 0:01:22
[2024-11-09 18:14:17 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_250.pth saving......
[2024-11-09 18:14:18 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_250.pth saved !!!
[2024-11-09 18:14:20 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.508 (2.508)	Loss 0.1969 (0.1969)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:14:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.237 (0.427)	Loss 0.2051 (0.1963)	Acc@1 96.875 (96.946)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:14:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.174 (0.303)	Loss 0.1776 (0.2048)	Acc@1 96.875 (96.280)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:14:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.183 (0.262)	Loss 0.2419 (0.2091)	Acc@1 92.188 (95.716)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:14:28 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.520 Acc@5 100.000
[2024-11-09 18:14:28 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.5%
[2024-11-09 18:14:28 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:14:31 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.615 (2.615)	Loss 0.1991 (0.1991)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:14:33 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.437)	Loss 0.2067 (0.2052)	Acc@1 96.094 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:14:35 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.189 (0.354)	Loss 0.2175 (0.2176)	Acc@1 96.094 (94.717)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:14:38 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.805 (0.333)	Loss 0.2788 (0.2314)	Acc@1 92.188 (94.027)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:14:41 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 93.980 Acc@5 100.000
[2024-11-09 18:14:41 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.0%
[2024-11-09 18:14:41 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 93.98%
[2024-11-09 18:14:44 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][0/156]	eta 0:08:28 lr 0.000010	 wd 0.0500	time 3.2574 (3.2574)	data time 2.8076 (2.8076)	model time 0.0000 (0.0000)	loss 0.4164 (0.4164)	grad_norm 4.3783 (4.3783)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:14:49 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][10/156]	eta 0:01:46 lr 0.000010	 wd 0.0500	time 0.4959 (0.7281)	data time 0.0191 (0.2641)	model time 0.0000 (0.0000)	loss 0.5441 (0.5215)	grad_norm 3.4746 (3.6065)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:14:54 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][20/156]	eta 0:01:22 lr 0.000010	 wd 0.0500	time 0.4365 (0.6100)	data time 0.0005 (0.1430)	model time 0.0000 (0.0000)	loss 0.6117 (0.5381)	grad_norm 2.9646 (3.3254)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:14:59 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][30/156]	eta 0:01:12 lr 0.000010	 wd 0.0500	time 0.4916 (0.5739)	data time 0.0102 (0.1066)	model time 0.0000 (0.0000)	loss 0.4340 (0.5436)	grad_norm 2.7822 (3.3217)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:03 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][40/156]	eta 0:01:03 lr 0.000010	 wd 0.0500	time 0.4746 (0.5465)	data time 0.0006 (0.0844)	model time 0.0000 (0.0000)	loss 0.5126 (0.5441)	grad_norm 3.6058 (3.3641)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:08 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][50/156]	eta 0:00:56 lr 0.000010	 wd 0.0500	time 0.5858 (0.5349)	data time 0.0009 (0.0696)	model time 0.0000 (0.0000)	loss 0.4206 (0.5421)	grad_norm 4.5874 (3.3846)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:13 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][60/156]	eta 0:00:50 lr 0.000010	 wd 0.0500	time 0.4292 (0.5280)	data time 0.0007 (0.0594)	model time 0.4285 (0.4858)	loss 0.5894 (0.5447)	grad_norm 2.2170 (3.3312)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:18 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][70/156]	eta 0:00:44 lr 0.000010	 wd 0.0500	time 0.4121 (0.5193)	data time 0.0005 (0.0523)	model time 0.4116 (0.4712)	loss 0.6610 (0.5437)	grad_norm 3.5314 (3.3521)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:22 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][80/156]	eta 0:00:38 lr 0.000010	 wd 0.0500	time 0.4150 (0.5115)	data time 0.0007 (0.0468)	model time 0.4143 (0.4636)	loss 0.4070 (0.5437)	grad_norm 3.0063 (3.3266)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:27 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][90/156]	eta 0:00:33 lr 0.000010	 wd 0.0500	time 0.4592 (0.5108)	data time 0.0046 (0.0431)	model time 0.4546 (0.4710)	loss 0.4401 (0.5407)	grad_norm 2.5877 (3.2866)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:32 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][100/156]	eta 0:00:28 lr 0.000010	 wd 0.0500	time 0.4038 (0.5045)	data time 0.0005 (0.0399)	model time 0.4033 (0.4639)	loss 0.6197 (0.5417)	grad_norm 4.3929 (3.3276)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:37 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][110/156]	eta 0:00:23 lr 0.000010	 wd 0.0500	time 0.4704 (0.5008)	data time 0.0038 (0.0365)	model time 0.4665 (0.4636)	loss 0.5731 (0.5434)	grad_norm 4.1622 (3.2959)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:41 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][120/156]	eta 0:00:17 lr 0.000010	 wd 0.0500	time 0.4311 (0.4965)	data time 0.0076 (0.0339)	model time 0.4235 (0.4605)	loss 0.5166 (0.5421)	grad_norm 2.6447 (3.3259)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:45 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][130/156]	eta 0:00:12 lr 0.000010	 wd 0.0500	time 0.4628 (0.4920)	data time 0.0337 (0.0320)	model time 0.4291 (0.4566)	loss 0.4232 (0.5398)	grad_norm 3.9907 (3.3076)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:50 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][140/156]	eta 0:00:07 lr 0.000010	 wd 0.0500	time 0.4098 (0.4890)	data time 0.0009 (0.0307)	model time 0.4089 (0.4543)	loss 0.4392 (0.5365)	grad_norm 3.8625 (3.3076)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:54 vssm1_tiny_0230s](training.py 201): INFO Train: [251/300][150/156]	eta 0:00:02 lr 0.000010	 wd 0.0500	time 0.4211 (0.4862)	data time 0.0006 (0.0287)	model time 0.4205 (0.4534)	loss 0.4953 (0.5386)	grad_norm 3.9564 (3.2840)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:15:57 vssm1_tiny_0230s](training.py 212): INFO EPOCH 251 training takes 0:01:15
[2024-11-09 18:15:57 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_251.pth saving......
[2024-11-09 18:15:57 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_251.pth saved !!!
[2024-11-09 18:16:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.850 (2.850)	Loss 0.1805 (0.1805)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:16:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.452)	Loss 0.1885 (0.1793)	Acc@1 96.094 (97.301)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:16:03 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.307)	Loss 0.1910 (0.1895)	Acc@1 97.656 (96.689)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:16:05 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.433 (0.273)	Loss 0.2590 (0.2039)	Acc@1 91.406 (95.892)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:16:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.400 Acc@5 100.000
[2024-11-09 18:16:08 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.4%
[2024-11-09 18:16:08 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:16:10 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.879 (2.879)	Loss 0.1992 (0.1992)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:16:12 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.140 (0.442)	Loss 0.2068 (0.2052)	Acc@1 95.312 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:16:14 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.322)	Loss 0.2166 (0.2175)	Acc@1 96.094 (94.754)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:16:16 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.157 (0.275)	Loss 0.2778 (0.2309)	Acc@1 92.188 (94.078)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:16:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.020 Acc@5 100.000
[2024-11-09 18:16:18 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.0%
[2024-11-09 18:16:18 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.02%
[2024-11-09 18:16:21 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][0/156]	eta 0:08:03 lr 0.000010	 wd 0.0500	time 3.0981 (3.0981)	data time 2.6509 (2.6509)	model time 0.0000 (0.0000)	loss 0.5134 (0.5134)	grad_norm 4.2355 (4.2355)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:16:26 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][10/156]	eta 0:01:53 lr 0.000010	 wd 0.0500	time 0.4579 (0.7756)	data time 0.0515 (0.2930)	model time 0.0000 (0.0000)	loss 0.5660 (0.5518)	grad_norm 1.9676 (3.1455)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:16:31 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][20/156]	eta 0:01:26 lr 0.000010	 wd 0.0500	time 0.5103 (0.6396)	data time 0.0385 (0.1580)	model time 0.0000 (0.0000)	loss 0.6085 (0.5229)	grad_norm 3.3181 (3.4147)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:16:36 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][30/156]	eta 0:01:14 lr 0.000010	 wd 0.0500	time 0.4533 (0.5878)	data time 0.0225 (0.1095)	model time 0.0000 (0.0000)	loss 0.5156 (0.5241)	grad_norm 2.0467 (3.2952)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:16:41 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][40/156]	eta 0:01:05 lr 0.000010	 wd 0.0500	time 0.4202 (0.5605)	data time 0.0036 (0.0859)	model time 0.0000 (0.0000)	loss 0.6394 (0.5314)	grad_norm 3.8489 (3.3749)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:16:45 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][50/156]	eta 0:00:57 lr 0.000010	 wd 0.0500	time 0.4087 (0.5386)	data time 0.0006 (0.0703)	model time 0.0000 (0.0000)	loss 0.5547 (0.5337)	grad_norm 2.7589 (3.3402)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:16:50 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][60/156]	eta 0:00:50 lr 0.000010	 wd 0.0500	time 0.5221 (0.5257)	data time 0.0299 (0.0602)	model time 0.4922 (0.4515)	loss 0.4178 (0.5318)	grad_norm 3.0087 (3.3883)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:16:55 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][70/156]	eta 0:00:44 lr 0.000010	 wd 0.0500	time 0.5744 (0.5201)	data time 0.0185 (0.0544)	model time 0.5559 (0.4592)	loss 0.5831 (0.5339)	grad_norm 3.0636 (3.4206)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:17:00 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][80/156]	eta 0:00:39 lr 0.000010	 wd 0.0500	time 0.5434 (0.5168)	data time 0.0066 (0.0489)	model time 0.5368 (0.4673)	loss 0.5957 (0.5330)	grad_norm 2.2211 (3.3602)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:17:05 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][90/156]	eta 0:00:33 lr 0.000010	 wd 0.0500	time 0.4963 (0.5134)	data time 0.0015 (0.0445)	model time 0.4948 (0.4696)	loss 0.5395 (0.5382)	grad_norm 2.1636 (3.3086)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:17:10 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][100/156]	eta 0:00:28 lr 0.000010	 wd 0.0500	time 0.4213 (0.5103)	data time 0.0018 (0.0419)	model time 0.4195 (0.4685)	loss 0.4247 (0.5371)	grad_norm 5.4695 (3.2927)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:17:14 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][110/156]	eta 0:00:23 lr 0.000010	 wd 0.0500	time 0.4875 (0.5074)	data time 0.0008 (0.0393)	model time 0.4868 (0.4680)	loss 0.5687 (0.5383)	grad_norm 2.4734 (3.2426)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:17:19 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][120/156]	eta 0:00:18 lr 0.000010	 wd 0.0500	time 0.4945 (0.5063)	data time 0.0498 (0.0370)	model time 0.4447 (0.4700)	loss 0.6102 (0.5382)	grad_norm 3.0864 (3.2433)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:17:24 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][130/156]	eta 0:00:13 lr 0.000010	 wd 0.0500	time 0.4948 (0.5049)	data time 0.0379 (0.0350)	model time 0.4569 (0.4709)	loss 0.5462 (0.5377)	grad_norm 4.1786 (3.2797)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:17:29 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][140/156]	eta 0:00:08 lr 0.000010	 wd 0.0500	time 0.4065 (0.5022)	data time 0.0010 (0.0334)	model time 0.4055 (0.4691)	loss 0.6377 (0.5392)	grad_norm 2.0315 (3.2980)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:17:33 vssm1_tiny_0230s](training.py 201): INFO Train: [252/300][150/156]	eta 0:00:02 lr 0.000010	 wd 0.0500	time 0.4096 (0.4995)	data time 0.0006 (0.0314)	model time 0.4090 (0.4680)	loss 0.5336 (0.5391)	grad_norm 2.8688 (3.3321)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:17:36 vssm1_tiny_0230s](training.py 212): INFO EPOCH 252 training takes 0:01:18
[2024-11-09 18:17:36 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_252.pth saving......
[2024-11-09 18:17:37 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_252.pth saved !!!
[2024-11-09 18:17:39 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.567 (2.567)	Loss 0.2023 (0.2023)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:17:42 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.164 (0.448)	Loss 0.2087 (0.2018)	Acc@1 96.094 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:17:44 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.342)	Loss 0.1786 (0.2102)	Acc@1 98.438 (96.019)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:17:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.292)	Loss 0.2394 (0.2124)	Acc@1 91.406 (95.766)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:17:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.580 Acc@5 100.000
[2024-11-09 18:17:48 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:17:48 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:17:50 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.379 (2.379)	Loss 0.1990 (0.1990)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:17:53 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.203 (0.466)	Loss 0.2064 (0.2048)	Acc@1 95.312 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:17:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.153 (0.350)	Loss 0.2153 (0.2170)	Acc@1 96.094 (94.717)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:17:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.183 (0.296)	Loss 0.2766 (0.2302)	Acc@1 92.188 (94.052)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:18:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.040 Acc@5 100.000
[2024-11-09 18:18:00 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.0%
[2024-11-09 18:18:00 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.04%
[2024-11-09 18:18:03 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][0/156]	eta 0:09:25 lr 0.000010	 wd 0.0500	time 3.6242 (3.6242)	data time 3.1158 (3.1158)	model time 0.0000 (0.0000)	loss 0.5854 (0.5854)	grad_norm 2.7221 (2.7221)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:08 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][10/156]	eta 0:01:54 lr 0.000010	 wd 0.0500	time 0.4825 (0.7837)	data time 0.0418 (0.3378)	model time 0.0000 (0.0000)	loss 0.6287 (0.5595)	grad_norm 3.7457 (3.0344)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:13 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][20/156]	eta 0:01:26 lr 0.000010	 wd 0.0500	time 0.4281 (0.6384)	data time 0.0018 (0.1837)	model time 0.0000 (0.0000)	loss 0.6544 (0.5616)	grad_norm 3.5668 (3.0283)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:18 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][30/156]	eta 0:01:13 lr 0.000010	 wd 0.0500	time 0.4331 (0.5841)	data time 0.0216 (0.1313)	model time 0.0000 (0.0000)	loss 0.6333 (0.5520)	grad_norm 2.7265 (3.0389)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:22 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][40/156]	eta 0:01:03 lr 0.000010	 wd 0.0500	time 0.4097 (0.5516)	data time 0.0046 (0.1007)	model time 0.0000 (0.0000)	loss 0.6121 (0.5565)	grad_norm 3.1760 (3.0200)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:27 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][50/156]	eta 0:00:57 lr 0.000010	 wd 0.0500	time 0.4489 (0.5385)	data time 0.0235 (0.0833)	model time 0.0000 (0.0000)	loss 0.5825 (0.5521)	grad_norm 2.6782 (3.0674)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:32 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][60/156]	eta 0:00:51 lr 0.000010	 wd 0.0500	time 0.4985 (0.5326)	data time 0.0071 (0.0715)	model time 0.4914 (0.4914)	loss 0.5925 (0.5553)	grad_norm 4.0680 (3.1797)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:37 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][70/156]	eta 0:00:45 lr 0.000009	 wd 0.0500	time 0.4568 (0.5290)	data time 0.0347 (0.0636)	model time 0.4221 (0.4915)	loss 0.5925 (0.5498)	grad_norm 2.3301 (3.2091)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:42 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][80/156]	eta 0:00:39 lr 0.000009	 wd 0.0500	time 0.4827 (0.5241)	data time 0.0625 (0.0577)	model time 0.4202 (0.4854)	loss 0.5853 (0.5450)	grad_norm 2.3030 (3.2067)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:47 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][90/156]	eta 0:00:34 lr 0.000009	 wd 0.0500	time 0.4229 (0.5175)	data time 0.0161 (0.0527)	model time 0.4068 (0.4771)	loss 0.4867 (0.5417)	grad_norm 2.4035 (3.2527)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:52 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][100/156]	eta 0:00:28 lr 0.000009	 wd 0.0500	time 0.4652 (0.5129)	data time 0.0396 (0.0489)	model time 0.4256 (0.4729)	loss 0.5858 (0.5411)	grad_norm 3.1684 (3.2593)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:18:56 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][110/156]	eta 0:00:23 lr 0.000009	 wd 0.0500	time 0.4484 (0.5097)	data time 0.0087 (0.0455)	model time 0.4397 (0.4719)	loss 0.5933 (0.5443)	grad_norm 3.3097 (3.2617)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:19:01 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][120/156]	eta 0:00:18 lr 0.000009	 wd 0.0500	time 0.4185 (0.5069)	data time 0.0110 (0.0431)	model time 0.4075 (0.4701)	loss 0.6252 (0.5447)	grad_norm 2.9745 (3.2418)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:19:06 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][130/156]	eta 0:00:13 lr 0.000009	 wd 0.0500	time 0.4078 (0.5041)	data time 0.0008 (0.0415)	model time 0.4070 (0.4674)	loss 0.4913 (0.5453)	grad_norm 5.0820 (3.2674)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:19:11 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][140/156]	eta 0:00:08 lr 0.000009	 wd 0.0500	time 0.5029 (0.5044)	data time 0.0008 (0.0392)	model time 0.5021 (0.4710)	loss 0.5849 (0.5451)	grad_norm 2.5333 (3.2415)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:19:17 vssm1_tiny_0230s](training.py 201): INFO Train: [253/300][150/156]	eta 0:00:03 lr 0.000009	 wd 0.0500	time 0.5317 (0.5079)	data time 0.0006 (0.0370)	model time 0.5311 (0.4790)	loss 0.6328 (0.5466)	grad_norm 2.2165 (3.2358)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:19:20 vssm1_tiny_0230s](training.py 212): INFO EPOCH 253 training takes 0:01:19
[2024-11-09 18:19:20 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_253.pth saving......
[2024-11-09 18:19:20 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_253.pth saved !!!
[2024-11-09 18:19:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.824 (2.824)	Loss 0.2102 (0.2102)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:19:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.156 (0.483)	Loss 0.2222 (0.2112)	Acc@1 94.531 (96.023)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:19:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.156 (0.351)	Loss 0.1851 (0.2186)	Acc@1 98.438 (95.908)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:19:30 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.535 (0.334)	Loss 0.2375 (0.2193)	Acc@1 92.969 (95.691)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:19:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.620 Acc@5 100.000
[2024-11-09 18:19:32 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:19:32 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:19:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.076 (2.076)	Loss 0.1987 (0.1987)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:19:36 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.348)	Loss 0.2062 (0.2045)	Acc@1 95.312 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:19:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.132 (0.294)	Loss 0.2146 (0.2167)	Acc@1 96.094 (94.717)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:19:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.260)	Loss 0.2759 (0.2297)	Acc@1 92.188 (94.078)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:19:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.060 Acc@5 100.000
[2024-11-09 18:19:42 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.1%
[2024-11-09 18:19:42 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.06%
[2024-11-09 18:19:44 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][0/156]	eta 0:05:48 lr 0.000009	 wd 0.0500	time 2.2320 (2.2320)	data time 1.8076 (1.8076)	model time 0.0000 (0.0000)	loss 0.4786 (0.4786)	grad_norm 3.6461 (3.6461)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:19:49 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][10/156]	eta 0:01:33 lr 0.000009	 wd 0.0500	time 0.4467 (0.6384)	data time 0.0317 (0.2117)	model time 0.0000 (0.0000)	loss 0.5336 (0.5314)	grad_norm 1.6715 (3.4052)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:19:53 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][20/156]	eta 0:01:14 lr 0.000009	 wd 0.0500	time 0.4080 (0.5467)	data time 0.0007 (0.1136)	model time 0.0000 (0.0000)	loss 0.5742 (0.5422)	grad_norm 3.1198 (3.3688)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:19:58 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][30/156]	eta 0:01:04 lr 0.000009	 wd 0.0500	time 0.4413 (0.5147)	data time 0.0062 (0.0780)	model time 0.0000 (0.0000)	loss 0.4484 (0.5436)	grad_norm 4.2562 (3.4006)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:02 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][40/156]	eta 0:00:57 lr 0.000009	 wd 0.0500	time 0.4501 (0.4991)	data time 0.0099 (0.0602)	model time 0.0000 (0.0000)	loss 0.4239 (0.5375)	grad_norm 3.5862 (3.3986)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:07 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][50/156]	eta 0:00:52 lr 0.000009	 wd 0.0500	time 0.4148 (0.4955)	data time 0.0101 (0.0559)	model time 0.0000 (0.0000)	loss 0.4842 (0.5452)	grad_norm 2.5746 (3.4076)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:12 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][60/156]	eta 0:00:47 lr 0.000009	 wd 0.0500	time 0.5664 (0.4915)	data time 0.0399 (0.0496)	model time 0.5265 (0.4536)	loss 0.5966 (0.5468)	grad_norm 5.4355 (3.4628)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:17 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][70/156]	eta 0:00:41 lr 0.000009	 wd 0.0500	time 0.4924 (0.4866)	data time 0.0871 (0.0465)	model time 0.4053 (0.4414)	loss 0.5293 (0.5451)	grad_norm 2.5232 (3.4244)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:21 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][80/156]	eta 0:00:36 lr 0.000009	 wd 0.0500	time 0.5210 (0.4862)	data time 0.0508 (0.0427)	model time 0.4702 (0.4501)	loss 0.4622 (0.5440)	grad_norm 2.5468 (3.4151)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:26 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][90/156]	eta 0:00:31 lr 0.000009	 wd 0.0500	time 0.4145 (0.4823)	data time 0.0057 (0.0389)	model time 0.4088 (0.4481)	loss 0.5540 (0.5415)	grad_norm 2.9714 (3.3860)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:31 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][100/156]	eta 0:00:26 lr 0.000009	 wd 0.0500	time 0.4562 (0.4815)	data time 0.0007 (0.0368)	model time 0.4555 (0.4497)	loss 0.5998 (0.5437)	grad_norm 2.3749 (3.3501)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:35 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][110/156]	eta 0:00:22 lr 0.000009	 wd 0.0500	time 0.6208 (0.4803)	data time 0.0592 (0.0345)	model time 0.5616 (0.4509)	loss 0.6415 (0.5438)	grad_norm 2.8828 (3.3168)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:40 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][120/156]	eta 0:00:17 lr 0.000009	 wd 0.0500	time 0.4689 (0.4787)	data time 0.0006 (0.0324)	model time 0.4683 (0.4512)	loss 0.5455 (0.5433)	grad_norm 3.0704 (3.3754)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:45 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][130/156]	eta 0:00:12 lr 0.000009	 wd 0.0500	time 0.4474 (0.4786)	data time 0.0046 (0.0310)	model time 0.4427 (0.4526)	loss 0.5854 (0.5425)	grad_norm 2.2656 (3.3578)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:49 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][140/156]	eta 0:00:07 lr 0.000009	 wd 0.0500	time 0.4172 (0.4767)	data time 0.0008 (0.0294)	model time 0.4164 (0.4517)	loss 0.4470 (0.5411)	grad_norm 3.5362 (3.3619)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:54 vssm1_tiny_0230s](training.py 201): INFO Train: [254/300][150/156]	eta 0:00:02 lr 0.000009	 wd 0.0500	time 0.4227 (0.4751)	data time 0.0004 (0.0275)	model time 0.4223 (0.4517)	loss 0.4346 (0.5410)	grad_norm 4.0699 (3.3328)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:20:56 vssm1_tiny_0230s](training.py 212): INFO EPOCH 254 training takes 0:01:14
[2024-11-09 18:20:56 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_254.pth saving......
[2024-11-09 18:20:57 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_254.pth saved !!!
[2024-11-09 18:21:01 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.528 (3.528)	Loss 0.1897 (0.1897)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:21:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.208 (0.474)	Loss 0.1987 (0.1907)	Acc@1 97.656 (96.946)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:21:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.174 (0.317)	Loss 0.1866 (0.1994)	Acc@1 98.438 (96.540)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:21:06 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.277)	Loss 0.2507 (0.2094)	Acc@1 92.188 (95.892)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:21:08 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.640 Acc@5 100.000
[2024-11-09 18:21:08 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:21:08 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:21:11 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.552 (3.552)	Loss 0.1986 (0.1986)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:21:13 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.459)	Loss 0.2059 (0.2042)	Acc@1 95.312 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:21:15 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.329)	Loss 0.2140 (0.2164)	Acc@1 96.094 (94.717)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:21:17 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.186 (0.308)	Loss 0.2751 (0.2292)	Acc@1 92.188 (94.103)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:21:19 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.100 Acc@5 100.000
[2024-11-09 18:21:19 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.1%
[2024-11-09 18:21:19 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.10%
[2024-11-09 18:21:23 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][0/156]	eta 0:09:14 lr 0.000009	 wd 0.0500	time 3.5546 (3.5546)	data time 3.1193 (3.1193)	model time 0.0000 (0.0000)	loss 0.5466 (0.5466)	grad_norm 3.7789 (3.7789)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:21:27 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][10/156]	eta 0:01:45 lr 0.000009	 wd 0.0500	time 0.4245 (0.7201)	data time 0.0006 (0.2860)	model time 0.0000 (0.0000)	loss 0.5519 (0.5246)	grad_norm 2.8002 (3.4860)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:21:32 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][20/156]	eta 0:01:22 lr 0.000009	 wd 0.0500	time 0.5520 (0.6082)	data time 0.0077 (0.1533)	model time 0.0000 (0.0000)	loss 0.4299 (0.5224)	grad_norm 4.3822 (3.3178)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:21:37 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][30/156]	eta 0:01:11 lr 0.000009	 wd 0.0500	time 0.4707 (0.5651)	data time 0.0023 (0.1055)	model time 0.0000 (0.0000)	loss 0.5929 (0.5343)	grad_norm 6.0793 (3.6010)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:21:41 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][40/156]	eta 0:01:02 lr 0.000009	 wd 0.0500	time 0.4137 (0.5403)	data time 0.0093 (0.0834)	model time 0.0000 (0.0000)	loss 0.5526 (0.5403)	grad_norm 4.1454 (3.6286)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:21:46 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][50/156]	eta 0:00:55 lr 0.000009	 wd 0.0500	time 0.4735 (0.5265)	data time 0.0168 (0.0707)	model time 0.0000 (0.0000)	loss 0.5707 (0.5428)	grad_norm 3.0206 (3.5384)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:21:51 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][60/156]	eta 0:00:50 lr 0.000009	 wd 0.0500	time 0.4318 (0.5274)	data time 0.0028 (0.0603)	model time 0.4290 (0.5253)	loss 0.4766 (0.5423)	grad_norm 1.8173 (3.5522)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:21:56 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][70/156]	eta 0:00:44 lr 0.000009	 wd 0.0500	time 0.4602 (0.5169)	data time 0.0090 (0.0533)	model time 0.4512 (0.4835)	loss 0.5319 (0.5382)	grad_norm 2.7100 (3.5958)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:22:00 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][80/156]	eta 0:00:38 lr 0.000009	 wd 0.0500	time 0.4767 (0.5113)	data time 0.0019 (0.0481)	model time 0.4748 (0.4758)	loss 0.6388 (0.5413)	grad_norm 2.4222 (3.6257)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:22:05 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][90/156]	eta 0:00:33 lr 0.000009	 wd 0.0500	time 0.4487 (0.5074)	data time 0.0043 (0.0444)	model time 0.4444 (0.4721)	loss 0.5612 (0.5433)	grad_norm 2.4369 (3.5930)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:22:10 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][100/156]	eta 0:00:28 lr 0.000009	 wd 0.0500	time 0.4841 (0.5066)	data time 0.0032 (0.0410)	model time 0.4808 (0.4758)	loss 0.5186 (0.5433)	grad_norm 2.4230 (3.5786)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:22:15 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][110/156]	eta 0:00:23 lr 0.000009	 wd 0.0500	time 0.5020 (0.5033)	data time 0.0290 (0.0392)	model time 0.4730 (0.4711)	loss 0.4421 (0.5389)	grad_norm 4.8675 (3.5807)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:22:20 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][120/156]	eta 0:00:18 lr 0.000009	 wd 0.0500	time 0.4183 (0.5006)	data time 0.0047 (0.0369)	model time 0.4137 (0.4694)	loss 0.6172 (0.5402)	grad_norm 2.9583 (3.5569)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:22:24 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][130/156]	eta 0:00:12 lr 0.000009	 wd 0.0500	time 0.4503 (0.4993)	data time 0.0006 (0.0348)	model time 0.4497 (0.4701)	loss 0.4557 (0.5376)	grad_norm 3.6354 (3.5755)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:22:29 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][140/156]	eta 0:00:07 lr 0.000009	 wd 0.0500	time 0.4745 (0.4972)	data time 0.0007 (0.0330)	model time 0.4738 (0.4689)	loss 0.5436 (0.5396)	grad_norm 2.6403 (3.5771)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:22:34 vssm1_tiny_0230s](training.py 201): INFO Train: [255/300][150/156]	eta 0:00:02 lr 0.000009	 wd 0.0500	time 0.4872 (0.4960)	data time 0.0004 (0.0314)	model time 0.4868 (0.4692)	loss 0.4318 (0.5379)	grad_norm 2.5581 (3.5601)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:22:37 vssm1_tiny_0230s](training.py 212): INFO EPOCH 255 training takes 0:01:17
[2024-11-09 18:22:37 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_255.pth saving......
[2024-11-09 18:22:37 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_255.pth saved !!!
[2024-11-09 18:22:40 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.659 (2.659)	Loss 0.1897 (0.1897)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:22:42 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.402)	Loss 0.1982 (0.1882)	Acc@1 96.094 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:22:44 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.329)	Loss 0.1841 (0.1970)	Acc@1 98.438 (96.354)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:22:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.147 (0.296)	Loss 0.2494 (0.2055)	Acc@1 92.188 (95.867)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:22:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.640 Acc@5 100.000
[2024-11-09 18:22:48 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:22:48 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:22:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.948 (3.948)	Loss 0.1987 (0.1987)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:22:55 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.219 (0.584)	Loss 0.2061 (0.2042)	Acc@1 95.312 (95.597)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:22:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.200 (0.458)	Loss 0.2131 (0.2162)	Acc@1 96.094 (94.754)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:23:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.406)	Loss 0.2744 (0.2288)	Acc@1 92.188 (94.128)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:23:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.120 Acc@5 100.000
[2024-11-09 18:23:03 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.1%
[2024-11-09 18:23:03 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.12%
[2024-11-09 18:23:08 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][0/156]	eta 0:10:47 lr 0.000009	 wd 0.0500	time 4.1516 (4.1516)	data time 3.5968 (3.5968)	model time 0.0000 (0.0000)	loss 0.5972 (0.5972)	grad_norm 1.8876 (1.8876)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:12 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][10/156]	eta 0:02:00 lr 0.000009	 wd 0.0500	time 0.5853 (0.8276)	data time 0.0056 (0.3336)	model time 0.0000 (0.0000)	loss 0.6118 (0.5724)	grad_norm 4.5392 (2.9876)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:17 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][20/156]	eta 0:01:28 lr 0.000009	 wd 0.0500	time 0.4147 (0.6492)	data time 0.0013 (0.1800)	model time 0.0000 (0.0000)	loss 0.4419 (0.5466)	grad_norm 3.0619 (3.0149)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:22 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][30/156]	eta 0:01:14 lr 0.000009	 wd 0.0500	time 0.4913 (0.5923)	data time 0.0048 (0.1273)	model time 0.0000 (0.0000)	loss 0.4506 (0.5364)	grad_norm 2.4513 (3.2593)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:26 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][40/156]	eta 0:01:04 lr 0.000009	 wd 0.0500	time 0.4135 (0.5559)	data time 0.0080 (0.0987)	model time 0.0000 (0.0000)	loss 0.5915 (0.5390)	grad_norm 3.3972 (3.4187)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:31 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][50/156]	eta 0:00:56 lr 0.000009	 wd 0.0500	time 0.4248 (0.5316)	data time 0.0200 (0.0800)	model time 0.0000 (0.0000)	loss 0.6034 (0.5433)	grad_norm 2.8095 (3.3983)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:35 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][60/156]	eta 0:00:49 lr 0.000009	 wd 0.0500	time 0.4180 (0.5176)	data time 0.0040 (0.0689)	model time 0.4139 (0.4339)	loss 0.5386 (0.5455)	grad_norm 3.4864 (3.2882)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:40 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][70/156]	eta 0:00:43 lr 0.000008	 wd 0.0500	time 0.5100 (0.5104)	data time 0.0809 (0.0617)	model time 0.4291 (0.4413)	loss 0.6149 (0.5455)	grad_norm 4.5854 (3.3393)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:44 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][80/156]	eta 0:00:38 lr 0.000008	 wd 0.0500	time 0.5385 (0.5057)	data time 0.0255 (0.0563)	model time 0.5130 (0.4457)	loss 0.5602 (0.5434)	grad_norm 3.0246 (3.3417)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:49 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][90/156]	eta 0:00:33 lr 0.000008	 wd 0.0500	time 0.5422 (0.5030)	data time 0.0148 (0.0521)	model time 0.5274 (0.4499)	loss 0.4619 (0.5362)	grad_norm 4.0945 (3.3787)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:54 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][100/156]	eta 0:00:27 lr 0.000008	 wd 0.0500	time 0.4422 (0.4994)	data time 0.0168 (0.0493)	model time 0.4254 (0.4486)	loss 0.5985 (0.5360)	grad_norm 3.3557 (3.4564)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:23:59 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][110/156]	eta 0:00:22 lr 0.000008	 wd 0.0500	time 0.4312 (0.4996)	data time 0.0078 (0.0466)	model time 0.4234 (0.4543)	loss 0.5178 (0.5330)	grad_norm 2.3033 (3.4330)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:24:04 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][120/156]	eta 0:00:17 lr 0.000008	 wd 0.0500	time 0.4491 (0.4989)	data time 0.0031 (0.0443)	model time 0.4460 (0.4567)	loss 0.4917 (0.5335)	grad_norm 4.4768 (3.4747)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:24:09 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][130/156]	eta 0:00:12 lr 0.000008	 wd 0.0500	time 0.4729 (0.4971)	data time 0.0231 (0.0423)	model time 0.4499 (0.4567)	loss 0.5427 (0.5347)	grad_norm 2.7949 (3.4629)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:24:13 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][140/156]	eta 0:00:07 lr 0.000008	 wd 0.0500	time 0.4164 (0.4957)	data time 0.0007 (0.0404)	model time 0.4157 (0.4574)	loss 0.4097 (0.5364)	grad_norm 3.0373 (3.4456)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:24:18 vssm1_tiny_0230s](training.py 201): INFO Train: [256/300][150/156]	eta 0:00:02 lr 0.000008	 wd 0.0500	time 0.4090 (0.4945)	data time 0.0005 (0.0377)	model time 0.4086 (0.4594)	loss 0.4555 (0.5355)	grad_norm 8.0232 (3.4842)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:24:21 vssm1_tiny_0230s](training.py 212): INFO EPOCH 256 training takes 0:01:17
[2024-11-09 18:24:21 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_256.pth saving......
[2024-11-09 18:24:21 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_256.pth saved !!!
[2024-11-09 18:24:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.456 (2.456)	Loss 0.1971 (0.1971)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:24:26 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.146 (0.422)	Loss 0.2059 (0.1982)	Acc@1 96.094 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:24:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.198 (0.304)	Loss 0.1746 (0.2062)	Acc@1 98.438 (95.871)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:24:29 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.274)	Loss 0.2347 (0.2085)	Acc@1 92.969 (95.741)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:24:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.640 Acc@5 100.000
[2024-11-09 18:24:31 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:24:31 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:24:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.096 (3.096)	Loss 0.1986 (0.1986)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:24:36 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.169 (0.502)	Loss 0.2058 (0.2040)	Acc@1 95.312 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:24:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.339)	Loss 0.2122 (0.2159)	Acc@1 96.094 (94.792)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:24:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.292)	Loss 0.2734 (0.2282)	Acc@1 92.188 (94.178)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:24:42 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.140 Acc@5 100.000
[2024-11-09 18:24:42 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.1%
[2024-11-09 18:24:42 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.14%
[2024-11-09 18:24:45 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][0/156]	eta 0:08:40 lr 0.000008	 wd 0.0500	time 3.3381 (3.3381)	data time 2.7761 (2.7761)	model time 0.0000 (0.0000)	loss 0.5981 (0.5981)	grad_norm 2.0004 (2.0004)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:24:51 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][10/156]	eta 0:01:58 lr 0.000008	 wd 0.0500	time 0.7084 (0.8123)	data time 0.0222 (0.3066)	model time 0.0000 (0.0000)	loss 0.5833 (0.5413)	grad_norm 2.5756 (3.4001)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:24:56 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][20/156]	eta 0:01:29 lr 0.000008	 wd 0.0500	time 0.5492 (0.6557)	data time 0.0249 (0.1643)	model time 0.0000 (0.0000)	loss 0.6073 (0.5368)	grad_norm 3.2795 (3.3249)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:00 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][30/156]	eta 0:01:14 lr 0.000008	 wd 0.0500	time 0.4641 (0.5898)	data time 0.0005 (0.1140)	model time 0.0000 (0.0000)	loss 0.5040 (0.5344)	grad_norm 3.4607 (3.5649)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:05 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][40/156]	eta 0:01:05 lr 0.000008	 wd 0.0500	time 0.5486 (0.5613)	data time 0.0230 (0.0900)	model time 0.0000 (0.0000)	loss 0.4992 (0.5370)	grad_norm 1.9605 (3.3861)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:10 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][50/156]	eta 0:00:58 lr 0.000008	 wd 0.0500	time 0.5300 (0.5508)	data time 0.0029 (0.0755)	model time 0.0000 (0.0000)	loss 0.4998 (0.5415)	grad_norm 3.7062 (3.3400)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:15 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][60/156]	eta 0:00:51 lr 0.000008	 wd 0.0500	time 0.4477 (0.5375)	data time 0.0008 (0.0645)	model time 0.4469 (0.4613)	loss 0.4222 (0.5434)	grad_norm 4.4348 (3.3025)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:20 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][70/156]	eta 0:00:45 lr 0.000008	 wd 0.0500	time 0.5200 (0.5341)	data time 0.0144 (0.0584)	model time 0.5056 (0.4767)	loss 0.4002 (0.5408)	grad_norm 5.4875 (3.2472)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:25 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][80/156]	eta 0:00:39 lr 0.000008	 wd 0.0500	time 0.4611 (0.5248)	data time 0.0052 (0.0518)	model time 0.4559 (0.4690)	loss 0.6179 (0.5429)	grad_norm 3.2862 (3.2554)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:29 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][90/156]	eta 0:00:34 lr 0.000008	 wd 0.0500	time 0.5535 (0.5198)	data time 0.0580 (0.0478)	model time 0.4955 (0.4678)	loss 0.5763 (0.5405)	grad_norm 3.2269 (3.2768)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:35 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][100/156]	eta 0:00:29 lr 0.000008	 wd 0.0500	time 0.5080 (0.5200)	data time 0.0576 (0.0454)	model time 0.4504 (0.4740)	loss 0.4832 (0.5376)	grad_norm 2.4667 (3.3463)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:40 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][110/156]	eta 0:00:23 lr 0.000008	 wd 0.0500	time 0.4092 (0.5189)	data time 0.0010 (0.0424)	model time 0.4082 (0.4775)	loss 0.6210 (0.5389)	grad_norm 3.5685 (3.3010)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:44 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][120/156]	eta 0:00:18 lr 0.000008	 wd 0.0500	time 0.4482 (0.5139)	data time 0.0229 (0.0394)	model time 0.4253 (0.4739)	loss 0.5990 (0.5388)	grad_norm 2.1294 (3.3117)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:50 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][130/156]	eta 0:00:13 lr 0.000008	 wd 0.0500	time 0.7155 (0.5159)	data time 0.0539 (0.0386)	model time 0.6616 (0.4784)	loss 0.5908 (0.5409)	grad_norm 3.5851 (3.3078)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:25:55 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][140/156]	eta 0:00:08 lr 0.000008	 wd 0.0500	time 0.4781 (0.5183)	data time 0.0010 (0.0369)	model time 0.4771 (0.4849)	loss 0.5406 (0.5410)	grad_norm 3.3946 (3.3262)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:26:00 vssm1_tiny_0230s](training.py 201): INFO Train: [257/300][150/156]	eta 0:00:03 lr 0.000008	 wd 0.0500	time 0.5904 (0.5179)	data time 0.0005 (0.0348)	model time 0.5899 (0.4870)	loss 0.4744 (0.5383)	grad_norm 2.9690 (3.3293)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:26:03 vssm1_tiny_0230s](training.py 212): INFO EPOCH 257 training takes 0:01:21
[2024-11-09 18:26:03 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_257.pth saving......
[2024-11-09 18:26:04 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_257.pth saved !!!
[2024-11-09 18:26:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.045 (3.045)	Loss 0.2153 (0.2153)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:26:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.182 (0.457)	Loss 0.2211 (0.2151)	Acc@1 94.531 (95.384)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:26:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.310)	Loss 0.1594 (0.2220)	Acc@1 99.219 (95.164)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:26:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.259)	Loss 0.2153 (0.2124)	Acc@1 92.969 (95.514)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:26:13 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.640 Acc@5 100.000
[2024-11-09 18:26:13 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:26:13 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:26:16 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.694 (2.694)	Loss 0.1984 (0.1984)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:26:18 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.173 (0.468)	Loss 0.2056 (0.2037)	Acc@1 95.312 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:26:20 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.178 (0.333)	Loss 0.2113 (0.2157)	Acc@1 96.094 (94.829)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:26:22 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.285)	Loss 0.2727 (0.2277)	Acc@1 92.188 (94.204)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:26:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.160 Acc@5 100.000
[2024-11-09 18:26:24 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.2%
[2024-11-09 18:26:24 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.16%
[2024-11-09 18:26:28 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][0/156]	eta 0:09:21 lr 0.000008	 wd 0.0500	time 3.6001 (3.6001)	data time 3.1249 (3.1249)	model time 0.0000 (0.0000)	loss 0.5996 (0.5996)	grad_norm 2.2792 (2.2792)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:26:32 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][10/156]	eta 0:01:47 lr 0.000008	 wd 0.0500	time 0.4073 (0.7329)	data time 0.0008 (0.2903)	model time 0.0000 (0.0000)	loss 0.4979 (0.5619)	grad_norm 2.1289 (3.3550)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:26:37 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][20/156]	eta 0:01:22 lr 0.000008	 wd 0.0500	time 0.4442 (0.6083)	data time 0.0077 (0.1585)	model time 0.0000 (0.0000)	loss 0.5550 (0.5674)	grad_norm 2.3918 (3.4111)	loss_scale 65536.0000 (34328.3810)	mem 13675MB
[2024-11-09 18:26:42 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][30/156]	eta 0:01:11 lr 0.000008	 wd 0.0500	time 0.4533 (0.5690)	data time 0.0017 (0.1113)	model time 0.0000 (0.0000)	loss 0.6077 (0.5693)	grad_norm 3.3310 (3.3319)	loss_scale 65536.0000 (44395.3548)	mem 13675MB
[2024-11-09 18:26:47 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][40/156]	eta 0:01:03 lr 0.000008	 wd 0.0500	time 0.4588 (0.5454)	data time 0.0037 (0.0873)	model time 0.0000 (0.0000)	loss 0.5571 (0.5700)	grad_norm 3.7083 (3.2512)	loss_scale 65536.0000 (49551.6098)	mem 13675MB
[2024-11-09 18:26:52 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][50/156]	eta 0:00:57 lr 0.000008	 wd 0.0500	time 0.5569 (0.5387)	data time 0.0432 (0.0730)	model time 0.0000 (0.0000)	loss 0.5006 (0.5682)	grad_norm 3.4117 (3.2613)	loss_scale 65536.0000 (52685.8039)	mem 13675MB
[2024-11-09 18:26:56 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][60/156]	eta 0:00:50 lr 0.000008	 wd 0.0500	time 0.4122 (0.5241)	data time 0.0006 (0.0623)	model time 0.4116 (0.4420)	loss 0.6178 (0.5677)	grad_norm 2.7489 (3.2683)	loss_scale 65536.0000 (54792.3934)	mem 13675MB
[2024-11-09 18:27:01 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][70/156]	eta 0:00:44 lr 0.000008	 wd 0.0500	time 0.4408 (0.5152)	data time 0.0007 (0.0550)	model time 0.4401 (0.4463)	loss 0.4731 (0.5635)	grad_norm 3.0630 (3.2854)	loss_scale 65536.0000 (56305.5775)	mem 13675MB
[2024-11-09 18:27:06 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][80/156]	eta 0:00:39 lr 0.000008	 wd 0.0500	time 0.5117 (0.5143)	data time 0.0066 (0.0492)	model time 0.5052 (0.4641)	loss 0.5816 (0.5600)	grad_norm 3.5705 (3.3056)	loss_scale 65536.0000 (57445.1358)	mem 13675MB
[2024-11-09 18:27:10 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][90/156]	eta 0:00:33 lr 0.000008	 wd 0.0500	time 0.4380 (0.5075)	data time 0.0106 (0.0442)	model time 0.4274 (0.4602)	loss 0.5109 (0.5552)	grad_norm 3.7948 (3.3942)	loss_scale 65536.0000 (58334.2418)	mem 13675MB
[2024-11-09 18:27:15 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][100/156]	eta 0:00:28 lr 0.000008	 wd 0.0500	time 0.4483 (0.5012)	data time 0.0007 (0.0405)	model time 0.4476 (0.4557)	loss 0.4510 (0.5513)	grad_norm 3.3676 (3.3439)	loss_scale 65536.0000 (59047.2871)	mem 13675MB
[2024-11-09 18:27:19 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][110/156]	eta 0:00:22 lr 0.000008	 wd 0.0500	time 0.4386 (0.4971)	data time 0.0140 (0.0372)	model time 0.4245 (0.4549)	loss 0.5199 (0.5509)	grad_norm 2.6540 (3.3590)	loss_scale 65536.0000 (59631.8559)	mem 13675MB
[2024-11-09 18:27:24 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][120/156]	eta 0:00:17 lr 0.000008	 wd 0.0500	time 0.4308 (0.4945)	data time 0.0027 (0.0349)	model time 0.4281 (0.4553)	loss 0.5493 (0.5495)	grad_norm 2.1233 (3.3682)	loss_scale 65536.0000 (60119.8017)	mem 13675MB
[2024-11-09 18:27:29 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][130/156]	eta 0:00:12 lr 0.000008	 wd 0.0500	time 0.4995 (0.4928)	data time 0.0098 (0.0331)	model time 0.4897 (0.4559)	loss 0.4625 (0.5489)	grad_norm 5.7692 (3.3690)	loss_scale 65536.0000 (60533.2519)	mem 13675MB
[2024-11-09 18:27:33 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][140/156]	eta 0:00:07 lr 0.000008	 wd 0.0500	time 0.5038 (0.4910)	data time 0.0009 (0.0315)	model time 0.5029 (0.4560)	loss 0.5885 (0.5501)	grad_norm 2.2716 (3.3621)	loss_scale 65536.0000 (60888.0567)	mem 13675MB
[2024-11-09 18:27:38 vssm1_tiny_0230s](training.py 201): INFO Train: [258/300][150/156]	eta 0:00:02 lr 0.000008	 wd 0.0500	time 0.4668 (0.4877)	data time 0.0005 (0.0295)	model time 0.4663 (0.4543)	loss 0.5013 (0.5502)	grad_norm 2.2615 (3.3657)	loss_scale 65536.0000 (61195.8675)	mem 13675MB
[2024-11-09 18:27:40 vssm1_tiny_0230s](training.py 212): INFO EPOCH 258 training takes 0:01:16
[2024-11-09 18:27:40 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_258.pth saving......
[2024-11-09 18:27:41 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_258.pth saved !!!
[2024-11-09 18:27:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.840 (2.840)	Loss 0.2013 (0.2013)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:27:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.222 (0.493)	Loss 0.2051 (0.2006)	Acc@1 96.094 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:27:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.149 (0.336)	Loss 0.1744 (0.2085)	Acc@1 99.219 (95.982)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:27:50 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.157 (0.295)	Loss 0.2306 (0.2095)	Acc@1 92.969 (95.817)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:27:52 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.640 Acc@5 100.000
[2024-11-09 18:27:52 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:27:52 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:27:54 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.292 (2.292)	Loss 0.1986 (0.1986)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:27:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.763 (0.431)	Loss 0.2057 (0.2037)	Acc@1 95.312 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:27:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.193 (0.314)	Loss 0.2106 (0.2156)	Acc@1 96.094 (94.792)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:28:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.223 (0.269)	Loss 0.2720 (0.2273)	Acc@1 92.188 (94.204)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:28:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.140 Acc@5 100.000
[2024-11-09 18:28:02 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.1%
[2024-11-09 18:28:02 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.16%
[2024-11-09 18:28:06 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][0/156]	eta 0:08:05 lr 0.000008	 wd 0.0500	time 3.1136 (3.1136)	data time 2.5811 (2.5811)	model time 0.0000 (0.0000)	loss 0.5044 (0.5044)	grad_norm 3.9898 (3.9898)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:10 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][10/156]	eta 0:01:41 lr 0.000008	 wd 0.0500	time 0.4076 (0.6930)	data time 0.0008 (0.2495)	model time 0.0000 (0.0000)	loss 0.4512 (0.5192)	grad_norm 2.0875 (3.5546)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:14 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][20/156]	eta 0:01:18 lr 0.000008	 wd 0.0500	time 0.4065 (0.5751)	data time 0.0007 (0.1359)	model time 0.0000 (0.0000)	loss 0.5010 (0.5355)	grad_norm 2.3820 (3.4133)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:19 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][30/156]	eta 0:01:08 lr 0.000008	 wd 0.0500	time 0.4281 (0.5415)	data time 0.0010 (0.0954)	model time 0.0000 (0.0000)	loss 0.6456 (0.5277)	grad_norm 2.2369 (3.6282)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:25 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][40/156]	eta 0:01:03 lr 0.000008	 wd 0.0500	time 0.5364 (0.5460)	data time 0.0026 (0.0744)	model time 0.0000 (0.0000)	loss 0.6023 (0.5329)	grad_norm 2.8532 (3.4806)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:30 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][50/156]	eta 0:00:56 lr 0.000008	 wd 0.0500	time 0.4778 (0.5327)	data time 0.0091 (0.0624)	model time 0.0000 (0.0000)	loss 0.5473 (0.5417)	grad_norm 3.7525 (3.4498)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:34 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][60/156]	eta 0:00:50 lr 0.000008	 wd 0.0500	time 0.5374 (0.5237)	data time 0.0160 (0.0538)	model time 0.5214 (0.4681)	loss 0.5918 (0.5470)	grad_norm 2.0191 (3.3820)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:39 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][70/156]	eta 0:00:43 lr 0.000008	 wd 0.0500	time 0.4063 (0.5096)	data time 0.0007 (0.0465)	model time 0.4056 (0.4446)	loss 0.5222 (0.5461)	grad_norm 2.6937 (3.3495)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:43 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][80/156]	eta 0:00:37 lr 0.000008	 wd 0.0500	time 0.4109 (0.4976)	data time 0.0090 (0.0410)	model time 0.4019 (0.4335)	loss 0.5600 (0.5503)	grad_norm 3.1303 (3.3291)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:48 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][90/156]	eta 0:00:32 lr 0.000008	 wd 0.0500	time 0.4295 (0.4958)	data time 0.0065 (0.0384)	model time 0.4230 (0.4408)	loss 0.5307 (0.5515)	grad_norm 4.0052 (3.3054)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:53 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][100/156]	eta 0:00:28 lr 0.000007	 wd 0.0500	time 0.5679 (0.5008)	data time 0.0232 (0.0361)	model time 0.5447 (0.4589)	loss 0.4330 (0.5497)	grad_norm 2.6897 (3.2893)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:28:58 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][110/156]	eta 0:00:23 lr 0.000007	 wd 0.0500	time 0.4550 (0.5034)	data time 0.0013 (0.0346)	model time 0.4537 (0.4676)	loss 0.6118 (0.5513)	grad_norm 2.3926 (3.2653)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:29:03 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][120/156]	eta 0:00:18 lr 0.000007	 wd 0.0500	time 0.4828 (0.5023)	data time 0.0008 (0.0328)	model time 0.4820 (0.4688)	loss 0.6009 (0.5534)	grad_norm 4.0347 (3.2583)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:29:08 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][130/156]	eta 0:00:13 lr 0.000007	 wd 0.0500	time 0.6087 (0.5016)	data time 0.0058 (0.0316)	model time 0.6029 (0.4698)	loss 0.4155 (0.5498)	grad_norm 5.4845 (3.2568)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:29:14 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][140/156]	eta 0:00:08 lr 0.000007	 wd 0.0500	time 0.6289 (0.5044)	data time 0.0008 (0.0304)	model time 0.6281 (0.4761)	loss 0.4808 (0.5474)	grad_norm 3.2230 (3.2991)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:29:19 vssm1_tiny_0230s](training.py 201): INFO Train: [259/300][150/156]	eta 0:00:03 lr 0.000007	 wd 0.0500	time 0.4619 (0.5064)	data time 0.0008 (0.0285)	model time 0.4611 (0.4818)	loss 0.5928 (0.5457)	grad_norm 3.2155 (3.3422)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:29:22 vssm1_tiny_0230s](training.py 212): INFO EPOCH 259 training takes 0:01:19
[2024-11-09 18:29:22 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_259.pth saving......
[2024-11-09 18:29:23 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_259.pth saved !!!
[2024-11-09 18:29:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.860 (3.860)	Loss 0.2102 (0.2102)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:29:30 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.161 (0.600)	Loss 0.2173 (0.2096)	Acc@1 95.312 (95.810)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:29:33 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.186 (0.444)	Loss 0.1682 (0.2163)	Acc@1 99.219 (95.536)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:29:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.201 (0.372)	Loss 0.2228 (0.2113)	Acc@1 94.531 (95.640)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:29:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.580 Acc@5 100.000
[2024-11-09 18:29:38 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:29:38 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:29:43 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 5.719 (5.719)	Loss 0.1985 (0.1985)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:29:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.142 (0.652)	Loss 0.2056 (0.2035)	Acc@1 95.312 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:29:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.464)	Loss 0.2100 (0.2153)	Acc@1 96.094 (94.792)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:29:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.385)	Loss 0.2712 (0.2269)	Acc@1 92.188 (94.204)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:29:52 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.140 Acc@5 100.000
[2024-11-09 18:29:52 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.1%
[2024-11-09 18:29:52 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.16%
[2024-11-09 18:29:57 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][0/156]	eta 0:12:49 lr 0.000007	 wd 0.0500	time 4.9338 (4.9338)	data time 4.5005 (4.5005)	model time 0.0000 (0.0000)	loss 0.4700 (0.4700)	grad_norm 4.9213 (4.9213)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:02 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][10/156]	eta 0:02:08 lr 0.000007	 wd 0.0500	time 0.4061 (0.8777)	data time 0.0006 (0.4175)	model time 0.0000 (0.0000)	loss 0.6375 (0.5801)	grad_norm 3.1105 (3.7224)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:07 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][20/156]	eta 0:01:32 lr 0.000007	 wd 0.0500	time 0.4368 (0.6820)	data time 0.0008 (0.2227)	model time 0.0000 (0.0000)	loss 0.5967 (0.5618)	grad_norm 2.5348 (3.5882)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:11 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][30/156]	eta 0:01:17 lr 0.000007	 wd 0.0500	time 0.4976 (0.6165)	data time 0.0240 (0.1538)	model time 0.0000 (0.0000)	loss 0.5552 (0.5461)	grad_norm 4.0743 (3.6459)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:16 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][40/156]	eta 0:01:07 lr 0.000007	 wd 0.0500	time 0.5127 (0.5793)	data time 0.0010 (0.1186)	model time 0.0000 (0.0000)	loss 0.6219 (0.5399)	grad_norm 2.1192 (3.6042)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:21 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][50/156]	eta 0:00:58 lr 0.000007	 wd 0.0500	time 0.5941 (0.5565)	data time 0.0009 (0.0975)	model time 0.0000 (0.0000)	loss 0.5698 (0.5359)	grad_norm 2.2227 (3.6394)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:25 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][60/156]	eta 0:00:51 lr 0.000007	 wd 0.0500	time 0.4245 (0.5392)	data time 0.0009 (0.0832)	model time 0.4236 (0.4415)	loss 0.6069 (0.5379)	grad_norm 7.1256 (3.6663)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:29 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][70/156]	eta 0:00:45 lr 0.000007	 wd 0.0500	time 0.4201 (0.5240)	data time 0.0005 (0.0729)	model time 0.4195 (0.4313)	loss 0.4741 (0.5372)	grad_norm 2.6356 (3.6399)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:34 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][80/156]	eta 0:00:39 lr 0.000007	 wd 0.0500	time 0.4075 (0.5146)	data time 0.0006 (0.0650)	model time 0.4069 (0.4337)	loss 0.5053 (0.5362)	grad_norm 2.3688 (3.5954)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:39 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][90/156]	eta 0:00:33 lr 0.000007	 wd 0.0500	time 0.5438 (0.5108)	data time 0.0136 (0.0586)	model time 0.5302 (0.4435)	loss 0.6217 (0.5375)	grad_norm 3.1611 (3.6177)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:43 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][100/156]	eta 0:00:28 lr 0.000007	 wd 0.0500	time 0.4155 (0.5041)	data time 0.0089 (0.0537)	model time 0.4066 (0.4417)	loss 0.5562 (0.5381)	grad_norm 5.7761 (3.6068)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:48 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][110/156]	eta 0:00:22 lr 0.000007	 wd 0.0500	time 0.4477 (0.4991)	data time 0.0242 (0.0498)	model time 0.4235 (0.4412)	loss 0.5365 (0.5394)	grad_norm 2.6613 (3.5901)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:52 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][120/156]	eta 0:00:17 lr 0.000007	 wd 0.0500	time 0.4201 (0.4965)	data time 0.0008 (0.0462)	model time 0.4193 (0.4440)	loss 0.4812 (0.5376)	grad_norm 2.6745 (3.5690)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:30:57 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][130/156]	eta 0:00:12 lr 0.000007	 wd 0.0500	time 0.4201 (0.4925)	data time 0.0058 (0.0433)	model time 0.4143 (0.4431)	loss 0.6368 (0.5353)	grad_norm 2.5483 (3.5676)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:31:01 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][140/156]	eta 0:00:07 lr 0.000007	 wd 0.0500	time 0.4354 (0.4899)	data time 0.0012 (0.0411)	model time 0.4342 (0.4431)	loss 0.4049 (0.5332)	grad_norm 3.4136 (3.5804)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:31:06 vssm1_tiny_0230s](training.py 201): INFO Train: [260/300][150/156]	eta 0:00:02 lr 0.000007	 wd 0.0500	time 0.4901 (0.4885)	data time 0.0005 (0.0386)	model time 0.4896 (0.4454)	loss 0.5708 (0.5334)	grad_norm 3.0029 (3.5500)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:31:08 vssm1_tiny_0230s](training.py 212): INFO EPOCH 260 training takes 0:01:16
[2024-11-09 18:31:08 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_260.pth saving......
[2024-11-09 18:31:09 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_260.pth saved !!!
[2024-11-09 18:31:12 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.580 (3.580)	Loss 0.1858 (0.1858)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:31:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.173 (0.560)	Loss 0.1959 (0.1869)	Acc@1 95.312 (96.733)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:31:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.168 (0.425)	Loss 0.1790 (0.1954)	Acc@1 99.219 (96.317)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:31:19 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.191 (0.336)	Loss 0.2407 (0.2024)	Acc@1 92.188 (95.817)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:31:21 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.620 Acc@5 100.000
[2024-11-09 18:31:21 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:31:21 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:31:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 6.650 (6.650)	Loss 0.1985 (0.1985)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:31:30 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.343 (0.809)	Loss 0.2054 (0.2034)	Acc@1 95.312 (95.668)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:31:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.273 (0.524)	Loss 0.2090 (0.2151)	Acc@1 96.094 (94.829)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:31:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.148 (0.489)	Loss 0.2703 (0.2264)	Acc@1 92.188 (94.279)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:31:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.220 Acc@5 100.000
[2024-11-09 18:31:38 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.2%
[2024-11-09 18:31:38 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.22%
[2024-11-09 18:31:42 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][0/156]	eta 0:11:12 lr 0.000007	 wd 0.0500	time 4.3083 (4.3083)	data time 3.6825 (3.6825)	model time 0.0000 (0.0000)	loss 0.5908 (0.5908)	grad_norm 3.3131 (3.3131)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:31:47 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][10/156]	eta 0:01:58 lr 0.000007	 wd 0.0500	time 0.4644 (0.8083)	data time 0.0133 (0.3413)	model time 0.0000 (0.0000)	loss 0.5090 (0.5681)	grad_norm 2.4812 (3.3548)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:31:52 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][20/156]	eta 0:01:28 lr 0.000007	 wd 0.0500	time 0.4344 (0.6525)	data time 0.0113 (0.1830)	model time 0.0000 (0.0000)	loss 0.4554 (0.5458)	grad_norm 2.6919 (3.5955)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:31:57 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][30/156]	eta 0:01:15 lr 0.000007	 wd 0.0500	time 0.6430 (0.6010)	data time 0.0171 (0.1262)	model time 0.0000 (0.0000)	loss 0.6178 (0.5455)	grad_norm 2.3391 (3.3711)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:02 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][40/156]	eta 0:01:06 lr 0.000007	 wd 0.0500	time 0.4825 (0.5709)	data time 0.0012 (0.0973)	model time 0.0000 (0.0000)	loss 0.5783 (0.5404)	grad_norm 1.7358 (3.4161)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:07 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][50/156]	eta 0:01:00 lr 0.000007	 wd 0.0500	time 0.4603 (0.5714)	data time 0.0007 (0.0822)	model time 0.0000 (0.0000)	loss 0.4912 (0.5419)	grad_norm 3.7120 (3.5261)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:13 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][60/156]	eta 0:00:54 lr 0.000007	 wd 0.0500	time 0.4458 (0.5634)	data time 0.0033 (0.0713)	model time 0.4425 (0.5070)	loss 0.5602 (0.5390)	grad_norm 3.2455 (3.5416)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:18 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][70/156]	eta 0:00:48 lr 0.000007	 wd 0.0500	time 0.4431 (0.5599)	data time 0.0067 (0.0635)	model time 0.4364 (0.5146)	loss 0.5815 (0.5355)	grad_norm 2.5810 (3.4902)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:23 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][80/156]	eta 0:00:42 lr 0.000007	 wd 0.0500	time 0.5418 (0.5566)	data time 0.0969 (0.0591)	model time 0.4449 (0.5115)	loss 0.6306 (0.5359)	grad_norm 2.7960 (3.4692)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:29 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][90/156]	eta 0:00:36 lr 0.000007	 wd 0.0500	time 0.4821 (0.5549)	data time 0.0398 (0.0543)	model time 0.4423 (0.5151)	loss 0.5749 (0.5359)	grad_norm 3.4794 (3.5699)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:34 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][100/156]	eta 0:00:30 lr 0.000007	 wd 0.0500	time 0.5626 (0.5532)	data time 0.0389 (0.0502)	model time 0.5237 (0.5171)	loss 0.5835 (0.5373)	grad_norm 2.8261 (3.5521)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:39 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][110/156]	eta 0:00:25 lr 0.000007	 wd 0.0500	time 0.4998 (0.5480)	data time 0.0033 (0.0476)	model time 0.4964 (0.5098)	loss 0.5964 (0.5342)	grad_norm 1.9279 (3.5477)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:44 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][120/156]	eta 0:00:19 lr 0.000007	 wd 0.0500	time 0.5202 (0.5440)	data time 0.0317 (0.0452)	model time 0.4885 (0.5059)	loss 0.6303 (0.5325)	grad_norm 7.1593 (3.6390)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:49 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][130/156]	eta 0:00:14 lr 0.000007	 wd 0.0500	time 0.4523 (0.5432)	data time 0.0015 (0.0428)	model time 0.4508 (0.5075)	loss 0.4810 (0.5309)	grad_norm 4.0662 (3.6089)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:54 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][140/156]	eta 0:00:08 lr 0.000007	 wd 0.0500	time 0.5216 (0.5389)	data time 0.0008 (0.0405)	model time 0.5207 (0.5037)	loss 0.6455 (0.5329)	grad_norm 4.5198 (3.6473)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:32:59 vssm1_tiny_0230s](training.py 201): INFO Train: [261/300][150/156]	eta 0:00:03 lr 0.000007	 wd 0.0500	time 0.5559 (0.5352)	data time 0.0004 (0.0379)	model time 0.5555 (0.5013)	loss 0.5208 (0.5332)	grad_norm 3.9294 (3.6265)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:33:02 vssm1_tiny_0230s](training.py 212): INFO EPOCH 261 training takes 0:01:23
[2024-11-09 18:33:02 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_261.pth saving......
[2024-11-09 18:33:02 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_261.pth saved !!!
[2024-11-09 18:33:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.495 (3.495)	Loss 0.1951 (0.1951)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:33:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.648)	Loss 0.2047 (0.1962)	Acc@1 95.312 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:33:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.463)	Loss 0.1709 (0.2037)	Acc@1 99.219 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:33:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.147 (0.375)	Loss 0.2321 (0.2056)	Acc@1 92.188 (95.766)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:33:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.700 Acc@5 100.000
[2024-11-09 18:33:17 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:33:17 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:33:20 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.018 (3.018)	Loss 0.1980 (0.1980)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:33:23 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.551 (0.533)	Loss 0.2051 (0.2029)	Acc@1 95.312 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:33:25 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.385)	Loss 0.2085 (0.2146)	Acc@1 96.875 (94.903)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:33:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.247 (0.345)	Loss 0.2698 (0.2259)	Acc@1 92.188 (94.330)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:33:30 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.260 Acc@5 100.000
[2024-11-09 18:33:30 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.3%
[2024-11-09 18:33:30 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.26%
[2024-11-09 18:33:35 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][0/156]	eta 0:12:18 lr 0.000007	 wd 0.0500	time 4.7329 (4.7329)	data time 4.2343 (4.2343)	model time 0.0000 (0.0000)	loss 0.4400 (0.4400)	grad_norm 3.3977 (3.3977)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:33:40 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][10/156]	eta 0:02:10 lr 0.000007	 wd 0.0500	time 0.4498 (0.8923)	data time 0.0057 (0.3929)	model time 0.0000 (0.0000)	loss 0.6057 (0.5327)	grad_norm 2.7053 (3.5135)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:33:45 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][20/156]	eta 0:01:36 lr 0.000007	 wd 0.0500	time 0.5233 (0.7127)	data time 0.0009 (0.2105)	model time 0.0000 (0.0000)	loss 0.5406 (0.5138)	grad_norm 3.3172 (3.5509)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:33:50 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][30/156]	eta 0:01:20 lr 0.000007	 wd 0.0500	time 0.4260 (0.6376)	data time 0.0195 (0.1515)	model time 0.0000 (0.0000)	loss 0.6718 (0.5343)	grad_norm 2.7758 (3.3788)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:33:55 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][40/156]	eta 0:01:10 lr 0.000007	 wd 0.0500	time 0.5547 (0.6059)	data time 0.0093 (0.1181)	model time 0.0000 (0.0000)	loss 0.5378 (0.5271)	grad_norm 1.8049 (3.4948)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:00 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][50/156]	eta 0:01:01 lr 0.000007	 wd 0.0500	time 0.4523 (0.5784)	data time 0.0099 (0.0976)	model time 0.0000 (0.0000)	loss 0.5930 (0.5314)	grad_norm 5.9203 (3.5381)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:05 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][60/156]	eta 0:00:53 lr 0.000007	 wd 0.0500	time 0.4774 (0.5620)	data time 0.0009 (0.0829)	model time 0.4765 (0.4701)	loss 0.6166 (0.5309)	grad_norm 3.3366 (3.4924)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:10 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][70/156]	eta 0:00:47 lr 0.000007	 wd 0.0500	time 0.4244 (0.5518)	data time 0.0005 (0.0748)	model time 0.4239 (0.4672)	loss 0.4430 (0.5270)	grad_norm 2.7106 (3.4669)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:14 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][80/156]	eta 0:00:41 lr 0.000007	 wd 0.0500	time 0.5193 (0.5431)	data time 0.0042 (0.0662)	model time 0.5151 (0.4704)	loss 0.5511 (0.5308)	grad_norm 2.0102 (3.4661)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:19 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][90/156]	eta 0:00:35 lr 0.000007	 wd 0.0500	time 0.4850 (0.5359)	data time 0.0005 (0.0601)	model time 0.4845 (0.4694)	loss 0.6162 (0.5307)	grad_norm 1.5935 (3.4365)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:24 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][100/156]	eta 0:00:29 lr 0.000007	 wd 0.0500	time 0.4997 (0.5316)	data time 0.0050 (0.0557)	model time 0.4947 (0.4708)	loss 0.5719 (0.5318)	grad_norm 3.9701 (3.5625)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:29 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][110/156]	eta 0:00:24 lr 0.000007	 wd 0.0500	time 0.4669 (0.5291)	data time 0.0101 (0.0519)	model time 0.4568 (0.4740)	loss 0.6203 (0.5354)	grad_norm 2.1583 (3.4841)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:34 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][120/156]	eta 0:00:18 lr 0.000007	 wd 0.0500	time 0.4625 (0.5246)	data time 0.0377 (0.0486)	model time 0.4248 (0.4725)	loss 0.5987 (0.5359)	grad_norm 3.7999 (3.4512)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:39 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][130/156]	eta 0:00:13 lr 0.000007	 wd 0.0500	time 0.5129 (0.5243)	data time 0.0164 (0.0458)	model time 0.4965 (0.4769)	loss 0.6441 (0.5359)	grad_norm 2.5658 (3.4052)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:44 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][140/156]	eta 0:00:08 lr 0.000007	 wd 0.0500	time 0.4275 (0.5223)	data time 0.0009 (0.0436)	model time 0.4265 (0.4775)	loss 0.5944 (0.5371)	grad_norm 3.0437 (3.3734)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:49 vssm1_tiny_0230s](training.py 201): INFO Train: [262/300][150/156]	eta 0:00:03 lr 0.000007	 wd 0.0500	time 0.4265 (0.5201)	data time 0.0007 (0.0409)	model time 0.4258 (0.4784)	loss 0.5390 (0.5379)	grad_norm 3.8805 (3.3762)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:34:52 vssm1_tiny_0230s](training.py 212): INFO EPOCH 262 training takes 0:01:21
[2024-11-09 18:34:52 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_262.pth saving......
[2024-11-09 18:34:52 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_262.pth saved !!!
[2024-11-09 18:34:56 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.945 (3.945)	Loss 0.1998 (0.1998)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:34:58 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.219 (0.547)	Loss 0.2115 (0.2026)	Acc@1 94.531 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:35:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.387)	Loss 0.1786 (0.2101)	Acc@1 99.219 (95.685)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:35:03 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.332)	Loss 0.2351 (0.2113)	Acc@1 92.188 (95.590)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:35:06 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.600 Acc@5 100.000
[2024-11-09 18:35:06 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:35:06 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:35:10 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.877 (3.877)	Loss 0.1981 (0.1981)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:35:12 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.586 (0.571)	Loss 0.2052 (0.2029)	Acc@1 95.312 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:35:15 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.425)	Loss 0.2076 (0.2145)	Acc@1 96.875 (94.903)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:35:17 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.365)	Loss 0.2690 (0.2255)	Acc@1 92.188 (94.330)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:35:20 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.260 Acc@5 100.000
[2024-11-09 18:35:20 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.3%
[2024-11-09 18:35:20 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.26%
[2024-11-09 18:35:26 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][0/156]	eta 0:14:55 lr 0.000007	 wd 0.0500	time 5.7400 (5.7400)	data time 5.2229 (5.2229)	model time 0.0000 (0.0000)	loss 0.5821 (0.5821)	grad_norm 2.2557 (2.2557)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:35:31 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][10/156]	eta 0:02:23 lr 0.000006	 wd 0.0500	time 0.6363 (0.9801)	data time 0.0045 (0.4870)	model time 0.0000 (0.0000)	loss 0.5640 (0.5386)	grad_norm 2.9962 (3.0914)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:35:36 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][20/156]	eta 0:01:43 lr 0.000006	 wd 0.0500	time 0.4777 (0.7617)	data time 0.0054 (0.2628)	model time 0.0000 (0.0000)	loss 0.4662 (0.5452)	grad_norm 2.8237 (3.0561)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:35:41 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][30/156]	eta 0:01:26 lr 0.000006	 wd 0.0500	time 0.4897 (0.6845)	data time 0.0101 (0.1810)	model time 0.0000 (0.0000)	loss 0.5483 (0.5333)	grad_norm 2.4657 (3.1004)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:35:46 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][40/156]	eta 0:01:13 lr 0.000006	 wd 0.0500	time 0.4273 (0.6353)	data time 0.0010 (0.1426)	model time 0.0000 (0.0000)	loss 0.5708 (0.5350)	grad_norm 3.5472 (3.1465)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:35:51 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][50/156]	eta 0:01:04 lr 0.000006	 wd 0.0500	time 0.4271 (0.6105)	data time 0.0198 (0.1178)	model time 0.0000 (0.0000)	loss 0.5749 (0.5426)	grad_norm 2.2846 (3.2328)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:35:56 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][60/156]	eta 0:00:57 lr 0.000006	 wd 0.0500	time 0.5377 (0.5940)	data time 0.0008 (0.1004)	model time 0.5369 (0.4984)	loss 0.5455 (0.5452)	grad_norm 3.2982 (3.1968)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:36:02 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][70/156]	eta 0:00:50 lr 0.000006	 wd 0.0500	time 0.5061 (0.5870)	data time 0.0058 (0.0893)	model time 0.5002 (0.5105)	loss 0.6319 (0.5474)	grad_norm 2.4632 (3.1961)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:36:07 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][80/156]	eta 0:00:43 lr 0.000006	 wd 0.0500	time 0.5455 (0.5749)	data time 0.0208 (0.0800)	model time 0.5248 (0.4986)	loss 0.6494 (0.5458)	grad_norm 2.3022 (3.2852)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:36:11 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][90/156]	eta 0:00:37 lr 0.000006	 wd 0.0500	time 0.4474 (0.5642)	data time 0.0008 (0.0731)	model time 0.4466 (0.4890)	loss 0.5805 (0.5483)	grad_norm 4.0137 (3.2616)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:36:16 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][100/156]	eta 0:00:31 lr 0.000006	 wd 0.0500	time 0.4774 (0.5566)	data time 0.0010 (0.0675)	model time 0.4764 (0.4855)	loss 0.6171 (0.5484)	grad_norm 2.2475 (3.2862)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:36:21 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][110/156]	eta 0:00:25 lr 0.000006	 wd 0.0500	time 0.4720 (0.5488)	data time 0.0410 (0.0627)	model time 0.4310 (0.4805)	loss 0.5311 (0.5512)	grad_norm 2.3932 (3.2593)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:36:26 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][120/156]	eta 0:00:19 lr 0.000006	 wd 0.0500	time 0.4407 (0.5456)	data time 0.0037 (0.0582)	model time 0.4370 (0.4836)	loss 0.5615 (0.5525)	grad_norm 4.3633 (3.2712)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:36:31 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][130/156]	eta 0:00:14 lr 0.000006	 wd 0.0500	time 0.5945 (0.5428)	data time 0.0249 (0.0550)	model time 0.5695 (0.4847)	loss 0.5595 (0.5521)	grad_norm 3.1105 (3.2630)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:36:36 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][140/156]	eta 0:00:08 lr 0.000006	 wd 0.0500	time 0.4122 (0.5414)	data time 0.0010 (0.0522)	model time 0.4112 (0.4872)	loss 0.5961 (0.5497)	grad_norm 2.0854 (3.3082)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:36:41 vssm1_tiny_0230s](training.py 201): INFO Train: [263/300][150/156]	eta 0:00:03 lr 0.000006	 wd 0.0500	time 0.4557 (0.5382)	data time 0.0004 (0.0488)	model time 0.4553 (0.4877)	loss 0.4918 (0.5493)	grad_norm 2.8685 (3.2909)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:36:44 vssm1_tiny_0230s](training.py 212): INFO EPOCH 263 training takes 0:01:24
[2024-11-09 18:36:44 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_263.pth saving......
[2024-11-09 18:36:44 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_263.pth saved !!!
[2024-11-09 18:36:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.864 (2.864)	Loss 0.1965 (0.1965)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:36:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.189 (0.525)	Loss 0.2063 (0.1989)	Acc@1 96.875 (96.946)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:36:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.174 (0.415)	Loss 0.1923 (0.2076)	Acc@1 98.438 (96.391)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:36:56 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 1.143 (0.391)	Loss 0.2517 (0.2147)	Acc@1 91.406 (95.892)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:37:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.660 Acc@5 100.000
[2024-11-09 18:37:00 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:37:00 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:37:04 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.316 (4.316)	Loss 0.1982 (0.1982)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:37:07 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.357 (0.620)	Loss 0.2052 (0.2028)	Acc@1 95.312 (95.739)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:37:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.488)	Loss 0.2069 (0.2143)	Acc@1 96.875 (94.903)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:37:13 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.135 (0.434)	Loss 0.2681 (0.2250)	Acc@1 92.188 (94.355)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:37:15 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.280 Acc@5 100.000
[2024-11-09 18:37:15 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.3%
[2024-11-09 18:37:15 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.28%
[2024-11-09 18:37:20 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][0/156]	eta 0:11:02 lr 0.000006	 wd 0.0500	time 4.2441 (4.2441)	data time 3.7560 (3.7560)	model time 0.0000 (0.0000)	loss 0.4020 (0.4020)	grad_norm 3.2326 (3.2326)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:37:25 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][10/156]	eta 0:02:11 lr 0.000006	 wd 0.0500	time 0.6063 (0.9010)	data time 0.0046 (0.4160)	model time 0.0000 (0.0000)	loss 0.5250 (0.5344)	grad_norm 2.3491 (3.4685)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:37:31 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][20/156]	eta 0:01:38 lr 0.000006	 wd 0.0500	time 0.5966 (0.7266)	data time 0.0069 (0.2244)	model time 0.0000 (0.0000)	loss 0.6343 (0.5424)	grad_norm 2.8649 (3.4831)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:37:36 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][30/156]	eta 0:01:23 lr 0.000006	 wd 0.0500	time 0.5336 (0.6652)	data time 0.0256 (0.1552)	model time 0.0000 (0.0000)	loss 0.6093 (0.5428)	grad_norm 3.4497 (3.2132)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:37:42 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][40/156]	eta 0:01:14 lr 0.000006	 wd 0.0500	time 0.5625 (0.6392)	data time 0.0084 (0.1224)	model time 0.0000 (0.0000)	loss 0.4241 (0.5343)	grad_norm 4.0510 (3.1664)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:37:47 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][50/156]	eta 0:01:05 lr 0.000006	 wd 0.0500	time 0.5881 (0.6221)	data time 0.0176 (0.1008)	model time 0.0000 (0.0000)	loss 0.5844 (0.5293)	grad_norm 4.5720 (3.2425)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:37:52 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][60/156]	eta 0:00:58 lr 0.000006	 wd 0.0500	time 0.4455 (0.6052)	data time 0.0042 (0.0869)	model time 0.4412 (0.5029)	loss 0.5916 (0.5307)	grad_norm 2.0206 (3.3531)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:37:58 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][70/156]	eta 0:00:50 lr 0.000006	 wd 0.0500	time 0.6095 (0.5924)	data time 0.0514 (0.0772)	model time 0.5581 (0.4996)	loss 0.5106 (0.5315)	grad_norm 4.8003 (3.4063)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:38:03 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][80/156]	eta 0:00:44 lr 0.000006	 wd 0.0500	time 0.4827 (0.5860)	data time 0.0005 (0.0697)	model time 0.4822 (0.5078)	loss 0.3882 (0.5320)	grad_norm 4.0799 (3.5146)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:38:08 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][90/156]	eta 0:00:38 lr 0.000006	 wd 0.0500	time 0.4753 (0.5764)	data time 0.0007 (0.0642)	model time 0.4746 (0.5006)	loss 0.4532 (0.5376)	grad_norm 3.2961 (3.4893)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:38:13 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][100/156]	eta 0:00:31 lr 0.000006	 wd 0.0500	time 0.5809 (0.5686)	data time 0.0111 (0.0596)	model time 0.5698 (0.4963)	loss 0.5586 (0.5412)	grad_norm 1.7997 (3.4352)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:38:19 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][110/156]	eta 0:00:26 lr 0.000006	 wd 0.0500	time 0.6119 (0.5696)	data time 0.0209 (0.0565)	model time 0.5910 (0.5062)	loss 0.5837 (0.5418)	grad_norm 2.4694 (3.4134)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:38:24 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][120/156]	eta 0:00:20 lr 0.000006	 wd 0.0500	time 0.5462 (0.5667)	data time 0.0227 (0.0539)	model time 0.5236 (0.5066)	loss 0.4643 (0.5435)	grad_norm 3.4450 (3.4274)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:38:29 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][130/156]	eta 0:00:14 lr 0.000006	 wd 0.0500	time 0.7677 (0.5647)	data time 0.0503 (0.0507)	model time 0.7175 (0.5093)	loss 0.5431 (0.5435)	grad_norm 2.1950 (3.4834)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:38:35 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][140/156]	eta 0:00:08 lr 0.000006	 wd 0.0500	time 0.5159 (0.5615)	data time 0.0010 (0.0477)	model time 0.5149 (0.5095)	loss 0.6043 (0.5431)	grad_norm 3.4529 (3.4935)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:38:39 vssm1_tiny_0230s](training.py 201): INFO Train: [264/300][150/156]	eta 0:00:03 lr 0.000006	 wd 0.0500	time 0.4875 (0.5558)	data time 0.0131 (0.0449)	model time 0.4744 (0.5057)	loss 0.5789 (0.5421)	grad_norm 3.8289 (3.4903)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:38:42 vssm1_tiny_0230s](training.py 212): INFO EPOCH 264 training takes 0:01:26
[2024-11-09 18:38:42 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_264.pth saving......
[2024-11-09 18:38:43 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_264.pth saved !!!
[2024-11-09 18:38:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.294 (4.294)	Loss 0.1985 (0.1985)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:38:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.161 (0.635)	Loss 0.2076 (0.1991)	Acc@1 96.094 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:38:52 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.150 (0.441)	Loss 0.1880 (0.2070)	Acc@1 98.438 (96.540)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:38:55 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.227 (0.411)	Loss 0.2496 (0.2125)	Acc@1 91.406 (95.892)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:38:57 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.600 Acc@5 100.000
[2024-11-09 18:38:57 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 18:38:57 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:39:02 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.484 (4.484)	Loss 0.1979 (0.1979)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:39:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.140 (0.543)	Loss 0.2050 (0.2024)	Acc@1 95.312 (95.810)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:39:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.238 (0.377)	Loss 0.2064 (0.2139)	Acc@1 96.875 (94.903)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:39:08 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.180 (0.334)	Loss 0.2678 (0.2246)	Acc@1 92.188 (94.380)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:39:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.320 Acc@5 100.000
[2024-11-09 18:39:10 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.3%
[2024-11-09 18:39:10 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.32%
[2024-11-09 18:39:15 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][0/156]	eta 0:13:29 lr 0.000006	 wd 0.0500	time 5.1913 (5.1913)	data time 4.7750 (4.7750)	model time 0.0000 (0.0000)	loss 0.4155 (0.4155)	grad_norm 5.4351 (5.4351)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:39:20 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][10/156]	eta 0:02:12 lr 0.000006	 wd 0.0500	time 0.5519 (0.9089)	data time 0.0083 (0.4447)	model time 0.0000 (0.0000)	loss 0.5106 (0.5158)	grad_norm 1.8645 (3.3658)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:39:25 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][20/156]	eta 0:01:37 lr 0.000006	 wd 0.0500	time 0.5045 (0.7169)	data time 0.0141 (0.2402)	model time 0.0000 (0.0000)	loss 0.6202 (0.5277)	grad_norm 5.0538 (3.5159)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:39:31 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][30/156]	eta 0:01:22 lr 0.000006	 wd 0.0500	time 0.5959 (0.6571)	data time 0.0425 (0.1727)	model time 0.0000 (0.0000)	loss 0.3999 (0.5337)	grad_norm 5.7300 (3.5538)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:39:36 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][40/156]	eta 0:01:12 lr 0.000006	 wd 0.0500	time 0.4643 (0.6233)	data time 0.0179 (0.1341)	model time 0.0000 (0.0000)	loss 0.4421 (0.5436)	grad_norm 4.0540 (3.5802)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:39:41 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][50/156]	eta 0:01:04 lr 0.000006	 wd 0.0500	time 0.4467 (0.6078)	data time 0.0028 (0.1098)	model time 0.0000 (0.0000)	loss 0.5471 (0.5387)	grad_norm 3.7950 (3.4989)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:39:46 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][60/156]	eta 0:00:56 lr 0.000006	 wd 0.0500	time 0.6119 (0.5883)	data time 0.0146 (0.0933)	model time 0.5973 (0.4797)	loss 0.4529 (0.5400)	grad_norm 4.3602 (3.4482)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:39:51 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][70/156]	eta 0:00:49 lr 0.000006	 wd 0.0500	time 0.4551 (0.5736)	data time 0.0006 (0.0811)	model time 0.4545 (0.4782)	loss 0.6271 (0.5399)	grad_norm 2.1906 (3.6064)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:39:56 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][80/156]	eta 0:00:43 lr 0.000006	 wd 0.0500	time 0.6465 (0.5667)	data time 0.0420 (0.0732)	model time 0.6046 (0.4858)	loss 0.5233 (0.5373)	grad_norm 3.3070 (3.6332)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:40:01 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][90/156]	eta 0:00:36 lr 0.000006	 wd 0.0500	time 0.5723 (0.5595)	data time 0.0037 (0.0668)	model time 0.5686 (0.4861)	loss 0.5896 (0.5353)	grad_norm 4.8041 (3.6355)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:40:06 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][100/156]	eta 0:00:30 lr 0.000006	 wd 0.0500	time 0.4416 (0.5525)	data time 0.0005 (0.0626)	model time 0.4411 (0.4817)	loss 0.5255 (0.5316)	grad_norm 4.6021 (3.6474)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:40:11 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][110/156]	eta 0:00:25 lr 0.000006	 wd 0.0500	time 0.6246 (0.5483)	data time 0.1366 (0.0598)	model time 0.4880 (0.4805)	loss 0.3941 (0.5325)	grad_norm 3.9466 (3.6358)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:40:16 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][120/156]	eta 0:00:19 lr 0.000006	 wd 0.0500	time 0.4761 (0.5438)	data time 0.0047 (0.0558)	model time 0.4714 (0.4807)	loss 0.4822 (0.5334)	grad_norm 3.8595 (3.6006)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:40:21 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][130/156]	eta 0:00:14 lr 0.000006	 wd 0.0500	time 0.5468 (0.5391)	data time 0.0016 (0.0521)	model time 0.5451 (0.4801)	loss 0.6414 (0.5319)	grad_norm 2.2097 (3.6312)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:40:26 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][140/156]	eta 0:00:08 lr 0.000006	 wd 0.0500	time 0.5398 (0.5383)	data time 0.0009 (0.0489)	model time 0.5388 (0.4845)	loss 0.5500 (0.5311)	grad_norm 2.7691 (3.6202)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:40:31 vssm1_tiny_0230s](training.py 201): INFO Train: [265/300][150/156]	eta 0:00:03 lr 0.000006	 wd 0.0500	time 0.5240 (0.5366)	data time 0.0007 (0.0458)	model time 0.5233 (0.4872)	loss 0.5685 (0.5314)	grad_norm 4.3661 (3.6138)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:40:35 vssm1_tiny_0230s](training.py 212): INFO EPOCH 265 training takes 0:01:24
[2024-11-09 18:40:35 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_265.pth saving......
[2024-11-09 18:40:35 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_265.pth saved !!!
[2024-11-09 18:40:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.045 (3.045)	Loss 0.2085 (0.2085)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:40:41 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.170 (0.497)	Loss 0.2201 (0.2123)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:40:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.159 (0.356)	Loss 0.1561 (0.2185)	Acc@1 99.219 (95.015)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:40:45 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.318)	Loss 0.2091 (0.2084)	Acc@1 94.531 (95.514)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:40:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.680 Acc@5 100.000
[2024-11-09 18:40:48 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:40:48 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:40:51 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.910 (2.910)	Loss 0.1978 (0.1978)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:40:54 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.995 (0.542)	Loss 0.2048 (0.2023)	Acc@1 95.312 (95.810)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:40:56 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.251 (0.392)	Loss 0.2058 (0.2137)	Acc@1 96.875 (94.903)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:40:59 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.401 (0.347)	Loss 0.2671 (0.2242)	Acc@1 92.188 (94.405)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:41:01 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.340 Acc@5 100.000
[2024-11-09 18:41:01 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.3%
[2024-11-09 18:41:01 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.34%
[2024-11-09 18:41:07 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][0/156]	eta 0:14:37 lr 0.000006	 wd 0.0500	time 5.6247 (5.6247)	data time 5.0786 (5.0786)	model time 0.0000 (0.0000)	loss 0.4052 (0.4052)	grad_norm 4.3857 (4.3857)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:41:11 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][10/156]	eta 0:02:16 lr 0.000006	 wd 0.0500	time 0.4271 (0.9355)	data time 0.0059 (0.4762)	model time 0.0000 (0.0000)	loss 0.5585 (0.5200)	grad_norm 2.3643 (4.5845)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:41:16 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][20/156]	eta 0:01:39 lr 0.000006	 wd 0.0500	time 0.4505 (0.7290)	data time 0.0041 (0.2563)	model time 0.0000 (0.0000)	loss 0.5809 (0.5483)	grad_norm 1.8725 (4.0661)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:41:22 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][30/156]	eta 0:01:23 lr 0.000006	 wd 0.0500	time 0.6223 (0.6654)	data time 0.0094 (0.1776)	model time 0.0000 (0.0000)	loss 0.5632 (0.5379)	grad_norm 2.8119 (3.8815)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:41:27 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][40/156]	eta 0:01:12 lr 0.000006	 wd 0.0500	time 0.4089 (0.6251)	data time 0.0008 (0.1401)	model time 0.0000 (0.0000)	loss 0.6014 (0.5351)	grad_norm 1.8002 (3.6562)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:41:32 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][50/156]	eta 0:01:03 lr 0.000006	 wd 0.0500	time 0.4919 (0.5983)	data time 0.0298 (0.1149)	model time 0.0000 (0.0000)	loss 0.4227 (0.5332)	grad_norm 3.0769 (3.5031)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:41:36 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][60/156]	eta 0:00:55 lr 0.000006	 wd 0.0500	time 0.5409 (0.5788)	data time 0.0154 (0.0974)	model time 0.5255 (0.4709)	loss 0.5848 (0.5335)	grad_norm 1.9996 (3.4755)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:41:42 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][70/156]	eta 0:00:48 lr 0.000006	 wd 0.0500	time 0.5312 (0.5691)	data time 0.0038 (0.0863)	model time 0.5273 (0.4811)	loss 0.5435 (0.5431)	grad_norm 4.2796 (3.4828)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:41:46 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][80/156]	eta 0:00:42 lr 0.000006	 wd 0.0500	time 0.4281 (0.5565)	data time 0.0174 (0.0789)	model time 0.4107 (0.4676)	loss 0.5175 (0.5438)	grad_norm 3.2180 (3.4856)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:41:51 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][90/156]	eta 0:00:36 lr 0.000006	 wd 0.0500	time 0.4352 (0.5513)	data time 0.0093 (0.0721)	model time 0.4260 (0.4737)	loss 0.6232 (0.5461)	grad_norm 3.0363 (3.4493)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:41:56 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][100/156]	eta 0:00:30 lr 0.000006	 wd 0.0500	time 0.4852 (0.5479)	data time 0.0240 (0.0660)	model time 0.4613 (0.4803)	loss 0.5685 (0.5465)	grad_norm 2.7200 (3.3849)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:42:01 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][110/156]	eta 0:00:24 lr 0.000006	 wd 0.0500	time 0.5902 (0.5423)	data time 0.0228 (0.0616)	model time 0.5673 (0.4783)	loss 0.4012 (0.5421)	grad_norm 3.5788 (3.4122)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:42:07 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][120/156]	eta 0:00:19 lr 0.000006	 wd 0.0500	time 0.6432 (0.5417)	data time 0.0057 (0.0581)	model time 0.6375 (0.4836)	loss 0.5893 (0.5424)	grad_norm 2.0936 (3.3901)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:42:12 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][130/156]	eta 0:00:13 lr 0.000005	 wd 0.0500	time 0.4536 (0.5376)	data time 0.0048 (0.0549)	model time 0.4488 (0.4823)	loss 0.5335 (0.5430)	grad_norm 3.2327 (3.3833)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:42:17 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][140/156]	eta 0:00:08 lr 0.000005	 wd 0.0500	time 0.4625 (0.5379)	data time 0.0008 (0.0532)	model time 0.4617 (0.4853)	loss 0.5002 (0.5399)	grad_norm 2.2063 (3.3888)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:42:22 vssm1_tiny_0230s](training.py 201): INFO Train: [266/300][150/156]	eta 0:00:03 lr 0.000005	 wd 0.0500	time 0.5805 (0.5359)	data time 0.0006 (0.0497)	model time 0.5799 (0.4876)	loss 0.4495 (0.5378)	grad_norm 2.9075 (3.4205)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:42:25 vssm1_tiny_0230s](training.py 212): INFO EPOCH 266 training takes 0:01:23
[2024-11-09 18:42:25 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_266.pth saving......
[2024-11-09 18:42:25 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_266.pth saved !!!
[2024-11-09 18:42:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.687 (3.687)	Loss 0.1873 (0.1873)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:42:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.185 (0.535)	Loss 0.1996 (0.1913)	Acc@1 96.094 (97.159)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:42:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.376 (0.395)	Loss 0.1777 (0.1992)	Acc@1 99.219 (96.615)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:42:37 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.381)	Loss 0.2375 (0.2056)	Acc@1 92.969 (96.069)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:42:40 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.720 Acc@5 100.000
[2024-11-09 18:42:40 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:42:40 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.74%
[2024-11-09 18:42:43 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.422 (2.422)	Loss 0.1978 (0.1978)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:42:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.168 (0.519)	Loss 0.2050 (0.2022)	Acc@1 96.094 (95.881)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:42:49 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.407)	Loss 0.2051 (0.2135)	Acc@1 96.875 (94.940)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:42:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.151 (0.346)	Loss 0.2661 (0.2238)	Acc@1 92.188 (94.506)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:42:54 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.400 Acc@5 100.000
[2024-11-09 18:42:54 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.4%
[2024-11-09 18:42:54 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.40%
[2024-11-09 18:42:57 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][0/156]	eta 0:08:12 lr 0.000005	 wd 0.0500	time 3.1598 (3.1598)	data time 2.6916 (2.6916)	model time 0.0000 (0.0000)	loss 0.6065 (0.6065)	grad_norm 5.6835 (5.6835)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:04 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][10/156]	eta 0:02:04 lr 0.000005	 wd 0.0500	time 0.4951 (0.8551)	data time 0.0006 (0.3235)	model time 0.0000 (0.0000)	loss 0.5214 (0.5170)	grad_norm 1.6956 (3.5190)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:08 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][20/156]	eta 0:01:31 lr 0.000005	 wd 0.0500	time 0.4175 (0.6721)	data time 0.0030 (0.1726)	model time 0.0000 (0.0000)	loss 0.5806 (0.5226)	grad_norm 2.9926 (3.6826)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:13 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][30/156]	eta 0:01:17 lr 0.000005	 wd 0.0500	time 0.5013 (0.6183)	data time 0.0173 (0.1217)	model time 0.0000 (0.0000)	loss 0.4967 (0.5314)	grad_norm 3.7330 (3.7644)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:18 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][40/156]	eta 0:01:08 lr 0.000005	 wd 0.0500	time 0.4415 (0.5907)	data time 0.0053 (0.0956)	model time 0.0000 (0.0000)	loss 0.5718 (0.5334)	grad_norm 2.0328 (3.6288)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:23 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][50/156]	eta 0:01:00 lr 0.000005	 wd 0.0500	time 0.4288 (0.5675)	data time 0.0042 (0.0786)	model time 0.0000 (0.0000)	loss 0.6199 (0.5337)	grad_norm 3.9700 (3.7958)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:28 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][60/156]	eta 0:00:53 lr 0.000005	 wd 0.0500	time 0.6506 (0.5557)	data time 0.0009 (0.0694)	model time 0.6497 (0.4733)	loss 0.4738 (0.5364)	grad_norm 4.1023 (3.8491)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:33 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][70/156]	eta 0:00:47 lr 0.000005	 wd 0.0500	time 0.4856 (0.5480)	data time 0.0016 (0.0618)	model time 0.4841 (0.4792)	loss 0.6681 (0.5344)	grad_norm 3.7991 (3.8239)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:38 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][80/156]	eta 0:00:41 lr 0.000005	 wd 0.0500	time 0.6085 (0.5460)	data time 0.0260 (0.0573)	model time 0.5825 (0.4884)	loss 0.4681 (0.5324)	grad_norm 3.2595 (3.8028)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:43 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][90/156]	eta 0:00:35 lr 0.000005	 wd 0.0500	time 0.4827 (0.5380)	data time 0.0238 (0.0529)	model time 0.4590 (0.4803)	loss 0.6054 (0.5320)	grad_norm 3.1179 (3.7697)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:48 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][100/156]	eta 0:00:30 lr 0.000005	 wd 0.0500	time 0.6297 (0.5366)	data time 0.0280 (0.0495)	model time 0.6016 (0.4852)	loss 0.4546 (0.5306)	grad_norm 3.1305 (3.6966)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:53 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][110/156]	eta 0:00:24 lr 0.000005	 wd 0.0500	time 0.5272 (0.5312)	data time 0.0091 (0.0466)	model time 0.5181 (0.4810)	loss 0.5660 (0.5323)	grad_norm 4.2289 (3.7062)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:43:59 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][120/156]	eta 0:00:19 lr 0.000005	 wd 0.0500	time 0.4965 (0.5323)	data time 0.0160 (0.0454)	model time 0.4805 (0.4853)	loss 0.5887 (0.5293)	grad_norm 2.0080 (3.7113)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:44:04 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][130/156]	eta 0:00:13 lr 0.000005	 wd 0.0500	time 0.5327 (0.5292)	data time 0.0188 (0.0428)	model time 0.5139 (0.4849)	loss 0.6236 (0.5309)	grad_norm 2.1665 (3.7021)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:44:09 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][140/156]	eta 0:00:08 lr 0.000005	 wd 0.0500	time 0.6404 (0.5325)	data time 0.0008 (0.0403)	model time 0.6396 (0.4940)	loss 0.6315 (0.5323)	grad_norm 1.7646 (3.7105)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:44:15 vssm1_tiny_0230s](training.py 201): INFO Train: [267/300][150/156]	eta 0:00:03 lr 0.000005	 wd 0.0500	time 0.4246 (0.5325)	data time 0.0006 (0.0380)	model time 0.4239 (0.4974)	loss 0.4680 (0.5322)	grad_norm 1.7193 (3.7241)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:44:18 vssm1_tiny_0230s](training.py 212): INFO EPOCH 267 training takes 0:01:23
[2024-11-09 18:44:18 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_267.pth saving......
[2024-11-09 18:44:18 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_267.pth saved !!!
[2024-11-09 18:44:22 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.054 (4.054)	Loss 0.1948 (0.1948)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:44:24 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.153 (0.518)	Loss 0.2035 (0.1957)	Acc@1 96.094 (96.804)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:44:26 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.378)	Loss 0.1761 (0.2039)	Acc@1 98.438 (96.280)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:44:28 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.317)	Loss 0.2333 (0.2063)	Acc@1 92.969 (95.993)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:44:31 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.820 Acc@5 100.000
[2024-11-09 18:44:31 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 18:44:31 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.82%
[2024-11-09 18:44:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.418 (3.418)	Loss 0.1973 (0.1973)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:44:36 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.140 (0.532)	Loss 0.2045 (0.2018)	Acc@1 96.094 (95.881)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:44:39 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.181 (0.386)	Loss 0.2048 (0.2131)	Acc@1 96.875 (94.940)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:44:41 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.325 (0.330)	Loss 0.2661 (0.2234)	Acc@1 92.188 (94.506)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:44:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.400 Acc@5 100.000
[2024-11-09 18:44:43 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.4%
[2024-11-09 18:44:43 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.40%
[2024-11-09 18:44:47 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][0/156]	eta 0:09:46 lr 0.000005	 wd 0.0500	time 3.7571 (3.7571)	data time 3.2891 (3.2891)	model time 0.0000 (0.0000)	loss 0.6722 (0.6722)	grad_norm 2.3283 (2.3283)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:44:52 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][10/156]	eta 0:01:56 lr 0.000005	 wd 0.0500	time 0.5437 (0.7966)	data time 0.0157 (0.3083)	model time 0.0000 (0.0000)	loss 0.5318 (0.5382)	grad_norm 5.1704 (3.5371)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:44:56 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][20/156]	eta 0:01:27 lr 0.000005	 wd 0.0500	time 0.4080 (0.6419)	data time 0.0006 (0.1669)	model time 0.0000 (0.0000)	loss 0.6455 (0.5350)	grad_norm 4.2549 (3.8212)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:01 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][30/156]	eta 0:01:13 lr 0.000005	 wd 0.0500	time 0.4311 (0.5827)	data time 0.0078 (0.1148)	model time 0.0000 (0.0000)	loss 0.3964 (0.5218)	grad_norm 3.2806 (3.7203)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:05 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][40/156]	eta 0:01:04 lr 0.000005	 wd 0.0500	time 0.5267 (0.5532)	data time 0.0273 (0.0918)	model time 0.0000 (0.0000)	loss 0.5783 (0.5284)	grad_norm 3.1843 (3.6722)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:12 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][50/156]	eta 0:01:00 lr 0.000005	 wd 0.0500	time 0.5459 (0.5692)	data time 0.0450 (0.0777)	model time 0.0000 (0.0000)	loss 0.5286 (0.5298)	grad_norm 4.2068 (3.7063)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:18 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][60/156]	eta 0:00:55 lr 0.000005	 wd 0.0500	time 0.6273 (0.5734)	data time 0.0210 (0.0698)	model time 0.6063 (0.5651)	loss 0.4748 (0.5321)	grad_norm 3.9034 (3.7238)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:24 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][70/156]	eta 0:00:49 lr 0.000005	 wd 0.0500	time 0.5045 (0.5772)	data time 0.0009 (0.0635)	model time 0.5036 (0.5702)	loss 0.4851 (0.5350)	grad_norm 2.4689 (3.6963)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:30 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][80/156]	eta 0:00:44 lr 0.000005	 wd 0.0500	time 0.4680 (0.5817)	data time 0.0019 (0.0567)	model time 0.4661 (0.5818)	loss 0.5811 (0.5355)	grad_norm 3.4269 (3.7000)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:37 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][90/156]	eta 0:00:39 lr 0.000005	 wd 0.0500	time 0.6216 (0.5929)	data time 0.0192 (0.0537)	model time 0.6025 (0.6001)	loss 0.5875 (0.5357)	grad_norm 2.2988 (3.6272)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:42 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][100/156]	eta 0:00:32 lr 0.000005	 wd 0.0500	time 0.4863 (0.5830)	data time 0.0266 (0.0495)	model time 0.4598 (0.5763)	loss 0.5015 (0.5389)	grad_norm 2.2379 (3.5453)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:46 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][110/156]	eta 0:00:26 lr 0.000005	 wd 0.0500	time 0.4672 (0.5715)	data time 0.0080 (0.0459)	model time 0.4593 (0.5544)	loss 0.5279 (0.5375)	grad_norm 3.3284 (3.5491)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:51 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][120/156]	eta 0:00:20 lr 0.000005	 wd 0.0500	time 0.4701 (0.5646)	data time 0.0250 (0.0436)	model time 0.4451 (0.5425)	loss 0.3902 (0.5355)	grad_norm 2.8728 (3.5820)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:45:56 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][130/156]	eta 0:00:14 lr 0.000005	 wd 0.0500	time 0.6218 (0.5584)	data time 0.0008 (0.0408)	model time 0.6210 (0.5342)	loss 0.6272 (0.5351)	grad_norm 2.7184 (3.5591)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:46:01 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][140/156]	eta 0:00:08 lr 0.000005	 wd 0.0500	time 0.4819 (0.5546)	data time 0.0011 (0.0389)	model time 0.4809 (0.5293)	loss 0.6000 (0.5365)	grad_norm 2.6781 (3.5344)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:46:06 vssm1_tiny_0230s](training.py 201): INFO Train: [268/300][150/156]	eta 0:00:03 lr 0.000005	 wd 0.0500	time 0.4265 (0.5530)	data time 0.0007 (0.0382)	model time 0.4258 (0.5266)	loss 0.5912 (0.5377)	grad_norm 4.1987 (3.4991)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:46:10 vssm1_tiny_0230s](training.py 212): INFO EPOCH 268 training takes 0:01:26
[2024-11-09 18:46:10 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_268.pth saving......
[2024-11-09 18:46:10 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_268.pth saved !!!
[2024-11-09 18:46:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.787 (2.787)	Loss 0.1956 (0.1956)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:46:16 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.203 (0.504)	Loss 0.2062 (0.1962)	Acc@1 95.312 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:46:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.230 (0.374)	Loss 0.1854 (0.2049)	Acc@1 98.438 (96.243)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:46:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.337)	Loss 0.2404 (0.2098)	Acc@1 92.969 (95.943)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:46:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.780 Acc@5 100.000
[2024-11-09 18:46:24 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 18:46:24 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.82%
[2024-11-09 18:46:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.632 (2.632)	Loss 0.1975 (0.1975)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:46:30 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.251 (0.599)	Loss 0.2046 (0.2018)	Acc@1 96.094 (95.810)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:46:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.156 (0.404)	Loss 0.2040 (0.2130)	Acc@1 96.875 (94.978)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:46:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.373)	Loss 0.2651 (0.2230)	Acc@1 92.188 (94.556)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:46:37 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.460 Acc@5 100.000
[2024-11-09 18:46:37 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.5%
[2024-11-09 18:46:37 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.46%
[2024-11-09 18:46:41 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][0/156]	eta 0:11:11 lr 0.000005	 wd 0.0500	time 4.3050 (4.3050)	data time 3.8443 (3.8443)	model time 0.0000 (0.0000)	loss 0.5970 (0.5970)	grad_norm 2.6071 (2.6071)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:46:46 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][10/156]	eta 0:02:05 lr 0.000005	 wd 0.0500	time 0.4646 (0.8624)	data time 0.0102 (0.3703)	model time 0.0000 (0.0000)	loss 0.4287 (0.5183)	grad_norm 5.7033 (3.9159)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:46:52 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][20/156]	eta 0:01:35 lr 0.000005	 wd 0.0500	time 0.5139 (0.7052)	data time 0.0008 (0.2003)	model time 0.0000 (0.0000)	loss 0.5747 (0.5450)	grad_norm 1.7311 (3.3609)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:46:57 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][30/156]	eta 0:01:21 lr 0.000005	 wd 0.0500	time 0.5242 (0.6450)	data time 0.0487 (0.1430)	model time 0.0000 (0.0000)	loss 0.5397 (0.5435)	grad_norm 2.6128 (3.3400)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:02 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][40/156]	eta 0:01:11 lr 0.000005	 wd 0.0500	time 0.4314 (0.6133)	data time 0.0011 (0.1107)	model time 0.0000 (0.0000)	loss 0.6706 (0.5467)	grad_norm 1.9247 (3.3577)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:07 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][50/156]	eta 0:01:02 lr 0.000005	 wd 0.0500	time 0.4848 (0.5882)	data time 0.0150 (0.0918)	model time 0.0000 (0.0000)	loss 0.4464 (0.5432)	grad_norm 2.9408 (3.3230)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:12 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][60/156]	eta 0:00:55 lr 0.000005	 wd 0.0500	time 0.4473 (0.5760)	data time 0.0183 (0.0785)	model time 0.4290 (0.5035)	loss 0.5383 (0.5386)	grad_norm 2.9164 (3.3540)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:17 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][70/156]	eta 0:00:48 lr 0.000005	 wd 0.0500	time 0.4461 (0.5665)	data time 0.0252 (0.0701)	model time 0.4209 (0.4965)	loss 0.4961 (0.5422)	grad_norm 4.8825 (3.3887)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:22 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][80/156]	eta 0:00:42 lr 0.000005	 wd 0.0500	time 0.4141 (0.5576)	data time 0.0007 (0.0640)	model time 0.4134 (0.4888)	loss 0.5271 (0.5432)	grad_norm 3.2157 (3.3637)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:27 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][90/156]	eta 0:00:36 lr 0.000005	 wd 0.0500	time 0.5026 (0.5519)	data time 0.0135 (0.0594)	model time 0.4891 (0.4875)	loss 0.5758 (0.5444)	grad_norm 3.0260 (3.3332)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:32 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][100/156]	eta 0:00:30 lr 0.000005	 wd 0.0500	time 0.4765 (0.5452)	data time 0.0219 (0.0553)	model time 0.4546 (0.4834)	loss 0.6077 (0.5438)	grad_norm 2.1331 (3.3688)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:37 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][110/156]	eta 0:00:24 lr 0.000005	 wd 0.0500	time 0.4522 (0.5407)	data time 0.0312 (0.0517)	model time 0.4211 (0.4827)	loss 0.5241 (0.5442)	grad_norm 4.7609 (3.3572)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:42 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][120/156]	eta 0:00:19 lr 0.000005	 wd 0.0500	time 0.4939 (0.5369)	data time 0.0277 (0.0488)	model time 0.4661 (0.4822)	loss 0.5545 (0.5420)	grad_norm 2.3203 (3.3510)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:47 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][130/156]	eta 0:00:13 lr 0.000005	 wd 0.0500	time 0.5108 (0.5333)	data time 0.0213 (0.0461)	model time 0.4895 (0.4813)	loss 0.3686 (0.5374)	grad_norm 4.0146 (3.3650)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:52 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][140/156]	eta 0:00:08 lr 0.000005	 wd 0.0500	time 0.4920 (0.5340)	data time 0.0186 (0.0442)	model time 0.4735 (0.4861)	loss 0.4780 (0.5384)	grad_norm 4.3877 (3.3764)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:47:57 vssm1_tiny_0230s](training.py 201): INFO Train: [269/300][150/156]	eta 0:00:03 lr 0.000005	 wd 0.0500	time 0.5898 (0.5305)	data time 0.0005 (0.0414)	model time 0.5893 (0.4855)	loss 0.5869 (0.5382)	grad_norm 4.2266 (3.3960)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:48:00 vssm1_tiny_0230s](training.py 212): INFO EPOCH 269 training takes 0:01:23
[2024-11-09 18:48:00 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_269.pth saving......
[2024-11-09 18:48:01 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_269.pth saved !!!
[2024-11-09 18:48:05 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.960 (3.960)	Loss 0.1851 (0.1851)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:48:07 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.553)	Loss 0.1969 (0.1878)	Acc@1 96.875 (97.230)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:48:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.227 (0.432)	Loss 0.1862 (0.1969)	Acc@1 98.438 (96.577)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:48:13 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.143 (0.378)	Loss 0.2445 (0.2055)	Acc@1 92.969 (95.993)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:48:15 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.720 Acc@5 100.000
[2024-11-09 18:48:15 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:48:15 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.82%
[2024-11-09 18:48:19 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.501 (3.501)	Loss 0.1975 (0.1975)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:48:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.696 (0.578)	Loss 0.2046 (0.2017)	Acc@1 96.094 (95.881)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:48:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.414)	Loss 0.2031 (0.2129)	Acc@1 96.875 (95.015)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:48:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.356)	Loss 0.2642 (0.2226)	Acc@1 92.188 (94.582)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:48:29 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.500 Acc@5 100.000
[2024-11-09 18:48:29 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.5%
[2024-11-09 18:48:29 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.50%
[2024-11-09 18:48:34 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][0/156]	eta 0:14:07 lr 0.000005	 wd 0.0500	time 5.4342 (5.4342)	data time 5.0163 (5.0163)	model time 0.0000 (0.0000)	loss 0.6350 (0.6350)	grad_norm 2.8857 (2.8857)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:48:40 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][10/156]	eta 0:02:22 lr 0.000005	 wd 0.0500	time 0.4871 (0.9769)	data time 0.0209 (0.4661)	model time 0.0000 (0.0000)	loss 0.4919 (0.5225)	grad_norm 4.0819 (3.5845)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:48:45 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][20/156]	eta 0:01:41 lr 0.000005	 wd 0.0500	time 0.5221 (0.7472)	data time 0.0381 (0.2554)	model time 0.0000 (0.0000)	loss 0.4271 (0.5366)	grad_norm 3.3016 (3.3007)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:48:50 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][30/156]	eta 0:01:24 lr 0.000005	 wd 0.0500	time 0.4209 (0.6694)	data time 0.0134 (0.1809)	model time 0.0000 (0.0000)	loss 0.5243 (0.5426)	grad_norm 2.7801 (3.5319)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:48:55 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][40/156]	eta 0:01:12 lr 0.000005	 wd 0.0500	time 0.4614 (0.6280)	data time 0.0007 (0.1413)	model time 0.0000 (0.0000)	loss 0.4397 (0.5342)	grad_norm 2.1378 (3.4087)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:00 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][50/156]	eta 0:01:03 lr 0.000005	 wd 0.0500	time 0.5924 (0.6034)	data time 0.0962 (0.1179)	model time 0.0000 (0.0000)	loss 0.6201 (0.5335)	grad_norm 1.5224 (3.4398)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:05 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][60/156]	eta 0:00:56 lr 0.000005	 wd 0.0500	time 0.5225 (0.5896)	data time 0.0006 (0.1021)	model time 0.5219 (0.4969)	loss 0.5686 (0.5389)	grad_norm 3.6791 (3.3841)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:10 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][70/156]	eta 0:00:49 lr 0.000005	 wd 0.0500	time 0.4630 (0.5787)	data time 0.0008 (0.0894)	model time 0.4623 (0.4988)	loss 0.6158 (0.5384)	grad_norm 2.5219 (3.4296)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:15 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][80/156]	eta 0:00:43 lr 0.000005	 wd 0.0500	time 0.5088 (0.5695)	data time 0.0243 (0.0808)	model time 0.4845 (0.4941)	loss 0.4938 (0.5430)	grad_norm 4.1570 (3.3813)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:20 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][90/156]	eta 0:00:37 lr 0.000005	 wd 0.0500	time 0.6281 (0.5612)	data time 0.1038 (0.0738)	model time 0.5244 (0.4896)	loss 0.4149 (0.5429)	grad_norm 4.8586 (3.3850)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:25 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][100/156]	eta 0:00:31 lr 0.000005	 wd 0.0500	time 0.5136 (0.5559)	data time 0.0011 (0.0679)	model time 0.5125 (0.4905)	loss 0.4614 (0.5431)	grad_norm 3.9072 (3.3990)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:30 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][110/156]	eta 0:00:25 lr 0.000005	 wd 0.0500	time 0.4552 (0.5500)	data time 0.0006 (0.0634)	model time 0.4545 (0.4875)	loss 0.4946 (0.5421)	grad_norm 2.4644 (3.3325)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:35 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][120/156]	eta 0:00:19 lr 0.000005	 wd 0.0500	time 0.5890 (0.5453)	data time 0.0057 (0.0589)	model time 0.5832 (0.4870)	loss 0.4842 (0.5428)	grad_norm 3.9384 (3.3415)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:40 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][130/156]	eta 0:00:14 lr 0.000005	 wd 0.0500	time 0.4363 (0.5406)	data time 0.0078 (0.0555)	model time 0.4284 (0.4848)	loss 0.6177 (0.5409)	grad_norm 2.5190 (3.3352)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:45 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][140/156]	eta 0:00:08 lr 0.000005	 wd 0.0500	time 0.6443 (0.5379)	data time 0.0312 (0.0527)	model time 0.6130 (0.4852)	loss 0.5084 (0.5438)	grad_norm 2.6045 (3.3164)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:50 vssm1_tiny_0230s](training.py 201): INFO Train: [270/300][150/156]	eta 0:00:03 lr 0.000005	 wd 0.0500	time 0.5032 (0.5362)	data time 0.0005 (0.0495)	model time 0.5028 (0.4874)	loss 0.4491 (0.5400)	grad_norm 4.9279 (3.3363)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:49:53 vssm1_tiny_0230s](training.py 212): INFO EPOCH 270 training takes 0:01:24
[2024-11-09 18:49:53 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_270.pth saving......
[2024-11-09 18:49:54 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_270.pth saved !!!
[2024-11-09 18:49:57 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.189 (3.189)	Loss 0.1985 (0.1985)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:50:00 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.155 (0.545)	Loss 0.2109 (0.2009)	Acc@1 95.312 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:50:01 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.363)	Loss 0.1731 (0.2085)	Acc@1 99.219 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:50:04 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.322)	Loss 0.2285 (0.2081)	Acc@1 93.750 (95.968)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:50:06 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.860 Acc@5 100.000
[2024-11-09 18:50:06 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.9%
[2024-11-09 18:50:06 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 18:50:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.973 (1.973)	Loss 0.1973 (0.1973)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:50:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.362)	Loss 0.2046 (0.2015)	Acc@1 96.094 (96.023)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:50:11 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.269)	Loss 0.2030 (0.2126)	Acc@1 96.875 (95.089)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:50:13 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.193 (0.234)	Loss 0.2639 (0.2222)	Acc@1 92.188 (94.632)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:50:15 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.540 Acc@5 100.000
[2024-11-09 18:50:15 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.5%
[2024-11-09 18:50:15 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.54%
[2024-11-09 18:50:21 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][0/156]	eta 0:14:00 lr 0.000004	 wd 0.0500	time 5.3855 (5.3855)	data time 4.8052 (4.8052)	model time 0.0000 (0.0000)	loss 0.5750 (0.5750)	grad_norm 3.8752 (3.8752)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:50:26 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][10/156]	eta 0:02:23 lr 0.000004	 wd 0.0500	time 0.5749 (0.9814)	data time 0.1001 (0.4701)	model time 0.0000 (0.0000)	loss 0.4689 (0.5500)	grad_norm 2.8652 (3.5680)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:50:31 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][20/156]	eta 0:01:43 lr 0.000004	 wd 0.0500	time 0.5474 (0.7579)	data time 0.0028 (0.2596)	model time 0.0000 (0.0000)	loss 0.5759 (0.5366)	grad_norm 2.7436 (3.3295)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:50:36 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][30/156]	eta 0:01:26 lr 0.000004	 wd 0.0500	time 0.4439 (0.6868)	data time 0.0163 (0.1862)	model time 0.0000 (0.0000)	loss 0.6230 (0.5492)	grad_norm 3.5679 (3.5143)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:50:41 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][40/156]	eta 0:01:14 lr 0.000004	 wd 0.0500	time 0.4092 (0.6415)	data time 0.0016 (0.1435)	model time 0.0000 (0.0000)	loss 0.5904 (0.5463)	grad_norm 2.5203 (3.3916)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:50:47 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][50/156]	eta 0:01:05 lr 0.000004	 wd 0.0500	time 0.6493 (0.6191)	data time 0.0644 (0.1206)	model time 0.0000 (0.0000)	loss 0.6597 (0.5542)	grad_norm 3.9642 (3.4264)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:50:52 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][60/156]	eta 0:00:57 lr 0.000004	 wd 0.0500	time 0.4135 (0.6004)	data time 0.0031 (0.1038)	model time 0.4104 (0.4870)	loss 0.5906 (0.5530)	grad_norm 2.1928 (3.4175)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:50:57 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][70/156]	eta 0:00:50 lr 0.000004	 wd 0.0500	time 0.4827 (0.5922)	data time 0.0021 (0.0917)	model time 0.4806 (0.5057)	loss 0.4529 (0.5502)	grad_norm 2.9527 (3.4178)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:51:02 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][80/156]	eta 0:00:43 lr 0.000004	 wd 0.0500	time 0.6217 (0.5787)	data time 0.0113 (0.0823)	model time 0.6104 (0.4928)	loss 0.6010 (0.5473)	grad_norm 2.5908 (3.4160)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:51:07 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][90/156]	eta 0:00:37 lr 0.000004	 wd 0.0500	time 0.5012 (0.5681)	data time 0.0011 (0.0745)	model time 0.5000 (0.4873)	loss 0.4747 (0.5450)	grad_norm 2.7834 (3.3924)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:51:12 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][100/156]	eta 0:00:31 lr 0.000004	 wd 0.0500	time 0.4664 (0.5585)	data time 0.0008 (0.0682)	model time 0.4656 (0.4820)	loss 0.6138 (0.5460)	grad_norm 5.5525 (3.4153)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:51:16 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][110/156]	eta 0:00:25 lr 0.000004	 wd 0.0500	time 0.4902 (0.5521)	data time 0.0122 (0.0629)	model time 0.4780 (0.4813)	loss 0.5924 (0.5411)	grad_norm 2.5991 (3.4561)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:51:22 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][120/156]	eta 0:00:19 lr 0.000004	 wd 0.0500	time 0.4649 (0.5496)	data time 0.0251 (0.0592)	model time 0.4398 (0.4845)	loss 0.5001 (0.5424)	grad_norm 2.3240 (3.4648)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:51:27 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][130/156]	eta 0:00:14 lr 0.000004	 wd 0.0500	time 0.4173 (0.5460)	data time 0.0039 (0.0554)	model time 0.4134 (0.4856)	loss 0.5062 (0.5431)	grad_norm 5.1040 (3.4543)	loss_scale 65536.0000 (34769.0992)	mem 13675MB
[2024-11-09 18:51:32 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][140/156]	eta 0:00:08 lr 0.000004	 wd 0.0500	time 0.5165 (0.5462)	data time 0.0080 (0.0523)	model time 0.5086 (0.4913)	loss 0.5259 (0.5406)	grad_norm 3.1113 (3.4604)	loss_scale 65536.0000 (36951.1489)	mem 13675MB
[2024-11-09 18:51:37 vssm1_tiny_0230s](training.py 201): INFO Train: [271/300][150/156]	eta 0:00:03 lr 0.000004	 wd 0.0500	time 0.4213 (0.5399)	data time 0.0004 (0.0488)	model time 0.4209 (0.4873)	loss 0.6237 (0.5408)	grad_norm 2.7301 (3.4861)	loss_scale 65536.0000 (38844.1854)	mem 13675MB
[2024-11-09 18:51:40 vssm1_tiny_0230s](training.py 212): INFO EPOCH 271 training takes 0:01:24
[2024-11-09 18:51:40 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_271.pth saving......
[2024-11-09 18:51:40 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_271.pth saved !!!
[2024-11-09 18:51:44 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.531 (3.531)	Loss 0.1888 (0.1888)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:51:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.530)	Loss 0.2012 (0.1909)	Acc@1 96.094 (96.946)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:51:48 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.356)	Loss 0.1807 (0.1993)	Acc@1 99.219 (96.689)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:51:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.288)	Loss 0.2401 (0.2058)	Acc@1 92.188 (96.069)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:51:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.760 Acc@5 100.000
[2024-11-09 18:51:51 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 18:51:51 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 18:51:55 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.569 (3.569)	Loss 0.1973 (0.1973)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:51:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.302 (0.480)	Loss 0.2046 (0.2015)	Acc@1 96.094 (95.952)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:51:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.149 (0.358)	Loss 0.2024 (0.2125)	Acc@1 96.875 (95.015)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:52:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.161 (0.315)	Loss 0.2632 (0.2219)	Acc@1 92.188 (94.582)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:52:04 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.500 Acc@5 100.000
[2024-11-09 18:52:04 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.5%
[2024-11-09 18:52:04 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.54%
[2024-11-09 18:52:09 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][0/156]	eta 0:14:23 lr 0.000004	 wd 0.0500	time 5.5325 (5.5325)	data time 5.0675 (5.0675)	model time 0.0000 (0.0000)	loss 0.5988 (0.5988)	grad_norm 3.3845 (3.3845)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:52:14 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][10/156]	eta 0:02:22 lr 0.000004	 wd 0.0500	time 0.4541 (0.9744)	data time 0.0063 (0.4748)	model time 0.0000 (0.0000)	loss 0.4362 (0.5272)	grad_norm 4.9155 (4.4617)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:52:20 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][20/156]	eta 0:01:42 lr 0.000004	 wd 0.0500	time 0.5516 (0.7573)	data time 0.1076 (0.2569)	model time 0.0000 (0.0000)	loss 0.4001 (0.5389)	grad_norm 2.9687 (3.7654)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:52:25 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][30/156]	eta 0:01:25 lr 0.000004	 wd 0.0500	time 0.4658 (0.6769)	data time 0.0009 (0.1817)	model time 0.0000 (0.0000)	loss 0.5284 (0.5382)	grad_norm 2.6139 (3.5261)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:52:29 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][40/156]	eta 0:01:12 lr 0.000004	 wd 0.0500	time 0.4401 (0.6279)	data time 0.0023 (0.1392)	model time 0.0000 (0.0000)	loss 0.5537 (0.5384)	grad_norm 3.2949 (3.4361)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:52:35 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][50/156]	eta 0:01:04 lr 0.000004	 wd 0.0500	time 0.5277 (0.6079)	data time 0.0506 (0.1145)	model time 0.0000 (0.0000)	loss 0.5988 (0.5399)	grad_norm 4.5506 (3.3996)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:52:40 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][60/156]	eta 0:00:56 lr 0.000004	 wd 0.0500	time 0.6129 (0.5910)	data time 0.0103 (0.0987)	model time 0.6026 (0.4869)	loss 0.5973 (0.5408)	grad_norm 4.1072 (3.4407)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:52:45 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][70/156]	eta 0:00:49 lr 0.000004	 wd 0.0500	time 0.4670 (0.5762)	data time 0.0128 (0.0868)	model time 0.4542 (0.4791)	loss 0.5832 (0.5471)	grad_norm 4.8774 (3.4569)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:52:49 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][80/156]	eta 0:00:42 lr 0.000004	 wd 0.0500	time 0.4970 (0.5656)	data time 0.0079 (0.0774)	model time 0.4892 (0.4794)	loss 0.5517 (0.5485)	grad_norm 3.2305 (3.4475)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:52:55 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][90/156]	eta 0:00:36 lr 0.000004	 wd 0.0500	time 0.5543 (0.5601)	data time 0.0077 (0.0719)	model time 0.5467 (0.4816)	loss 0.5134 (0.5488)	grad_norm 4.7157 (3.4813)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:53:00 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][100/156]	eta 0:00:31 lr 0.000004	 wd 0.0500	time 0.6909 (0.5586)	data time 0.0396 (0.0681)	model time 0.6513 (0.4876)	loss 0.5877 (0.5471)	grad_norm 2.9327 (3.4281)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:53:05 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][110/156]	eta 0:00:25 lr 0.000004	 wd 0.0500	time 0.4939 (0.5566)	data time 0.0721 (0.0637)	model time 0.4219 (0.4926)	loss 0.5935 (0.5477)	grad_norm 5.0180 (3.4307)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:53:10 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][120/156]	eta 0:00:19 lr 0.000004	 wd 0.0500	time 0.4692 (0.5502)	data time 0.0302 (0.0597)	model time 0.4390 (0.4884)	loss 0.4676 (0.5471)	grad_norm 4.1419 (3.4953)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:53:15 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][130/156]	eta 0:00:14 lr 0.000004	 wd 0.0500	time 0.4519 (0.5470)	data time 0.0049 (0.0568)	model time 0.4470 (0.4881)	loss 0.3841 (0.5403)	grad_norm 5.4332 (3.5087)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:53:21 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][140/156]	eta 0:00:08 lr 0.000004	 wd 0.0500	time 0.5307 (0.5465)	data time 0.0011 (0.0558)	model time 0.5296 (0.4891)	loss 0.5498 (0.5430)	grad_norm 3.9988 (3.4810)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:53:26 vssm1_tiny_0230s](training.py 201): INFO Train: [272/300][150/156]	eta 0:00:03 lr 0.000004	 wd 0.0500	time 0.4176 (0.5422)	data time 0.0005 (0.0523)	model time 0.4172 (0.4882)	loss 0.5048 (0.5422)	grad_norm 3.4077 (3.5247)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:53:29 vssm1_tiny_0230s](training.py 212): INFO EPOCH 272 training takes 0:01:25
[2024-11-09 18:53:29 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_272.pth saving......
[2024-11-09 18:53:29 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_272.pth saved !!!
[2024-11-09 18:53:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.442 (4.442)	Loss 0.1926 (0.1926)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:53:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.153 (0.683)	Loss 0.2045 (0.1932)	Acc@1 96.094 (96.804)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:53:39 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.160 (0.464)	Loss 0.1844 (0.2018)	Acc@1 98.438 (96.429)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:53:42 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.168 (0.394)	Loss 0.2435 (0.2082)	Acc@1 92.188 (95.892)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:53:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.700 Acc@5 100.000
[2024-11-09 18:53:43 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:53:43 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 18:53:47 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.304 (3.304)	Loss 0.1973 (0.1973)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:53:50 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.188 (0.584)	Loss 0.2046 (0.2013)	Acc@1 96.094 (95.952)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:53:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.438)	Loss 0.2020 (0.2122)	Acc@1 96.875 (95.015)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:53:54 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.167 (0.352)	Loss 0.2629 (0.2216)	Acc@1 92.188 (94.607)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:53:56 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.520 Acc@5 100.000
[2024-11-09 18:53:56 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.5%
[2024-11-09 18:53:56 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.54%
[2024-11-09 18:54:01 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][0/156]	eta 0:12:37 lr 0.000004	 wd 0.0500	time 4.8554 (4.8554)	data time 4.3758 (4.3758)	model time 0.0000 (0.0000)	loss 0.5837 (0.5837)	grad_norm 2.1099 (2.1099)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:06 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][10/156]	eta 0:02:12 lr 0.000004	 wd 0.0500	time 0.4569 (0.9088)	data time 0.0009 (0.4183)	model time 0.0000 (0.0000)	loss 0.4298 (0.5136)	grad_norm 2.2406 (3.2541)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:12 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][20/156]	eta 0:01:38 lr 0.000004	 wd 0.0500	time 0.4540 (0.7258)	data time 0.0154 (0.2257)	model time 0.0000 (0.0000)	loss 0.6072 (0.5277)	grad_norm 2.5385 (3.3755)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:17 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][30/156]	eta 0:01:23 lr 0.000004	 wd 0.0500	time 0.5808 (0.6630)	data time 0.0007 (0.1614)	model time 0.0000 (0.0000)	loss 0.5020 (0.5248)	grad_norm 2.0348 (3.3179)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:22 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][40/156]	eta 0:01:12 lr 0.000004	 wd 0.0500	time 0.5351 (0.6270)	data time 0.0197 (0.1293)	model time 0.0000 (0.0000)	loss 0.4383 (0.5276)	grad_norm 6.9093 (3.3968)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:28 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][50/156]	eta 0:01:04 lr 0.000004	 wd 0.0500	time 0.6276 (0.6096)	data time 0.0092 (0.1110)	model time 0.0000 (0.0000)	loss 0.5295 (0.5346)	grad_norm 1.9891 (3.3309)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:33 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][60/156]	eta 0:00:56 lr 0.000004	 wd 0.0500	time 0.4304 (0.5912)	data time 0.0222 (0.0946)	model time 0.4081 (0.4864)	loss 0.6032 (0.5347)	grad_norm 2.8955 (3.2909)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:38 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][70/156]	eta 0:00:50 lr 0.000004	 wd 0.0500	time 0.5432 (0.5821)	data time 0.0007 (0.0840)	model time 0.5425 (0.4967)	loss 0.3863 (0.5327)	grad_norm 4.7787 (3.3792)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:43 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][80/156]	eta 0:00:43 lr 0.000004	 wd 0.0500	time 0.5143 (0.5738)	data time 0.0120 (0.0748)	model time 0.5023 (0.4996)	loss 0.5259 (0.5321)	grad_norm 3.2807 (3.4324)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:49 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][90/156]	eta 0:00:37 lr 0.000004	 wd 0.0500	time 0.4536 (0.5718)	data time 0.0082 (0.0695)	model time 0.4455 (0.5070)	loss 0.6221 (0.5351)	grad_norm 3.3385 (3.4484)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:54 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][100/156]	eta 0:00:31 lr 0.000004	 wd 0.0500	time 0.4126 (0.5681)	data time 0.0030 (0.0641)	model time 0.4096 (0.5096)	loss 0.4241 (0.5322)	grad_norm 2.9230 (3.4159)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:54:59 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][110/156]	eta 0:00:25 lr 0.000004	 wd 0.0500	time 0.5312 (0.5650)	data time 0.0105 (0.0602)	model time 0.5207 (0.5100)	loss 0.5428 (0.5331)	grad_norm 2.7626 (3.4978)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:55:04 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][120/156]	eta 0:00:20 lr 0.000004	 wd 0.0500	time 0.5354 (0.5598)	data time 0.0161 (0.0563)	model time 0.5193 (0.5070)	loss 0.5667 (0.5326)	grad_norm 2.0517 (3.5860)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:55:10 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][130/156]	eta 0:00:14 lr 0.000004	 wd 0.0500	time 0.4800 (0.5577)	data time 0.0128 (0.0534)	model time 0.4673 (0.5079)	loss 0.6076 (0.5344)	grad_norm 3.4408 (3.5622)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:55:15 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][140/156]	eta 0:00:08 lr 0.000004	 wd 0.0500	time 0.5415 (0.5547)	data time 0.0008 (0.0511)	model time 0.5406 (0.5064)	loss 0.6651 (0.5343)	grad_norm 2.1764 (3.5562)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:55:20 vssm1_tiny_0230s](training.py 201): INFO Train: [273/300][150/156]	eta 0:00:03 lr 0.000004	 wd 0.0500	time 0.4925 (0.5526)	data time 0.0005 (0.0479)	model time 0.4919 (0.5078)	loss 0.6099 (0.5375)	grad_norm 2.0393 (3.5401)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:55:23 vssm1_tiny_0230s](training.py 212): INFO EPOCH 273 training takes 0:01:26
[2024-11-09 18:55:23 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_273.pth saving......
[2024-11-09 18:55:23 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_273.pth saved !!!
[2024-11-09 18:55:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.744 (3.744)	Loss 0.1990 (0.1990)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:55:29 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.158 (0.531)	Loss 0.2111 (0.2000)	Acc@1 95.312 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:55:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.172 (0.399)	Loss 0.1785 (0.2076)	Acc@1 99.219 (96.354)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:55:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.377)	Loss 0.2352 (0.2096)	Acc@1 92.188 (95.968)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:55:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.800 Acc@5 100.000
[2024-11-09 18:55:38 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 18:55:38 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 18:55:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.339 (4.339)	Loss 0.1970 (0.1970)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:55:44 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.151 (0.586)	Loss 0.2045 (0.2010)	Acc@1 96.094 (95.952)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:55:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.219 (0.421)	Loss 0.2013 (0.2120)	Acc@1 96.875 (95.052)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:55:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.144 (0.366)	Loss 0.2620 (0.2211)	Acc@1 92.188 (94.632)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:55:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.540 Acc@5 100.000
[2024-11-09 18:55:51 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.5%
[2024-11-09 18:55:51 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.54%
[2024-11-09 18:55:56 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][0/156]	eta 0:12:40 lr 0.000004	 wd 0.0500	time 4.8766 (4.8766)	data time 4.1642 (4.1642)	model time 0.0000 (0.0000)	loss 0.5260 (0.5260)	grad_norm 3.1887 (3.1887)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:01 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][10/156]	eta 0:02:10 lr 0.000004	 wd 0.0500	time 0.4079 (0.8957)	data time 0.0007 (0.3918)	model time 0.0000 (0.0000)	loss 0.3915 (0.5197)	grad_norm 2.2526 (3.2712)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:06 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][20/156]	eta 0:01:38 lr 0.000004	 wd 0.0500	time 0.6303 (0.7213)	data time 0.0185 (0.2145)	model time 0.0000 (0.0000)	loss 0.5642 (0.5331)	grad_norm 2.1226 (3.1361)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:11 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][30/156]	eta 0:01:22 lr 0.000004	 wd 0.0500	time 0.4079 (0.6521)	data time 0.0045 (0.1495)	model time 0.0000 (0.0000)	loss 0.6267 (0.5316)	grad_norm 5.8280 (3.3415)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:16 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][40/156]	eta 0:01:11 lr 0.000004	 wd 0.0500	time 0.5089 (0.6154)	data time 0.0602 (0.1174)	model time 0.0000 (0.0000)	loss 0.6192 (0.5279)	grad_norm 2.6321 (3.5107)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:21 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][50/156]	eta 0:01:02 lr 0.000004	 wd 0.0500	time 0.4545 (0.5902)	data time 0.0172 (0.0992)	model time 0.0000 (0.0000)	loss 0.5053 (0.5295)	grad_norm 1.9411 (3.4638)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:26 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][60/156]	eta 0:00:55 lr 0.000004	 wd 0.0500	time 0.4633 (0.5749)	data time 0.0118 (0.0864)	model time 0.4515 (0.4760)	loss 0.5639 (0.5377)	grad_norm 3.5227 (3.3861)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:31 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][70/156]	eta 0:00:49 lr 0.000004	 wd 0.0500	time 0.5464 (0.5700)	data time 0.0270 (0.0760)	model time 0.5195 (0.5016)	loss 0.4286 (0.5338)	grad_norm 5.2034 (3.4721)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:36 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][80/156]	eta 0:00:42 lr 0.000004	 wd 0.0500	time 0.4544 (0.5591)	data time 0.0210 (0.0684)	model time 0.4334 (0.4903)	loss 0.6125 (0.5390)	grad_norm 2.1483 (3.4313)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:41 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][90/156]	eta 0:00:36 lr 0.000004	 wd 0.0500	time 0.4424 (0.5522)	data time 0.0006 (0.0618)	model time 0.4418 (0.4899)	loss 0.5175 (0.5381)	grad_norm 5.3949 (3.4679)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:46 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][100/156]	eta 0:00:30 lr 0.000004	 wd 0.0500	time 0.4143 (0.5468)	data time 0.0007 (0.0577)	model time 0.4136 (0.4871)	loss 0.4826 (0.5384)	grad_norm 1.8493 (3.4322)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:51 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][110/156]	eta 0:00:24 lr 0.000004	 wd 0.0500	time 0.4387 (0.5403)	data time 0.0161 (0.0537)	model time 0.4226 (0.4830)	loss 0.6534 (0.5390)	grad_norm 4.0941 (3.5177)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:56:56 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][120/156]	eta 0:00:19 lr 0.000004	 wd 0.0500	time 0.5263 (0.5357)	data time 0.0006 (0.0501)	model time 0.5257 (0.4818)	loss 0.4632 (0.5397)	grad_norm 2.7474 (3.4431)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:57:01 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][130/156]	eta 0:00:13 lr 0.000004	 wd 0.0500	time 0.4380 (0.5317)	data time 0.0090 (0.0475)	model time 0.4290 (0.4799)	loss 0.5564 (0.5406)	grad_norm 5.7566 (3.4726)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:57:06 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][140/156]	eta 0:00:08 lr 0.000004	 wd 0.0500	time 0.5868 (0.5306)	data time 0.0655 (0.0452)	model time 0.5213 (0.4823)	loss 0.5889 (0.5393)	grad_norm 2.7624 (3.4969)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:57:11 vssm1_tiny_0230s](training.py 201): INFO Train: [274/300][150/156]	eta 0:00:03 lr 0.000004	 wd 0.0500	time 0.4309 (0.5289)	data time 0.0005 (0.0427)	model time 0.4305 (0.4837)	loss 0.4603 (0.5360)	grad_norm 3.4061 (3.5072)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:57:13 vssm1_tiny_0230s](training.py 212): INFO EPOCH 274 training takes 0:01:22
[2024-11-09 18:57:13 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_274.pth saving......
[2024-11-09 18:57:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_274.pth saved !!!
[2024-11-09 18:57:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.623 (3.623)	Loss 0.2074 (0.2074)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:57:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 1.864 (0.729)	Loss 0.2192 (0.2092)	Acc@1 94.531 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:57:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.480)	Loss 0.1649 (0.2161)	Acc@1 99.219 (95.685)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:57:27 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.141 (0.406)	Loss 0.2195 (0.2104)	Acc@1 92.969 (95.817)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:57:29 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.800 Acc@5 100.000
[2024-11-09 18:57:29 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 18:57:29 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 18:57:33 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.068 (4.068)	Loss 0.1971 (0.1971)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:57:35 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.156 (0.552)	Loss 0.2045 (0.2010)	Acc@1 96.094 (95.952)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:57:37 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.401)	Loss 0.2009 (0.2119)	Acc@1 96.875 (95.089)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:57:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.175 (0.370)	Loss 0.2617 (0.2209)	Acc@1 92.188 (94.682)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:57:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.600 Acc@5 100.000
[2024-11-09 18:57:43 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.6%
[2024-11-09 18:57:43 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.60%
[2024-11-09 18:57:46 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][0/156]	eta 0:08:43 lr 0.000004	 wd 0.0500	time 3.3585 (3.3585)	data time 2.8864 (2.8864)	model time 0.0000 (0.0000)	loss 0.4369 (0.4369)	grad_norm 3.6100 (3.6100)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:57:52 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][10/156]	eta 0:01:57 lr 0.000004	 wd 0.0500	time 0.5560 (0.8038)	data time 0.0393 (0.3134)	model time 0.0000 (0.0000)	loss 0.4805 (0.5218)	grad_norm 2.3473 (3.3349)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:57:57 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][20/156]	eta 0:01:30 lr 0.000004	 wd 0.0500	time 0.5707 (0.6658)	data time 0.0172 (0.1755)	model time 0.0000 (0.0000)	loss 0.5466 (0.5262)	grad_norm 2.6596 (3.3897)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:02 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][30/156]	eta 0:01:17 lr 0.000004	 wd 0.0500	time 0.4665 (0.6125)	data time 0.0180 (0.1227)	model time 0.0000 (0.0000)	loss 0.4497 (0.5284)	grad_norm 4.3141 (3.4630)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:07 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][40/156]	eta 0:01:06 lr 0.000004	 wd 0.0500	time 0.4416 (0.5748)	data time 0.0053 (0.0959)	model time 0.0000 (0.0000)	loss 0.4352 (0.5180)	grad_norm 2.6780 (3.5118)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:12 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][50/156]	eta 0:00:59 lr 0.000004	 wd 0.0500	time 0.6264 (0.5624)	data time 0.0045 (0.0797)	model time 0.0000 (0.0000)	loss 0.6380 (0.5199)	grad_norm 2.8975 (3.6777)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:17 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][60/156]	eta 0:00:52 lr 0.000004	 wd 0.0500	time 0.4305 (0.5514)	data time 0.0103 (0.0687)	model time 0.4202 (0.4833)	loss 0.4638 (0.5200)	grad_norm 3.4718 (3.7474)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:22 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][70/156]	eta 0:00:46 lr 0.000004	 wd 0.0500	time 0.4139 (0.5428)	data time 0.0007 (0.0599)	model time 0.4132 (0.4832)	loss 0.5143 (0.5224)	grad_norm 4.4580 (3.7072)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:27 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][80/156]	eta 0:00:40 lr 0.000004	 wd 0.0500	time 0.4351 (0.5386)	data time 0.0009 (0.0544)	model time 0.4342 (0.4869)	loss 0.5292 (0.5226)	grad_norm 3.2478 (3.6594)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:32 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][90/156]	eta 0:00:35 lr 0.000004	 wd 0.0500	time 0.4418 (0.5352)	data time 0.0022 (0.0497)	model time 0.4397 (0.4892)	loss 0.6017 (0.5245)	grad_norm 2.9246 (3.6175)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:37 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][100/156]	eta 0:00:29 lr 0.000004	 wd 0.0500	time 0.4559 (0.5345)	data time 0.0144 (0.0461)	model time 0.4415 (0.4944)	loss 0.5929 (0.5241)	grad_norm 3.5811 (3.5738)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:42 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][110/156]	eta 0:00:24 lr 0.000004	 wd 0.0500	time 0.5531 (0.5332)	data time 0.1207 (0.0442)	model time 0.4324 (0.4944)	loss 0.5701 (0.5261)	grad_norm 2.7240 (3.5886)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:47 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][120/156]	eta 0:00:19 lr 0.000004	 wd 0.0500	time 0.5443 (0.5304)	data time 0.0219 (0.0427)	model time 0.5223 (0.4914)	loss 0.5070 (0.5260)	grad_norm 5.3475 (3.6353)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:52 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][130/156]	eta 0:00:13 lr 0.000004	 wd 0.0500	time 0.4462 (0.5262)	data time 0.0228 (0.0403)	model time 0.4234 (0.4881)	loss 0.5966 (0.5284)	grad_norm 3.4169 (3.6187)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:58:57 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][140/156]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.5498 (0.5224)	data time 0.0010 (0.0382)	model time 0.5487 (0.4850)	loss 0.5831 (0.5293)	grad_norm 3.4324 (3.6103)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:59:02 vssm1_tiny_0230s](training.py 201): INFO Train: [275/300][150/156]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.5305 (0.5250)	data time 0.0008 (0.0360)	model time 0.5297 (0.4924)	loss 0.6010 (0.5301)	grad_norm 3.8796 (3.5859)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:59:05 vssm1_tiny_0230s](training.py 212): INFO EPOCH 275 training takes 0:01:22
[2024-11-09 18:59:05 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_275.pth saving......
[2024-11-09 18:59:06 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_275.pth saved !!!
[2024-11-09 18:59:09 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.815 (2.815)	Loss 0.1927 (0.1927)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:59:11 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.468)	Loss 0.2030 (0.1941)	Acc@1 95.312 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:59:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.162 (0.345)	Loss 0.1775 (0.2020)	Acc@1 98.438 (96.317)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:59:15 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.210 (0.302)	Loss 0.2350 (0.2059)	Acc@1 92.188 (95.867)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:59:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.700 Acc@5 100.000
[2024-11-09 18:59:18 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 18:59:18 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 18:59:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.522 (4.522)	Loss 0.1970 (0.1970)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:59:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.151 (0.650)	Loss 0.2045 (0.2009)	Acc@1 96.094 (95.952)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:59:27 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.180 (0.429)	Loss 0.2001 (0.2117)	Acc@1 96.875 (95.164)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:59:29 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.357)	Loss 0.2607 (0.2205)	Acc@1 92.188 (94.733)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 18:59:32 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.660 Acc@5 100.000
[2024-11-09 18:59:32 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.7%
[2024-11-09 18:59:32 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.66%
[2024-11-09 18:59:36 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][0/156]	eta 0:11:28 lr 0.000003	 wd 0.0500	time 4.4107 (4.4107)	data time 3.7881 (3.7881)	model time 0.0000 (0.0000)	loss 0.5308 (0.5308)	grad_norm 2.0986 (2.0986)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:59:42 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][10/156]	eta 0:02:12 lr 0.000003	 wd 0.0500	time 0.5692 (0.9043)	data time 0.0124 (0.3561)	model time 0.0000 (0.0000)	loss 0.4540 (0.5419)	grad_norm 4.3278 (3.5716)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:59:47 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][20/156]	eta 0:01:39 lr 0.000003	 wd 0.0500	time 0.4748 (0.7350)	data time 0.0274 (0.1958)	model time 0.0000 (0.0000)	loss 0.6159 (0.5558)	grad_norm 3.2076 (3.2396)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:59:53 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][30/156]	eta 0:01:24 lr 0.000003	 wd 0.0500	time 0.5717 (0.6738)	data time 0.0561 (0.1375)	model time 0.0000 (0.0000)	loss 0.6409 (0.5614)	grad_norm 2.1000 (3.2406)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 18:59:58 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][40/156]	eta 0:01:12 lr 0.000003	 wd 0.0500	time 0.6746 (0.6287)	data time 0.0010 (0.1063)	model time 0.0000 (0.0000)	loss 0.5174 (0.5597)	grad_norm 3.0018 (3.3571)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:02 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][50/156]	eta 0:01:03 lr 0.000003	 wd 0.0500	time 0.4943 (0.6004)	data time 0.0154 (0.0892)	model time 0.0000 (0.0000)	loss 0.5963 (0.5542)	grad_norm 2.2619 (3.3582)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:08 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][60/156]	eta 0:00:56 lr 0.000003	 wd 0.0500	time 0.4396 (0.5876)	data time 0.0062 (0.0788)	model time 0.4334 (0.4966)	loss 0.6331 (0.5582)	grad_norm 2.4816 (3.4305)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:13 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][70/156]	eta 0:00:49 lr 0.000003	 wd 0.0500	time 0.5344 (0.5791)	data time 0.0189 (0.0693)	model time 0.5155 (0.5060)	loss 0.5684 (0.5499)	grad_norm 2.3736 (3.4293)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:18 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][80/156]	eta 0:00:43 lr 0.000003	 wd 0.0500	time 0.4690 (0.5706)	data time 0.0060 (0.0621)	model time 0.4631 (0.5038)	loss 0.4303 (0.5433)	grad_norm 3.4080 (3.4531)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:23 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][90/156]	eta 0:00:36 lr 0.000003	 wd 0.0500	time 0.5349 (0.5600)	data time 0.0199 (0.0580)	model time 0.5150 (0.4904)	loss 0.5868 (0.5454)	grad_norm 4.4864 (3.4828)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:28 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][100/156]	eta 0:00:30 lr 0.000003	 wd 0.0500	time 0.5109 (0.5533)	data time 0.0255 (0.0532)	model time 0.4853 (0.4887)	loss 0.5223 (0.5426)	grad_norm 3.5409 (3.5098)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:32 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][110/156]	eta 0:00:25 lr 0.000003	 wd 0.0500	time 0.4875 (0.5454)	data time 0.0120 (0.0495)	model time 0.4756 (0.4830)	loss 0.5688 (0.5410)	grad_norm 3.3086 (3.5854)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:37 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][120/156]	eta 0:00:19 lr 0.000003	 wd 0.0500	time 0.4276 (0.5427)	data time 0.0032 (0.0464)	model time 0.4244 (0.4854)	loss 0.6212 (0.5441)	grad_norm 2.6935 (3.5451)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:43 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][130/156]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4782 (0.5412)	data time 0.0150 (0.0436)	model time 0.4632 (0.4890)	loss 0.5641 (0.5445)	grad_norm 2.5752 (3.5404)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:48 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][140/156]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.5463 (0.5371)	data time 0.0009 (0.0416)	model time 0.5454 (0.4865)	loss 0.5658 (0.5446)	grad_norm 3.3034 (3.5645)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:52 vssm1_tiny_0230s](training.py 201): INFO Train: [276/300][150/156]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.4630 (0.5330)	data time 0.0028 (0.0389)	model time 0.4602 (0.4853)	loss 0.4773 (0.5441)	grad_norm 4.5070 (3.5702)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:00:56 vssm1_tiny_0230s](training.py 212): INFO EPOCH 276 training takes 0:01:23
[2024-11-09 19:00:56 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_276.pth saving......
[2024-11-09 19:00:56 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_276.pth saved !!!
[2024-11-09 19:00:59 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.227 (3.227)	Loss 0.2046 (0.2046)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:01:02 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.203 (0.533)	Loss 0.2137 (0.2054)	Acc@1 95.312 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:01:04 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.227 (0.384)	Loss 0.1769 (0.2128)	Acc@1 99.219 (95.908)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:01:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.357)	Loss 0.2308 (0.2123)	Acc@1 92.969 (95.842)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:01:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.800 Acc@5 100.000
[2024-11-09 19:01:10 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:01:10 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:01:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.937 (2.937)	Loss 0.1968 (0.1968)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:01:16 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.529)	Loss 0.2042 (0.2005)	Acc@1 96.094 (96.023)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:01:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.407)	Loss 0.2000 (0.2113)	Acc@1 96.875 (95.238)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:01:22 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.170 (0.380)	Loss 0.2607 (0.2202)	Acc@1 92.188 (94.783)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:01:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.720 Acc@5 100.000
[2024-11-09 19:01:25 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.7%
[2024-11-09 19:01:25 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.72%
[2024-11-09 19:01:30 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][0/156]	eta 0:12:40 lr 0.000003	 wd 0.0500	time 4.8741 (4.8741)	data time 4.2662 (4.2662)	model time 0.0000 (0.0000)	loss 0.5740 (0.5740)	grad_norm 3.5541 (3.5541)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:01:35 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][10/156]	eta 0:02:10 lr 0.000003	 wd 0.0500	time 0.4823 (0.8971)	data time 0.0008 (0.3979)	model time 0.0000 (0.0000)	loss 0.6285 (0.5639)	grad_norm 2.4033 (3.0337)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:01:40 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][20/156]	eta 0:01:35 lr 0.000003	 wd 0.0500	time 0.4280 (0.7024)	data time 0.0006 (0.2132)	model time 0.0000 (0.0000)	loss 0.5419 (0.5505)	grad_norm 3.2733 (3.1809)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:01:45 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][30/156]	eta 0:01:21 lr 0.000003	 wd 0.0500	time 0.4834 (0.6436)	data time 0.0009 (0.1504)	model time 0.0000 (0.0000)	loss 0.5522 (0.5540)	grad_norm 5.6279 (3.2279)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:01:50 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][40/156]	eta 0:01:10 lr 0.000003	 wd 0.0500	time 0.5368 (0.6070)	data time 0.0206 (0.1194)	model time 0.0000 (0.0000)	loss 0.5611 (0.5608)	grad_norm 2.2144 (3.1695)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:01:55 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][50/156]	eta 0:01:01 lr 0.000003	 wd 0.0500	time 0.4601 (0.5812)	data time 0.0054 (0.0980)	model time 0.0000 (0.0000)	loss 0.4447 (0.5574)	grad_norm 4.6222 (3.2487)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:01:59 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][60/156]	eta 0:00:53 lr 0.000003	 wd 0.0500	time 0.4247 (0.5611)	data time 0.0169 (0.0838)	model time 0.4078 (0.4470)	loss 0.6056 (0.5572)	grad_norm 2.9368 (3.2542)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:02:04 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][70/156]	eta 0:00:47 lr 0.000003	 wd 0.0500	time 0.4621 (0.5533)	data time 0.0268 (0.0738)	model time 0.4353 (0.4699)	loss 0.4885 (0.5576)	grad_norm 2.1462 (3.2827)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:02:09 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][80/156]	eta 0:00:41 lr 0.000003	 wd 0.0500	time 0.4548 (0.5484)	data time 0.0158 (0.0655)	model time 0.4390 (0.4824)	loss 0.6161 (0.5595)	grad_norm 2.5190 (3.2339)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:02:14 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][90/156]	eta 0:00:35 lr 0.000003	 wd 0.0500	time 0.5002 (0.5427)	data time 0.0320 (0.0596)	model time 0.4681 (0.4830)	loss 0.4288 (0.5547)	grad_norm 4.3430 (3.2633)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:02:20 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][100/156]	eta 0:00:30 lr 0.000003	 wd 0.0500	time 0.5205 (0.5423)	data time 0.0312 (0.0552)	model time 0.4893 (0.4910)	loss 0.6746 (0.5517)	grad_norm 3.0554 (3.2187)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:02:25 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][110/156]	eta 0:00:24 lr 0.000003	 wd 0.0500	time 0.4701 (0.5415)	data time 0.0058 (0.0520)	model time 0.4643 (0.4947)	loss 0.4446 (0.5492)	grad_norm 8.4745 (3.2976)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:02:31 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][120/156]	eta 0:00:19 lr 0.000003	 wd 0.0500	time 0.6907 (0.5421)	data time 0.0509 (0.0495)	model time 0.6397 (0.4994)	loss 0.6157 (0.5497)	grad_norm 3.5911 (3.3074)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:02:36 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][130/156]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.5096 (0.5422)	data time 0.0708 (0.0477)	model time 0.4389 (0.5017)	loss 0.5592 (0.5496)	grad_norm 5.0988 (3.3266)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:02:41 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][140/156]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.4243 (0.5399)	data time 0.0011 (0.0448)	model time 0.4232 (0.5018)	loss 0.5802 (0.5490)	grad_norm 2.4677 (3.3091)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:02:46 vssm1_tiny_0230s](training.py 201): INFO Train: [277/300][150/156]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.4676 (0.5365)	data time 0.0004 (0.0418)	model time 0.4672 (0.5005)	loss 0.4166 (0.5473)	grad_norm 3.3313 (3.3153)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:02:49 vssm1_tiny_0230s](training.py 212): INFO EPOCH 277 training takes 0:01:23
[2024-11-09 19:02:49 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_277.pth saving......
[2024-11-09 19:02:49 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_277.pth saved !!!
[2024-11-09 19:02:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.137 (3.137)	Loss 0.1997 (0.1997)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:02:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.602 (0.603)	Loss 0.2086 (0.2009)	Acc@1 95.312 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:02:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.336 (0.420)	Loss 0.1835 (0.2086)	Acc@1 99.219 (95.982)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:03:01 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.365)	Loss 0.2375 (0.2116)	Acc@1 92.969 (95.842)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:03:03 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.700 Acc@5 100.000
[2024-11-09 19:03:03 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 19:03:03 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:03:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.798 (3.798)	Loss 0.1968 (0.1968)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:03:09 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.162 (0.579)	Loss 0.2043 (0.2006)	Acc@1 96.094 (96.023)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:03:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.145 (0.428)	Loss 0.1993 (0.2113)	Acc@1 96.875 (95.275)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:03:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.146 (0.354)	Loss 0.2600 (0.2199)	Acc@1 92.188 (94.808)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:03:17 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.780 Acc@5 100.000
[2024-11-09 19:03:17 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.8%
[2024-11-09 19:03:17 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.78%
[2024-11-09 19:03:21 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][0/156]	eta 0:11:43 lr 0.000003	 wd 0.0500	time 4.5112 (4.5112)	data time 4.0320 (4.0320)	model time 0.0000 (0.0000)	loss 0.5969 (0.5969)	grad_norm 3.2935 (3.2935)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:03:27 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][10/156]	eta 0:02:08 lr 0.000003	 wd 0.0500	time 0.4800 (0.8823)	data time 0.0104 (0.3813)	model time 0.0000 (0.0000)	loss 0.6089 (0.5299)	grad_norm 2.8774 (3.4637)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:03:31 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][20/156]	eta 0:01:34 lr 0.000003	 wd 0.0500	time 0.5061 (0.6924)	data time 0.0051 (0.2077)	model time 0.0000 (0.0000)	loss 0.4443 (0.5419)	grad_norm 5.0438 (3.3982)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:03:37 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][30/156]	eta 0:01:20 lr 0.000003	 wd 0.0500	time 0.5909 (0.6368)	data time 0.0228 (0.1497)	model time 0.0000 (0.0000)	loss 0.5918 (0.5425)	grad_norm 3.6348 (3.5160)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:03:42 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][40/156]	eta 0:01:11 lr 0.000003	 wd 0.0500	time 0.4678 (0.6201)	data time 0.0204 (0.1236)	model time 0.0000 (0.0000)	loss 0.5381 (0.5438)	grad_norm 6.6711 (3.5325)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:03:48 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][50/156]	eta 0:01:04 lr 0.000003	 wd 0.0500	time 0.6763 (0.6065)	data time 0.0137 (0.1031)	model time 0.0000 (0.0000)	loss 0.5921 (0.5445)	grad_norm 1.8030 (3.4394)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:03:54 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][60/156]	eta 0:00:57 lr 0.000003	 wd 0.0500	time 0.4308 (0.6019)	data time 0.0008 (0.0905)	model time 0.4300 (0.5525)	loss 0.5870 (0.5458)	grad_norm 3.7886 (3.3300)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:03:59 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][70/156]	eta 0:00:51 lr 0.000003	 wd 0.0500	time 0.5446 (0.5949)	data time 0.0008 (0.0801)	model time 0.5438 (0.5440)	loss 0.5570 (0.5472)	grad_norm 3.3894 (3.3026)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:04:05 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][80/156]	eta 0:00:45 lr 0.000003	 wd 0.0500	time 0.5256 (0.5957)	data time 0.0010 (0.0740)	model time 0.5246 (0.5529)	loss 0.4997 (0.5487)	grad_norm 5.1176 (3.3409)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:04:10 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][90/156]	eta 0:00:38 lr 0.000003	 wd 0.0500	time 0.5017 (0.5873)	data time 0.0008 (0.0674)	model time 0.5009 (0.5410)	loss 0.5031 (0.5482)	grad_norm 2.6717 (3.2802)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:04:15 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][100/156]	eta 0:00:32 lr 0.000003	 wd 0.0500	time 0.5062 (0.5789)	data time 0.0076 (0.0626)	model time 0.4986 (0.5295)	loss 0.5826 (0.5461)	grad_norm 4.0210 (3.3086)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:04:21 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][110/156]	eta 0:00:26 lr 0.000003	 wd 0.0500	time 0.4943 (0.5768)	data time 0.0082 (0.0584)	model time 0.4861 (0.5311)	loss 0.6076 (0.5463)	grad_norm 4.8293 (3.3131)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:04:26 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][120/156]	eta 0:00:20 lr 0.000003	 wd 0.0500	time 0.5764 (0.5698)	data time 0.0298 (0.0552)	model time 0.5467 (0.5228)	loss 0.5027 (0.5431)	grad_norm 2.9940 (3.3264)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:04:31 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][130/156]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.5990 (0.5644)	data time 0.0994 (0.0529)	model time 0.4996 (0.5166)	loss 0.4414 (0.5400)	grad_norm 3.3832 (3.3670)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:04:36 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][140/156]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.4668 (0.5588)	data time 0.0009 (0.0498)	model time 0.4659 (0.5123)	loss 0.5285 (0.5398)	grad_norm 3.2349 (3.3481)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:04:41 vssm1_tiny_0230s](training.py 201): INFO Train: [278/300][150/156]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.5582 (0.5587)	data time 0.0005 (0.0468)	model time 0.5577 (0.5162)	loss 0.4178 (0.5381)	grad_norm 2.9664 (3.3971)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:04:45 vssm1_tiny_0230s](training.py 212): INFO EPOCH 278 training takes 0:01:27
[2024-11-09 19:04:45 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_278.pth saving......
[2024-11-09 19:04:45 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_278.pth saved !!!
[2024-11-09 19:04:49 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.097 (4.097)	Loss 0.1927 (0.1927)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:04:51 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.164 (0.562)	Loss 0.2024 (0.1943)	Acc@1 95.312 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:04:53 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.383)	Loss 0.1801 (0.2020)	Acc@1 99.219 (96.429)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:04:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.356 (0.371)	Loss 0.2365 (0.2066)	Acc@1 92.188 (95.917)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:04:59 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.720 Acc@5 100.000
[2024-11-09 19:04:59 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 19:04:59 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:05:02 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.113 (3.113)	Loss 0.1970 (0.1970)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:05:05 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.516 (0.499)	Loss 0.2045 (0.2006)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:05:07 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.136 (0.352)	Loss 0.1991 (0.2113)	Acc@1 96.875 (95.350)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:05:10 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.228 (0.328)	Loss 0.2598 (0.2197)	Acc@1 92.188 (94.859)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:05:12 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.780 Acc@5 100.000
[2024-11-09 19:05:12 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.8%
[2024-11-09 19:05:12 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.78%
[2024-11-09 19:05:16 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][0/156]	eta 0:09:39 lr 0.000003	 wd 0.0500	time 3.7132 (3.7132)	data time 3.2351 (3.2351)	model time 0.0000 (0.0000)	loss 0.5042 (0.5042)	grad_norm 3.1181 (3.1181)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:05:21 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][10/156]	eta 0:01:55 lr 0.000003	 wd 0.0500	time 0.6286 (0.7935)	data time 0.0055 (0.3082)	model time 0.0000 (0.0000)	loss 0.5868 (0.4965)	grad_norm 4.9225 (3.7488)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:05:26 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][20/156]	eta 0:01:28 lr 0.000003	 wd 0.0500	time 0.5667 (0.6524)	data time 0.0580 (0.1733)	model time 0.0000 (0.0000)	loss 0.5353 (0.5064)	grad_norm 2.8476 (3.3596)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:05:31 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][30/156]	eta 0:01:17 lr 0.000003	 wd 0.0500	time 0.5977 (0.6149)	data time 0.0214 (0.1242)	model time 0.0000 (0.0000)	loss 0.5836 (0.5250)	grad_norm 2.7466 (3.3243)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:05:36 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][40/156]	eta 0:01:07 lr 0.000003	 wd 0.0500	time 0.4610 (0.5857)	data time 0.0026 (0.0962)	model time 0.0000 (0.0000)	loss 0.5685 (0.5274)	grad_norm 3.1286 (3.3632)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:05:41 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][50/156]	eta 0:00:59 lr 0.000003	 wd 0.0500	time 0.4314 (0.5617)	data time 0.0227 (0.0808)	model time 0.0000 (0.0000)	loss 0.4852 (0.5303)	grad_norm 4.9842 (3.4607)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:05:46 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][60/156]	eta 0:00:53 lr 0.000003	 wd 0.0500	time 0.5601 (0.5561)	data time 0.0847 (0.0711)	model time 0.4754 (0.5067)	loss 0.4045 (0.5282)	grad_norm 5.5851 (3.6082)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:05:51 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][70/156]	eta 0:00:47 lr 0.000003	 wd 0.0500	time 0.6031 (0.5530)	data time 0.0006 (0.0629)	model time 0.6024 (0.5135)	loss 0.6336 (0.5316)	grad_norm 2.5341 (3.5353)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:05:56 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][80/156]	eta 0:00:41 lr 0.000003	 wd 0.0500	time 0.5242 (0.5461)	data time 0.0028 (0.0567)	model time 0.5214 (0.5039)	loss 0.4651 (0.5374)	grad_norm 4.6917 (3.6736)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:06:01 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][90/156]	eta 0:00:35 lr 0.000003	 wd 0.0500	time 0.4722 (0.5391)	data time 0.0027 (0.0513)	model time 0.4695 (0.4967)	loss 0.5597 (0.5368)	grad_norm 2.8668 (3.6968)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:06:06 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][100/156]	eta 0:00:29 lr 0.000003	 wd 0.0500	time 0.5492 (0.5328)	data time 0.0144 (0.0471)	model time 0.5348 (0.4906)	loss 0.4436 (0.5335)	grad_norm 3.7189 (3.6633)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:06:11 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][110/156]	eta 0:00:24 lr 0.000003	 wd 0.0500	time 0.4284 (0.5291)	data time 0.0074 (0.0435)	model time 0.4210 (0.4896)	loss 0.4882 (0.5348)	grad_norm 2.4899 (3.6976)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:06:16 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][120/156]	eta 0:00:18 lr 0.000003	 wd 0.0500	time 0.5047 (0.5277)	data time 0.0180 (0.0410)	model time 0.4867 (0.4909)	loss 0.5742 (0.5342)	grad_norm 2.7876 (3.6962)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:06:21 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][130/156]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4409 (0.5269)	data time 0.0007 (0.0389)	model time 0.4402 (0.4925)	loss 0.5925 (0.5361)	grad_norm 2.2250 (3.6520)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:06:26 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][140/156]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.5116 (0.5239)	data time 0.0009 (0.0372)	model time 0.5107 (0.4900)	loss 0.5471 (0.5372)	grad_norm 3.7166 (3.6368)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:06:31 vssm1_tiny_0230s](training.py 201): INFO Train: [279/300][150/156]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.4754 (0.5227)	data time 0.0007 (0.0350)	model time 0.4747 (0.4912)	loss 0.4676 (0.5380)	grad_norm 3.3557 (3.6618)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:06:34 vssm1_tiny_0230s](training.py 212): INFO EPOCH 279 training takes 0:01:21
[2024-11-09 19:06:34 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_279.pth saving......
[2024-11-09 19:06:34 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_279.pth saved !!!
[2024-11-09 19:06:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.452 (3.452)	Loss 0.1890 (0.1890)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:06:40 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.196 (0.561)	Loss 0.1978 (0.1900)	Acc@1 96.094 (97.017)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:06:43 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.167 (0.417)	Loss 0.1847 (0.1984)	Acc@1 98.438 (96.726)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:06:45 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.361)	Loss 0.2446 (0.2066)	Acc@1 91.406 (96.018)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:06:48 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.740 Acc@5 100.000
[2024-11-09 19:06:48 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 19:06:48 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:06:51 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.761 (3.761)	Loss 0.1967 (0.1967)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:06:54 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.149 (0.536)	Loss 0.2042 (0.2003)	Acc@1 96.094 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:06:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.358)	Loss 0.1987 (0.2109)	Acc@1 96.875 (95.461)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:06:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.315)	Loss 0.2593 (0.2194)	Acc@1 92.188 (94.934)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:07:00 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.900 Acc@5 100.000
[2024-11-09 19:07:00 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.9%
[2024-11-09 19:07:00 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.90%
[2024-11-09 19:07:03 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][0/156]	eta 0:09:58 lr 0.000003	 wd 0.0500	time 3.8397 (3.8397)	data time 3.4336 (3.4336)	model time 0.0000 (0.0000)	loss 0.4244 (0.4244)	grad_norm 4.0632 (4.0632)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:07:09 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][10/156]	eta 0:02:10 lr 0.000003	 wd 0.0500	time 0.5267 (0.8945)	data time 0.0058 (0.3824)	model time 0.0000 (0.0000)	loss 0.5901 (0.5597)	grad_norm 2.6969 (3.5332)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:07:14 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][20/156]	eta 0:01:34 lr 0.000003	 wd 0.0500	time 0.5026 (0.6983)	data time 0.0504 (0.2080)	model time 0.0000 (0.0000)	loss 0.4723 (0.5537)	grad_norm 3.6411 (3.5581)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:07:20 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][30/156]	eta 0:01:21 lr 0.000003	 wd 0.0500	time 0.4730 (0.6452)	data time 0.0275 (0.1503)	model time 0.0000 (0.0000)	loss 0.6023 (0.5522)	grad_norm 2.4837 (3.4677)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:07:25 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][40/156]	eta 0:01:10 lr 0.000003	 wd 0.0500	time 0.4668 (0.6114)	data time 0.0157 (0.1158)	model time 0.0000 (0.0000)	loss 0.5579 (0.5610)	grad_norm 3.8290 (3.4232)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:07:30 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][50/156]	eta 0:01:02 lr 0.000003	 wd 0.0500	time 0.4918 (0.5887)	data time 0.0008 (0.0954)	model time 0.0000 (0.0000)	loss 0.6601 (0.5556)	grad_norm 2.6025 (3.5038)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:07:34 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][60/156]	eta 0:00:54 lr 0.000003	 wd 0.0500	time 0.5043 (0.5721)	data time 0.0236 (0.0827)	model time 0.4808 (0.4701)	loss 0.6021 (0.5550)	grad_norm 4.7400 (3.5296)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:07:39 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][70/156]	eta 0:00:48 lr 0.000003	 wd 0.0500	time 0.4604 (0.5618)	data time 0.0123 (0.0728)	model time 0.4482 (0.4783)	loss 0.5076 (0.5528)	grad_norm 2.6312 (3.5077)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:07:45 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][80/156]	eta 0:00:42 lr 0.000003	 wd 0.0500	time 0.5686 (0.5600)	data time 0.0494 (0.0664)	model time 0.5192 (0.4942)	loss 0.5580 (0.5546)	grad_norm 2.9714 (3.4643)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:07:50 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][90/156]	eta 0:00:36 lr 0.000003	 wd 0.0500	time 0.4208 (0.5549)	data time 0.0128 (0.0617)	model time 0.4080 (0.4930)	loss 0.6379 (0.5506)	grad_norm 2.4043 (3.4598)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:07:55 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][100/156]	eta 0:00:30 lr 0.000003	 wd 0.0500	time 0.4921 (0.5498)	data time 0.0475 (0.0582)	model time 0.4446 (0.4899)	loss 0.5687 (0.5479)	grad_norm 3.6686 (3.4692)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:08:00 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][110/156]	eta 0:00:25 lr 0.000003	 wd 0.0500	time 0.4414 (0.5461)	data time 0.0185 (0.0543)	model time 0.4229 (0.4906)	loss 0.6065 (0.5486)	grad_norm 2.6325 (3.4572)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:08:05 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][120/156]	eta 0:00:19 lr 0.000003	 wd 0.0500	time 0.4816 (0.5445)	data time 0.0027 (0.0521)	model time 0.4789 (0.4919)	loss 0.4166 (0.5445)	grad_norm 3.1584 (3.5302)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:08:11 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][130/156]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.5798 (0.5424)	data time 0.0530 (0.0496)	model time 0.5268 (0.4926)	loss 0.4952 (0.5431)	grad_norm 3.0782 (3.5441)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:08:16 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][140/156]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.4480 (0.5419)	data time 0.0010 (0.0484)	model time 0.4470 (0.4936)	loss 0.5714 (0.5440)	grad_norm 1.7851 (3.5060)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:08:21 vssm1_tiny_0230s](training.py 201): INFO Train: [280/300][150/156]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.4985 (0.5396)	data time 0.0004 (0.0454)	model time 0.4980 (0.4947)	loss 0.5069 (0.5440)	grad_norm 2.0798 (3.4559)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:08:24 vssm1_tiny_0230s](training.py 212): INFO EPOCH 280 training takes 0:01:24
[2024-11-09 19:08:24 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_280.pth saving......
[2024-11-09 19:08:24 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_280.pth saved !!!
[2024-11-09 19:08:28 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.089 (4.089)	Loss 0.1998 (0.1998)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:08:32 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.205 (0.658)	Loss 0.2107 (0.2015)	Acc@1 95.312 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:08:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.221 (0.445)	Loss 0.1750 (0.2085)	Acc@1 99.219 (96.317)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:08:37 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.392)	Loss 0.2318 (0.2092)	Acc@1 91.406 (95.867)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:08:39 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.740 Acc@5 100.000
[2024-11-09 19:08:39 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 19:08:39 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:08:41 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.496 (2.496)	Loss 0.1969 (0.1969)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:08:44 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.194 (0.505)	Loss 0.2043 (0.2004)	Acc@1 96.094 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:08:46 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.135 (0.362)	Loss 0.1982 (0.2109)	Acc@1 96.875 (95.499)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:08:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.131 (0.328)	Loss 0.2588 (0.2192)	Acc@1 92.188 (94.960)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:08:52 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.920 Acc@5 100.000
[2024-11-09 19:08:52 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.9%
[2024-11-09 19:08:52 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.92%
[2024-11-09 19:08:56 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][0/156]	eta 0:10:08 lr 0.000003	 wd 0.0500	time 3.9036 (3.9036)	data time 3.3877 (3.3877)	model time 0.0000 (0.0000)	loss 0.4208 (0.4208)	grad_norm 4.4060 (4.4060)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:01 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][10/156]	eta 0:02:00 lr 0.000003	 wd 0.0500	time 0.4400 (0.8234)	data time 0.0072 (0.3508)	model time 0.0000 (0.0000)	loss 0.6151 (0.5439)	grad_norm 3.4195 (3.3257)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:06 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][20/156]	eta 0:01:30 lr 0.000003	 wd 0.0500	time 0.4522 (0.6641)	data time 0.0319 (0.1908)	model time 0.0000 (0.0000)	loss 0.6094 (0.5504)	grad_norm 6.1189 (3.2167)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:11 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][30/156]	eta 0:01:17 lr 0.000003	 wd 0.0500	time 0.6002 (0.6186)	data time 0.0132 (0.1333)	model time 0.0000 (0.0000)	loss 0.4336 (0.5353)	grad_norm 3.3241 (3.4022)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:16 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][40/156]	eta 0:01:08 lr 0.000003	 wd 0.0500	time 0.4583 (0.5884)	data time 0.0006 (0.1059)	model time 0.0000 (0.0000)	loss 0.5428 (0.5348)	grad_norm 2.3645 (3.4944)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:22 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][50/156]	eta 0:01:01 lr 0.000003	 wd 0.0500	time 0.5975 (0.5838)	data time 0.0039 (0.0880)	model time 0.0000 (0.0000)	loss 0.5911 (0.5361)	grad_norm 2.7203 (3.4980)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:28 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][60/156]	eta 0:00:56 lr 0.000003	 wd 0.0500	time 0.4784 (0.5855)	data time 0.0241 (0.0757)	model time 0.4543 (0.5812)	loss 0.6260 (0.5331)	grad_norm 2.7681 (3.4711)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:33 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][70/156]	eta 0:00:50 lr 0.000003	 wd 0.0500	time 0.7348 (0.5819)	data time 0.0378 (0.0672)	model time 0.6970 (0.5629)	loss 0.5537 (0.5370)	grad_norm 4.4858 (3.4746)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:39 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][80/156]	eta 0:00:44 lr 0.000003	 wd 0.0500	time 0.5732 (0.5811)	data time 0.0103 (0.0599)	model time 0.5629 (0.5645)	loss 0.5434 (0.5388)	grad_norm 4.1082 (3.5124)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:44 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][90/156]	eta 0:00:37 lr 0.000003	 wd 0.0500	time 0.5056 (0.5704)	data time 0.0201 (0.0548)	model time 0.4856 (0.5409)	loss 0.5771 (0.5390)	grad_norm 2.5230 (3.5054)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:49 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][100/156]	eta 0:00:31 lr 0.000003	 wd 0.0500	time 0.4559 (0.5679)	data time 0.0030 (0.0505)	model time 0.4528 (0.5395)	loss 0.6441 (0.5415)	grad_norm 2.6182 (3.4813)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:09:55 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][110/156]	eta 0:00:26 lr 0.000003	 wd 0.0500	time 0.4662 (0.5661)	data time 0.0006 (0.0478)	model time 0.4656 (0.5374)	loss 0.5838 (0.5388)	grad_norm 4.6946 (3.5104)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:10:00 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][120/156]	eta 0:00:20 lr 0.000003	 wd 0.0500	time 0.5850 (0.5659)	data time 0.0164 (0.0456)	model time 0.5686 (0.5382)	loss 0.4473 (0.5381)	grad_norm 5.5821 (3.5265)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:10:06 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][130/156]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.6080 (0.5622)	data time 0.0009 (0.0437)	model time 0.6070 (0.5330)	loss 0.5414 (0.5387)	grad_norm 4.2622 (3.5000)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:10:11 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][140/156]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.6017 (0.5597)	data time 0.0010 (0.0416)	model time 0.6007 (0.5308)	loss 0.6184 (0.5410)	grad_norm 3.6867 (3.5167)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:10:16 vssm1_tiny_0230s](training.py 201): INFO Train: [281/300][150/156]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.4178 (0.5555)	data time 0.0007 (0.0391)	model time 0.4171 (0.5268)	loss 0.4397 (0.5398)	grad_norm 2.9724 (3.4925)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:10:19 vssm1_tiny_0230s](training.py 212): INFO EPOCH 281 training takes 0:01:27
[2024-11-09 19:10:19 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_281.pth saving......
[2024-11-09 19:10:19 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_281.pth saved !!!
[2024-11-09 19:10:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.534 (3.534)	Loss 0.1930 (0.1930)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:10:26 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.149 (0.610)	Loss 0.2036 (0.1950)	Acc@1 95.312 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:10:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.151 (0.434)	Loss 0.1830 (0.2027)	Acc@1 99.219 (96.317)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:10:32 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.162 (0.395)	Loss 0.2401 (0.2081)	Acc@1 91.406 (95.791)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:10:35 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.640 Acc@5 100.000
[2024-11-09 19:10:35 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.6%
[2024-11-09 19:10:35 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:10:38 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.834 (3.834)	Loss 0.1968 (0.1968)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:10:41 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.148 (0.582)	Loss 0.2043 (0.2002)	Acc@1 96.094 (96.236)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:10:44 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.183 (0.432)	Loss 0.1978 (0.2107)	Acc@1 96.875 (95.461)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:10:46 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.359)	Loss 0.2581 (0.2188)	Acc@1 92.188 (94.960)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:10:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.920 Acc@5 100.000
[2024-11-09 19:10:49 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.9%
[2024-11-09 19:10:49 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.92%
[2024-11-09 19:10:53 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][0/156]	eta 0:12:22 lr 0.000003	 wd 0.0500	time 4.7596 (4.7596)	data time 4.1928 (4.1928)	model time 0.0000 (0.0000)	loss 0.4896 (0.4896)	grad_norm 2.8955 (2.8955)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:10:58 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][10/156]	eta 0:02:06 lr 0.000002	 wd 0.0500	time 0.4330 (0.8656)	data time 0.0007 (0.3930)	model time 0.0000 (0.0000)	loss 0.6055 (0.5338)	grad_norm 2.0019 (3.0741)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:03 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][20/156]	eta 0:01:33 lr 0.000002	 wd 0.0500	time 0.5445 (0.6890)	data time 0.0385 (0.2137)	model time 0.0000 (0.0000)	loss 0.4723 (0.5282)	grad_norm 3.3837 (3.2747)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:08 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][30/156]	eta 0:01:17 lr 0.000002	 wd 0.0500	time 0.4217 (0.6133)	data time 0.0037 (0.1487)	model time 0.0000 (0.0000)	loss 0.5044 (0.5201)	grad_norm 2.3475 (3.4318)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:13 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][40/156]	eta 0:01:08 lr 0.000002	 wd 0.0500	time 0.6816 (0.5876)	data time 0.0048 (0.1168)	model time 0.0000 (0.0000)	loss 0.6372 (0.5304)	grad_norm 2.9727 (3.4853)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:18 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][50/156]	eta 0:01:01 lr 0.000002	 wd 0.0500	time 0.4494 (0.5799)	data time 0.0005 (0.0962)	model time 0.0000 (0.0000)	loss 0.5337 (0.5383)	grad_norm 2.5023 (3.4528)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:23 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][60/156]	eta 0:00:54 lr 0.000002	 wd 0.0500	time 0.4646 (0.5642)	data time 0.0071 (0.0831)	model time 0.4575 (0.4682)	loss 0.6276 (0.5396)	grad_norm 3.8506 (3.5316)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:29 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][70/156]	eta 0:00:48 lr 0.000002	 wd 0.0500	time 0.4299 (0.5609)	data time 0.0009 (0.0744)	model time 0.4290 (0.4935)	loss 0.5429 (0.5387)	grad_norm 2.9869 (3.5486)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:33 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][80/156]	eta 0:00:41 lr 0.000002	 wd 0.0500	time 0.6313 (0.5501)	data time 0.0009 (0.0666)	model time 0.6305 (0.4832)	loss 0.4811 (0.5374)	grad_norm 2.0627 (3.4611)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:38 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][90/156]	eta 0:00:35 lr 0.000002	 wd 0.0500	time 0.4980 (0.5423)	data time 0.0301 (0.0606)	model time 0.4679 (0.4793)	loss 0.6293 (0.5385)	grad_norm 2.6973 (3.4862)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:43 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][100/156]	eta 0:00:30 lr 0.000002	 wd 0.0500	time 0.4300 (0.5408)	data time 0.0007 (0.0560)	model time 0.4293 (0.4859)	loss 0.6150 (0.5376)	grad_norm 2.9964 (3.5124)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:48 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][110/156]	eta 0:00:24 lr 0.000002	 wd 0.0500	time 0.4484 (0.5361)	data time 0.0017 (0.0525)	model time 0.4467 (0.4835)	loss 0.5426 (0.5388)	grad_norm 3.7116 (3.5207)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:53 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][120/156]	eta 0:00:19 lr 0.000002	 wd 0.0500	time 0.4353 (0.5334)	data time 0.0252 (0.0499)	model time 0.4100 (0.4833)	loss 0.5668 (0.5402)	grad_norm 3.6652 (3.4858)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:11:58 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][130/156]	eta 0:00:13 lr 0.000002	 wd 0.0500	time 0.5032 (0.5306)	data time 0.0008 (0.0470)	model time 0.5024 (0.4836)	loss 0.5411 (0.5404)	grad_norm 2.8962 (3.4561)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:12:03 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][140/156]	eta 0:00:08 lr 0.000002	 wd 0.0500	time 0.4126 (0.5259)	data time 0.0008 (0.0445)	model time 0.4118 (0.4800)	loss 0.5707 (0.5418)	grad_norm 2.5582 (3.4450)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:12:08 vssm1_tiny_0230s](training.py 201): INFO Train: [282/300][150/156]	eta 0:00:03 lr 0.000002	 wd 0.0500	time 0.4944 (0.5223)	data time 0.0008 (0.0416)	model time 0.4936 (0.4791)	loss 0.6101 (0.5412)	grad_norm 4.1519 (3.4337)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:12:10 vssm1_tiny_0230s](training.py 212): INFO EPOCH 282 training takes 0:01:21
[2024-11-09 19:12:10 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_282.pth saving......
[2024-11-09 19:12:11 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_282.pth saved !!!
[2024-11-09 19:12:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.648 (2.648)	Loss 0.1967 (0.1967)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:12:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.163 (0.403)	Loss 0.2090 (0.1991)	Acc@1 95.312 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:12:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.335)	Loss 0.1801 (0.2064)	Acc@1 99.219 (96.280)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:12:20 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.186 (0.300)	Loss 0.2350 (0.2094)	Acc@1 92.188 (95.892)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:12:23 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.740 Acc@5 100.000
[2024-11-09 19:12:23 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 19:12:23 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:12:26 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.337 (3.337)	Loss 0.1969 (0.1969)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:12:29 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.134 (0.537)	Loss 0.2045 (0.2002)	Acc@1 96.094 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:12:31 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.166 (0.399)	Loss 0.1974 (0.2107)	Acc@1 96.875 (95.499)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:12:33 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.345)	Loss 0.2576 (0.2186)	Acc@1 92.188 (94.985)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:12:36 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.940 Acc@5 100.000
[2024-11-09 19:12:36 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 94.9%
[2024-11-09 19:12:36 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.94%
[2024-11-09 19:12:42 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][0/156]	eta 0:14:40 lr 0.000002	 wd 0.0500	time 5.6456 (5.6456)	data time 4.9185 (4.9185)	model time 0.0000 (0.0000)	loss 0.5869 (0.5869)	grad_norm 2.5802 (2.5802)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:12:47 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][10/156]	eta 0:02:24 lr 0.000002	 wd 0.0500	time 0.4759 (0.9903)	data time 0.0329 (0.4653)	model time 0.0000 (0.0000)	loss 0.5470 (0.5562)	grad_norm 3.0157 (2.8811)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:12:52 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][20/156]	eta 0:01:42 lr 0.000002	 wd 0.0500	time 0.5966 (0.7533)	data time 0.0570 (0.2519)	model time 0.0000 (0.0000)	loss 0.4076 (0.5492)	grad_norm 2.8342 (2.8735)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:12:57 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][30/156]	eta 0:01:24 lr 0.000002	 wd 0.0500	time 0.5193 (0.6736)	data time 0.0079 (0.1797)	model time 0.0000 (0.0000)	loss 0.4202 (0.5458)	grad_norm 3.5332 (3.0475)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:02 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][40/156]	eta 0:01:13 lr 0.000002	 wd 0.0500	time 0.4804 (0.6337)	data time 0.0207 (0.1387)	model time 0.0000 (0.0000)	loss 0.5920 (0.5560)	grad_norm 2.5755 (3.1142)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:07 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][50/156]	eta 0:01:03 lr 0.000002	 wd 0.0500	time 0.6390 (0.5997)	data time 0.0211 (0.1134)	model time 0.0000 (0.0000)	loss 0.6399 (0.5584)	grad_norm 2.7713 (3.0939)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:12 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][60/156]	eta 0:00:56 lr 0.000002	 wd 0.0500	time 0.5703 (0.5835)	data time 0.0702 (0.0985)	model time 0.5001 (0.4785)	loss 0.4183 (0.5492)	grad_norm 5.2674 (3.2096)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:17 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][70/156]	eta 0:00:48 lr 0.000002	 wd 0.0500	time 0.4214 (0.5697)	data time 0.0011 (0.0860)	model time 0.4203 (0.4771)	loss 0.6089 (0.5514)	grad_norm 2.5501 (3.2334)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:22 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][80/156]	eta 0:00:42 lr 0.000002	 wd 0.0500	time 0.4302 (0.5606)	data time 0.0155 (0.0770)	model time 0.4147 (0.4789)	loss 0.4478 (0.5503)	grad_norm 3.8491 (3.2505)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:27 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][90/156]	eta 0:00:36 lr 0.000002	 wd 0.0500	time 0.4977 (0.5559)	data time 0.0009 (0.0700)	model time 0.4968 (0.4854)	loss 0.5466 (0.5492)	grad_norm 3.4563 (3.2004)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:32 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][100/156]	eta 0:00:30 lr 0.000002	 wd 0.0500	time 0.4883 (0.5490)	data time 0.0019 (0.0647)	model time 0.4864 (0.4823)	loss 0.5708 (0.5501)	grad_norm 4.7734 (3.1960)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:36 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][110/156]	eta 0:00:25 lr 0.000002	 wd 0.0500	time 0.5052 (0.5437)	data time 0.0012 (0.0598)	model time 0.5040 (0.4817)	loss 0.5066 (0.5492)	grad_norm 2.2188 (3.2242)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:42 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][120/156]	eta 0:00:19 lr 0.000002	 wd 0.0500	time 0.4560 (0.5418)	data time 0.0016 (0.0559)	model time 0.4544 (0.4856)	loss 0.5737 (0.5477)	grad_norm 3.7814 (3.2455)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:47 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][130/156]	eta 0:00:14 lr 0.000002	 wd 0.0500	time 0.6322 (0.5411)	data time 0.0028 (0.0529)	model time 0.6294 (0.4895)	loss 0.3966 (0.5473)	grad_norm 3.3691 (3.2671)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:52 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][140/156]	eta 0:00:08 lr 0.000002	 wd 0.0500	time 0.5264 (0.5383)	data time 0.0008 (0.0502)	model time 0.5256 (0.4892)	loss 0.4163 (0.5446)	grad_norm 5.5319 (3.3128)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:13:57 vssm1_tiny_0230s](training.py 201): INFO Train: [283/300][150/156]	eta 0:00:03 lr 0.000002	 wd 0.0500	time 0.4345 (0.5332)	data time 0.0005 (0.0470)	model time 0.4340 (0.4862)	loss 0.6065 (0.5459)	grad_norm 1.5589 (3.3778)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:14:00 vssm1_tiny_0230s](training.py 212): INFO EPOCH 283 training takes 0:01:24
[2024-11-09 19:14:00 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_283.pth saving......
[2024-11-09 19:14:01 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_283.pth saved !!!
[2024-11-09 19:14:05 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.156 (4.156)	Loss 0.1906 (0.1906)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:14:07 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.173 (0.594)	Loss 0.2012 (0.1920)	Acc@1 96.094 (96.804)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:14:10 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.172 (0.440)	Loss 0.1880 (0.2003)	Acc@1 97.656 (96.540)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:14:12 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.189 (0.371)	Loss 0.2461 (0.2085)	Acc@1 92.188 (95.968)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:14:15 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.740 Acc@5 100.000
[2024-11-09 19:14:15 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 19:14:15 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:14:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.738 (3.738)	Loss 0.1968 (0.1968)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:14:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.135 (0.522)	Loss 0.2043 (0.2001)	Acc@1 96.094 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:14:24 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.422)	Loss 0.1970 (0.2105)	Acc@1 96.875 (95.499)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:14:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.228 (0.371)	Loss 0.2571 (0.2183)	Acc@1 92.969 (95.035)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:14:28 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 94.980 Acc@5 100.000
[2024-11-09 19:14:28 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 19:14:28 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 94.98%
[2024-11-09 19:14:32 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][0/156]	eta 0:09:56 lr 0.000002	 wd 0.0500	time 3.8207 (3.8207)	data time 3.3906 (3.3906)	model time 0.0000 (0.0000)	loss 0.4210 (0.4210)	grad_norm 6.2734 (6.2734)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:14:38 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][10/156]	eta 0:02:05 lr 0.000002	 wd 0.0500	time 0.6263 (0.8625)	data time 0.0083 (0.3669)	model time 0.0000 (0.0000)	loss 0.5497 (0.5279)	grad_norm 2.2701 (3.0547)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:14:43 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][20/156]	eta 0:01:33 lr 0.000002	 wd 0.0500	time 0.5813 (0.6855)	data time 0.0198 (0.2008)	model time 0.0000 (0.0000)	loss 0.4219 (0.5249)	grad_norm 4.1377 (3.2741)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:14:48 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][30/156]	eta 0:01:19 lr 0.000002	 wd 0.0500	time 0.5478 (0.6337)	data time 0.0011 (0.1428)	model time 0.0000 (0.0000)	loss 0.5043 (0.5375)	grad_norm 3.8860 (3.3449)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:14:53 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][40/156]	eta 0:01:09 lr 0.000002	 wd 0.0500	time 0.4345 (0.5971)	data time 0.0040 (0.1139)	model time 0.0000 (0.0000)	loss 0.5094 (0.5334)	grad_norm 2.0231 (3.3450)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:14:57 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][50/156]	eta 0:01:00 lr 0.000002	 wd 0.0500	time 0.4429 (0.5695)	data time 0.0005 (0.0926)	model time 0.0000 (0.0000)	loss 0.6015 (0.5447)	grad_norm 2.1332 (3.4311)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:15:02 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][60/156]	eta 0:00:52 lr 0.000002	 wd 0.0500	time 0.4451 (0.5499)	data time 0.0034 (0.0785)	model time 0.4417 (0.4429)	loss 0.5835 (0.5477)	grad_norm 2.8054 (3.3630)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:15:07 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][70/156]	eta 0:00:46 lr 0.000002	 wd 0.0500	time 0.5418 (0.5436)	data time 0.0316 (0.0695)	model time 0.5102 (0.4668)	loss 0.6793 (0.5454)	grad_norm 4.7898 (3.3969)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:15:12 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][80/156]	eta 0:00:40 lr 0.000002	 wd 0.0500	time 0.4458 (0.5349)	data time 0.0008 (0.0633)	model time 0.4450 (0.4628)	loss 0.5192 (0.5489)	grad_norm 4.9347 (3.4032)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:15:17 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][90/156]	eta 0:00:35 lr 0.000002	 wd 0.0500	time 0.5409 (0.5323)	data time 0.0165 (0.0572)	model time 0.5244 (0.4727)	loss 0.5857 (0.5487)	grad_norm 3.0272 (3.4214)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:15:22 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][100/156]	eta 0:00:29 lr 0.000002	 wd 0.0500	time 0.5067 (0.5298)	data time 0.0937 (0.0535)	model time 0.4130 (0.4757)	loss 0.6084 (0.5475)	grad_norm 4.6416 (3.4248)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:15:27 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][110/156]	eta 0:00:24 lr 0.000002	 wd 0.0500	time 0.4909 (0.5276)	data time 0.0110 (0.0504)	model time 0.4798 (0.4773)	loss 0.4622 (0.5437)	grad_norm 2.3888 (3.4089)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:15:32 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][120/156]	eta 0:00:18 lr 0.000002	 wd 0.0500	time 0.4321 (0.5259)	data time 0.0013 (0.0472)	model time 0.4307 (0.4801)	loss 0.4895 (0.5425)	grad_norm 3.1674 (3.4063)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:15:37 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][130/156]	eta 0:00:13 lr 0.000002	 wd 0.0500	time 0.5188 (0.5241)	data time 0.0465 (0.0448)	model time 0.4723 (0.4809)	loss 0.4379 (0.5422)	grad_norm 2.1493 (3.4138)	loss_scale 65536.0000 (34018.6870)	mem 13675MB
[2024-11-09 19:15:42 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][140/156]	eta 0:00:08 lr 0.000002	 wd 0.0500	time 0.5638 (0.5235)	data time 0.0010 (0.0423)	model time 0.5629 (0.4836)	loss 0.5513 (0.5420)	grad_norm 6.7409 (3.4210)	loss_scale 65536.0000 (36253.9574)	mem 13675MB
[2024-11-09 19:15:47 vssm1_tiny_0230s](training.py 201): INFO Train: [284/300][150/156]	eta 0:00:03 lr 0.000002	 wd 0.0500	time 0.4521 (0.5230)	data time 0.0007 (0.0396)	model time 0.4514 (0.4867)	loss 0.5677 (0.5389)	grad_norm 2.7711 (3.4532)	loss_scale 65536.0000 (38193.1656)	mem 13675MB
[2024-11-09 19:15:50 vssm1_tiny_0230s](training.py 212): INFO EPOCH 284 training takes 0:01:21
[2024-11-09 19:15:50 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_284.pth saving......
[2024-11-09 19:15:50 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_284.pth saved !!!
[2024-11-09 19:15:54 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.613 (3.613)	Loss 0.1986 (0.1986)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:15:56 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.167 (0.524)	Loss 0.2091 (0.1994)	Acc@1 95.312 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:15:58 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.132 (0.354)	Loss 0.1769 (0.2067)	Acc@1 99.219 (96.131)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:16:00 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.316)	Loss 0.2318 (0.2082)	Acc@1 92.188 (95.842)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:16:02 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.740 Acc@5 100.000
[2024-11-09 19:16:02 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 19:16:02 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:16:06 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.414 (4.414)	Loss 0.1963 (0.1963)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:16:08 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.133 (0.586)	Loss 0.2041 (0.1997)	Acc@1 96.094 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:16:11 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.133 (0.420)	Loss 0.1968 (0.2101)	Acc@1 96.875 (95.536)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:16:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.207 (0.379)	Loss 0.2568 (0.2180)	Acc@1 92.188 (95.086)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:16:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.020 Acc@5 100.000
[2024-11-09 19:16:16 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 19:16:16 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.02%
[2024-11-09 19:16:20 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][0/156]	eta 0:11:38 lr 0.000002	 wd 0.0500	time 4.4792 (4.4792)	data time 4.0143 (4.0143)	model time 0.0000 (0.0000)	loss 0.4692 (0.4692)	grad_norm 3.1426 (3.1426)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 19:16:26 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][10/156]	eta 0:02:08 lr 0.000002	 wd 0.0500	time 0.4509 (0.8815)	data time 0.0229 (0.3851)	model time 0.0000 (0.0000)	loss 0.5041 (0.5676)	grad_norm 3.4271 (3.9600)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 19:16:31 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][20/156]	eta 0:01:35 lr 0.000002	 wd 0.0500	time 0.5522 (0.7037)	data time 0.0137 (0.2104)	model time 0.0000 (0.0000)	loss 0.6456 (0.5487)	grad_norm 2.6199 (3.8414)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 19:16:36 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][30/156]	eta 0:01:20 lr 0.000002	 wd 0.0500	time 0.4390 (0.6377)	data time 0.0157 (0.1496)	model time 0.0000 (0.0000)	loss 0.5931 (0.5464)	grad_norm 1.7151 (3.7529)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 19:16:41 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][40/156]	eta 0:01:10 lr 0.000002	 wd 0.0500	time 0.4862 (0.6086)	data time 0.0406 (0.1193)	model time 0.0000 (0.0000)	loss 0.5244 (0.5460)	grad_norm 2.5911 (3.5708)	loss_scale 65536.0000 (65536.0000)	mem 13675MB
[2024-11-09 19:16:46 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][50/156]	eta 0:01:02 lr 0.000002	 wd 0.0500	time 0.5101 (0.5904)	data time 0.0503 (0.1005)	model time 0.0000 (0.0000)	loss 0.5279 (0.5398)	grad_norm 4.4202 (inf)	loss_scale 32768.0000 (63608.4706)	mem 13675MB
[2024-11-09 19:16:51 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][60/156]	eta 0:00:55 lr 0.000002	 wd 0.0500	time 0.5517 (0.5744)	data time 0.0288 (0.0865)	model time 0.5229 (0.4781)	loss 0.4496 (0.5401)	grad_norm 4.5950 (inf)	loss_scale 32768.0000 (58552.6557)	mem 13675MB
[2024-11-09 19:16:56 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][70/156]	eta 0:00:48 lr 0.000002	 wd 0.0500	time 0.4976 (0.5665)	data time 0.0449 (0.0768)	model time 0.4527 (0.4892)	loss 0.5713 (0.5327)	grad_norm 1.9745 (inf)	loss_scale 32768.0000 (54921.0141)	mem 13675MB
[2024-11-09 19:17:01 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][80/156]	eta 0:00:42 lr 0.000002	 wd 0.0500	time 0.6658 (0.5597)	data time 0.0013 (0.0681)	model time 0.6645 (0.4946)	loss 0.5879 (0.5345)	grad_norm 3.9952 (inf)	loss_scale 32768.0000 (52186.0741)	mem 13675MB
[2024-11-09 19:17:07 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][90/156]	eta 0:00:36 lr 0.000002	 wd 0.0500	time 0.4381 (0.5585)	data time 0.0047 (0.0632)	model time 0.4334 (0.5021)	loss 0.5396 (0.5365)	grad_norm 2.4159 (inf)	loss_scale 32768.0000 (50052.2198)	mem 13675MB
[2024-11-09 19:17:12 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][100/156]	eta 0:00:30 lr 0.000002	 wd 0.0500	time 0.5898 (0.5515)	data time 0.0005 (0.0578)	model time 0.5892 (0.4975)	loss 0.5460 (0.5331)	grad_norm 3.7954 (inf)	loss_scale 32768.0000 (48340.9109)	mem 13675MB
[2024-11-09 19:17:16 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][110/156]	eta 0:00:24 lr 0.000002	 wd 0.0500	time 0.5636 (0.5433)	data time 0.0007 (0.0534)	model time 0.5629 (0.4900)	loss 0.4216 (0.5324)	grad_norm 3.1453 (inf)	loss_scale 32768.0000 (46937.9459)	mem 13675MB
[2024-11-09 19:17:21 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][120/156]	eta 0:00:19 lr 0.000002	 wd 0.0500	time 0.4318 (0.5386)	data time 0.0157 (0.0502)	model time 0.4162 (0.4873)	loss 0.5413 (0.5327)	grad_norm 3.1898 (inf)	loss_scale 32768.0000 (45766.8760)	mem 13675MB
[2024-11-09 19:17:26 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][130/156]	eta 0:00:13 lr 0.000002	 wd 0.0500	time 0.4802 (0.5376)	data time 0.0089 (0.0484)	model time 0.4713 (0.4888)	loss 0.6273 (0.5342)	grad_norm 2.8993 (inf)	loss_scale 32768.0000 (44774.5954)	mem 13675MB
[2024-11-09 19:17:32 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][140/156]	eta 0:00:08 lr 0.000002	 wd 0.0500	time 0.8076 (0.5398)	data time 0.0008 (0.0466)	model time 0.8068 (0.4950)	loss 0.5624 (0.5354)	grad_norm 2.7121 (inf)	loss_scale 32768.0000 (43923.0638)	mem 13675MB
[2024-11-09 19:17:37 vssm1_tiny_0230s](training.py 201): INFO Train: [285/300][150/156]	eta 0:00:03 lr 0.000002	 wd 0.0500	time 0.4294 (0.5362)	data time 0.0032 (0.0436)	model time 0.4262 (0.4939)	loss 0.5664 (0.5377)	grad_norm 4.7212 (inf)	loss_scale 32768.0000 (43184.3179)	mem 13675MB
[2024-11-09 19:17:40 vssm1_tiny_0230s](training.py 212): INFO EPOCH 285 training takes 0:01:24
[2024-11-09 19:17:40 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_285.pth saving......
[2024-11-09 19:17:41 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_285.pth saved !!!
[2024-11-09 19:17:45 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.698 (3.698)	Loss 0.1913 (0.1913)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:17:47 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.157 (0.590)	Loss 0.2024 (0.1935)	Acc@1 95.312 (96.662)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:17:50 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.220 (0.439)	Loss 0.1782 (0.2013)	Acc@1 99.219 (96.354)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:17:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.375)	Loss 0.2358 (0.2062)	Acc@1 92.188 (95.968)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:17:55 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.820 Acc@5 100.000
[2024-11-09 19:17:55 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:17:55 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:17:58 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.453 (2.453)	Loss 0.1963 (0.1963)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:18:00 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.145 (0.419)	Loss 0.2041 (0.1996)	Acc@1 96.094 (96.307)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:18:02 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.356 (0.330)	Loss 0.1964 (0.2100)	Acc@1 96.875 (95.536)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:18:04 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.144 (0.275)	Loss 0.2563 (0.2177)	Acc@1 92.188 (95.136)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:18:06 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.060 Acc@5 100.000
[2024-11-09 19:18:06 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:18:06 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.06%
[2024-11-09 19:18:11 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][0/156]	eta 0:10:47 lr 0.000002	 wd 0.0500	time 4.1478 (4.1478)	data time 3.6954 (3.6954)	model time 0.0000 (0.0000)	loss 0.4980 (0.4980)	grad_norm 2.5221 (2.5221)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:18:16 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][10/156]	eta 0:02:09 lr 0.000002	 wd 0.0500	time 0.6586 (0.8865)	data time 0.0009 (0.3441)	model time 0.0000 (0.0000)	loss 0.6070 (0.5361)	grad_norm 5.4418 (3.4000)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:18:22 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][20/156]	eta 0:01:37 lr 0.000002	 wd 0.0500	time 0.4231 (0.7195)	data time 0.0008 (0.1849)	model time 0.0000 (0.0000)	loss 0.6010 (0.5281)	grad_norm 3.5554 (3.1750)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:18:27 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][30/156]	eta 0:01:22 lr 0.000002	 wd 0.0500	time 0.4683 (0.6517)	data time 0.0035 (0.1288)	model time 0.0000 (0.0000)	loss 0.5887 (0.5395)	grad_norm 3.4675 (3.2366)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:18:32 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][40/156]	eta 0:01:11 lr 0.000002	 wd 0.0500	time 0.4931 (0.6168)	data time 0.0417 (0.0990)	model time 0.0000 (0.0000)	loss 0.4256 (0.5369)	grad_norm 5.0294 (3.1555)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:18:37 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][50/156]	eta 0:01:03 lr 0.000002	 wd 0.0500	time 0.4830 (0.5948)	data time 0.0008 (0.0849)	model time 0.0000 (0.0000)	loss 0.5844 (0.5401)	grad_norm 3.8987 (3.1983)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:18:42 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][60/156]	eta 0:00:56 lr 0.000002	 wd 0.0500	time 0.5490 (0.5854)	data time 0.0421 (0.0739)	model time 0.5069 (0.5192)	loss 0.4890 (0.5347)	grad_norm 2.5312 (3.1665)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:18:47 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][70/156]	eta 0:00:48 lr 0.000002	 wd 0.0500	time 0.4584 (0.5685)	data time 0.0080 (0.0644)	model time 0.4504 (0.4894)	loss 0.6036 (0.5362)	grad_norm 1.8527 (3.2454)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:18:52 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][80/156]	eta 0:00:42 lr 0.000002	 wd 0.0500	time 0.5006 (0.5635)	data time 0.0300 (0.0586)	model time 0.4705 (0.4965)	loss 0.3913 (0.5338)	grad_norm 2.7124 (3.2043)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:18:57 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][90/156]	eta 0:00:36 lr 0.000002	 wd 0.0500	time 0.5102 (0.5574)	data time 0.0013 (0.0536)	model time 0.5090 (0.4961)	loss 0.4200 (0.5341)	grad_norm 3.9683 (3.2299)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:19:02 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][100/156]	eta 0:00:30 lr 0.000002	 wd 0.0500	time 0.4641 (0.5495)	data time 0.0296 (0.0505)	model time 0.4345 (0.4879)	loss 0.5407 (0.5367)	grad_norm 3.4252 (3.1750)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:19:06 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][110/156]	eta 0:00:24 lr 0.000002	 wd 0.0500	time 0.4337 (0.5412)	data time 0.0186 (0.0468)	model time 0.4151 (0.4812)	loss 0.4981 (0.5379)	grad_norm 3.8927 (3.1563)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:19:12 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][120/156]	eta 0:00:19 lr 0.000002	 wd 0.0500	time 0.4388 (0.5394)	data time 0.0164 (0.0439)	model time 0.4223 (0.4850)	loss 0.4372 (0.5391)	grad_norm 4.8919 (3.1831)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:19:17 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][130/156]	eta 0:00:13 lr 0.000002	 wd 0.0500	time 0.4829 (0.5373)	data time 0.0217 (0.0412)	model time 0.4612 (0.4872)	loss 0.5192 (0.5403)	grad_norm 1.9789 (3.2151)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:19:22 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][140/156]	eta 0:00:08 lr 0.000002	 wd 0.0500	time 0.4228 (0.5353)	data time 0.0010 (0.0396)	model time 0.4218 (0.4876)	loss 0.5750 (0.5410)	grad_norm 1.7459 (3.2354)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:19:27 vssm1_tiny_0230s](training.py 201): INFO Train: [286/300][150/156]	eta 0:00:03 lr 0.000002	 wd 0.0500	time 0.5308 (0.5339)	data time 0.0006 (0.0375)	model time 0.5301 (0.4896)	loss 0.5720 (0.5397)	grad_norm 2.3048 (3.2208)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:19:30 vssm1_tiny_0230s](training.py 212): INFO EPOCH 286 training takes 0:01:23
[2024-11-09 19:19:30 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_286.pth saving......
[2024-11-09 19:19:31 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_286.pth saved !!!
[2024-11-09 19:19:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.198 (3.198)	Loss 0.1965 (0.1965)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:19:38 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.628)	Loss 0.2087 (0.1989)	Acc@1 95.312 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:19:41 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.215 (0.472)	Loss 0.1753 (0.2063)	Acc@1 99.219 (96.317)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:19:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.304 (0.386)	Loss 0.2322 (0.2082)	Acc@1 92.188 (95.968)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:19:45 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.840 Acc@5 100.000
[2024-11-09 19:19:45 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:19:45 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:19:48 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.175 (3.175)	Loss 0.1964 (0.1964)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:19:52 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.624)	Loss 0.2041 (0.1996)	Acc@1 96.094 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:19:54 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.436)	Loss 0.1959 (0.2099)	Acc@1 96.875 (95.573)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:19:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.382)	Loss 0.2559 (0.2175)	Acc@1 92.188 (95.161)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:19:59 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.080 Acc@5 100.000
[2024-11-09 19:19:59 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:19:59 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.08%
[2024-11-09 19:20:05 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][0/156]	eta 0:14:05 lr 0.000002	 wd 0.0500	time 5.4205 (5.4205)	data time 4.9574 (4.9574)	model time 0.0000 (0.0000)	loss 0.5756 (0.5756)	grad_norm 4.0762 (4.0762)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:20:10 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][10/156]	eta 0:02:21 lr 0.000002	 wd 0.0500	time 0.6024 (0.9706)	data time 0.0272 (0.4565)	model time 0.0000 (0.0000)	loss 0.6120 (0.5451)	grad_norm 2.5299 (3.3712)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:20:15 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][20/156]	eta 0:01:43 lr 0.000002	 wd 0.0500	time 0.6143 (0.7580)	data time 0.0151 (0.2474)	model time 0.0000 (0.0000)	loss 0.5607 (0.5468)	grad_norm 3.3333 (3.3491)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:20:20 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][30/156]	eta 0:01:24 lr 0.000002	 wd 0.0500	time 0.5997 (0.6686)	data time 0.0019 (0.1736)	model time 0.0000 (0.0000)	loss 0.5846 (0.5522)	grad_norm 4.3983 (3.5019)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:20:25 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][40/156]	eta 0:01:13 lr 0.000002	 wd 0.0500	time 0.4609 (0.6309)	data time 0.0422 (0.1360)	model time 0.0000 (0.0000)	loss 0.4493 (0.5467)	grad_norm 4.2525 (3.4038)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:20:30 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][50/156]	eta 0:01:03 lr 0.000002	 wd 0.0500	time 0.5395 (0.6010)	data time 0.0165 (0.1129)	model time 0.0000 (0.0000)	loss 0.6460 (0.5407)	grad_norm 2.8885 (3.5258)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:20:35 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][60/156]	eta 0:00:56 lr 0.000002	 wd 0.0500	time 0.4733 (0.5884)	data time 0.0129 (0.1005)	model time 0.4604 (0.4870)	loss 0.6429 (0.5429)	grad_norm 5.1142 (3.6476)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:20:41 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][70/156]	eta 0:00:49 lr 0.000002	 wd 0.0500	time 0.5708 (0.5811)	data time 0.0280 (0.0888)	model time 0.5428 (0.5029)	loss 0.4573 (0.5378)	grad_norm 3.8161 (3.7143)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:20:46 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][80/156]	eta 0:00:43 lr 0.000002	 wd 0.0500	time 0.5351 (0.5725)	data time 0.0174 (0.0801)	model time 0.5178 (0.4998)	loss 0.4177 (0.5388)	grad_norm 4.8429 (3.7718)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:20:52 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][90/156]	eta 0:00:37 lr 0.000002	 wd 0.0500	time 0.5843 (0.5737)	data time 0.0023 (0.0738)	model time 0.5820 (0.5149)	loss 0.5511 (0.5376)	grad_norm 2.2560 (3.7606)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:20:57 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][100/156]	eta 0:00:31 lr 0.000002	 wd 0.0500	time 0.6015 (0.5672)	data time 0.0053 (0.0675)	model time 0.5962 (0.5117)	loss 0.5206 (0.5335)	grad_norm 3.5481 (3.7068)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:21:02 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][110/156]	eta 0:00:26 lr 0.000002	 wd 0.0500	time 0.6312 (0.5655)	data time 0.0060 (0.0634)	model time 0.6252 (0.5139)	loss 0.5554 (0.5345)	grad_norm 2.5688 (3.6649)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:21:07 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][120/156]	eta 0:00:20 lr 0.000002	 wd 0.0500	time 0.5018 (0.5584)	data time 0.0163 (0.0591)	model time 0.4855 (0.5075)	loss 0.4938 (0.5375)	grad_norm 2.5962 (3.6357)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:21:12 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][130/156]	eta 0:00:14 lr 0.000002	 wd 0.0500	time 0.4556 (0.5522)	data time 0.0006 (0.0554)	model time 0.4550 (0.5023)	loss 0.5362 (0.5351)	grad_norm 2.6729 (3.6238)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:21:17 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][140/156]	eta 0:00:08 lr 0.000002	 wd 0.0500	time 0.4612 (0.5501)	data time 0.0052 (0.0525)	model time 0.4561 (0.5030)	loss 0.5992 (0.5351)	grad_norm 4.3564 (3.6215)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:21:22 vssm1_tiny_0230s](training.py 201): INFO Train: [287/300][150/156]	eta 0:00:03 lr 0.000002	 wd 0.0500	time 0.5902 (0.5484)	data time 0.0005 (0.0493)	model time 0.5897 (0.5047)	loss 0.5442 (0.5357)	grad_norm 2.5802 (3.6265)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:21:25 vssm1_tiny_0230s](training.py 212): INFO EPOCH 287 training takes 0:01:25
[2024-11-09 19:21:25 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_287.pth saving......
[2024-11-09 19:21:26 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_287.pth saved !!!
[2024-11-09 19:21:29 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.394 (3.394)	Loss 0.1991 (0.1991)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:21:32 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.598)	Loss 0.2098 (0.2013)	Acc@1 95.312 (96.378)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:21:34 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.189 (0.391)	Loss 0.1691 (0.2081)	Acc@1 99.219 (96.057)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:21:36 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.146 (0.342)	Loss 0.2255 (0.2073)	Acc@1 92.188 (95.867)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:21:39 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.800 Acc@5 100.000
[2024-11-09 19:21:39 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:21:39 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:21:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.957 (2.957)	Loss 0.1963 (0.1963)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:21:45 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.975 (0.530)	Loss 0.2041 (0.1995)	Acc@1 96.094 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:21:47 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.143 (0.375)	Loss 0.1956 (0.2097)	Acc@1 96.875 (95.573)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:21:49 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.335)	Loss 0.2556 (0.2173)	Acc@1 92.188 (95.161)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:21:51 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.080 Acc@5 100.000
[2024-11-09 19:21:51 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:21:51 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.08%
[2024-11-09 19:21:55 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][0/156]	eta 0:10:12 lr 0.000002	 wd 0.0500	time 3.9258 (3.9258)	data time 3.4089 (3.4089)	model time 0.0000 (0.0000)	loss 0.6196 (0.6196)	grad_norm 2.9172 (2.9172)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:00 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][10/156]	eta 0:01:56 lr 0.000002	 wd 0.0500	time 0.5066 (0.7970)	data time 0.0206 (0.3299)	model time 0.0000 (0.0000)	loss 0.6381 (0.5326)	grad_norm 4.7460 (3.8633)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:05 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][20/156]	eta 0:01:29 lr 0.000002	 wd 0.0500	time 0.4778 (0.6544)	data time 0.0050 (0.1770)	model time 0.0000 (0.0000)	loss 0.5488 (0.5366)	grad_norm 2.8363 (3.4691)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:10 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][30/156]	eta 0:01:15 lr 0.000002	 wd 0.0500	time 0.4575 (0.5988)	data time 0.0054 (0.1261)	model time 0.0000 (0.0000)	loss 0.5153 (0.5426)	grad_norm 3.7510 (3.5623)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:14 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][40/156]	eta 0:01:05 lr 0.000002	 wd 0.0500	time 0.4059 (0.5637)	data time 0.0034 (0.0975)	model time 0.0000 (0.0000)	loss 0.6052 (0.5431)	grad_norm 2.3265 (3.5647)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:19 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][50/156]	eta 0:00:57 lr 0.000002	 wd 0.0500	time 0.4371 (0.5450)	data time 0.0097 (0.0796)	model time 0.0000 (0.0000)	loss 0.5310 (0.5449)	grad_norm 2.4996 (3.4736)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:24 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][60/156]	eta 0:00:51 lr 0.000002	 wd 0.0500	time 0.4076 (0.5349)	data time 0.0010 (0.0683)	model time 0.4066 (0.4726)	loss 0.5721 (0.5391)	grad_norm 2.1452 (3.4730)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:29 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][70/156]	eta 0:00:45 lr 0.000002	 wd 0.0500	time 0.5482 (0.5319)	data time 0.0006 (0.0598)	model time 0.5475 (0.4893)	loss 0.6846 (0.5447)	grad_norm 3.2373 (3.5246)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:34 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][80/156]	eta 0:00:40 lr 0.000002	 wd 0.0500	time 0.5185 (0.5275)	data time 0.0036 (0.0546)	model time 0.5149 (0.4858)	loss 0.5515 (0.5468)	grad_norm 1.4951 (3.5142)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:39 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][90/156]	eta 0:00:34 lr 0.000002	 wd 0.0500	time 0.6161 (0.5250)	data time 0.0008 (0.0498)	model time 0.6154 (0.4877)	loss 0.4405 (0.5443)	grad_norm 5.2733 (3.4946)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:44 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][100/156]	eta 0:00:29 lr 0.000002	 wd 0.0500	time 0.5030 (0.5239)	data time 0.0171 (0.0473)	model time 0.4859 (0.4880)	loss 0.6408 (0.5465)	grad_norm 3.9238 (3.5658)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:49 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][110/156]	eta 0:00:24 lr 0.000002	 wd 0.0500	time 0.4634 (0.5241)	data time 0.0203 (0.0450)	model time 0.4431 (0.4909)	loss 0.6202 (0.5483)	grad_norm 2.9962 (3.5753)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:22:55 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][120/156]	eta 0:00:18 lr 0.000002	 wd 0.0500	time 0.4668 (0.5230)	data time 0.0018 (0.0422)	model time 0.4649 (0.4921)	loss 0.6419 (0.5489)	grad_norm 2.8714 (3.5378)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:23:00 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][130/156]	eta 0:00:13 lr 0.000002	 wd 0.0500	time 0.6201 (0.5218)	data time 0.0007 (0.0402)	model time 0.6194 (0.4920)	loss 0.5241 (0.5476)	grad_norm 3.0968 (3.5847)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:23:05 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][140/156]	eta 0:00:08 lr 0.000002	 wd 0.0500	time 0.4740 (0.5223)	data time 0.0009 (0.0384)	model time 0.4730 (0.4944)	loss 0.5121 (0.5473)	grad_norm 4.3675 (3.5423)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:23:11 vssm1_tiny_0230s](training.py 201): INFO Train: [288/300][150/156]	eta 0:00:03 lr 0.000002	 wd 0.0500	time 0.5795 (0.5256)	data time 0.0006 (0.0361)	model time 0.5789 (0.5018)	loss 0.6023 (0.5499)	grad_norm 2.6270 (3.5459)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:23:13 vssm1_tiny_0230s](training.py 212): INFO EPOCH 288 training takes 0:01:21
[2024-11-09 19:23:13 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_288.pth saving......
[2024-11-09 19:23:14 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_288.pth saved !!!
[2024-11-09 19:23:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 4.302 (4.302)	Loss 0.1973 (0.1973)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:23:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.163 (0.599)	Loss 0.2079 (0.1993)	Acc@1 96.094 (96.733)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:23:23 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.448)	Loss 0.1830 (0.2068)	Acc@1 99.219 (96.540)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:23:26 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.210 (0.399)	Loss 0.2402 (0.2114)	Acc@1 92.188 (96.043)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:23:29 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.820 Acc@5 100.000
[2024-11-09 19:23:29 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:23:29 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:23:34 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 5.117 (5.117)	Loss 0.1963 (0.1963)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:23:37 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.260 (0.687)	Loss 0.2041 (0.1994)	Acc@1 96.094 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:23:39 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.142 (0.464)	Loss 0.1953 (0.2096)	Acc@1 96.875 (95.573)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:23:42 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.405)	Loss 0.2551 (0.2170)	Acc@1 92.188 (95.161)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:23:44 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.040 Acc@5 100.000
[2024-11-09 19:23:44 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.0%
[2024-11-09 19:23:44 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.08%
[2024-11-09 19:23:50 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][0/156]	eta 0:14:53 lr 0.000002	 wd 0.0500	time 5.7288 (5.7288)	data time 5.1808 (5.1808)	model time 0.0000 (0.0000)	loss 0.5713 (0.5713)	grad_norm 2.9471 (2.9471)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:23:55 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][10/156]	eta 0:02:25 lr 0.000002	 wd 0.0500	time 0.5619 (0.9963)	data time 0.0097 (0.4788)	model time 0.0000 (0.0000)	loss 0.5663 (0.5612)	grad_norm 3.1405 (3.2424)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:00 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][20/156]	eta 0:01:44 lr 0.000002	 wd 0.0500	time 0.4447 (0.7647)	data time 0.0078 (0.2548)	model time 0.0000 (0.0000)	loss 0.6672 (0.5533)	grad_norm 1.9694 (3.3080)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:05 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][30/156]	eta 0:01:25 lr 0.000002	 wd 0.0500	time 0.4418 (0.6823)	data time 0.0078 (0.1754)	model time 0.0000 (0.0000)	loss 0.5488 (0.5481)	grad_norm 4.2775 (3.2994)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:10 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][40/156]	eta 0:01:14 lr 0.000002	 wd 0.0500	time 0.4402 (0.6380)	data time 0.0077 (0.1341)	model time 0.0000 (0.0000)	loss 0.4611 (0.5432)	grad_norm 2.1680 (3.2502)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:15 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][50/156]	eta 0:01:05 lr 0.000002	 wd 0.0500	time 0.7357 (0.6177)	data time 0.0251 (0.1112)	model time 0.0000 (0.0000)	loss 0.5778 (0.5460)	grad_norm 2.4806 (3.2451)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:21 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][60/156]	eta 0:00:57 lr 0.000002	 wd 0.0500	time 0.4569 (0.6014)	data time 0.0007 (0.0964)	model time 0.4562 (0.4977)	loss 0.5868 (0.5461)	grad_norm 3.2527 (3.2691)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:26 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][70/156]	eta 0:00:50 lr 0.000002	 wd 0.0500	time 0.4878 (0.5877)	data time 0.0081 (0.0836)	model time 0.4797 (0.4977)	loss 0.4593 (0.5453)	grad_norm 2.5566 (3.2585)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:30 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][80/156]	eta 0:00:43 lr 0.000002	 wd 0.0500	time 0.4199 (0.5733)	data time 0.0026 (0.0750)	model time 0.4173 (0.4844)	loss 0.6030 (0.5408)	grad_norm 3.1693 (3.3696)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:35 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][90/156]	eta 0:00:37 lr 0.000002	 wd 0.0500	time 0.4394 (0.5639)	data time 0.0032 (0.0679)	model time 0.4362 (0.4827)	loss 0.4869 (0.5410)	grad_norm 3.8809 (3.3141)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:40 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][100/156]	eta 0:00:31 lr 0.000002	 wd 0.0500	time 0.5093 (0.5594)	data time 0.0347 (0.0631)	model time 0.4746 (0.4858)	loss 0.4820 (0.5424)	grad_norm 3.6985 (3.3110)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:45 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][110/156]	eta 0:00:25 lr 0.000002	 wd 0.0500	time 0.6332 (0.5535)	data time 0.0928 (0.0588)	model time 0.5404 (0.4845)	loss 0.4406 (0.5413)	grad_norm 4.0227 (3.3474)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:51 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][120/156]	eta 0:00:19 lr 0.000002	 wd 0.0500	time 0.4297 (0.5531)	data time 0.0180 (0.0554)	model time 0.4117 (0.4912)	loss 0.5815 (0.5412)	grad_norm 3.5309 (3.3620)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:24:56 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][130/156]	eta 0:00:14 lr 0.000002	 wd 0.0500	time 0.4674 (0.5509)	data time 0.0108 (0.0527)	model time 0.4566 (0.4929)	loss 0.4729 (0.5402)	grad_norm 3.5471 (3.3666)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:25:01 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][140/156]	eta 0:00:08 lr 0.000002	 wd 0.0500	time 0.4461 (0.5487)	data time 0.0008 (0.0498)	model time 0.4453 (0.4946)	loss 0.5914 (0.5394)	grad_norm 1.7788 (3.3549)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:25:06 vssm1_tiny_0230s](training.py 201): INFO Train: [289/300][150/156]	eta 0:00:03 lr 0.000002	 wd 0.0500	time 0.5297 (0.5454)	data time 0.0007 (0.0467)	model time 0.5290 (0.4948)	loss 0.5025 (0.5389)	grad_norm 2.8230 (3.3473)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:25:10 vssm1_tiny_0230s](training.py 212): INFO EPOCH 289 training takes 0:01:25
[2024-11-09 19:25:10 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_289.pth saving......
[2024-11-09 19:25:10 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_289.pth saved !!!
[2024-11-09 19:25:14 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.165 (3.165)	Loss 0.1970 (0.1970)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:25:16 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.138 (0.537)	Loss 0.2073 (0.1993)	Acc@1 95.312 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:25:20 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.234 (0.433)	Loss 0.1783 (0.2066)	Acc@1 99.219 (96.391)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:25:22 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.263 (0.378)	Loss 0.2362 (0.2096)	Acc@1 92.188 (95.993)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:25:25 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.800 Acc@5 100.000
[2024-11-09 19:25:25 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:25:25 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:25:28 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.161 (3.161)	Loss 0.1963 (0.1963)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:25:31 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.185 (0.509)	Loss 0.2041 (0.1994)	Acc@1 96.094 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:25:33 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.180 (0.386)	Loss 0.1948 (0.2095)	Acc@1 96.875 (95.610)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:25:35 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.331)	Loss 0.2549 (0.2169)	Acc@1 92.188 (95.186)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:25:38 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.100 Acc@5 100.000
[2024-11-09 19:25:38 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:25:38 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.10%
[2024-11-09 19:25:43 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][0/156]	eta 0:10:52 lr 0.000002	 wd 0.0500	time 4.1817 (4.1817)	data time 3.7773 (3.7773)	model time 0.0000 (0.0000)	loss 0.4407 (0.4407)	grad_norm 5.4207 (5.4207)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:25:48 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][10/156]	eta 0:02:00 lr 0.000002	 wd 0.0500	time 0.5129 (0.8231)	data time 0.0119 (0.3497)	model time 0.0000 (0.0000)	loss 0.4522 (0.5104)	grad_norm 3.3828 (3.8891)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:25:52 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][20/156]	eta 0:01:30 lr 0.000002	 wd 0.0500	time 0.4549 (0.6681)	data time 0.0031 (0.1905)	model time 0.0000 (0.0000)	loss 0.4516 (0.5354)	grad_norm 4.1551 (3.7352)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:25:57 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][30/156]	eta 0:01:16 lr 0.000002	 wd 0.0500	time 0.4089 (0.6111)	data time 0.0013 (0.1318)	model time 0.0000 (0.0000)	loss 0.4965 (0.5360)	grad_norm 3.2191 (3.5508)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:03 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][40/156]	eta 0:01:08 lr 0.000002	 wd 0.0500	time 0.5554 (0.5866)	data time 0.0201 (0.1030)	model time 0.0000 (0.0000)	loss 0.5582 (0.5370)	grad_norm 2.8909 (3.5091)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:08 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][50/156]	eta 0:01:01 lr 0.000002	 wd 0.0500	time 0.4310 (0.5764)	data time 0.0007 (0.0870)	model time 0.0000 (0.0000)	loss 0.5666 (0.5390)	grad_norm 2.8151 (3.3760)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:13 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][60/156]	eta 0:00:54 lr 0.000002	 wd 0.0500	time 0.5171 (0.5701)	data time 0.0858 (0.0762)	model time 0.4312 (0.5162)	loss 0.5073 (0.5426)	grad_norm 1.8639 (3.3677)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:19 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][70/156]	eta 0:00:48 lr 0.000002	 wd 0.0500	time 0.4977 (0.5646)	data time 0.0268 (0.0673)	model time 0.4709 (0.5174)	loss 0.5180 (0.5484)	grad_norm 2.1817 (3.3058)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:24 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][80/156]	eta 0:00:42 lr 0.000002	 wd 0.0500	time 0.5604 (0.5581)	data time 0.0060 (0.0618)	model time 0.5544 (0.5080)	loss 0.4325 (0.5476)	grad_norm 2.6693 (3.2593)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:29 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][90/156]	eta 0:00:36 lr 0.000002	 wd 0.0500	time 0.4959 (0.5545)	data time 0.0051 (0.0575)	model time 0.4908 (0.5065)	loss 0.6283 (0.5434)	grad_norm 2.5901 (3.2681)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:34 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][100/156]	eta 0:00:30 lr 0.000002	 wd 0.0500	time 0.4711 (0.5511)	data time 0.0052 (0.0559)	model time 0.4659 (0.5011)	loss 0.5595 (0.5428)	grad_norm 5.5701 (3.3243)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:39 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][110/156]	eta 0:00:25 lr 0.000002	 wd 0.0500	time 0.4350 (0.5488)	data time 0.0005 (0.0521)	model time 0.4345 (0.5028)	loss 0.4453 (0.5412)	grad_norm 3.8626 (3.3820)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:45 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][120/156]	eta 0:00:19 lr 0.000002	 wd 0.0500	time 0.6334 (0.5481)	data time 0.0026 (0.0496)	model time 0.6308 (0.5053)	loss 0.6281 (0.5394)	grad_norm 2.0974 (3.3774)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:50 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][130/156]	eta 0:00:14 lr 0.000002	 wd 0.0500	time 0.5114 (0.5442)	data time 0.0007 (0.0471)	model time 0.5107 (0.5020)	loss 0.6131 (0.5380)	grad_norm 3.7683 (3.3802)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:26:55 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][140/156]	eta 0:00:08 lr 0.000002	 wd 0.0500	time 0.5275 (0.5408)	data time 0.0009 (0.0451)	model time 0.5266 (0.4992)	loss 0.4315 (0.5338)	grad_norm 3.9754 (3.4187)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:27:00 vssm1_tiny_0230s](training.py 201): INFO Train: [290/300][150/156]	eta 0:00:03 lr 0.000002	 wd 0.0500	time 0.5619 (0.5410)	data time 0.0006 (0.0425)	model time 0.5613 (0.5032)	loss 0.4515 (0.5367)	grad_norm 2.8046 (3.3859)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:27:03 vssm1_tiny_0230s](training.py 212): INFO EPOCH 290 training takes 0:01:24
[2024-11-09 19:27:03 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_290.pth saving......
[2024-11-09 19:27:04 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_290.pth saved !!!
[2024-11-09 19:27:07 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.636 (3.636)	Loss 0.1943 (0.1943)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:27:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.541)	Loss 0.2039 (0.1962)	Acc@1 96.094 (96.662)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:27:12 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.149 (0.406)	Loss 0.1782 (0.2038)	Acc@1 99.219 (96.540)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:27:14 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.143 (0.342)	Loss 0.2362 (0.2076)	Acc@1 92.188 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:27:16 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.860 Acc@5 100.000
[2024-11-09 19:27:16 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.9%
[2024-11-09 19:27:16 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:27:18 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.203 (2.203)	Loss 0.1959 (0.1959)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:27:22 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.972 (0.560)	Loss 0.2039 (0.1991)	Acc@1 96.094 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:27:25 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.139 (0.423)	Loss 0.1946 (0.2092)	Acc@1 96.875 (95.610)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:27:27 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.132 (0.349)	Loss 0.2544 (0.2165)	Acc@1 92.188 (95.212)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:27:30 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.100 Acc@5 100.000
[2024-11-09 19:27:30 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:27:30 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.10%
[2024-11-09 19:27:35 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][0/156]	eta 0:12:35 lr 0.000002	 wd 0.0500	time 4.8409 (4.8409)	data time 4.2355 (4.2355)	model time 0.0000 (0.0000)	loss 0.4888 (0.4888)	grad_norm 4.2916 (4.2916)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:27:40 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][10/156]	eta 0:02:14 lr 0.000002	 wd 0.0500	time 0.4897 (0.9237)	data time 0.0236 (0.3988)	model time 0.0000 (0.0000)	loss 0.6027 (0.5361)	grad_norm 5.6054 (3.9440)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:27:45 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][20/156]	eta 0:01:36 lr 0.000002	 wd 0.0500	time 0.5161 (0.7060)	data time 0.0126 (0.2129)	model time 0.0000 (0.0000)	loss 0.6431 (0.5371)	grad_norm 4.4318 (3.9233)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:27:50 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][30/156]	eta 0:01:20 lr 0.000002	 wd 0.0500	time 0.5801 (0.6379)	data time 0.0218 (0.1486)	model time 0.0000 (0.0000)	loss 0.6136 (0.5388)	grad_norm 1.6696 (3.7109)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:27:55 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][40/156]	eta 0:01:10 lr 0.000002	 wd 0.0500	time 0.4577 (0.6100)	data time 0.0022 (0.1164)	model time 0.0000 (0.0000)	loss 0.6257 (0.5424)	grad_norm 2.7124 (3.6347)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:00 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][50/156]	eta 0:01:01 lr 0.000002	 wd 0.0500	time 0.4252 (0.5849)	data time 0.0019 (0.0956)	model time 0.0000 (0.0000)	loss 0.5189 (0.5430)	grad_norm 4.5944 (3.6258)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:05 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][60/156]	eta 0:00:55 lr 0.000002	 wd 0.0500	time 0.7147 (0.5755)	data time 0.0274 (0.0819)	model time 0.6873 (0.5156)	loss 0.5825 (0.5415)	grad_norm 2.2663 (3.5614)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:10 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][70/156]	eta 0:00:47 lr 0.000002	 wd 0.0500	time 0.4155 (0.5578)	data time 0.0042 (0.0726)	model time 0.4113 (0.4749)	loss 0.6600 (0.5408)	grad_norm 2.2542 (3.5064)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:15 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][80/156]	eta 0:00:41 lr 0.000002	 wd 0.0500	time 0.5902 (0.5526)	data time 0.0129 (0.0648)	model time 0.5773 (0.4853)	loss 0.6321 (0.5374)	grad_norm 4.5136 (3.5011)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:20 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][90/156]	eta 0:00:36 lr 0.000002	 wd 0.0500	time 0.4562 (0.5455)	data time 0.0141 (0.0588)	model time 0.4420 (0.4835)	loss 0.6181 (0.5407)	grad_norm 3.1453 (3.4469)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:25 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][100/156]	eta 0:00:30 lr 0.000002	 wd 0.0500	time 0.4233 (0.5421)	data time 0.0128 (0.0544)	model time 0.4105 (0.4860)	loss 0.5493 (0.5398)	grad_norm 2.3273 (3.4752)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:30 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][110/156]	eta 0:00:24 lr 0.000002	 wd 0.0500	time 0.4952 (0.5398)	data time 0.0243 (0.0508)	model time 0.4710 (0.4887)	loss 0.6033 (0.5395)	grad_norm 3.1409 (3.4698)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:35 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][120/156]	eta 0:00:19 lr 0.000002	 wd 0.0500	time 0.5548 (0.5360)	data time 0.0185 (0.0478)	model time 0.5363 (0.4873)	loss 0.6047 (0.5364)	grad_norm 3.6242 (3.4518)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:41 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][130/156]	eta 0:00:13 lr 0.000002	 wd 0.0500	time 0.6997 (0.5381)	data time 0.0179 (0.0465)	model time 0.6818 (0.4932)	loss 0.5875 (0.5356)	grad_norm 3.3313 (3.4807)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:46 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][140/156]	eta 0:00:08 lr 0.000002	 wd 0.0500	time 0.5278 (0.5378)	data time 0.0010 (0.0445)	model time 0.5268 (0.4956)	loss 0.5014 (0.5315)	grad_norm 4.4076 (3.5001)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:51 vssm1_tiny_0230s](training.py 201): INFO Train: [291/300][150/156]	eta 0:00:03 lr 0.000002	 wd 0.0500	time 0.5092 (0.5332)	data time 0.0006 (0.0416)	model time 0.5086 (0.4928)	loss 0.5137 (0.5324)	grad_norm 3.2788 (3.4813)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:28:53 vssm1_tiny_0230s](training.py 212): INFO EPOCH 291 training takes 0:01:23
[2024-11-09 19:28:53 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_291.pth saving......
[2024-11-09 19:28:54 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_291.pth saved !!!
[2024-11-09 19:29:00 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 5.555 (5.555)	Loss 0.1908 (0.1908)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:29:03 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.191 (0.813)	Loss 0.2010 (0.1930)	Acc@1 96.094 (96.662)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:29:05 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.519)	Loss 0.1776 (0.2008)	Acc@1 99.219 (96.429)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:29:07 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.427)	Loss 0.2363 (0.2052)	Acc@1 92.188 (95.993)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:29:10 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.760 Acc@5 100.000
[2024-11-09 19:29:10 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:29:10 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:29:13 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.009 (3.009)	Loss 0.1962 (0.1962)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:29:15 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.172 (0.481)	Loss 0.2040 (0.1991)	Acc@1 96.094 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:29:18 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.146 (0.375)	Loss 0.1943 (0.2092)	Acc@1 96.875 (95.647)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:29:21 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.134 (0.357)	Loss 0.2542 (0.2164)	Acc@1 92.188 (95.237)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:29:24 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.160 Acc@5 100.000
[2024-11-09 19:29:24 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.2%
[2024-11-09 19:29:24 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.16%
[2024-11-09 19:29:28 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][0/156]	eta 0:10:25 lr 0.000001	 wd 0.0500	time 4.0095 (4.0095)	data time 3.5824 (3.5824)	model time 0.0000 (0.0000)	loss 0.6172 (0.6172)	grad_norm 2.7130 (2.7130)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:29:34 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][10/156]	eta 0:02:08 lr 0.000001	 wd 0.0500	time 0.5455 (0.8805)	data time 0.0009 (0.3837)	model time 0.0000 (0.0000)	loss 0.5938 (0.5716)	grad_norm 2.7100 (3.3509)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:29:39 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][20/156]	eta 0:01:39 lr 0.000001	 wd 0.0500	time 0.4181 (0.7297)	data time 0.0007 (0.2169)	model time 0.0000 (0.0000)	loss 0.4353 (0.5360)	grad_norm 3.2162 (3.2907)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:29:45 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][30/156]	eta 0:01:22 lr 0.000001	 wd 0.0500	time 0.5796 (0.6582)	data time 0.0269 (0.1566)	model time 0.0000 (0.0000)	loss 0.5536 (0.5367)	grad_norm 4.7420 (3.4544)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:29:50 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][40/156]	eta 0:01:12 lr 0.000001	 wd 0.0500	time 0.4501 (0.6209)	data time 0.0017 (0.1221)	model time 0.0000 (0.0000)	loss 0.5600 (0.5471)	grad_norm 2.6382 (3.3167)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:29:55 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][50/156]	eta 0:01:04 lr 0.000001	 wd 0.0500	time 0.4933 (0.6118)	data time 0.0245 (0.1021)	model time 0.0000 (0.0000)	loss 0.5990 (0.5394)	grad_norm 3.7069 (3.2816)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:00 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][60/156]	eta 0:00:57 lr 0.000001	 wd 0.0500	time 0.4797 (0.5956)	data time 0.0025 (0.0885)	model time 0.4771 (0.4941)	loss 0.6334 (0.5423)	grad_norm 2.0856 (3.2753)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:06 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][70/156]	eta 0:00:50 lr 0.000001	 wd 0.0500	time 0.4071 (0.5895)	data time 0.0008 (0.0781)	model time 0.4062 (0.5157)	loss 0.5028 (0.5419)	grad_norm 2.9172 (3.3717)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:11 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][80/156]	eta 0:00:44 lr 0.000001	 wd 0.0500	time 0.4686 (0.5813)	data time 0.0191 (0.0708)	model time 0.4495 (0.5119)	loss 0.4369 (0.5418)	grad_norm 3.3997 (3.3839)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:16 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][90/156]	eta 0:00:37 lr 0.000001	 wd 0.0500	time 0.5492 (0.5702)	data time 0.0146 (0.0649)	model time 0.5346 (0.4996)	loss 0.6042 (0.5406)	grad_norm 3.6492 (3.4568)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:21 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][100/156]	eta 0:00:31 lr 0.000001	 wd 0.0500	time 0.4933 (0.5672)	data time 0.0326 (0.0601)	model time 0.4606 (0.5045)	loss 0.5212 (0.5370)	grad_norm 3.0095 (3.4898)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:27 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][110/156]	eta 0:00:25 lr 0.000001	 wd 0.0500	time 0.4825 (0.5626)	data time 0.0200 (0.0568)	model time 0.4625 (0.5025)	loss 0.5782 (0.5379)	grad_norm 2.0790 (3.4828)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:31 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][120/156]	eta 0:00:20 lr 0.000001	 wd 0.0500	time 0.4699 (0.5569)	data time 0.0249 (0.0534)	model time 0.4450 (0.4990)	loss 0.6324 (0.5419)	grad_norm 2.8309 (3.4597)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:37 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][130/156]	eta 0:00:14 lr 0.000001	 wd 0.0500	time 0.4558 (0.5555)	data time 0.0151 (0.0503)	model time 0.4407 (0.5023)	loss 0.5659 (0.5429)	grad_norm 2.7849 (3.5112)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:42 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][140/156]	eta 0:00:08 lr 0.000001	 wd 0.0500	time 0.4663 (0.5546)	data time 0.0008 (0.0479)	model time 0.4655 (0.5050)	loss 0.5847 (0.5425)	grad_norm 3.4764 (3.4887)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:47 vssm1_tiny_0230s](training.py 201): INFO Train: [292/300][150/156]	eta 0:00:03 lr 0.000001	 wd 0.0500	time 0.4203 (0.5521)	data time 0.0006 (0.0449)	model time 0.4197 (0.5060)	loss 0.5859 (0.5451)	grad_norm 3.6344 (3.4799)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:30:50 vssm1_tiny_0230s](training.py 212): INFO EPOCH 292 training takes 0:01:26
[2024-11-09 19:30:50 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_292.pth saving......
[2024-11-09 19:30:51 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_292.pth saved !!!
[2024-11-09 19:30:53 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.130 (2.130)	Loss 0.1937 (0.1937)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:30:57 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.604)	Loss 0.2037 (0.1956)	Acc@1 96.094 (96.733)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:30:59 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.137 (0.408)	Loss 0.1826 (0.2035)	Acc@1 99.219 (96.429)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:31:02 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.352)	Loss 0.2396 (0.2081)	Acc@1 92.188 (96.069)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:31:05 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.840 Acc@5 100.000
[2024-11-09 19:31:05 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:31:05 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:31:08 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.867 (3.867)	Loss 0.1959 (0.1959)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:31:10 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.165 (0.506)	Loss 0.2039 (0.1990)	Acc@1 96.094 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:31:13 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.155 (0.413)	Loss 0.1941 (0.2090)	Acc@1 96.875 (95.647)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:31:16 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.140 (0.358)	Loss 0.2539 (0.2162)	Acc@1 92.188 (95.237)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:31:18 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.140 Acc@5 100.000
[2024-11-09 19:31:18 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:31:18 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.16%
[2024-11-09 19:31:23 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][0/156]	eta 0:12:21 lr 0.000001	 wd 0.0500	time 4.7523 (4.7523)	data time 4.2750 (4.2750)	model time 0.0000 (0.0000)	loss 0.6054 (0.6054)	grad_norm 3.5731 (3.5731)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:31:28 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][10/156]	eta 0:02:08 lr 0.000001	 wd 0.0500	time 0.4490 (0.8787)	data time 0.0098 (0.4040)	model time 0.0000 (0.0000)	loss 0.5583 (0.5559)	grad_norm 4.5102 (3.1888)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:31:33 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][20/156]	eta 0:01:34 lr 0.000001	 wd 0.0500	time 0.4596 (0.6961)	data time 0.0012 (0.2183)	model time 0.0000 (0.0000)	loss 0.5182 (0.5632)	grad_norm 2.2303 (3.2063)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:31:37 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][30/156]	eta 0:01:17 lr 0.000001	 wd 0.0500	time 0.4833 (0.6177)	data time 0.0154 (0.1525)	model time 0.0000 (0.0000)	loss 0.5027 (0.5433)	grad_norm 3.4407 (3.4882)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:31:42 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][40/156]	eta 0:01:07 lr 0.000001	 wd 0.0500	time 0.4551 (0.5835)	data time 0.0009 (0.1190)	model time 0.0000 (0.0000)	loss 0.5934 (0.5410)	grad_norm 4.6040 (3.5141)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:31:47 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][50/156]	eta 0:01:00 lr 0.000001	 wd 0.0500	time 0.5995 (0.5692)	data time 0.0114 (0.0993)	model time 0.0000 (0.0000)	loss 0.5218 (0.5368)	grad_norm 2.8675 (3.4519)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:31:52 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][60/156]	eta 0:00:53 lr 0.000001	 wd 0.0500	time 0.4285 (0.5554)	data time 0.0172 (0.0841)	model time 0.4113 (0.4782)	loss 0.4984 (0.5367)	grad_norm 4.7831 (3.4905)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:31:57 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][70/156]	eta 0:00:47 lr 0.000001	 wd 0.0500	time 0.6036 (0.5480)	data time 0.0144 (0.0742)	model time 0.5892 (0.4840)	loss 0.5284 (0.5420)	grad_norm 2.9024 (3.4558)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:32:03 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][80/156]	eta 0:00:41 lr 0.000001	 wd 0.0500	time 0.5676 (0.5463)	data time 0.0007 (0.0668)	model time 0.5669 (0.4958)	loss 0.5860 (0.5402)	grad_norm 3.5621 (3.4316)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:32:08 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][90/156]	eta 0:00:35 lr 0.000001	 wd 0.0500	time 0.4553 (0.5413)	data time 0.0034 (0.0601)	model time 0.4518 (0.4956)	loss 0.4106 (0.5332)	grad_norm 4.4600 (3.4493)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:32:13 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][100/156]	eta 0:00:30 lr 0.000001	 wd 0.0500	time 0.6336 (0.5384)	data time 0.0056 (0.0551)	model time 0.6281 (0.4968)	loss 0.5675 (0.5308)	grad_norm 5.5590 (3.4822)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:32:17 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][110/156]	eta 0:00:24 lr 0.000001	 wd 0.0500	time 0.4593 (0.5309)	data time 0.0007 (0.0508)	model time 0.4587 (0.4889)	loss 0.5134 (0.5314)	grad_norm 2.3107 (3.4415)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:32:22 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][120/156]	eta 0:00:18 lr 0.000001	 wd 0.0500	time 0.4152 (0.5250)	data time 0.0033 (0.0467)	model time 0.4119 (0.4844)	loss 0.5819 (0.5337)	grad_norm 6.9509 (3.4856)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:32:27 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][130/156]	eta 0:00:13 lr 0.000001	 wd 0.0500	time 0.4670 (0.5207)	data time 0.0107 (0.0442)	model time 0.4563 (0.4806)	loss 0.3990 (0.5336)	grad_norm 2.6913 (3.4754)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:32:32 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][140/156]	eta 0:00:08 lr 0.000001	 wd 0.0500	time 0.4283 (0.5213)	data time 0.0013 (0.0423)	model time 0.4270 (0.4841)	loss 0.4448 (0.5328)	grad_norm 2.0179 (3.4609)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:32:37 vssm1_tiny_0230s](training.py 201): INFO Train: [293/300][150/156]	eta 0:00:03 lr 0.000001	 wd 0.0500	time 0.4067 (0.5181)	data time 0.0007 (0.0396)	model time 0.4060 (0.4829)	loss 0.4987 (0.5313)	grad_norm 2.4960 (3.4491)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:32:39 vssm1_tiny_0230s](training.py 212): INFO EPOCH 293 training takes 0:01:21
[2024-11-09 19:32:39 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_293.pth saving......
[2024-11-09 19:32:40 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_293.pth saved !!!
[2024-11-09 19:32:43 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.125 (3.125)	Loss 0.1918 (0.1918)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:32:46 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.159 (0.548)	Loss 0.2021 (0.1936)	Acc@1 95.312 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:32:49 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.147 (0.435)	Loss 0.1783 (0.2015)	Acc@1 99.219 (96.317)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:32:51 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.133 (0.370)	Loss 0.2365 (0.2058)	Acc@1 92.188 (95.993)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:32:54 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.800 Acc@5 100.000
[2024-11-09 19:32:54 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:32:54 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:32:58 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.667 (3.667)	Loss 0.1958 (0.1958)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:33:00 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.221 (0.502)	Loss 0.2037 (0.1988)	Acc@1 96.094 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:33:02 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.148 (0.384)	Loss 0.1937 (0.2088)	Acc@1 96.875 (95.647)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:33:05 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.161 (0.327)	Loss 0.2534 (0.2159)	Acc@1 92.188 (95.237)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:33:07 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.140 Acc@5 100.000
[2024-11-09 19:33:07 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:33:07 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.16%
[2024-11-09 19:33:12 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][0/156]	eta 0:13:34 lr 0.000001	 wd 0.0500	time 5.2230 (5.2230)	data time 4.7839 (4.7839)	model time 0.0000 (0.0000)	loss 0.4206 (0.4206)	grad_norm 5.2525 (5.2525)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:33:17 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][10/156]	eta 0:02:18 lr 0.000001	 wd 0.0500	time 0.5318 (0.9483)	data time 0.0009 (0.4497)	model time 0.0000 (0.0000)	loss 0.6276 (0.5092)	grad_norm 2.3227 (3.7925)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:33:22 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][20/156]	eta 0:01:39 lr 0.000001	 wd 0.0500	time 0.5146 (0.7295)	data time 0.0141 (0.2435)	model time 0.0000 (0.0000)	loss 0.5744 (0.5301)	grad_norm 4.8314 (3.6952)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:33:28 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][30/156]	eta 0:01:24 lr 0.000001	 wd 0.0500	time 0.4470 (0.6703)	data time 0.0008 (0.1761)	model time 0.0000 (0.0000)	loss 0.5269 (0.5258)	grad_norm 3.0909 (3.6108)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:33:33 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][40/156]	eta 0:01:13 lr 0.000001	 wd 0.0500	time 0.4605 (0.6375)	data time 0.0233 (0.1361)	model time 0.0000 (0.0000)	loss 0.5393 (0.5236)	grad_norm 3.3646 (3.6445)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:33:38 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][50/156]	eta 0:01:04 lr 0.000001	 wd 0.0500	time 0.4745 (0.6079)	data time 0.0032 (0.1134)	model time 0.0000 (0.0000)	loss 0.5694 (0.5244)	grad_norm 2.1860 (3.6730)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:33:43 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][60/156]	eta 0:00:56 lr 0.000001	 wd 0.0500	time 0.5240 (0.5885)	data time 0.0489 (0.0977)	model time 0.4751 (0.4719)	loss 0.3970 (0.5290)	grad_norm 3.1769 (3.6784)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:33:48 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][70/156]	eta 0:00:49 lr 0.000001	 wd 0.0500	time 0.5750 (0.5766)	data time 0.0008 (0.0854)	model time 0.5742 (0.4826)	loss 0.5616 (0.5309)	grad_norm 3.8389 (3.6245)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:33:52 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][80/156]	eta 0:00:42 lr 0.000001	 wd 0.0500	time 0.4080 (0.5617)	data time 0.0008 (0.0768)	model time 0.4072 (0.4686)	loss 0.5897 (0.5365)	grad_norm 3.3927 (3.5839)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:33:57 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][90/156]	eta 0:00:36 lr 0.000001	 wd 0.0500	time 0.4958 (0.5551)	data time 0.0143 (0.0692)	model time 0.4815 (0.4749)	loss 0.5100 (0.5381)	grad_norm 7.0132 (3.6467)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:34:03 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][100/156]	eta 0:00:31 lr 0.000001	 wd 0.0500	time 0.4305 (0.5536)	data time 0.0217 (0.0642)	model time 0.4089 (0.4842)	loss 0.5668 (0.5391)	grad_norm 4.0210 (3.6206)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:34:07 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][110/156]	eta 0:00:25 lr 0.000001	 wd 0.0500	time 0.6263 (0.5465)	data time 0.0029 (0.0592)	model time 0.6234 (0.4812)	loss 0.6113 (0.5403)	grad_norm 3.6847 (3.5686)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:34:12 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][120/156]	eta 0:00:19 lr 0.000001	 wd 0.0500	time 0.4121 (0.5384)	data time 0.0009 (0.0556)	model time 0.4112 (0.4742)	loss 0.5578 (0.5394)	grad_norm 3.6773 (3.5633)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:34:17 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][130/156]	eta 0:00:14 lr 0.000001	 wd 0.0500	time 0.5290 (0.5392)	data time 0.0204 (0.0529)	model time 0.5086 (0.4810)	loss 0.4471 (0.5396)	grad_norm 2.9703 (3.5123)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:34:22 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][140/156]	eta 0:00:08 lr 0.000001	 wd 0.0500	time 0.4389 (0.5323)	data time 0.0009 (0.0497)	model time 0.4380 (0.4759)	loss 0.5535 (0.5411)	grad_norm 2.3351 (3.5129)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:34:26 vssm1_tiny_0230s](training.py 201): INFO Train: [294/300][150/156]	eta 0:00:03 lr 0.000001	 wd 0.0500	time 0.5175 (0.5274)	data time 0.0004 (0.0465)	model time 0.5171 (0.4739)	loss 0.5882 (0.5406)	grad_norm 3.1410 (3.5055)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:34:29 vssm1_tiny_0230s](training.py 212): INFO EPOCH 294 training takes 0:01:22
[2024-11-09 19:34:29 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_294.pth saving......
[2024-11-09 19:34:30 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_294.pth saved !!!
[2024-11-09 19:34:33 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.533 (3.533)	Loss 0.1913 (0.1913)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:34:36 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.185 (0.586)	Loss 0.2017 (0.1934)	Acc@1 95.312 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:34:38 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.140 (0.412)	Loss 0.1810 (0.2014)	Acc@1 99.219 (96.354)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:34:40 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.149 (0.344)	Loss 0.2391 (0.2067)	Acc@1 92.188 (95.968)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:34:43 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.780 Acc@5 100.000
[2024-11-09 19:34:43 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:34:43 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:34:46 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.893 (2.893)	Loss 0.1958 (0.1958)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:34:48 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.144 (0.504)	Loss 0.2039 (0.1988)	Acc@1 96.094 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:34:51 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.154 (0.379)	Loss 0.1932 (0.2088)	Acc@1 96.875 (95.573)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:34:53 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.139 (0.324)	Loss 0.2529 (0.2157)	Acc@1 92.188 (95.186)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:34:56 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.120 Acc@5 100.000
[2024-11-09 19:34:56 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:34:56 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.16%
[2024-11-09 19:35:01 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][0/156]	eta 0:12:21 lr 0.000001	 wd 0.0500	time 4.7554 (4.7554)	data time 4.3491 (4.3491)	model time 0.0000 (0.0000)	loss 0.5234 (0.5234)	grad_norm 3.3822 (3.3822)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:06 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][10/156]	eta 0:02:08 lr 0.000001	 wd 0.0500	time 0.4852 (0.8775)	data time 0.0213 (0.4141)	model time 0.0000 (0.0000)	loss 0.5047 (0.5520)	grad_norm 2.8504 (3.3704)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:11 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][20/156]	eta 0:01:36 lr 0.000001	 wd 0.0500	time 0.4435 (0.7130)	data time 0.0310 (0.2298)	model time 0.0000 (0.0000)	loss 0.5940 (0.5501)	grad_norm 2.9167 (3.5877)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:17 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][30/156]	eta 0:01:23 lr 0.000001	 wd 0.0500	time 0.5091 (0.6608)	data time 0.0005 (0.1623)	model time 0.0000 (0.0000)	loss 0.5989 (0.5424)	grad_norm 2.1605 (3.5538)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:21 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][40/156]	eta 0:01:10 lr 0.000001	 wd 0.0500	time 0.4100 (0.6094)	data time 0.0030 (0.1249)	model time 0.0000 (0.0000)	loss 0.4953 (0.5401)	grad_norm 3.8438 (3.5517)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:26 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][50/156]	eta 0:01:02 lr 0.000001	 wd 0.0500	time 0.5865 (0.5870)	data time 0.0052 (0.1045)	model time 0.0000 (0.0000)	loss 0.4352 (0.5378)	grad_norm 4.3644 (3.5424)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:31 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][60/156]	eta 0:00:55 lr 0.000001	 wd 0.0500	time 0.5298 (0.5755)	data time 0.0195 (0.0928)	model time 0.5103 (0.4836)	loss 0.5588 (0.5416)	grad_norm 2.8621 (3.5407)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:37 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][70/156]	eta 0:00:49 lr 0.000001	 wd 0.0500	time 0.4952 (0.5710)	data time 0.0091 (0.0822)	model time 0.4861 (0.5049)	loss 0.5958 (0.5376)	grad_norm 3.4010 (3.5041)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:42 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][80/156]	eta 0:00:42 lr 0.000001	 wd 0.0500	time 0.5825 (0.5632)	data time 0.0359 (0.0745)	model time 0.5466 (0.4991)	loss 0.5667 (0.5388)	grad_norm 2.4344 (3.4808)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:47 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][90/156]	eta 0:00:36 lr 0.000001	 wd 0.0500	time 0.4836 (0.5541)	data time 0.0447 (0.0675)	model time 0.4389 (0.4918)	loss 0.5478 (0.5391)	grad_norm 2.9823 (3.4909)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:51 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][100/156]	eta 0:00:30 lr 0.000001	 wd 0.0500	time 0.4420 (0.5438)	data time 0.0250 (0.0621)	model time 0.4170 (0.4809)	loss 0.5715 (0.5401)	grad_norm 2.0514 (3.4488)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:35:56 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][110/156]	eta 0:00:24 lr 0.000001	 wd 0.0500	time 0.4430 (0.5382)	data time 0.0017 (0.0579)	model time 0.4413 (0.4783)	loss 0.4389 (0.5381)	grad_norm 5.4090 (3.4880)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:36:01 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][120/156]	eta 0:00:19 lr 0.000001	 wd 0.0500	time 0.5056 (0.5324)	data time 0.0151 (0.0540)	model time 0.4905 (0.4753)	loss 0.5721 (0.5380)	grad_norm 3.9314 (3.4626)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:36:06 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][130/156]	eta 0:00:13 lr 0.000001	 wd 0.0500	time 0.4348 (0.5312)	data time 0.0170 (0.0527)	model time 0.4178 (0.4760)	loss 0.5730 (0.5404)	grad_norm 2.1542 (3.4742)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:36:11 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][140/156]	eta 0:00:08 lr 0.000001	 wd 0.0500	time 0.5561 (0.5310)	data time 0.0009 (0.0494)	model time 0.5553 (0.4810)	loss 0.6176 (0.5403)	grad_norm 3.7600 (3.4840)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:36:16 vssm1_tiny_0230s](training.py 201): INFO Train: [295/300][150/156]	eta 0:00:03 lr 0.000001	 wd 0.0500	time 0.5130 (0.5307)	data time 0.0006 (0.0462)	model time 0.5125 (0.4856)	loss 0.5779 (0.5403)	grad_norm 1.9539 (3.4443)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:36:20 vssm1_tiny_0230s](training.py 212): INFO EPOCH 295 training takes 0:01:23
[2024-11-09 19:36:20 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_295.pth saving......
[2024-11-09 19:36:20 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_295.pth saved !!!
[2024-11-09 19:36:23 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.012 (3.012)	Loss 0.1907 (0.1907)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:36:25 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.151 (0.464)	Loss 0.2003 (0.1923)	Acc@1 96.094 (96.804)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:36:28 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.233 (0.362)	Loss 0.1864 (0.2004)	Acc@1 99.219 (96.652)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:36:30 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.150 (0.311)	Loss 0.2455 (0.2078)	Acc@1 92.188 (96.119)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:36:33 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.840 Acc@5 100.000
[2024-11-09 19:36:33 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:36:33 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.86%
[2024-11-09 19:36:36 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.463 (3.463)	Loss 0.1958 (0.1958)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:36:38 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.147 (0.501)	Loss 0.2037 (0.1987)	Acc@1 96.094 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:36:40 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.267 (0.380)	Loss 0.1930 (0.2086)	Acc@1 96.875 (95.573)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:36:43 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.136 (0.332)	Loss 0.2527 (0.2155)	Acc@1 92.188 (95.186)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:36:46 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.120 Acc@5 100.000
[2024-11-09 19:36:46 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:36:46 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.16%
[2024-11-09 19:36:52 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][0/156]	eta 0:14:44 lr 0.000001	 wd 0.0500	time 5.6726 (5.6726)	data time 5.1137 (5.1137)	model time 0.0000 (0.0000)	loss 0.5677 (0.5677)	grad_norm 2.1307 (2.1307)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:36:57 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][10/156]	eta 0:02:30 lr 0.000001	 wd 0.0500	time 0.6700 (1.0335)	data time 0.0226 (0.4732)	model time 0.0000 (0.0000)	loss 0.6120 (0.5432)	grad_norm 2.3383 (2.8399)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:02 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][20/156]	eta 0:01:46 lr 0.000001	 wd 0.0500	time 0.5686 (0.7840)	data time 0.0024 (0.2547)	model time 0.0000 (0.0000)	loss 0.6051 (0.5598)	grad_norm 2.2291 (2.7670)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:08 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][30/156]	eta 0:01:28 lr 0.000001	 wd 0.0500	time 0.4233 (0.7053)	data time 0.0176 (0.1828)	model time 0.0000 (0.0000)	loss 0.5858 (0.5418)	grad_norm 2.9916 (3.0402)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:12 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][40/156]	eta 0:01:14 lr 0.000001	 wd 0.0500	time 0.4182 (0.6451)	data time 0.0059 (0.1417)	model time 0.0000 (0.0000)	loss 0.5409 (0.5433)	grad_norm 3.1718 (3.1264)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:17 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][50/156]	eta 0:01:05 lr 0.000001	 wd 0.0500	time 0.5518 (0.6158)	data time 0.0186 (0.1163)	model time 0.0000 (0.0000)	loss 0.5715 (0.5442)	grad_norm 5.0403 (3.3050)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:22 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][60/156]	eta 0:00:57 lr 0.000001	 wd 0.0500	time 0.4753 (0.5947)	data time 0.0263 (0.1011)	model time 0.4490 (0.4631)	loss 0.6393 (0.5433)	grad_norm 3.7234 (3.2838)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:27 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][70/156]	eta 0:00:49 lr 0.000001	 wd 0.0500	time 0.5739 (0.5776)	data time 0.0145 (0.0882)	model time 0.5595 (0.4634)	loss 0.5129 (0.5385)	grad_norm 3.6557 (3.3472)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:32 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][80/156]	eta 0:00:43 lr 0.000001	 wd 0.0500	time 0.4853 (0.5697)	data time 0.0024 (0.0796)	model time 0.4830 (0.4742)	loss 0.6273 (0.5403)	grad_norm 2.9118 (3.3508)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:37 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][90/156]	eta 0:00:37 lr 0.000001	 wd 0.0500	time 0.4497 (0.5619)	data time 0.0175 (0.0721)	model time 0.4322 (0.4774)	loss 0.4788 (0.5399)	grad_norm 4.6300 (3.3435)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:42 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][100/156]	eta 0:00:31 lr 0.000001	 wd 0.0500	time 0.4427 (0.5569)	data time 0.0356 (0.0668)	model time 0.4071 (0.4805)	loss 0.5992 (0.5375)	grad_norm 3.9414 (3.4097)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:47 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][110/156]	eta 0:00:25 lr 0.000001	 wd 0.0500	time 0.4816 (0.5530)	data time 0.0218 (0.0623)	model time 0.4598 (0.4833)	loss 0.5311 (0.5404)	grad_norm 2.6401 (3.3976)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:52 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][120/156]	eta 0:00:19 lr 0.000001	 wd 0.0500	time 0.4529 (0.5472)	data time 0.0396 (0.0592)	model time 0.4132 (0.4797)	loss 0.4406 (0.5417)	grad_norm 4.6871 (3.3819)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:37:57 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][130/156]	eta 0:00:14 lr 0.000001	 wd 0.0500	time 0.5435 (0.5461)	data time 0.0048 (0.0556)	model time 0.5387 (0.4847)	loss 0.4350 (0.5382)	grad_norm 4.4754 (3.3934)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:38:02 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][140/156]	eta 0:00:08 lr 0.000001	 wd 0.0500	time 0.4818 (0.5413)	data time 0.0012 (0.0527)	model time 0.4807 (0.4824)	loss 0.6209 (0.5406)	grad_norm 1.6224 (3.4083)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:38:07 vssm1_tiny_0230s](training.py 201): INFO Train: [296/300][150/156]	eta 0:00:03 lr 0.000001	 wd 0.0500	time 0.4383 (0.5379)	data time 0.0005 (0.0494)	model time 0.4378 (0.4829)	loss 0.5225 (0.5414)	grad_norm 1.8872 (3.4177)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:38:10 vssm1_tiny_0230s](training.py 212): INFO EPOCH 296 training takes 0:01:24
[2024-11-09 19:38:10 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_296.pth saving......
[2024-11-09 19:38:10 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_296.pth saved !!!
[2024-11-09 19:38:12 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.687 (1.687)	Loss 0.1930 (0.1930)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:38:14 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.140 (0.334)	Loss 0.2021 (0.1945)	Acc@1 96.094 (96.804)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:38:17 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.187 (0.332)	Loss 0.1852 (0.2025)	Acc@1 99.219 (96.577)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:38:19 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.166 (0.296)	Loss 0.2429 (0.2085)	Acc@1 92.188 (96.119)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:38:21 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.880 Acc@5 100.000
[2024-11-09 19:38:21 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.9%
[2024-11-09 19:38:21 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.88%
[2024-11-09 19:38:25 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.883 (3.883)	Loss 0.1958 (0.1958)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:38:27 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.170 (0.571)	Loss 0.2037 (0.1986)	Acc@1 96.094 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:38:29 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.206 (0.374)	Loss 0.1926 (0.2085)	Acc@1 96.875 (95.573)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:38:31 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.707 (0.329)	Loss 0.2524 (0.2153)	Acc@1 92.188 (95.186)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:38:34 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.120 Acc@5 100.000
[2024-11-09 19:38:34 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:38:34 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.16%
[2024-11-09 19:38:39 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][0/156]	eta 0:14:36 lr 0.000001	 wd 0.0500	time 5.6163 (5.6163)	data time 5.1341 (5.1341)	model time 0.0000 (0.0000)	loss 0.5803 (0.5803)	grad_norm 2.3332 (2.3332)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:38:44 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][10/156]	eta 0:02:18 lr 0.000001	 wd 0.0500	time 0.4554 (0.9471)	data time 0.0057 (0.4760)	model time 0.0000 (0.0000)	loss 0.6091 (0.5848)	grad_norm 2.6743 (3.1411)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:38:49 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][20/156]	eta 0:01:37 lr 0.000001	 wd 0.0500	time 0.4091 (0.7181)	data time 0.0008 (0.2545)	model time 0.0000 (0.0000)	loss 0.4833 (0.5468)	grad_norm 4.2720 (3.1263)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:38:53 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][30/156]	eta 0:01:20 lr 0.000001	 wd 0.0500	time 0.4362 (0.6358)	data time 0.0177 (0.1779)	model time 0.0000 (0.0000)	loss 0.5152 (0.5504)	grad_norm 2.5596 (3.2269)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:38:58 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][40/156]	eta 0:01:09 lr 0.000001	 wd 0.0500	time 0.4910 (0.5950)	data time 0.0294 (0.1380)	model time 0.0000 (0.0000)	loss 0.4965 (0.5566)	grad_norm 1.9295 (3.1048)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:03 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][50/156]	eta 0:01:00 lr 0.000001	 wd 0.0500	time 0.4456 (0.5692)	data time 0.0116 (0.1136)	model time 0.0000 (0.0000)	loss 0.5431 (0.5487)	grad_norm 3.0739 (3.1865)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:08 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][60/156]	eta 0:00:53 lr 0.000001	 wd 0.0500	time 0.4834 (0.5585)	data time 0.0008 (0.0991)	model time 0.4826 (0.4782)	loss 0.5315 (0.5466)	grad_norm 3.4147 (3.2590)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:12 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][70/156]	eta 0:00:46 lr 0.000001	 wd 0.0500	time 0.5009 (0.5455)	data time 0.0200 (0.0868)	model time 0.4809 (0.4662)	loss 0.4760 (0.5484)	grad_norm 3.9881 (3.4106)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:17 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][80/156]	eta 0:00:40 lr 0.000001	 wd 0.0500	time 0.4881 (0.5381)	data time 0.0016 (0.0780)	model time 0.4865 (0.4674)	loss 0.4270 (0.5514)	grad_norm 2.7544 (3.4603)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:22 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][90/156]	eta 0:00:35 lr 0.000001	 wd 0.0500	time 0.4427 (0.5315)	data time 0.0052 (0.0709)	model time 0.4375 (0.4669)	loss 0.5928 (0.5499)	grad_norm 4.5999 (3.4662)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:26 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][100/156]	eta 0:00:29 lr 0.000001	 wd 0.0500	time 0.5188 (0.5239)	data time 0.0197 (0.0653)	model time 0.4991 (0.4617)	loss 0.4637 (0.5474)	grad_norm 1.9294 (3.4150)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:31 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][110/156]	eta 0:00:23 lr 0.000001	 wd 0.0500	time 0.4348 (0.5199)	data time 0.0008 (0.0610)	model time 0.4340 (0.4615)	loss 0.4588 (0.5452)	grad_norm 5.4013 (3.4044)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:36 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][120/156]	eta 0:00:18 lr 0.000001	 wd 0.0500	time 0.4752 (0.5199)	data time 0.0014 (0.0575)	model time 0.4738 (0.4672)	loss 0.5915 (0.5465)	grad_norm 2.2321 (3.3898)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:42 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][130/156]	eta 0:00:13 lr 0.000001	 wd 0.0500	time 0.5086 (0.5222)	data time 0.0040 (0.0542)	model time 0.5046 (0.4759)	loss 0.4657 (0.5467)	grad_norm 3.4801 (3.3664)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:47 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][140/156]	eta 0:00:08 lr 0.000001	 wd 0.0500	time 0.4774 (0.5178)	data time 0.0012 (0.0509)	model time 0.4762 (0.4733)	loss 0.5898 (0.5479)	grad_norm 4.9723 (3.3606)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:51 vssm1_tiny_0230s](training.py 201): INFO Train: [297/300][150/156]	eta 0:00:03 lr 0.000001	 wd 0.0500	time 0.4739 (0.5148)	data time 0.0005 (0.0476)	model time 0.4733 (0.4731)	loss 0.5939 (0.5449)	grad_norm 1.8736 (3.3706)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:39:54 vssm1_tiny_0230s](training.py 212): INFO EPOCH 297 training takes 0:01:20
[2024-11-09 19:39:54 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_297.pth saving......
[2024-11-09 19:39:55 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_297.pth saved !!!
[2024-11-09 19:39:57 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.316 (2.316)	Loss 0.1971 (0.1971)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:39:59 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.152 (0.410)	Loss 0.2067 (0.1985)	Acc@1 95.312 (96.591)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:40:02 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.339)	Loss 0.1833 (0.2062)	Acc@1 99.219 (96.354)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:40:04 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.185 (0.306)	Loss 0.2402 (0.2101)	Acc@1 92.188 (95.993)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:40:07 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.780 Acc@5 100.000
[2024-11-09 19:40:07 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:40:07 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.88%
[2024-11-09 19:40:10 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 3.039 (3.039)	Loss 0.1959 (0.1959)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:40:13 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.461 (0.570)	Loss 0.2040 (0.1987)	Acc@1 96.094 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:40:15 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.177 (0.398)	Loss 0.1923 (0.2086)	Acc@1 96.875 (95.610)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:40:18 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.138 (0.353)	Loss 0.2517 (0.2151)	Acc@1 92.188 (95.212)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:40:20 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.140 Acc@5 100.000
[2024-11-09 19:40:20 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:40:20 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.16%
[2024-11-09 19:40:23 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][0/156]	eta 0:08:20 lr 0.000001	 wd 0.0500	time 3.2070 (3.2070)	data time 2.5979 (2.5979)	model time 0.0000 (0.0000)	loss 0.5893 (0.5893)	grad_norm 3.3972 (3.3972)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:40:28 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][10/156]	eta 0:01:53 lr 0.000001	 wd 0.0500	time 0.4580 (0.7778)	data time 0.0031 (0.2536)	model time 0.0000 (0.0000)	loss 0.4596 (0.5270)	grad_norm 3.8340 (3.4536)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:40:33 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][20/156]	eta 0:01:27 lr 0.000001	 wd 0.0500	time 0.5694 (0.6424)	data time 0.0018 (0.1402)	model time 0.0000 (0.0000)	loss 0.4009 (0.5166)	grad_norm 4.6790 (3.6932)	loss_scale 65536.0000 (34328.3810)	mem 13675MB
[2024-11-09 19:40:38 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][30/156]	eta 0:01:13 lr 0.000001	 wd 0.0500	time 0.5349 (0.5847)	data time 0.0068 (0.0972)	model time 0.0000 (0.0000)	loss 0.5725 (0.5193)	grad_norm 3.3287 (3.7358)	loss_scale 65536.0000 (44395.3548)	mem 13675MB
[2024-11-09 19:40:43 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][40/156]	eta 0:01:04 lr 0.000001	 wd 0.0500	time 0.4083 (0.5588)	data time 0.0007 (0.0762)	model time 0.0000 (0.0000)	loss 0.5817 (0.5249)	grad_norm 2.5325 (3.5816)	loss_scale 65536.0000 (49551.6098)	mem 13675MB
[2024-11-09 19:40:48 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][50/156]	eta 0:00:57 lr 0.000001	 wd 0.0500	time 0.4461 (0.5411)	data time 0.0241 (0.0642)	model time 0.0000 (0.0000)	loss 0.6541 (0.5290)	grad_norm 3.6768 (3.5536)	loss_scale 65536.0000 (52685.8039)	mem 13675MB
[2024-11-09 19:40:52 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][60/156]	eta 0:00:51 lr 0.000001	 wd 0.0500	time 0.5685 (0.5333)	data time 0.0007 (0.0584)	model time 0.5678 (0.4652)	loss 0.6143 (0.5307)	grad_norm 2.1695 (3.4244)	loss_scale 65536.0000 (54792.3934)	mem 13675MB
[2024-11-09 19:40:58 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][70/156]	eta 0:00:45 lr 0.000001	 wd 0.0500	time 0.4391 (0.5332)	data time 0.0057 (0.0524)	model time 0.4334 (0.4910)	loss 0.3910 (0.5270)	grad_norm 4.8929 (3.3829)	loss_scale 65536.0000 (56305.5775)	mem 13675MB
[2024-11-09 19:41:02 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][80/156]	eta 0:00:39 lr 0.000001	 wd 0.0500	time 0.4445 (0.5239)	data time 0.0085 (0.0467)	model time 0.4359 (0.4778)	loss 0.4242 (0.5299)	grad_norm 2.9476 (3.3779)	loss_scale 65536.0000 (57445.1358)	mem 13675MB
[2024-11-09 19:41:07 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][90/156]	eta 0:00:34 lr 0.000001	 wd 0.0500	time 0.4641 (0.5160)	data time 0.0014 (0.0428)	model time 0.4627 (0.4684)	loss 0.5334 (0.5333)	grad_norm 3.5965 (3.3762)	loss_scale 65536.0000 (58334.2418)	mem 13675MB
[2024-11-09 19:41:12 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][100/156]	eta 0:00:28 lr 0.000001	 wd 0.0500	time 0.5812 (0.5132)	data time 0.0011 (0.0394)	model time 0.5801 (0.4707)	loss 0.5969 (0.5329)	grad_norm 4.0017 (inf)	loss_scale 32768.0000 (57425.1089)	mem 13675MB
[2024-11-09 19:41:17 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][110/156]	eta 0:00:23 lr 0.000001	 wd 0.0500	time 0.4908 (0.5163)	data time 0.0811 (0.0372)	model time 0.4097 (0.4809)	loss 0.4029 (0.5338)	grad_norm 4.1834 (inf)	loss_scale 32768.0000 (55203.7477)	mem 13675MB
[2024-11-09 19:41:22 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][120/156]	eta 0:00:18 lr 0.000001	 wd 0.0500	time 0.4602 (0.5107)	data time 0.0008 (0.0349)	model time 0.4594 (0.4750)	loss 0.5883 (0.5346)	grad_norm 2.9565 (inf)	loss_scale 32768.0000 (53349.5537)	mem 13675MB
[2024-11-09 19:41:26 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][130/156]	eta 0:00:13 lr 0.000001	 wd 0.0500	time 0.5174 (0.5065)	data time 0.0180 (0.0333)	model time 0.4994 (0.4710)	loss 0.4413 (0.5327)	grad_norm 4.8649 (inf)	loss_scale 32768.0000 (51778.4427)	mem 13675MB
[2024-11-09 19:41:31 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][140/156]	eta 0:00:08 lr 0.000001	 wd 0.0500	time 0.4458 (0.5062)	data time 0.0372 (0.0317)	model time 0.4086 (0.4731)	loss 0.5388 (0.5338)	grad_norm 4.3749 (inf)	loss_scale 32768.0000 (50430.1844)	mem 13675MB
[2024-11-09 19:41:36 vssm1_tiny_0230s](training.py 201): INFO Train: [298/300][150/156]	eta 0:00:03 lr 0.000001	 wd 0.0500	time 0.4287 (0.5041)	data time 0.0004 (0.0296)	model time 0.4282 (0.4732)	loss 0.5874 (0.5360)	grad_norm 3.1960 (inf)	loss_scale 32768.0000 (49260.5033)	mem 13675MB
[2024-11-09 19:41:39 vssm1_tiny_0230s](training.py 212): INFO EPOCH 298 training takes 0:01:18
[2024-11-09 19:41:39 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_298.pth saving......
[2024-11-09 19:41:39 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_298.pth saved !!!
[2024-11-09 19:41:42 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.745 (2.745)	Loss 0.1962 (0.1962)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:41:43 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.136 (0.396)	Loss 0.2062 (0.1977)	Acc@1 95.312 (96.520)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:41:45 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.134 (0.288)	Loss 0.1785 (0.2053)	Acc@1 99.219 (96.280)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:41:47 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.137 (0.253)	Loss 0.2358 (0.2082)	Acc@1 92.188 (95.968)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:41:49 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.780 Acc@5 100.000
[2024-11-09 19:41:49 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.8%
[2024-11-09 19:41:49 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.88%
[2024-11-09 19:41:52 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.945 (2.945)	Loss 0.1959 (0.1959)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:41:54 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.148 (0.424)	Loss 0.2040 (0.1986)	Acc@1 96.094 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:41:55 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.227 (0.300)	Loss 0.1923 (0.2084)	Acc@1 96.875 (95.647)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:41:57 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.156 (0.251)	Loss 0.2517 (0.2150)	Acc@1 92.188 (95.237)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:41:58 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.120 Acc@5 100.000
[2024-11-09 19:41:58 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:41:58 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.16%
[2024-11-09 19:42:01 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][0/156]	eta 0:07:26 lr 0.000001	 wd 0.0500	time 2.8606 (2.8606)	data time 2.4353 (2.4353)	model time 0.0000 (0.0000)	loss 0.5979 (0.5979)	grad_norm 4.2888 (4.2888)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:05 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][10/156]	eta 0:01:35 lr 0.000001	 wd 0.0500	time 0.4098 (0.6569)	data time 0.0005 (0.2245)	model time 0.0000 (0.0000)	loss 0.5163 (0.5410)	grad_norm 4.6456 (3.6201)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:10 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][20/156]	eta 0:01:15 lr 0.000001	 wd 0.0500	time 0.4697 (0.5579)	data time 0.0125 (0.1218)	model time 0.0000 (0.0000)	loss 0.4151 (0.5305)	grad_norm 3.8588 (3.4181)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:14 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][30/156]	eta 0:01:05 lr 0.000001	 wd 0.0500	time 0.4789 (0.5185)	data time 0.0007 (0.0832)	model time 0.0000 (0.0000)	loss 0.5084 (0.5378)	grad_norm 4.1412 (3.4454)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:19 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][40/156]	eta 0:00:57 lr 0.000001	 wd 0.0500	time 0.4300 (0.4976)	data time 0.0196 (0.0644)	model time 0.0000 (0.0000)	loss 0.4126 (0.5340)	grad_norm 6.6873 (3.5115)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:23 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][50/156]	eta 0:00:52 lr 0.000001	 wd 0.0500	time 0.5464 (0.4939)	data time 0.0155 (0.0533)	model time 0.0000 (0.0000)	loss 0.5259 (0.5321)	grad_norm 3.2507 (3.4494)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:29 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][60/156]	eta 0:00:47 lr 0.000001	 wd 0.0500	time 0.5184 (0.4986)	data time 0.0512 (0.0482)	model time 0.4672 (0.5005)	loss 0.3946 (0.5281)	grad_norm 5.5103 (3.4851)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:34 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][70/156]	eta 0:00:43 lr 0.000001	 wd 0.0500	time 0.6414 (0.5004)	data time 0.0023 (0.0440)	model time 0.6391 (0.4969)	loss 0.5773 (0.5301)	grad_norm 3.0031 (3.5590)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:38 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][80/156]	eta 0:00:37 lr 0.000001	 wd 0.0500	time 0.5249 (0.4948)	data time 0.0010 (0.0395)	model time 0.5239 (0.4806)	loss 0.5216 (0.5304)	grad_norm 1.5184 (3.5175)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:44 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][90/156]	eta 0:00:32 lr 0.000001	 wd 0.0500	time 0.4432 (0.4986)	data time 0.0153 (0.0369)	model time 0.4278 (0.4887)	loss 0.4188 (0.5277)	grad_norm 3.3584 (3.5623)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:49 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][100/156]	eta 0:00:28 lr 0.000001	 wd 0.0500	time 0.6944 (0.5012)	data time 0.0224 (0.0353)	model time 0.6720 (0.4919)	loss 0.4675 (0.5275)	grad_norm 3.5524 (3.5764)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:53 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][110/156]	eta 0:00:22 lr 0.000001	 wd 0.0500	time 0.4231 (0.4972)	data time 0.0007 (0.0331)	model time 0.4224 (0.4840)	loss 0.5825 (0.5253)	grad_norm 2.0566 (3.5499)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:42:58 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][120/156]	eta 0:00:17 lr 0.000001	 wd 0.0500	time 0.4561 (0.4959)	data time 0.0066 (0.0316)	model time 0.4495 (0.4817)	loss 0.6258 (0.5293)	grad_norm 2.1106 (3.4861)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:43:03 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][130/156]	eta 0:00:12 lr 0.000001	 wd 0.0500	time 0.4524 (0.4928)	data time 0.0006 (0.0296)	model time 0.4518 (0.4776)	loss 0.4989 (0.5314)	grad_norm 3.7387 (3.4982)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:43:07 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][140/156]	eta 0:00:07 lr 0.000001	 wd 0.0500	time 0.4257 (0.4908)	data time 0.0011 (0.0284)	model time 0.4246 (0.4748)	loss 0.5914 (0.5343)	grad_norm 3.5095 (3.4619)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:43:12 vssm1_tiny_0230s](training.py 201): INFO Train: [299/300][150/156]	eta 0:00:02 lr 0.000001	 wd 0.0500	time 0.4116 (0.4875)	data time 0.0005 (0.0266)	model time 0.4111 (0.4714)	loss 0.5490 (0.5354)	grad_norm 2.6957 (3.4225)	loss_scale 32768.0000 (32768.0000)	mem 13675MB
[2024-11-09 19:43:14 vssm1_tiny_0230s](training.py 212): INFO EPOCH 299 training takes 0:01:16
[2024-11-09 19:43:14 vssm1_tiny_0230s](utils.py 99): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_299.pth saving......
[2024-11-09 19:43:15 vssm1_tiny_0230s](utils.py 101): INFO /home/ntu/dql/project/output/training/vssm1_tiny_0230s/20241109103419/ckpt_epoch_299.pth saved !!!
[2024-11-09 19:43:17 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 2.479 (2.479)	Loss 0.1945 (0.1945)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:43:20 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.424)	Loss 0.2051 (0.1964)	Acc@1 95.312 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:43:21 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.196 (0.300)	Loss 0.1772 (0.2040)	Acc@1 99.219 (96.205)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:43:23 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.354 (0.257)	Loss 0.2347 (0.2074)	Acc@1 92.188 (95.867)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:43:26 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.740 Acc@5 100.000
[2024-11-09 19:43:26 vssm1_tiny_0230s](training.py 127): INFO Accuracy of the network on the 5000 test images: 95.7%
[2024-11-09 19:43:26 vssm1_tiny_0230s](training.py 129): INFO Max accuracy: 95.88%
[2024-11-09 19:43:27 vssm1_tiny_0230s](training.py 257): INFO Test: [0/40]	Time 1.620 (1.620)	Loss 0.1956 (0.1956)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:43:29 vssm1_tiny_0230s](training.py 257): INFO Test: [10/40]	Time 0.137 (0.302)	Loss 0.2036 (0.1983)	Acc@1 96.094 (96.449)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:43:32 vssm1_tiny_0230s](training.py 257): INFO Test: [20/40]	Time 0.138 (0.269)	Loss 0.1921 (0.2081)	Acc@1 96.875 (95.685)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:43:33 vssm1_tiny_0230s](training.py 257): INFO Test: [30/40]	Time 0.145 (0.233)	Loss 0.2517 (0.2148)	Acc@1 92.188 (95.237)	Acc@5 100.000 (100.000)	Mem 13675MB
[2024-11-09 19:43:35 vssm1_tiny_0230s](training.py 264): INFO  * Acc@1 95.120 Acc@5 100.000
[2024-11-09 19:43:35 vssm1_tiny_0230s](training.py 132): INFO Accuracy of the network on the 5000 test images: 95.1%
[2024-11-09 19:43:35 vssm1_tiny_0230s](training.py 134): INFO Max accuracy ema: 95.16%
[2024-11-09 19:43:35 vssm1_tiny_0230s](training.py 139): INFO Training time 9:08:54
[rank0]:[W1109 19:43:36.039454539 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
